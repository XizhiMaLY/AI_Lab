{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3293060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入相关模块\n",
    "import os \n",
    "import glob \n",
    "import time\n",
    "import subprocess \n",
    "import pickle\n",
    "import numpy as np\n",
    "from pickle import dump, load \n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as DataSet\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 读取作曲任务所需序列数据\n",
    "musicians = load(open('./data/musicians', 'rb'))\n",
    "namelist = load(open('./data/namelist', 'rb'))\n",
    "seqs = load(open('./data/seqs', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5f00425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "589"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "803f59bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始序列\n",
      "['2.5', '1.4', 'D2', '4.7', '2.5', 'D2', 'A3', 'G3', 'D2', 'B-3', 'A3', 'A3', 'D2', '2.5.9', '1.4.7', 'D2', '1.4.7.9', '2.5.9', 'D2', '2.5.9', '1.4.7.10', 'D2', '1.4.7.10', '2.5.9', '2.5.9', 'D2', 'D4', 'C#4', 'E4', 'C#3', 'D4', 'D3', 'D4', 'C#4', 'E4', 'C#4', 'D4', 'D4', 'D4', 'C4', 'B-3', 'A3', 'G3', 'A3', 'B-3', 'B3', 'A3', 'A2', 'A2', '2.5', '4.7', '5.9', 'A2', '4.7', '2.5', '1.4', 'A2', '2.5', '4.7', '2.5', 'A2', '10.2.5', '9.1.4', 'A2', '8.11.2', '9.1.4', 'A2', 'B-4', 'A4', 'G4', 'F4', 'E4', 'F4', 'G4', 'C4', 'F4', 'B-4', 'B-4', 'A4', 'G4', 'A4', 'B-4', 'B4', 'C5', 'C3', '0.4', '11.2', 'C3', '2.5', '0.4', '0.4', 'C3', '0.4.7', '5.8.0', 'C3', '5.8.0', '0.4.7', '0.4.7', 'C3']\n",
      "\n",
      " 编码后的结果\n",
      "[113, 150, 19, 155, 113, 19, 3, 2, 19, 22, 3, 3, 19, 89, 276, 19, 279, 89, 19, 89, 88, 19, 88, 89, 89, 19, 5, 48, 37, 77, 5, 4, 5, 48, 37, 48, 5, 5, 5, 10, 22, 3, 2, 3, 22, 78, 3, 45, 45, 113, 155, 56, 45, 155, 113, 150, 45, 113, 155, 113, 45, 58, 145, 45, 231, 145, 45, 29, 11, 15, 30, 37, 30, 15, 10, 30, 29, 29, 11, 15, 11, 29, 80, 28, 34, 156, 153, 34, 113, 156, 156, 34, 229, 110, 34, 110, 229, 229, 34]\n"
     ]
    }
   ],
   "source": [
    "# 定义序列编码函数\n",
    "def seq_encode(seqs):\n",
    "    seq2idx = {}\n",
    "    seqs_digit = []\n",
    "    \n",
    "    i = 1\n",
    "    for seq in seqs:\n",
    "        for s in seq:\n",
    "            if seq2idx.get(s) == None:\n",
    "                seq2idx[s] = i\n",
    "                i += 1\n",
    "                \n",
    "    for seq in seqs:\n",
    "        seq_digit = []\n",
    "        for s in seq:\n",
    "            seq_digit.append(seq2idx[s])\n",
    "        seqs_digit.append(seq_digit)\n",
    "    return seq2idx, seqs_digit\n",
    "\n",
    "seq2idx, seqs_digit = seq_encode(seqs)\n",
    "print(\"原始序列\")\n",
    "print(seqs[123][1:100])\n",
    "print(\"\\n 编码后的结果\")\n",
    "print(seqs_digit[123][1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a35343b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始序列\n",
      "['schubert', 'schubert', 'schubert', 'haydn', 'chopin', 'chopin', 'vivaldi', 'schumann', 'mendelsonn', 'schubert', 'schubert', 'schubert', 'schubert', 'schubert', 'schubert', 'mendelsonn', 'schubert', 'schubert', 'schubert', 'liszt']\n",
      "\n",
      " 编码后的结果\n",
      "[6, 6, 6, 7, 1, 1, 4, 0, 2, 6, 6, 6, 6, 6, 6, 2, 6, 6, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "### 定义音乐家姓名编码函数\n",
    "def musician_encode(namelist):\n",
    "    # 创建音乐家编码字典\n",
    "    name2idx = {}\n",
    "    i = 0\n",
    "    for name in namelist:\n",
    "        if name2idx.get(name) == None:\n",
    "                name2idx[name] = i\n",
    "                i += 1\n",
    "                \n",
    "    # 对音乐家列表进行编码\n",
    "    namelist_digit = []\n",
    "    for name in namelist:\n",
    "        namelist_digit.append(name2idx[name])\n",
    "    return name2idx, namelist_digit\n",
    "\n",
    "name2idx, namelist_digit = musician_encode(namelist)\n",
    "print(\"原始序列\")\n",
    "print(namelist[25:45])\n",
    "print(\"\\n 编码后的结果\")\n",
    "print(namelist_digit[25:45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a53a8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([589, 9])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将音乐家姓名编码转为one-hot形式\n",
    "namelist_digit = F.one_hot(torch.tensor(namelist_digit))\n",
    "namelist_digit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3949a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始乐曲（部分）: \n",
      "['2.5', '1.4', 'D2', '4.7', '2.5', 'D2', 'A3', 'G3', 'D2', 'B-3', 'A3', 'A3', 'D2', '2.5.9', '1.4.7', 'D2', '1.4.7.9', '2.5.9', 'D2', '2.5.9', '1.4.7.10', 'D2', '1.4.7.10', '2.5.9', '2.5.9', 'D2', 'D4', 'C#4', 'E4', 'C#3', 'D4', 'D3', 'D4', 'C#4', 'E4', 'C#4', 'D4', 'D4', 'D4', 'C4', 'B-3', 'A3', 'G3', 'A3', 'B-3', 'B3', 'A3', 'A2', 'A2']\n",
      "变量X（音符序列）: \n",
      "[24, 18, 2, 46, 31, 34, 31, 34, 15, 2, 36, 10, 36, 10, 41, 15, 63, 28, 41, 15, 36, 10, 36, 10, 15, 2, 31, 34, 31, 34, 2, 46, 4, 18, 71, 47, 5, 34, 5, 34, 69, 32, 27, 10, 27, 10, 60, 30, 104, 28, 60, 30, 27, 10, 27, 10, 69, 32, 5, 34, 5, 34, 71, 47, 32, 18, 10, 75, 30, 34, 30, 34, 28, 71, 33, 10, 33, 10, 70, 69, 62, 28, 70, 69, 33, 10, 33, 10, 28, 71, 30, 34, 30, 34, 10, 75, 24, 18, 2, 46, 31, 34, 31, 34, 15, 2, 36, 10, 36, 10, 41, 15, 63, 28, 41, 15, 36, 10, 36, 10, 15, 2, 31, 34, 31, 34, 2, 46, 4, 18, 71, 47, 5, 34, 5, 34, 69, 32, 27, 10, 27, 10, 60, 30, 104, 28, 60, 30, 27, 10, 27, 10, 69, 32, 5, 34, 5, 34, 71, 47, 24, 18, 71, 47, 31, 76, 31, 34, 69, 71, 36, 78, 36, 10, 60, 30, 63, 80, 60, 30, 36, 10, 36, 78, 69, 32, 31, 34, 31, 76, 71, 47, 34, 18, 24, 46, 10, 34, 10, 34, 31, 2, 28, 10, 31, 2, 10, 34, 31, 2, 29, 10, 31, 2, 10, 34, 31, 2, 69, 10, 31, 2, 10, 34, 5, 69, 2, 15, 78, 5, 2, 78, 34, 48, 2, 15, 22, 48, 2, 22, 34, 10, 32, 30, 3, 10, 32, 3, 34, 78, 32, 30, 71, 78, 32, 71, 34, 24, 18, 2, 46, 31, 34, 31, 34, 15, 2, 36, 10, 36, 10, 41, 15, 63, 28, 41, 15, 36, 10, 36, 10, 15, 2, 31, 34, 31, 34, 2, 46, 4, 18, 71, 47, 5, 34, 5, 34, 69, 32, 27, 10, 27, 10, 60, 30, 104, 28, 60, 30, 27, 10, 27, 10, 69, 32, 5, 34, 5, 34, 71, 47, 32, 18, 10, 75, 30, 34, 30, 34, 28, 71, 33, 10, 33, 10, 70, 69, 62, 28, 70, 69, 33, 10, 33, 10, 28, 71, 30, 34, 30, 34, 10, 75, 39, 18, 10, 46, 37, 34, 37, 34, 28, 2, 90, 10, 90, 10, 70, 15, 128, 28, 70, 15, 90, 10, 90, 10, 28, 2, 37, 34, 37, 34, 10, 46, 71, 47, 48, 77, 69, 32, 69, 32, 53, 48, 60, 30, 60, 30, 64, 53, 161, 33, 64, 53, 60, 30, 60, 30, 53, 48, 69, 32, 69, 32, 48, 77, 2, 46, 78, 4, 15, 32, 15, 2, 80, 5, 41, 30, 41, 15, 103, 80, 105, 33, 103, 80, 41, 15, 41, 30, 80, 5, 15, 2, 15, 4, 78, 46, 39, 18, 2, 46, 37, 34, 37, 34, 15, 2, 90, 10, 90, 10, 41, 15, 128, 28, 128, 28, 105, 41, 282, 70, 105, 41, 128, 28, 128, 28, 41, 15, 90, 10, 90, 10, 15, 2, 37, 34, 37, 34, 2, 46, 39, 18, 2, 46, 4, 76, 2, 46, 5, 18, 2, 46, 32, 4, 2, 46, 15, 18, 2, 46, 39, 18, 2, 46, 37, 34, 37, 34, 15, 2, 90, 10, 90, 10, 41, 15, 128, 28, 128, 28, 105, 41, 282, 70, 105, 41, 128, 28, 128, 28, 41, 15, 90, 10, 90, 10, 15, 2, 37, 34, 37, 34, 2, 46, 39, 18, 2, 46, 4, 76, 2, 46, 5, 18, 2, 46, 34, 45, 2, 46, 10, 18, 2, 46, 4, 18, 2, 46, 5, 76, 5, 76, 15, 2, 27, 78, 27, 10, 41, 15, 104, 80, 104, 28, 105, 41, 283, 103, 105, 41, 104, 28, 104, 80, 41, 15, 27, 10, 27, 78, 15, 2, 5, 34, 5, 76, 2, 46, 4, 18, 2, 46, 34, 45, 32, 47, 10, 18, 32, 47, 34, 45, 32, 47, 3, 18, 32, 47, 34, 18, 32, 75, 10, 34, 10, 34, 30, 71, 28, 10, 28, 10, 33, 69, 70, 28, 33, 69, 28, 10, 28, 10, 30, 71, 10, 34, 10, 34, 32, 75, 34, 18, 39, 46, 10, 34, 10, 34, 37, 2, 28, 10, 28, 10, 90, 15, 70, 28, 90, 15, 28, 10, 28, 10, 37, 2, 10, 34, 10, 34, 39, 46, 34, 244, 24, 21, 10, 75, 10, 75, 31, 24, 28, 71, 28, 71, 36, 31, 70, 69, 70, 69, 63, 36, 255, 60, 63, 36, 70, 69, 70, 69, 36, 31, 28, 71, 28, 71, 31, 24, 10, 75, 10, 75, 24, 21, 34, 244, 24, 21, 35, 46, 24, 21, 22, 244, 24, 21, 77, 35, 24, 21, 31, 244, 24, 21, 34, 244, 24, 21, 10, 75, 10, 75, 31, 24, 28, 71, 28, 71, 36, 31, 70, 69, 70, 69, 63, 36, 255, 60, 63, 36, 70, 69, 70, 69, 36, 31, 28, 71, 28, 71, 31, 24, 10, 75, 10, 75, 24, 21, 34, 244, 24, 21, 35, 46, 24, 21, 22, 244, 24, 21, 75, 47, 24, 21, 71, 244, 24, 21, 35, 244, 24, 21, 22, 46, 22, 75, 31, 24, 29, 2, 29, 71, 36, 31, 57, 15, 57, 69, 63, 36, 184, 41, 63, 36, 57, 69, 57, 15, 36, 31, 29, 71, 29, 2, 31, 24, 22, 75, 22, 46, 24, 21, 35, 244, 24, 21, 75, 47, 77, 40, 71, 244, 77, 40, 75, 47, 77, 40, 32, 244, 77, 40, 75, 244, 77, 49, 71, 75, 71, 75, 48, 39, 69, 71, 69, 71, 53, 37, 60, 69, 53, 37, 69, 71, 69, 71, 48, 39, 71, 75, 71, 75, 77, 49, 75, 244, 34, 21, 71, 75, 71, 75, 10, 24, 69, 71, 10, 24, 71, 75, 100, 244, 34, 19, 74, 75, 74, 75, 10, 4, 44, 71, 10, 4, 74, 75, 46, 1, 76, 19, 2, 46, 2, 46, 78, 4, 15, 2, 15, 2, 80, 5, 41, 15, 80, 5, 15, 2, 15, 2, 78, 4, 2, 46, 2, 46, 76, 19, 75, 1, 34, 21, 71, 46]\n",
      "变量X（作曲家）: \n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "变量Y: \n",
      "71\n"
     ]
    }
   ],
   "source": [
    "### 定义生成训练输入输出序列函数\n",
    "def generate_XY(seqs_digit, namelist, max_len):\n",
    "    X = []\n",
    "    Y = []\n",
    "    i = -1\n",
    "    for seq_digit in seqs_digit:\n",
    "        i += 1\n",
    "        if len(seq_digit) < 1:\n",
    "            continue\n",
    "\n",
    "        # 将每首乐曲的最后一个音符作为Y\n",
    "        Y.append(seq_digit[-1])\n",
    "        # 将最后一个音符之前的部分作为X，并补齐字符\n",
    "        x = seq_digit[:-1] + [0]*(max_len - len(seq_digit))\n",
    "        l = namelist_digit[i].tolist()\n",
    "        X.append(x+l)\n",
    "    # 将所有数据的顺序打乱重排\n",
    "    idx = np.random.permutation(range(len(X)))\n",
    "    X = [X[i] for i in idx]\n",
    "    Y = [Y[i] for i in idx]\n",
    "    return X, Y\n",
    "\n",
    "X, Y = generate_XY(seqs_digit, namelist, 1000)\n",
    "print(\"原始乐曲（部分）: \")\n",
    "print(seqs[123][1:50])\n",
    "print(\"变量X（音符序列）: \")\n",
    "print(X[123][0:999])\n",
    "print(\"变量X（作曲家）: \")\n",
    "print(X[123][-9:])\n",
    "print(\"变量Y: \")\n",
    "print(Y[123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4222bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设定batch size\n",
    "batch_size = 64\n",
    "# 创建Tensor形式的数据集\n",
    "ds = DataSet.TensorDataset(torch.IntTensor(np.array(X, dtype=int)), torch.IntTensor(np.array(Y, dtype=int)))\n",
    "# 形成数据集加载器\n",
    "loader = DataSet.DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc923cc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### 定义一个LSTM模型类\n",
    "class LSTMNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size, word_num, embedding_size, hidden_size, num_layers=1):\n",
    "        super(LSTMNetwork, self).__init__()\n",
    "        # 一个embedding层\n",
    "        self.embedding = nn.Embedding(word_num, embedding_size) \n",
    "        # PyTorch的LSTM层，batch_first标识可以让输入的张量的第一个维度表示batch指标\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, batch_first=True)\n",
    "        # 输出的全连接层\n",
    "        self.fc = nn.Linear(hidden_size, output_size) \n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.embedding_size = embedding_size\n",
    "    \n",
    "    ### 定义前向计算流程\n",
    "    def forward(self, x2, hidden):\n",
    "        # 先进行embedding层的计算\n",
    "        x = self.embedding(x2)\n",
    "        # 读入隐含层的初始信息\n",
    "        hh = hidden#[0]\n",
    "        # 从输入到隐含层的计算\n",
    "        # x的尺寸为：batch_size，num_step，hidden_size\n",
    "        output, hidden = self.lstm(x, hh)\n",
    "        # 从output中去除最后一个时间步的数值（output中包含了所有时间步的结果）\n",
    "        output = output[:, -1, ...]\n",
    "        # 最后一层全连接网络\n",
    "        output = self.fc(output)\n",
    "        # output的尺寸为：batch_size，output_size\n",
    "        return output\n",
    "    \n",
    "    ### 对隐含单元初始化\n",
    "    def initHidden(self, x1, x1_size, batch_size):\n",
    "        x = self.embedding(x1).cuda()     \n",
    "        # 初始化的隐藏元和记忆元,通常它们的维度是一样的\n",
    "        h1 = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size)).cuda()\n",
    "        c1 = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size)).cuda()\n",
    "        # 这里我们要对后面的LSTM模型的隐藏状态进行条件初始化\n",
    "        # 需要借助一个LSTM来获得其在对应音乐家特征向量输入下输出的隐藏状态\n",
    "        _, out = self.lstm(x, (h1, c1)) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "086d2eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMNetwork(\n",
      "  (embedding): Embedding(732, 256)\n",
      "  (lstm): LSTM(256, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=732, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 获取数据集包含的音符数量\n",
    "seq_size = len(seq2idx.keys())+1\n",
    "# 设定学习率和训练轮数\n",
    "lr = 1e-2\n",
    "epochs = 50\n",
    "# 序列最大长度\n",
    "max_len = 1000\n",
    "# 生成一个简单的LSTM，输入size为999，输出size为seq_size（字符总数）\n",
    "lstm = LSTMNetwork(input_size=max_len-1, output_size=seq_size, word_num=seq_size, embedding_size=256, hidden_size=128)\n",
    "# 转为GPU下的模型\n",
    "lstm = lstm.cuda()\n",
    "#交叉熵损失函数\n",
    "criterion = torch.nn.CrossEntropyLoss() \n",
    "#Adam优化算法\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=lr) \n",
    "#查看模型具体信息\n",
    "print(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dfa9f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 定义预测准确率的函数\n",
    "def accuracy(pre, label):\n",
    "    #得到每一行（每一个样本）输出值最大元素的下标\n",
    "    pre = torch.max(pre.data, 1)[1]\n",
    "    #将下标与label比较，计算正确的数量\n",
    "    rights = pre.eq(label.data).sum()\n",
    "    #计算正确预测所占百分比\n",
    "    acc = rights.data / len(label)\n",
    "    return acc.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "015f7759",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 定义一个tensor分割函数\n",
    "def split_x1_x2(x):\n",
    "    x = x.tolist()\n",
    "    x1 = [x[i][0:999] for i in range(len(x))]\n",
    "    x2 = [x[i][-9:] for i in range(len(x))]\n",
    "    x1 = torch.IntTensor(np.array(x1, dtype=int))\n",
    "    x2 = torch.IntTensor(np.array(x2, dtype=int))\n",
    "    return Variable(x1).cuda(), Variable(x2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77bbfdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义打印日志函数\n",
    "def print_log(epoch, train_time, train_loss, train_acc, epochs=10):\n",
    "    print(f\"Epoch [{epoch}/{epochs}], time: {train_time:.2f}s, loss: {train_loss:.4f}, acc: {train_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d71a293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 定义模型训练函数\n",
    "def train(model,optimizer, train_loader, epochs=1):\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        model.train() \n",
    "        # 记录当前epoch开始时间\n",
    "        start = time.time()  \n",
    "        for batch, data in enumerate(train_loader):\n",
    "            # batch为数字，表示已经进行了几个batch\n",
    "            # data为一个二元组，存储了一个样本的输入和标签\n",
    "            x, y = Variable(data[0]), Variable(data[1])\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            x1, x2 = split_x1_x2(x)\n",
    "            init_hidden = model.initHidden(x2, 9, len(data[0]))\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x1, init_hidden)\n",
    "            y = y.long()\n",
    "            # 计算当前损失\n",
    "            loss = criterion(outputs, y) \n",
    "            train_loss += loss.data.cpu().numpy()  \n",
    "            train_acc += accuracy(outputs, y) \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "            \n",
    "        # 记录当前epoch结束时间\n",
    "        end = time.time()  \n",
    "        # 计算当前epoch的训练耗时 \n",
    "        train_time = end - start\n",
    "        # 计算平均损失\n",
    "        train_loss /= len(train_loader) \n",
    "        # 计算平均准确率 \n",
    "        train_acc /= len(train_loader)              \n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        # 打印训练过程信息\n",
    "        print_log(epoch + 1, train_time, train_loss, train_acc, epochs=epochs)  \n",
    "\n",
    "    return train_losses, train_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7847ed70",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], time: 0.61s, loss: 6.0757, acc: 0.0122\n",
      "Epoch [2/50], time: 0.21s, loss: 4.4390, acc: 0.0874\n",
      "Epoch [3/50], time: 0.23s, loss: 3.5908, acc: 0.2727\n",
      "Epoch [4/50], time: 0.23s, loss: 2.8582, acc: 0.4361\n",
      "Epoch [5/50], time: 0.21s, loss: 2.4330, acc: 0.5264\n",
      "Epoch [6/50], time: 0.21s, loss: 2.2569, acc: 0.5383\n",
      "Epoch [7/50], time: 0.21s, loss: 2.2053, acc: 0.5432\n",
      "Epoch [8/50], time: 0.20s, loss: 2.1686, acc: 0.5354\n",
      "Epoch [9/50], time: 0.22s, loss: 2.1604, acc: 0.5453\n",
      "Epoch [10/50], time: 0.21s, loss: 2.1625, acc: 0.5412\n",
      "Epoch [11/50], time: 0.22s, loss: 2.1451, acc: 0.5387\n",
      "Epoch [12/50], time: 0.22s, loss: 2.1481, acc: 0.5403\n",
      "Epoch [13/50], time: 0.21s, loss: 2.1353, acc: 0.5448\n",
      "Epoch [14/50], time: 0.21s, loss: 2.1066, acc: 0.5385\n",
      "Epoch [15/50], time: 0.21s, loss: 2.0903, acc: 0.5466\n",
      "Epoch [16/50], time: 0.22s, loss: 2.0687, acc: 0.5538\n",
      "Epoch [17/50], time: 0.22s, loss: 2.0369, acc: 0.5464\n",
      "Epoch [18/50], time: 0.21s, loss: 2.0260, acc: 0.5594\n",
      "Epoch [19/50], time: 0.22s, loss: 2.0237, acc: 0.5516\n",
      "Epoch [20/50], time: 0.20s, loss: 2.0139, acc: 0.5499\n",
      "Epoch [21/50], time: 0.22s, loss: 1.9934, acc: 0.5438\n",
      "Epoch [22/50], time: 0.20s, loss: 2.0010, acc: 0.5436\n",
      "Epoch [23/50], time: 0.21s, loss: 2.0065, acc: 0.5519\n",
      "Epoch [24/50], time: 0.22s, loss: 1.9955, acc: 0.5557\n",
      "Epoch [25/50], time: 0.19s, loss: 1.9841, acc: 0.5557\n",
      "Epoch [26/50], time: 0.19s, loss: 1.9707, acc: 0.5473\n",
      "Epoch [27/50], time: 0.22s, loss: 1.9551, acc: 0.5590\n",
      "Epoch [28/50], time: 0.20s, loss: 1.9447, acc: 0.5581\n",
      "Epoch [29/50], time: 0.20s, loss: 1.9465, acc: 0.5485\n",
      "Epoch [30/50], time: 0.22s, loss: 1.9323, acc: 0.5596\n",
      "Epoch [31/50], time: 0.23s, loss: 1.9241, acc: 0.5527\n",
      "Epoch [32/50], time: 0.21s, loss: 1.9344, acc: 0.5453\n",
      "Epoch [33/50], time: 0.20s, loss: 1.9188, acc: 0.5525\n",
      "Epoch [34/50], time: 0.21s, loss: 1.9138, acc: 0.5520\n",
      "Epoch [35/50], time: 0.20s, loss: 1.9093, acc: 0.5591\n",
      "Epoch [36/50], time: 0.21s, loss: 1.9068, acc: 0.5609\n",
      "Epoch [37/50], time: 0.21s, loss: 1.9135, acc: 0.5535\n",
      "Epoch [38/50], time: 0.20s, loss: 1.9042, acc: 0.5469\n",
      "Epoch [39/50], time: 0.24s, loss: 1.8971, acc: 0.5472\n",
      "Epoch [40/50], time: 0.20s, loss: 1.8921, acc: 0.5557\n",
      "Epoch [41/50], time: 0.20s, loss: 1.8835, acc: 0.5597\n",
      "Epoch [42/50], time: 0.22s, loss: 1.8878, acc: 0.5542\n",
      "Epoch [43/50], time: 0.22s, loss: 1.8887, acc: 0.5457\n",
      "Epoch [44/50], time: 0.20s, loss: 1.8837, acc: 0.5588\n",
      "Epoch [45/50], time: 0.20s, loss: 1.8733, acc: 0.5618\n",
      "Epoch [46/50], time: 0.21s, loss: 1.8778, acc: 0.5529\n",
      "Epoch [47/50], time: 0.21s, loss: 1.8748, acc: 0.5544\n",
      "Epoch [48/50], time: 0.19s, loss: 1.8778, acc: 0.5589\n",
      "Epoch [49/50], time: 0.21s, loss: 1.8704, acc: 0.5613\n",
      "Epoch [50/50], time: 0.19s, loss: 1.8672, acc: 0.5595\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "history = train(lstm, optimizer, loader, epochs=epochs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc908eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 生成指定音乐家的音乐\n",
    "# 导入随机模块\n",
    "import random\n",
    "# 指定音乐家\n",
    "musicianname = 'beethoven'\n",
    "# 获得指定音乐家的数字序号\n",
    "name_digit = name2idx[musicianname]\n",
    "# 将指定音乐家变为输入的one-hot向量\n",
    "name_digit = F.one_hot(torch.tensor(name_digit), num_classes=9)\n",
    "# 用于存储后续模型输入的初始部分音乐序列\n",
    "input_index = []\n",
    "#随机抽取所选音乐家的一段已有乐曲用于后续辅助\n",
    "for i in range(len(seqs)):\n",
    "    if namelist[i] == musicianname:\n",
    "        temp = seqs_digit[i][0:20]\n",
    "        vocab = list(seqs_digit[i])\n",
    "        if random.random() > 0.5:\n",
    "            input_index = seqs_digit[i][0:20]\n",
    "            vocab = list(seqs_digit[i])\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "if len(input_index) == 0:\n",
    "    input_index = temp\n",
    "\n",
    "input_index = list(input_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d0ba789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '10.3', 'B-2', 'B-2', 'B-2', 'B-2', 'B-2', 'B-2', 'B-2', 'B-2', 'B-2', 'B-2', 'B-2', 'B-2', 'B-2', 'B-2', 'B-2', 'B-2', 'B-2', 'B-2', 'B-2', 'B-2', 'B-2', 'B-2', 'B-2', '5.10', '5.10', '0.3.7', '0.3.7', '0.3.7', '0.3.7', '0.3.7', '0.3.7', '0.3.7', '0.3.7', '0.3.7', '0.3.7', '0.3.7', '0.3.7', '0.3.7', '0.3.7', '0.3.7', '0.3.7', '0.3.7', '0.3.7', '0.3.7', '0.3.7', '0.3.7', '0.3.7', 'G#1', 'F1', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', 'A3', '5.8.0', '5.8.0', '5.8.0', '5.8.0', '5.8.0', '5.8.0', '5.8.0', '5.8.0', '5.8.0', '5.8.0', '5.8.0', '5.8.0', '5.8.0', '5.8.0', '5.8.0', '5.8.0', '5.8.0', '5.8.0', '5.8.0', '5.8.0', '5.8.0', '5.8.0', '5.8.0', 'A3', 'A3', 'G#5', '5', '5.8.0', '0.5', '0.5', '7.11.2', '7.11.2', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', 'A3', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'E3', 'G4', 'G4', 'E3', 'G4', 'G4', 'E3', 'G4', 'G4', 'E3', 'G4', 'G4', 'E3', 'G4', 'G4', 'E3', 'G4', 'G4', 'E3', 'G4', 'G4', 'E3', 'A2', 'A2', 'D3', 'B-3', 'C#2', 'C#2', 'G2', 'D3', 'G2', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', 'F1', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', 'F1', 'F1', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'G#1', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '0.4.7', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', '7', 'C3', 'E1', 'C3', 'C3', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', '7.11.2', '7.11.2', '7.11.2', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', '8.1', 'C3', 'C3', 'F1', '7.11.2', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '7.11.2', 'F1', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', '9.2', 'C#4', 'B5', 'C#4', 'C#4', 'C#4', 'C#4', 'C#4', 'C#4', 'C#4', 'C#4', 'C#4', 'C#2', 'G5', 'G5', 'C#2', 'C#2', 'C#2', 'D3', 'G2', 'G2', 'E3', 'G4', 'G4', 'G4']\n"
     ]
    }
   ],
   "source": [
    "### 模型预测生成音乐的过程\n",
    "# 用于存储输出的乐曲序列\n",
    "output_word = []\n",
    "# 指定要生成的乐曲长度\n",
    "length = 500 \n",
    "for i in range(length):\n",
    "    # 由于乐曲序列往往较长，随着预测长度边长，可能会出现信息缺失导致预测效果变差（如重复的旋律等）\n",
    "    # 所以每间隔一段距离在此在输入序列中加入一定辅助乐曲片段作为补充信息\n",
    "    if i % 25 == 0:\n",
    "        indexs = list(random.sample(vocab, 5))\n",
    "        input_index.extend(indexs)\n",
    "    else:\n",
    "        # 预测过程与作诗模型就比较相像了\n",
    "        # 用经预测出的乐曲序列作为输入预测下一个音符存入输出序列中\n",
    "        # 同时每预测出一个音符也要对输入序列进行更新\n",
    "        # 将当前字符与之前的字符拼接形成新的输入序列\n",
    "        x1 = input_index + [0]*(max_len - 1 - len(input_index)) \n",
    "        x1 = [int(i.cpu()) if type(i) != int else i for i in x1]\n",
    "        x1 = torch.IntTensor(np.array([x1], dtype=int))\n",
    "        x1 = Variable(x1).cuda()\n",
    "\n",
    "        x2 = torch.IntTensor(np.array([name_digit.tolist()], dtype=int))\n",
    "        x2 = Variable(x2).cuda()\n",
    "        init_hidden = lstm.initHidden(x2, 9, 1)\n",
    "        pre = lstm(x1, init_hidden)\n",
    "        # 提取最大概率的字符所在的位置，记录其编号\n",
    "        index = torch.argmax(pre) \n",
    "        # 提取上述编号所对应的字符\n",
    "        current_word = [k for k, v in seq2idx.items() if v == index][0] \n",
    "        # 将其存入输出序列\n",
    "        output_word.append(current_word)   \n",
    "        # 同时对输入序列也要更新\n",
    "        input_index.append(index)\n",
    "\n",
    "# 最后展示一下预测出的完整的乐曲序列\n",
    "print(output_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d55b82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 定义生成音乐函数\n",
    "def seq_to_mid(prediction):\n",
    "    # 偏移累积量，防止数据覆盖\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    # 将预测的乐曲序列中的每一个音符符号转换生成对应的Note或chord对象\n",
    "    for data in prediction:\n",
    "        # 如果是和弦chord：列如45.21.78\n",
    "        # data中有.或者有数字\n",
    "        if ('.' in data) or data.isdigit():\n",
    "            # 用.分隔和弦中的每个音\n",
    "            note_in_chord = data.split('.')\n",
    "            # notes列表接收单音\n",
    "            notes = []\n",
    "            for current_note in note_in_chord:\n",
    "                # 把当前音符化成整数，在对应midi_number转换成note\n",
    "                new_note = note.Note(int(current_note))\n",
    "                # 乐器使用钢琴\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            # 再把notes中的音化成新的和弦\n",
    "            new_chord = chord.Chord(notes)\n",
    "            # 初试定的偏移给和弦的偏移\n",
    "            new_chord.offset = offset\n",
    "            # 把转化好的new_chord弦传到output_notes中\n",
    "            output_notes.append(new_chord)\n",
    "        # 是音符note：\n",
    "        else:\n",
    "            # note直接可以把data变成新的note\n",
    "            new_note = note.Note(data)\n",
    "            new_note.offset = offset\n",
    "            # 乐器用钢琴\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            # 把new_note传到output_notes中\n",
    "            output_notes.append(new_note)\n",
    "        # 每次迭代都将偏移增加，防止交叠覆盖\n",
    "        offset += 0.5\n",
    "    # 将上述转化好的output_notes传到外层的流stream\n",
    "    # 注由于我们只涉及了钢琴一种乐器所以这里stream只由一个part构成即可\n",
    "    # 把上面的循环输出结果传到流\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    # 将流stream写入midi文件\n",
    "    # 最终输出的文件名是output.mid，格式是mid\n",
    "    midi_stream.write('midi', fp='output.mid')\n",
    "    \n",
    "# 调用函数将输出的音乐列转为midi格式文件存储\n",
    "seq_to_mid(output_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05fc950",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cops3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
