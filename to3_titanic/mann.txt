2024-03-28 17:25:12,874 - config - INFO - resume: None
2024-03-28 17:25:12,874 - config - INFO - device: cpu
2024-03-28 17:25:12,874 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-28 17:25:12,874 - config - INFO - learning_rate: 0.001
2024-03-28 17:25:12,874 - config - INFO - num_epochs: 20
2024-03-28 17:25:12,874 - config - INFO - batch_size: 64
2024-03-28 17:25:12,874 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = None
        self.prev_val_loss = float('inf')

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 17:25:12,887 - config - INFO - Dataset size: 891
2024-03-28 17:25:12,911 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.6 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = val_loss
            return False


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.eval()
    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 17:25:12,911 - config - INFO - Training start
2024-03-28 17:25:15,306 - config - INFO - Epoch [1/20], Train Loss: 0.6922
2024-03-28 17:25:15,335 - config - INFO - Epoch [2/20], Train Loss: 0.6580
2024-03-28 17:25:15,363 - config - INFO - Epoch [3/20], Train Loss: 0.6189
2024-03-28 17:25:15,386 - config - INFO - Epoch [4/20], Train Loss: 0.5950
2024-03-28 17:25:15,409 - config - INFO - Epoch [5/20], Train Loss: 0.5662
2024-03-28 17:25:15,431 - config - INFO - Epoch [6/20], Train Loss: 0.5448
2024-03-28 17:25:15,453 - config - INFO - Epoch [7/20], Train Loss: 0.5248
2024-03-28 17:41:21,094 - config - INFO - resume: None
2024-03-28 17:41:21,094 - config - INFO - device: cpu
2024-03-28 17:41:21,094 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-28 17:41:21,094 - config - INFO - learning_rate: 0.001
2024-03-28 17:41:21,094 - config - INFO - num_epochs: 20
2024-03-28 17:41:21,094 - config - INFO - batch_size: 64
2024-03-28 17:41:21,094 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = None
        self.prev_val_loss = float('inf')

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 17:41:21,107 - config - INFO - Dataset size: 891
2024-03-28 17:41:21,128 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.6 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = val_loss
            return False


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.eval()
    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 17:41:21,128 - config - INFO - Training start
2024-03-28 17:41:23,432 - config - INFO - Epoch [1/20], Train Loss: 0.6892
2024-03-28 17:41:23,458 - config - INFO - Epoch [2/20], Train Loss: 0.6634
2024-03-28 17:41:23,483 - config - INFO - Epoch [3/20], Train Loss: 0.6491
2024-03-28 17:41:23,507 - config - INFO - Epoch [4/20], Train Loss: 0.6351
2024-03-28 17:41:23,532 - config - INFO - Epoch [5/20], Train Loss: 0.6208
2024-03-28 17:41:23,555 - config - INFO - Epoch [6/20], Train Loss: 0.6077
2024-03-28 17:41:23,579 - config - INFO - Epoch [7/20], Train Loss: 0.5951
2024-03-28 17:41:23,603 - config - INFO - Epoch [8/20], Train Loss: 0.5839
2024-03-28 17:41:23,626 - config - INFO - Epoch [9/20], Train Loss: 0.5730
2024-03-28 17:41:23,650 - config - INFO - Epoch [10/20], Train Loss: 0.5603
2024-03-28 17:41:23,674 - config - INFO - Epoch [11/20], Train Loss: 0.5516
2024-03-28 17:41:23,697 - config - INFO - Epoch [12/20], Train Loss: 0.5399
2024-03-28 17:41:23,719 - config - INFO - Epoch [13/20], Train Loss: 0.5307
2024-03-28 17:41:23,742 - config - INFO - Epoch [14/20], Train Loss: 0.5227
2024-03-28 17:41:23,765 - config - INFO - Epoch [15/20], Train Loss: 0.5139
2024-03-28 17:41:23,788 - config - INFO - Epoch [16/20], Train Loss: 0.5056
2024-03-28 17:41:23,811 - config - INFO - Epoch [17/20], Train Loss: 0.4987
2024-03-28 17:41:23,833 - config - INFO - Epoch [18/20], Train Loss: 0.4917
2024-03-28 17:41:23,855 - config - INFO - Epoch [19/20], Train Loss: 0.4866
2024-03-28 17:41:23,877 - config - INFO - Epoch [20/20], Train Loss: 0.4808
2024-03-28 17:41:23,882 - config - INFO - Validation Loss: 0.4618
2024-03-28 17:42:07,079 - config - INFO - resume: None
2024-03-28 17:42:07,079 - config - INFO - device: cpu
2024-03-28 17:42:07,079 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-28 17:42:07,079 - config - INFO - learning_rate: 0.001
2024-03-28 17:42:07,079 - config - INFO - num_epochs: 20
2024-03-28 17:42:07,079 - config - INFO - batch_size: 64
2024-03-28 17:42:07,079 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = None
        self.prev_val_loss = float('inf')

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 17:42:07,092 - config - INFO - Dataset size: 891
2024-03-28 17:42:07,119 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.6 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = val_loss
            return False


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.eval()
    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 17:42:07,119 - config - INFO - Training start
2024-03-28 17:42:09,373 - config - INFO - Epoch [1/20], Train Loss: 0.7039
2024-03-28 17:42:09,397 - config - INFO - Epoch [2/20], Train Loss: 0.6759
2024-03-28 17:42:09,427 - config - INFO - Epoch [3/20], Train Loss: 0.6624
2024-03-28 17:42:09,448 - config - INFO - Epoch [4/20], Train Loss: 0.6540
2024-03-28 17:42:09,468 - config - INFO - Epoch [5/20], Train Loss: 0.6479
2024-03-28 17:42:09,487 - config - INFO - Epoch [6/20], Train Loss: 0.6405
2024-03-28 17:42:09,507 - config - INFO - Epoch [7/20], Train Loss: 0.6338
2024-03-28 17:42:09,527 - config - INFO - Epoch [8/20], Train Loss: 0.6272
2024-03-28 17:42:09,546 - config - INFO - Epoch [9/20], Train Loss: 0.6205
2024-03-28 17:42:09,566 - config - INFO - Epoch [10/20], Train Loss: 0.6137
2024-03-28 17:42:09,586 - config - INFO - Epoch [11/20], Train Loss: 0.6070
2024-03-28 17:42:09,612 - config - INFO - Epoch [12/20], Train Loss: 0.5999
2024-03-28 17:42:09,631 - config - INFO - Epoch [13/20], Train Loss: 0.5928
2024-03-28 17:42:09,651 - config - INFO - Epoch [14/20], Train Loss: 0.5855
2024-03-28 17:42:09,670 - config - INFO - Epoch [15/20], Train Loss: 0.5784
2024-03-28 17:42:09,690 - config - INFO - Epoch [16/20], Train Loss: 0.5710
2024-03-28 17:42:09,709 - config - INFO - Epoch [17/20], Train Loss: 0.5640
2024-03-28 17:42:09,729 - config - INFO - Epoch [18/20], Train Loss: 0.5569
2024-03-28 17:42:09,745 - config - INFO - Epoch [19/20], Train Loss: 0.5498
2024-03-28 17:42:09,761 - config - INFO - Epoch [20/20], Train Loss: 0.5430
2024-03-28 17:42:09,765 - config - INFO - Validation Loss: 0.5781
2024-03-28 17:52:11,850 - config - INFO - resume: None
2024-03-28 17:52:11,851 - config - INFO - device: cpu
2024-03-28 17:52:11,851 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-28 17:52:11,851 - config - INFO - learning_rate: 0.001
2024-03-28 17:52:11,851 - config - INFO - num_epochs: 200
2024-03-28 17:52:11,851 - config - INFO - batch_size: 64
2024-03-28 17:52:11,851 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = None
        self.prev_val_loss = float('inf')

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 17:52:11,864 - config - INFO - Dataset size: 891
2024-03-28 17:52:11,891 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.6 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = val_loss
            return False


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()

    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 17:52:11,891 - config - INFO - Training start
2024-03-28 17:52:14,275 - config - INFO - Epoch [1/200], Train Loss: 0.7047
2024-03-28 17:52:14,282 - config - INFO - Validation Loss: 0.6630
2024-03-28 17:52:14,307 - config - INFO - Epoch [2/200], Train Loss: 0.6406
2024-03-28 17:52:14,312 - config - INFO - Validation Loss: 0.6571
2024-03-28 17:52:14,335 - config - INFO - Epoch [3/200], Train Loss: 0.6268
2024-03-28 17:52:14,340 - config - INFO - Validation Loss: 0.6585
2024-03-28 17:52:14,340 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 17:55:46,868 - config - INFO - resume: None
2024-03-28 17:55:46,868 - config - INFO - device: cpu
2024-03-28 17:55:46,868 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-28 17:55:46,868 - config - INFO - learning_rate: 0.001
2024-03-28 17:55:46,868 - config - INFO - num_epochs: 200
2024-03-28 17:55:46,868 - config - INFO - batch_size: 64
2024-03-28 17:55:46,868 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = None
        self.prev_val_loss = float('inf')
        self.tolerance = 0.1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 17:55:46,881 - config - INFO - Dataset size: 891
2024-03-28 17:55:46,907 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.6 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = val_loss
            return False


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()

    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 17:55:46,907 - config - INFO - Training start
2024-03-28 17:55:49,192 - config - INFO - Epoch [1/200], Train Loss: 0.7655
2024-03-28 17:55:49,200 - config - INFO - Validation Loss: 0.7026
2024-03-28 17:55:49,223 - config - INFO - Epoch [2/200], Train Loss: 0.6755
2024-03-28 17:55:49,228 - config - INFO - Validation Loss: 0.6570
2024-03-28 17:55:49,251 - config - INFO - Epoch [3/200], Train Loss: 0.6474
2024-03-28 17:55:49,255 - config - INFO - Validation Loss: 0.6477
2024-03-28 17:55:49,278 - config - INFO - Epoch [4/200], Train Loss: 0.6410
2024-03-28 17:55:49,284 - config - INFO - Validation Loss: 0.6407
2024-03-28 17:55:49,311 - config - INFO - Epoch [5/200], Train Loss: 0.6294
2024-03-28 17:55:49,315 - config - INFO - Validation Loss: 0.6290
2024-03-28 17:55:49,336 - config - INFO - Epoch [6/200], Train Loss: 0.6172
2024-03-28 17:55:49,340 - config - INFO - Validation Loss: 0.6187
2024-03-28 17:55:49,361 - config - INFO - Epoch [7/200], Train Loss: 0.6069
2024-03-28 17:55:49,365 - config - INFO - Validation Loss: 0.6104
2024-03-28 17:55:49,386 - config - INFO - Epoch [8/200], Train Loss: 0.5967
2024-03-28 17:55:49,390 - config - INFO - Validation Loss: 0.6012
2024-03-28 17:55:49,410 - config - INFO - Epoch [9/200], Train Loss: 0.5862
2024-03-28 17:55:49,415 - config - INFO - Validation Loss: 0.5926
2024-03-28 17:55:49,436 - config - INFO - Epoch [10/200], Train Loss: 0.5769
2024-03-28 17:55:49,440 - config - INFO - Validation Loss: 0.5844
2024-03-28 17:55:49,461 - config - INFO - Epoch [11/200], Train Loss: 0.5678
2024-03-28 17:55:49,465 - config - INFO - Validation Loss: 0.5757
2024-03-28 17:55:49,486 - config - INFO - Epoch [12/200], Train Loss: 0.5577
2024-03-28 17:55:49,490 - config - INFO - Validation Loss: 0.5670
2024-03-28 17:55:49,510 - config - INFO - Epoch [13/200], Train Loss: 0.5486
2024-03-28 17:55:49,514 - config - INFO - Validation Loss: 0.5588
2024-03-28 17:55:49,533 - config - INFO - Epoch [14/200], Train Loss: 0.5397
2024-03-28 17:55:49,538 - config - INFO - Validation Loss: 0.5512
2024-03-28 17:55:49,557 - config - INFO - Epoch [15/200], Train Loss: 0.5311
2024-03-28 17:55:49,561 - config - INFO - Validation Loss: 0.5443
2024-03-28 17:55:49,580 - config - INFO - Epoch [16/200], Train Loss: 0.5233
2024-03-28 17:55:49,585 - config - INFO - Validation Loss: 0.5369
2024-03-28 17:55:49,606 - config - INFO - Epoch [17/200], Train Loss: 0.5150
2024-03-28 17:55:49,624 - config - INFO - Validation Loss: 0.5305
2024-03-28 17:55:49,647 - config - INFO - Epoch [18/200], Train Loss: 0.5077
2024-03-28 17:55:49,652 - config - INFO - Validation Loss: 0.5250
2024-03-28 17:55:49,671 - config - INFO - Epoch [19/200], Train Loss: 0.5007
2024-03-28 17:55:49,675 - config - INFO - Validation Loss: 0.5186
2024-03-28 17:55:49,691 - config - INFO - Epoch [20/200], Train Loss: 0.4940
2024-03-28 17:55:49,694 - config - INFO - Validation Loss: 0.5129
2024-03-28 17:55:49,711 - config - INFO - Epoch [21/200], Train Loss: 0.4875
2024-03-28 17:55:49,715 - config - INFO - Validation Loss: 0.5080
2024-03-28 17:55:49,731 - config - INFO - Epoch [22/200], Train Loss: 0.4823
2024-03-28 17:55:49,734 - config - INFO - Validation Loss: 0.5044
2024-03-28 17:55:49,750 - config - INFO - Epoch [23/200], Train Loss: 0.4764
2024-03-28 17:55:49,754 - config - INFO - Validation Loss: 0.4997
2024-03-28 17:55:49,770 - config - INFO - Epoch [24/200], Train Loss: 0.4713
2024-03-28 17:55:49,773 - config - INFO - Validation Loss: 0.4960
2024-03-28 17:55:49,789 - config - INFO - Epoch [25/200], Train Loss: 0.4670
2024-03-28 17:55:49,793 - config - INFO - Validation Loss: 0.4928
2024-03-28 17:55:49,808 - config - INFO - Epoch [26/200], Train Loss: 0.4623
2024-03-28 17:55:49,812 - config - INFO - Validation Loss: 0.4901
2024-03-28 17:55:49,828 - config - INFO - Epoch [27/200], Train Loss: 0.4580
2024-03-28 17:55:49,831 - config - INFO - Validation Loss: 0.4874
2024-03-28 17:55:49,847 - config - INFO - Epoch [28/200], Train Loss: 0.4541
2024-03-28 17:55:49,851 - config - INFO - Validation Loss: 0.4851
2024-03-28 17:55:49,866 - config - INFO - Epoch [29/200], Train Loss: 0.4510
2024-03-28 17:55:49,870 - config - INFO - Validation Loss: 0.4832
2024-03-28 17:55:49,886 - config - INFO - Epoch [30/200], Train Loss: 0.4479
2024-03-28 17:55:49,889 - config - INFO - Validation Loss: 0.4814
2024-03-28 17:55:49,905 - config - INFO - Epoch [31/200], Train Loss: 0.4452
2024-03-28 17:55:49,908 - config - INFO - Validation Loss: 0.4799
2024-03-28 17:55:49,924 - config - INFO - Epoch [32/200], Train Loss: 0.4421
2024-03-28 17:55:49,928 - config - INFO - Validation Loss: 0.4792
2024-03-28 17:55:49,943 - config - INFO - Epoch [33/200], Train Loss: 0.4402
2024-03-28 17:55:49,947 - config - INFO - Validation Loss: 0.4791
2024-03-28 17:55:49,963 - config - INFO - Epoch [34/200], Train Loss: 0.4384
2024-03-28 17:55:49,966 - config - INFO - Validation Loss: 0.4791
2024-03-28 17:55:49,982 - config - INFO - Epoch [35/200], Train Loss: 0.4367
2024-03-28 17:55:49,985 - config - INFO - Validation Loss: 0.4768
2024-03-28 17:55:50,001 - config - INFO - Epoch [36/200], Train Loss: 0.4340
2024-03-28 17:55:50,005 - config - INFO - Validation Loss: 0.4762
2024-03-28 17:55:50,020 - config - INFO - Epoch [37/200], Train Loss: 0.4322
2024-03-28 17:55:50,024 - config - INFO - Validation Loss: 0.4759
2024-03-28 17:55:50,040 - config - INFO - Epoch [38/200], Train Loss: 0.4305
2024-03-28 17:55:50,043 - config - INFO - Validation Loss: 0.4761
2024-03-28 17:55:50,059 - config - INFO - Epoch [39/200], Train Loss: 0.4293
2024-03-28 17:55:50,063 - config - INFO - Validation Loss: 0.4762
2024-03-28 17:55:50,078 - config - INFO - Epoch [40/200], Train Loss: 0.4284
2024-03-28 17:55:50,082 - config - INFO - Validation Loss: 0.4765
2024-03-28 17:55:50,098 - config - INFO - Epoch [41/200], Train Loss: 0.4269
2024-03-28 17:55:50,101 - config - INFO - Validation Loss: 0.4756
2024-03-28 17:55:50,117 - config - INFO - Epoch [42/200], Train Loss: 0.4260
2024-03-28 17:55:50,121 - config - INFO - Validation Loss: 0.4755
2024-03-28 17:55:50,137 - config - INFO - Epoch [43/200], Train Loss: 0.4254
2024-03-28 17:55:50,140 - config - INFO - Validation Loss: 0.4756
2024-03-28 17:55:50,156 - config - INFO - Epoch [44/200], Train Loss: 0.4247
2024-03-28 17:55:50,160 - config - INFO - Validation Loss: 0.4764
2024-03-28 17:55:50,175 - config - INFO - Epoch [45/200], Train Loss: 0.4239
2024-03-28 17:55:50,179 - config - INFO - Validation Loss: 0.4767
2024-03-28 17:55:50,195 - config - INFO - Epoch [46/200], Train Loss: 0.4231
2024-03-28 17:55:50,198 - config - INFO - Validation Loss: 0.4772
2024-03-28 17:55:50,214 - config - INFO - Epoch [47/200], Train Loss: 0.4228
2024-03-28 17:55:50,217 - config - INFO - Validation Loss: 0.4776
2024-03-28 17:55:50,233 - config - INFO - Epoch [48/200], Train Loss: 0.4225
2024-03-28 17:55:50,237 - config - INFO - Validation Loss: 0.4783
2024-03-28 17:55:50,252 - config - INFO - Epoch [49/200], Train Loss: 0.4219
2024-03-28 17:55:50,256 - config - INFO - Validation Loss: 0.4779
2024-03-28 17:55:50,272 - config - INFO - Epoch [50/200], Train Loss: 0.4214
2024-03-28 17:55:50,275 - config - INFO - Validation Loss: 0.4780
2024-03-28 17:55:50,291 - config - INFO - Epoch [51/200], Train Loss: 0.4211
2024-03-28 17:55:50,294 - config - INFO - Validation Loss: 0.4784
2024-03-28 17:55:50,310 - config - INFO - Epoch [52/200], Train Loss: 0.4209
2024-03-28 17:55:50,314 - config - INFO - Validation Loss: 0.4792
2024-03-28 17:55:50,330 - config - INFO - Epoch [53/200], Train Loss: 0.4213
2024-03-28 17:55:50,333 - config - INFO - Validation Loss: 0.4792
2024-03-28 17:55:50,349 - config - INFO - Epoch [54/200], Train Loss: 0.4203
2024-03-28 17:55:50,352 - config - INFO - Validation Loss: 0.4799
2024-03-28 17:55:50,368 - config - INFO - Epoch [55/200], Train Loss: 0.4207
2024-03-28 17:55:50,372 - config - INFO - Validation Loss: 0.4809
2024-03-28 17:55:50,388 - config - INFO - Epoch [56/200], Train Loss: 0.4205
2024-03-28 17:55:50,391 - config - INFO - Validation Loss: 0.4803
2024-03-28 17:55:50,407 - config - INFO - Epoch [57/200], Train Loss: 0.4200
2024-03-28 17:55:50,410 - config - INFO - Validation Loss: 0.4799
2024-03-28 17:55:50,426 - config - INFO - Epoch [58/200], Train Loss: 0.4207
2024-03-28 17:55:50,430 - config - INFO - Validation Loss: 0.4814
2024-03-28 17:55:50,446 - config - INFO - Epoch [59/200], Train Loss: 0.4205
2024-03-28 17:55:50,449 - config - INFO - Validation Loss: 0.4806
2024-03-28 17:55:50,465 - config - INFO - Epoch [60/200], Train Loss: 0.4197
2024-03-28 17:55:50,468 - config - INFO - Validation Loss: 0.4809
2024-03-28 17:55:50,484 - config - INFO - Epoch [61/200], Train Loss: 0.4196
2024-03-28 17:55:50,488 - config - INFO - Validation Loss: 0.4818
2024-03-28 17:55:50,504 - config - INFO - Epoch [62/200], Train Loss: 0.4194
2024-03-28 17:55:50,507 - config - INFO - Validation Loss: 0.4816
2024-03-28 17:55:50,523 - config - INFO - Epoch [63/200], Train Loss: 0.4194
2024-03-28 17:55:50,526 - config - INFO - Validation Loss: 0.4812
2024-03-28 17:55:50,542 - config - INFO - Epoch [64/200], Train Loss: 0.4193
2024-03-28 17:55:50,546 - config - INFO - Validation Loss: 0.4814
2024-03-28 17:55:50,562 - config - INFO - Epoch [65/200], Train Loss: 0.4196
2024-03-28 17:55:50,565 - config - INFO - Validation Loss: 0.4816
2024-03-28 17:55:50,581 - config - INFO - Epoch [66/200], Train Loss: 0.4189
2024-03-28 17:55:50,584 - config - INFO - Validation Loss: 0.4815
2024-03-28 17:55:50,600 - config - INFO - Epoch [67/200], Train Loss: 0.4190
2024-03-28 17:55:50,604 - config - INFO - Validation Loss: 0.4820
2024-03-28 17:55:50,625 - config - INFO - Epoch [68/200], Train Loss: 0.4194
2024-03-28 17:55:50,629 - config - INFO - Validation Loss: 0.4820
2024-03-28 17:55:50,645 - config - INFO - Epoch [69/200], Train Loss: 0.4190
2024-03-28 17:55:50,648 - config - INFO - Validation Loss: 0.4816
2024-03-28 17:55:50,664 - config - INFO - Epoch [70/200], Train Loss: 0.4191
2024-03-28 17:55:50,668 - config - INFO - Validation Loss: 0.4817
2024-03-28 17:55:50,684 - config - INFO - Epoch [71/200], Train Loss: 0.4186
2024-03-28 17:55:50,687 - config - INFO - Validation Loss: 0.4822
2024-03-28 17:55:50,703 - config - INFO - Epoch [72/200], Train Loss: 0.4195
2024-03-28 17:55:50,706 - config - INFO - Validation Loss: 0.4827
2024-03-28 17:55:50,722 - config - INFO - Epoch [73/200], Train Loss: 0.4185
2024-03-28 17:55:50,726 - config - INFO - Validation Loss: 0.4816
2024-03-28 17:55:50,742 - config - INFO - Epoch [74/200], Train Loss: 0.4189
2024-03-28 17:55:50,745 - config - INFO - Validation Loss: 0.4814
2024-03-28 17:55:50,761 - config - INFO - Epoch [75/200], Train Loss: 0.4187
2024-03-28 17:55:50,764 - config - INFO - Validation Loss: 0.4817
2024-03-28 17:55:50,780 - config - INFO - Epoch [76/200], Train Loss: 0.4187
2024-03-28 17:55:50,784 - config - INFO - Validation Loss: 0.4818
2024-03-28 17:55:50,801 - config - INFO - Epoch [77/200], Train Loss: 0.4187
2024-03-28 17:55:50,804 - config - INFO - Validation Loss: 0.4821
2024-03-28 17:55:50,821 - config - INFO - Epoch [78/200], Train Loss: 0.4187
2024-03-28 17:55:50,825 - config - INFO - Validation Loss: 0.4823
2024-03-28 17:55:50,842 - config - INFO - Epoch [79/200], Train Loss: 0.4189
2024-03-28 17:55:50,846 - config - INFO - Validation Loss: 0.4812
2024-03-28 17:55:50,863 - config - INFO - Epoch [80/200], Train Loss: 0.4182
2024-03-28 17:55:50,867 - config - INFO - Validation Loss: 0.4818
2024-03-28 17:55:50,884 - config - INFO - Epoch [81/200], Train Loss: 0.4187
2024-03-28 17:55:50,887 - config - INFO - Validation Loss: 0.4831
2024-03-28 17:55:50,904 - config - INFO - Epoch [82/200], Train Loss: 0.4188
2024-03-28 17:55:50,908 - config - INFO - Validation Loss: 0.4824
2024-03-28 17:55:50,924 - config - INFO - Epoch [83/200], Train Loss: 0.4179
2024-03-28 17:55:50,927 - config - INFO - Validation Loss: 0.4815
2024-03-28 17:55:50,943 - config - INFO - Epoch [84/200], Train Loss: 0.4186
2024-03-28 17:55:50,946 - config - INFO - Validation Loss: 0.4812
2024-03-28 17:55:50,962 - config - INFO - Epoch [85/200], Train Loss: 0.4182
2024-03-28 17:55:50,966 - config - INFO - Validation Loss: 0.4810
2024-03-28 17:55:50,982 - config - INFO - Epoch [86/200], Train Loss: 0.4180
2024-03-28 17:55:50,985 - config - INFO - Validation Loss: 0.4816
2024-03-28 17:55:51,001 - config - INFO - Epoch [87/200], Train Loss: 0.4182
2024-03-28 17:55:51,004 - config - INFO - Validation Loss: 0.4817
2024-03-28 17:55:51,020 - config - INFO - Epoch [88/200], Train Loss: 0.4184
2024-03-28 17:55:51,024 - config - INFO - Validation Loss: 0.4809
2024-03-28 17:55:51,040 - config - INFO - Epoch [89/200], Train Loss: 0.4186
2024-03-28 17:55:51,043 - config - INFO - Validation Loss: 0.4818
2024-03-28 17:55:51,059 - config - INFO - Epoch [90/200], Train Loss: 0.4178
2024-03-28 17:55:51,062 - config - INFO - Validation Loss: 0.4810
2024-03-28 17:55:51,078 - config - INFO - Epoch [91/200], Train Loss: 0.4177
2024-03-28 17:55:51,082 - config - INFO - Validation Loss: 0.4805
2024-03-28 17:55:51,098 - config - INFO - Epoch [92/200], Train Loss: 0.4179
2024-03-28 17:55:51,101 - config - INFO - Validation Loss: 0.4806
2024-03-28 17:55:51,135 - config - INFO - Epoch [93/200], Train Loss: 0.4181
2024-03-28 17:55:51,140 - config - INFO - Validation Loss: 0.4809
2024-03-28 17:55:51,162 - config - INFO - Epoch [94/200], Train Loss: 0.4176
2024-03-28 17:55:51,166 - config - INFO - Validation Loss: 0.4806
2024-03-28 17:55:51,187 - config - INFO - Epoch [95/200], Train Loss: 0.4183
2024-03-28 17:55:51,192 - config - INFO - Validation Loss: 0.4813
2024-03-28 17:55:51,213 - config - INFO - Epoch [96/200], Train Loss: 0.4177
2024-03-28 17:55:51,218 - config - INFO - Validation Loss: 0.4808
2024-03-28 17:55:51,239 - config - INFO - Epoch [97/200], Train Loss: 0.4177
2024-03-28 17:55:51,244 - config - INFO - Validation Loss: 0.4811
2024-03-28 17:55:51,265 - config - INFO - Epoch [98/200], Train Loss: 0.4175
2024-03-28 17:55:51,270 - config - INFO - Validation Loss: 0.4815
2024-03-28 17:55:51,291 - config - INFO - Epoch [99/200], Train Loss: 0.4177
2024-03-28 17:55:51,296 - config - INFO - Validation Loss: 0.4815
2024-03-28 17:55:51,317 - config - INFO - Epoch [100/200], Train Loss: 0.4182
2024-03-28 17:55:51,322 - config - INFO - Validation Loss: 0.4813
2024-03-28 17:55:51,343 - config - INFO - Epoch [101/200], Train Loss: 0.4173
2024-03-28 17:55:51,348 - config - INFO - Validation Loss: 0.4824
2024-03-28 17:55:51,369 - config - INFO - Epoch [102/200], Train Loss: 0.4180
2024-03-28 17:55:51,374 - config - INFO - Validation Loss: 0.4834
2024-03-28 17:55:51,395 - config - INFO - Epoch [103/200], Train Loss: 0.4176
2024-03-28 17:55:51,399 - config - INFO - Validation Loss: 0.4824
2024-03-28 17:55:51,421 - config - INFO - Epoch [104/200], Train Loss: 0.4174
2024-03-28 17:55:51,425 - config - INFO - Validation Loss: 0.4820
2024-03-28 17:55:51,446 - config - INFO - Epoch [105/200], Train Loss: 0.4175
2024-03-28 17:55:51,451 - config - INFO - Validation Loss: 0.4822
2024-03-28 17:55:51,472 - config - INFO - Epoch [106/200], Train Loss: 0.4172
2024-03-28 17:55:51,477 - config - INFO - Validation Loss: 0.4818
2024-03-28 17:55:51,498 - config - INFO - Epoch [107/200], Train Loss: 0.4174
2024-03-28 17:55:51,503 - config - INFO - Validation Loss: 0.4834
2024-03-28 17:55:51,524 - config - INFO - Epoch [108/200], Train Loss: 0.4184
2024-03-28 17:55:51,529 - config - INFO - Validation Loss: 0.4848
2024-03-28 17:55:51,550 - config - INFO - Epoch [109/200], Train Loss: 0.4185
2024-03-28 17:55:51,555 - config - INFO - Validation Loss: 0.4829
2024-03-28 17:55:51,576 - config - INFO - Epoch [110/200], Train Loss: 0.4175
2024-03-28 17:55:51,580 - config - INFO - Validation Loss: 0.4829
2024-03-28 17:55:51,602 - config - INFO - Epoch [111/200], Train Loss: 0.4173
2024-03-28 17:55:51,606 - config - INFO - Validation Loss: 0.4837
2024-03-28 17:55:51,627 - config - INFO - Epoch [112/200], Train Loss: 0.4173
2024-03-28 17:55:51,632 - config - INFO - Validation Loss: 0.4838
2024-03-28 17:55:51,653 - config - INFO - Epoch [113/200], Train Loss: 0.4169
2024-03-28 17:55:51,658 - config - INFO - Validation Loss: 0.4833
2024-03-28 17:55:51,679 - config - INFO - Epoch [114/200], Train Loss: 0.4167
2024-03-28 17:55:51,684 - config - INFO - Validation Loss: 0.4823
2024-03-28 17:55:51,705 - config - INFO - Epoch [115/200], Train Loss: 0.4177
2024-03-28 17:55:51,709 - config - INFO - Validation Loss: 0.4820
2024-03-28 17:55:51,731 - config - INFO - Epoch [116/200], Train Loss: 0.4177
2024-03-28 17:55:51,735 - config - INFO - Validation Loss: 0.4823
2024-03-28 17:55:51,756 - config - INFO - Epoch [117/200], Train Loss: 0.4167
2024-03-28 17:55:51,761 - config - INFO - Validation Loss: 0.4820
2024-03-28 17:55:51,782 - config - INFO - Epoch [118/200], Train Loss: 0.4176
2024-03-28 17:55:51,787 - config - INFO - Validation Loss: 0.4821
2024-03-28 17:55:51,808 - config - INFO - Epoch [119/200], Train Loss: 0.4167
2024-03-28 17:55:51,813 - config - INFO - Validation Loss: 0.4819
2024-03-28 17:55:51,834 - config - INFO - Epoch [120/200], Train Loss: 0.4167
2024-03-28 17:55:51,839 - config - INFO - Validation Loss: 0.4817
2024-03-28 17:55:51,860 - config - INFO - Epoch [121/200], Train Loss: 0.4168
2024-03-28 17:55:51,865 - config - INFO - Validation Loss: 0.4818
2024-03-28 17:55:51,886 - config - INFO - Epoch [122/200], Train Loss: 0.4168
2024-03-28 17:55:51,890 - config - INFO - Validation Loss: 0.4815
2024-03-28 17:55:51,912 - config - INFO - Epoch [123/200], Train Loss: 0.4169
2024-03-28 17:55:51,916 - config - INFO - Validation Loss: 0.4824
2024-03-28 17:55:51,938 - config - INFO - Epoch [124/200], Train Loss: 0.4163
2024-03-28 17:55:51,942 - config - INFO - Validation Loss: 0.4832
2024-03-28 17:55:51,963 - config - INFO - Epoch [125/200], Train Loss: 0.4167
2024-03-28 17:55:51,968 - config - INFO - Validation Loss: 0.4822
2024-03-28 17:55:51,989 - config - INFO - Epoch [126/200], Train Loss: 0.4167
2024-03-28 17:55:51,994 - config - INFO - Validation Loss: 0.4818
2024-03-28 17:55:52,015 - config - INFO - Epoch [127/200], Train Loss: 0.4161
2024-03-28 17:55:52,020 - config - INFO - Validation Loss: 0.4818
2024-03-28 17:55:52,041 - config - INFO - Epoch [128/200], Train Loss: 0.4164
2024-03-28 17:55:52,046 - config - INFO - Validation Loss: 0.4817
2024-03-28 17:55:52,067 - config - INFO - Epoch [129/200], Train Loss: 0.4163
2024-03-28 17:55:52,071 - config - INFO - Validation Loss: 0.4816
2024-03-28 17:55:52,092 - config - INFO - Epoch [130/200], Train Loss: 0.4170
2024-03-28 17:55:52,097 - config - INFO - Validation Loss: 0.4817
2024-03-28 17:55:52,118 - config - INFO - Epoch [131/200], Train Loss: 0.4161
2024-03-28 17:55:52,123 - config - INFO - Validation Loss: 0.4814
2024-03-28 17:55:52,150 - config - INFO - Epoch [132/200], Train Loss: 0.4167
2024-03-28 17:55:52,155 - config - INFO - Validation Loss: 0.4815
2024-03-28 17:55:52,176 - config - INFO - Epoch [133/200], Train Loss: 0.4159
2024-03-28 17:55:52,181 - config - INFO - Validation Loss: 0.4816
2024-03-28 17:55:52,202 - config - INFO - Epoch [134/200], Train Loss: 0.4165
2024-03-28 17:55:52,207 - config - INFO - Validation Loss: 0.4821
2024-03-28 17:55:52,229 - config - INFO - Epoch [135/200], Train Loss: 0.4162
2024-03-28 17:55:52,233 - config - INFO - Validation Loss: 0.4816
2024-03-28 17:55:52,255 - config - INFO - Epoch [136/200], Train Loss: 0.4160
2024-03-28 17:55:52,259 - config - INFO - Validation Loss: 0.4819
2024-03-28 17:55:52,281 - config - INFO - Epoch [137/200], Train Loss: 0.4182
2024-03-28 17:55:52,285 - config - INFO - Validation Loss: 0.4815
2024-03-28 17:55:52,307 - config - INFO - Epoch [138/200], Train Loss: 0.4162
2024-03-28 17:55:52,311 - config - INFO - Validation Loss: 0.4813
2024-03-28 17:55:52,333 - config - INFO - Epoch [139/200], Train Loss: 0.4156
2024-03-28 17:55:52,337 - config - INFO - Validation Loss: 0.4817
2024-03-28 17:55:52,359 - config - INFO - Epoch [140/200], Train Loss: 0.4155
2024-03-28 17:55:52,363 - config - INFO - Validation Loss: 0.4817
2024-03-28 17:55:52,385 - config - INFO - Epoch [141/200], Train Loss: 0.4157
2024-03-28 17:55:52,389 - config - INFO - Validation Loss: 0.4815
2024-03-28 17:55:52,411 - config - INFO - Epoch [142/200], Train Loss: 0.4155
2024-03-28 17:55:52,415 - config - INFO - Validation Loss: 0.4816
2024-03-28 17:55:52,436 - config - INFO - Epoch [143/200], Train Loss: 0.4158
2024-03-28 17:55:52,441 - config - INFO - Validation Loss: 0.4818
2024-03-28 17:55:52,462 - config - INFO - Epoch [144/200], Train Loss: 0.4159
2024-03-28 17:55:52,467 - config - INFO - Validation Loss: 0.4817
2024-03-28 17:55:52,488 - config - INFO - Epoch [145/200], Train Loss: 0.4154
2024-03-28 17:55:52,493 - config - INFO - Validation Loss: 0.4815
2024-03-28 17:55:52,514 - config - INFO - Epoch [146/200], Train Loss: 0.4154
2024-03-28 17:55:52,519 - config - INFO - Validation Loss: 0.4815
2024-03-28 17:55:52,540 - config - INFO - Epoch [147/200], Train Loss: 0.4154
2024-03-28 17:55:52,545 - config - INFO - Validation Loss: 0.4813
2024-03-28 17:55:52,566 - config - INFO - Epoch [148/200], Train Loss: 0.4151
2024-03-28 17:55:52,570 - config - INFO - Validation Loss: 0.4815
2024-03-28 17:55:52,592 - config - INFO - Epoch [149/200], Train Loss: 0.4152
2024-03-28 17:55:52,596 - config - INFO - Validation Loss: 0.4808
2024-03-28 17:55:52,618 - config - INFO - Epoch [150/200], Train Loss: 0.4151
2024-03-28 17:55:52,622 - config - INFO - Validation Loss: 0.4813
2024-03-28 17:55:52,644 - config - INFO - Epoch [151/200], Train Loss: 0.4149
2024-03-28 17:55:52,648 - config - INFO - Validation Loss: 0.4811
2024-03-28 17:55:52,670 - config - INFO - Epoch [152/200], Train Loss: 0.4153
2024-03-28 17:55:52,675 - config - INFO - Validation Loss: 0.4802
2024-03-28 17:55:52,696 - config - INFO - Epoch [153/200], Train Loss: 0.4147
2024-03-28 17:55:52,701 - config - INFO - Validation Loss: 0.4804
2024-03-28 17:55:52,722 - config - INFO - Epoch [154/200], Train Loss: 0.4155
2024-03-28 17:55:52,726 - config - INFO - Validation Loss: 0.4815
2024-03-28 17:55:52,748 - config - INFO - Epoch [155/200], Train Loss: 0.4146
2024-03-28 17:55:52,752 - config - INFO - Validation Loss: 0.4807
2024-03-28 17:55:52,774 - config - INFO - Epoch [156/200], Train Loss: 0.4152
2024-03-28 17:55:52,778 - config - INFO - Validation Loss: 0.4806
2024-03-28 17:55:52,799 - config - INFO - Epoch [157/200], Train Loss: 0.4152
2024-03-28 17:55:52,804 - config - INFO - Validation Loss: 0.4802
2024-03-28 17:55:52,826 - config - INFO - Epoch [158/200], Train Loss: 0.4148
2024-03-28 17:55:52,830 - config - INFO - Validation Loss: 0.4797
2024-03-28 17:55:52,852 - config - INFO - Epoch [159/200], Train Loss: 0.4146
2024-03-28 17:55:52,856 - config - INFO - Validation Loss: 0.4797
2024-03-28 17:55:52,878 - config - INFO - Epoch [160/200], Train Loss: 0.4144
2024-03-28 17:55:52,882 - config - INFO - Validation Loss: 0.4796
2024-03-28 17:55:52,903 - config - INFO - Epoch [161/200], Train Loss: 0.4143
2024-03-28 17:55:52,908 - config - INFO - Validation Loss: 0.4798
2024-03-28 17:55:52,929 - config - INFO - Epoch [162/200], Train Loss: 0.4146
2024-03-28 17:55:52,934 - config - INFO - Validation Loss: 0.4798
2024-03-28 17:55:52,955 - config - INFO - Epoch [163/200], Train Loss: 0.4146
2024-03-28 17:55:52,960 - config - INFO - Validation Loss: 0.4798
2024-03-28 17:55:52,981 - config - INFO - Epoch [164/200], Train Loss: 0.4178
2024-03-28 17:55:52,986 - config - INFO - Validation Loss: 0.4820
2024-03-28 17:55:53,007 - config - INFO - Epoch [165/200], Train Loss: 0.4150
2024-03-28 17:55:53,012 - config - INFO - Validation Loss: 0.4792
2024-03-28 17:55:53,033 - config - INFO - Epoch [166/200], Train Loss: 0.4143
2024-03-28 17:55:53,038 - config - INFO - Validation Loss: 0.4792
2024-03-28 17:55:53,059 - config - INFO - Epoch [167/200], Train Loss: 0.4137
2024-03-28 17:55:53,063 - config - INFO - Validation Loss: 0.4789
2024-03-28 17:55:53,085 - config - INFO - Epoch [168/200], Train Loss: 0.4147
2024-03-28 17:55:53,089 - config - INFO - Validation Loss: 0.4796
2024-03-28 17:55:53,111 - config - INFO - Epoch [169/200], Train Loss: 0.4137
2024-03-28 17:55:53,115 - config - INFO - Validation Loss: 0.4789
2024-03-28 17:55:53,140 - config - INFO - Epoch [170/200], Train Loss: 0.4148
2024-03-28 17:55:53,144 - config - INFO - Validation Loss: 0.4790
2024-03-28 17:55:53,166 - config - INFO - Epoch [171/200], Train Loss: 0.4143
2024-03-28 17:55:53,170 - config - INFO - Validation Loss: 0.4788
2024-03-28 17:55:53,191 - config - INFO - Epoch [172/200], Train Loss: 0.4137
2024-03-28 17:55:53,196 - config - INFO - Validation Loss: 0.4788
2024-03-28 17:55:53,217 - config - INFO - Epoch [173/200], Train Loss: 0.4139
2024-03-28 17:55:53,222 - config - INFO - Validation Loss: 0.4791
2024-03-28 17:55:53,243 - config - INFO - Epoch [174/200], Train Loss: 0.4136
2024-03-28 17:55:53,248 - config - INFO - Validation Loss: 0.4792
2024-03-28 17:55:53,269 - config - INFO - Epoch [175/200], Train Loss: 0.4142
2024-03-28 17:55:53,274 - config - INFO - Validation Loss: 0.4787
2024-03-28 17:55:53,295 - config - INFO - Epoch [176/200], Train Loss: 0.4145
2024-03-28 17:55:53,299 - config - INFO - Validation Loss: 0.4790
2024-03-28 17:55:53,321 - config - INFO - Epoch [177/200], Train Loss: 0.4133
2024-03-28 17:55:53,325 - config - INFO - Validation Loss: 0.4793
2024-03-28 17:55:53,347 - config - INFO - Epoch [178/200], Train Loss: 0.4132
2024-03-28 17:55:53,351 - config - INFO - Validation Loss: 0.4796
2024-03-28 17:55:53,372 - config - INFO - Epoch [179/200], Train Loss: 0.4134
2024-03-28 17:55:53,377 - config - INFO - Validation Loss: 0.4799
2024-03-28 17:55:53,398 - config - INFO - Epoch [180/200], Train Loss: 0.4132
2024-03-28 17:55:53,403 - config - INFO - Validation Loss: 0.4794
2024-03-28 17:55:53,424 - config - INFO - Epoch [181/200], Train Loss: 0.4135
2024-03-28 17:55:53,429 - config - INFO - Validation Loss: 0.4791
2024-03-28 17:55:53,450 - config - INFO - Epoch [182/200], Train Loss: 0.4133
2024-03-28 17:55:53,454 - config - INFO - Validation Loss: 0.4792
2024-03-28 17:55:53,475 - config - INFO - Epoch [183/200], Train Loss: 0.4128
2024-03-28 17:55:53,480 - config - INFO - Validation Loss: 0.4794
2024-03-28 17:55:53,501 - config - INFO - Epoch [184/200], Train Loss: 0.4132
2024-03-28 17:55:53,506 - config - INFO - Validation Loss: 0.4793
2024-03-28 17:55:53,527 - config - INFO - Epoch [185/200], Train Loss: 0.4129
2024-03-28 17:55:53,532 - config - INFO - Validation Loss: 0.4796
2024-03-28 17:55:53,553 - config - INFO - Epoch [186/200], Train Loss: 0.4132
2024-03-28 17:55:53,558 - config - INFO - Validation Loss: 0.4795
2024-03-28 17:55:53,579 - config - INFO - Epoch [187/200], Train Loss: 0.4129
2024-03-28 17:55:53,584 - config - INFO - Validation Loss: 0.4797
2024-03-28 17:55:53,605 - config - INFO - Epoch [188/200], Train Loss: 0.4126
2024-03-28 17:55:53,610 - config - INFO - Validation Loss: 0.4810
2024-03-28 17:55:53,631 - config - INFO - Epoch [189/200], Train Loss: 0.4127
2024-03-28 17:55:53,635 - config - INFO - Validation Loss: 0.4806
2024-03-28 17:55:53,657 - config - INFO - Epoch [190/200], Train Loss: 0.4128
2024-03-28 17:55:53,661 - config - INFO - Validation Loss: 0.4793
2024-03-28 17:55:53,682 - config - INFO - Epoch [191/200], Train Loss: 0.4129
2024-03-28 17:55:53,687 - config - INFO - Validation Loss: 0.4800
2024-03-28 17:55:53,708 - config - INFO - Epoch [192/200], Train Loss: 0.4119
2024-03-28 17:55:53,713 - config - INFO - Validation Loss: 0.4799
2024-03-28 17:55:53,734 - config - INFO - Epoch [193/200], Train Loss: 0.4122
2024-03-28 17:55:53,739 - config - INFO - Validation Loss: 0.4794
2024-03-28 17:55:53,760 - config - INFO - Epoch [194/200], Train Loss: 0.4132
2024-03-28 17:55:53,765 - config - INFO - Validation Loss: 0.4794
2024-03-28 17:55:53,786 - config - INFO - Epoch [195/200], Train Loss: 0.4116
2024-03-28 17:55:53,791 - config - INFO - Validation Loss: 0.4782
2024-03-28 17:55:53,812 - config - INFO - Epoch [196/200], Train Loss: 0.4134
2024-03-28 17:55:53,816 - config - INFO - Validation Loss: 0.4787
2024-03-28 17:55:53,837 - config - INFO - Epoch [197/200], Train Loss: 0.4124
2024-03-28 17:55:53,842 - config - INFO - Validation Loss: 0.4787
2024-03-28 17:55:53,863 - config - INFO - Epoch [198/200], Train Loss: 0.4117
2024-03-28 17:55:53,868 - config - INFO - Validation Loss: 0.4797
2024-03-28 17:55:53,889 - config - INFO - Epoch [199/200], Train Loss: 0.4113
2024-03-28 17:55:53,894 - config - INFO - Validation Loss: 0.4787
2024-03-28 17:55:53,915 - config - INFO - Epoch [200/200], Train Loss: 0.4130
2024-03-28 17:55:53,920 - config - INFO - Validation Loss: 0.4785
2024-03-28 18:02:21,660 - config - INFO - resume: None
2024-03-28 18:02:21,660 - config - INFO - device: cpu
2024-03-28 18:02:21,660 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-28 18:02:21,660 - config - INFO - learning_rate: 0.001
2024-03-28 18:02:21,660 - config - INFO - num_epochs: 200
2024-03-28 18:02:21,660 - config - INFO - batch_size: 64
2024-03-28 18:02:21,661 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = None
        self.prev_val_loss = float('inf')
        self.tolerance = 0.03

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 18:02:21,674 - config - INFO - Dataset size: 891
2024-03-28 18:02:21,700 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.6 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()

    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 18:02:21,700 - config - INFO - Training start
2024-03-28 18:02:24,064 - config - INFO - Epoch [1/200], Train Loss: 0.6555
2024-03-28 18:02:24,070 - config - INFO - Validation Loss: 0.6563
2024-03-28 18:02:24,093 - config - INFO - Epoch [2/200], Train Loss: 0.6426
2024-03-28 18:02:24,098 - config - INFO - Validation Loss: 0.6497
2024-03-28 18:02:24,120 - config - INFO - Epoch [3/200], Train Loss: 0.6304
2024-03-28 18:02:24,125 - config - INFO - Validation Loss: 0.6303
2024-03-28 18:02:24,152 - config - INFO - Epoch [4/200], Train Loss: 0.6165
2024-03-28 18:02:24,156 - config - INFO - Validation Loss: 0.6131
2024-03-28 18:02:24,172 - config - INFO - Epoch [5/200], Train Loss: 0.6068
2024-03-28 18:02:24,175 - config - INFO - Validation Loss: 0.5983
2024-03-28 18:02:24,191 - config - INFO - Epoch [6/200], Train Loss: 0.5961
2024-03-28 18:02:24,195 - config - INFO - Validation Loss: 0.5864
2024-03-28 18:02:24,210 - config - INFO - Epoch [7/200], Train Loss: 0.5859
2024-03-28 18:02:24,215 - config - INFO - Validation Loss: 0.5736
2024-03-28 18:02:24,231 - config - INFO - Epoch [8/200], Train Loss: 0.5765
2024-03-28 18:02:24,235 - config - INFO - Validation Loss: 0.5594
2024-03-28 18:02:24,250 - config - INFO - Epoch [9/200], Train Loss: 0.5666
2024-03-28 18:02:24,254 - config - INFO - Validation Loss: 0.5474
2024-03-28 18:02:24,270 - config - INFO - Epoch [10/200], Train Loss: 0.5584
2024-03-28 18:02:24,273 - config - INFO - Validation Loss: 0.5355
2024-03-28 18:02:24,289 - config - INFO - Epoch [11/200], Train Loss: 0.5500
2024-03-28 18:02:24,292 - config - INFO - Validation Loss: 0.5240
2024-03-28 18:02:24,308 - config - INFO - Epoch [12/200], Train Loss: 0.5427
2024-03-28 18:02:24,311 - config - INFO - Validation Loss: 0.5161
2024-03-28 18:02:24,327 - config - INFO - Epoch [13/200], Train Loss: 0.5344
2024-03-28 18:02:24,330 - config - INFO - Validation Loss: 0.5045
2024-03-28 18:02:24,346 - config - INFO - Epoch [14/200], Train Loss: 0.5277
2024-03-28 18:02:24,350 - config - INFO - Validation Loss: 0.4937
2024-03-28 18:02:24,365 - config - INFO - Epoch [15/200], Train Loss: 0.5208
2024-03-28 18:02:24,369 - config - INFO - Validation Loss: 0.4845
2024-03-28 18:02:24,384 - config - INFO - Epoch [16/200], Train Loss: 0.5153
2024-03-28 18:02:24,388 - config - INFO - Validation Loss: 0.4772
2024-03-28 18:02:24,404 - config - INFO - Epoch [17/200], Train Loss: 0.5093
2024-03-28 18:02:24,407 - config - INFO - Validation Loss: 0.4708
2024-03-28 18:02:24,423 - config - INFO - Epoch [18/200], Train Loss: 0.5051
2024-03-28 18:02:24,426 - config - INFO - Validation Loss: 0.4629
2024-03-28 18:02:24,442 - config - INFO - Epoch [19/200], Train Loss: 0.5007
2024-03-28 18:02:24,445 - config - INFO - Validation Loss: 0.4551
2024-03-28 18:02:24,474 - config - INFO - Epoch [20/200], Train Loss: 0.4963
2024-03-28 18:02:24,477 - config - INFO - Validation Loss: 0.4494
2024-03-28 18:02:24,493 - config - INFO - Epoch [21/200], Train Loss: 0.4932
2024-03-28 18:02:24,496 - config - INFO - Validation Loss: 0.4432
2024-03-28 18:02:24,512 - config - INFO - Epoch [22/200], Train Loss: 0.4895
2024-03-28 18:02:24,515 - config - INFO - Validation Loss: 0.4382
2024-03-28 18:02:24,531 - config - INFO - Epoch [23/200], Train Loss: 0.4866
2024-03-28 18:02:24,534 - config - INFO - Validation Loss: 0.4348
2024-03-28 18:02:24,550 - config - INFO - Epoch [24/200], Train Loss: 0.4844
2024-03-28 18:02:24,554 - config - INFO - Validation Loss: 0.4309
2024-03-28 18:02:24,569 - config - INFO - Epoch [25/200], Train Loss: 0.4820
2024-03-28 18:02:24,573 - config - INFO - Validation Loss: 0.4275
2024-03-28 18:02:24,588 - config - INFO - Epoch [26/200], Train Loss: 0.4799
2024-03-28 18:02:24,592 - config - INFO - Validation Loss: 0.4229
2024-03-28 18:02:24,607 - config - INFO - Epoch [27/200], Train Loss: 0.4787
2024-03-28 18:02:24,611 - config - INFO - Validation Loss: 0.4185
2024-03-28 18:02:24,627 - config - INFO - Epoch [28/200], Train Loss: 0.4780
2024-03-28 18:02:24,630 - config - INFO - Validation Loss: 0.4139
2024-03-28 18:02:24,646 - config - INFO - Epoch [29/200], Train Loss: 0.4774
2024-03-28 18:02:24,649 - config - INFO - Validation Loss: 0.4141
2024-03-28 18:02:24,666 - config - INFO - Epoch [30/200], Train Loss: 0.4745
2024-03-28 18:02:24,670 - config - INFO - Validation Loss: 0.4102
2024-03-28 18:02:24,689 - config - INFO - Epoch [31/200], Train Loss: 0.4732
2024-03-28 18:02:24,693 - config - INFO - Validation Loss: 0.4071
2024-03-28 18:02:24,711 - config - INFO - Epoch [32/200], Train Loss: 0.4723
2024-03-28 18:02:24,715 - config - INFO - Validation Loss: 0.4046
2024-03-28 18:02:24,734 - config - INFO - Epoch [33/200], Train Loss: 0.4715
2024-03-28 18:02:24,737 - config - INFO - Validation Loss: 0.4053
2024-03-28 18:02:24,756 - config - INFO - Epoch [34/200], Train Loss: 0.4711
2024-03-28 18:02:24,760 - config - INFO - Validation Loss: 0.4028
2024-03-28 18:02:24,778 - config - INFO - Epoch [35/200], Train Loss: 0.4700
2024-03-28 18:02:24,782 - config - INFO - Validation Loss: 0.4012
2024-03-28 18:02:24,800 - config - INFO - Epoch [36/200], Train Loss: 0.4698
2024-03-28 18:02:24,804 - config - INFO - Validation Loss: 0.4012
2024-03-28 18:02:24,823 - config - INFO - Epoch [37/200], Train Loss: 0.4700
2024-03-28 18:02:24,827 - config - INFO - Validation Loss: 0.3984
2024-03-28 18:02:24,845 - config - INFO - Epoch [38/200], Train Loss: 0.4688
2024-03-28 18:02:24,849 - config - INFO - Validation Loss: 0.3980
2024-03-28 18:02:24,867 - config - INFO - Epoch [39/200], Train Loss: 0.4688
2024-03-28 18:02:24,871 - config - INFO - Validation Loss: 0.3967
2024-03-28 18:02:24,890 - config - INFO - Epoch [40/200], Train Loss: 0.4682
2024-03-28 18:02:24,894 - config - INFO - Validation Loss: 0.3964
2024-03-28 18:02:24,912 - config - INFO - Epoch [41/200], Train Loss: 0.4684
2024-03-28 18:02:24,916 - config - INFO - Validation Loss: 0.3950
2024-03-28 18:02:24,936 - config - INFO - Epoch [42/200], Train Loss: 0.4683
2024-03-28 18:02:24,941 - config - INFO - Validation Loss: 0.3956
2024-03-28 18:02:24,965 - config - INFO - Epoch [43/200], Train Loss: 0.4693
2024-03-28 18:02:24,969 - config - INFO - Validation Loss: 0.3938
2024-03-28 18:02:24,989 - config - INFO - Epoch [44/200], Train Loss: 0.4686
2024-03-28 18:02:24,993 - config - INFO - Validation Loss: 0.3963
2024-03-28 18:02:25,013 - config - INFO - Epoch [45/200], Train Loss: 0.4672
2024-03-28 18:02:25,017 - config - INFO - Validation Loss: 0.3940
2024-03-28 18:02:25,036 - config - INFO - Epoch [46/200], Train Loss: 0.4669
2024-03-28 18:02:25,040 - config - INFO - Validation Loss: 0.3921
2024-03-28 18:02:25,059 - config - INFO - Epoch [47/200], Train Loss: 0.4668
2024-03-28 18:02:25,063 - config - INFO - Validation Loss: 0.3918
2024-03-28 18:02:25,083 - config - INFO - Epoch [48/200], Train Loss: 0.4664
2024-03-28 18:02:25,087 - config - INFO - Validation Loss: 0.3926
2024-03-28 18:02:25,106 - config - INFO - Epoch [49/200], Train Loss: 0.4663
2024-03-28 18:02:25,110 - config - INFO - Validation Loss: 0.3911
2024-03-28 18:02:25,129 - config - INFO - Epoch [50/200], Train Loss: 0.4663
2024-03-28 18:02:25,133 - config - INFO - Validation Loss: 0.3914
2024-03-28 18:02:25,152 - config - INFO - Epoch [51/200], Train Loss: 0.4660
2024-03-28 18:02:25,156 - config - INFO - Validation Loss: 0.3903
2024-03-28 18:02:25,175 - config - INFO - Epoch [52/200], Train Loss: 0.4661
2024-03-28 18:02:25,180 - config - INFO - Validation Loss: 0.3898
2024-03-28 18:02:25,199 - config - INFO - Epoch [53/200], Train Loss: 0.4669
2024-03-28 18:02:25,203 - config - INFO - Validation Loss: 0.3881
2024-03-28 18:02:25,222 - config - INFO - Epoch [54/200], Train Loss: 0.4654
2024-03-28 18:02:25,226 - config - INFO - Validation Loss: 0.3883
2024-03-28 18:02:25,245 - config - INFO - Epoch [55/200], Train Loss: 0.4655
2024-03-28 18:02:25,250 - config - INFO - Validation Loss: 0.3893
2024-03-28 18:02:25,271 - config - INFO - Epoch [56/200], Train Loss: 0.4656
2024-03-28 18:02:25,275 - config - INFO - Validation Loss: 0.3885
2024-03-28 18:02:25,294 - config - INFO - Epoch [57/200], Train Loss: 0.4658
2024-03-28 18:02:25,298 - config - INFO - Validation Loss: 0.3873
2024-03-28 18:02:25,317 - config - INFO - Epoch [58/200], Train Loss: 0.4666
2024-03-28 18:02:25,321 - config - INFO - Validation Loss: 0.3893
2024-03-28 18:02:25,340 - config - INFO - Epoch [59/200], Train Loss: 0.4653
2024-03-28 18:02:25,344 - config - INFO - Validation Loss: 0.3865
2024-03-28 18:02:25,363 - config - INFO - Epoch [60/200], Train Loss: 0.4691
2024-03-28 18:02:25,367 - config - INFO - Validation Loss: 0.3843
2024-03-28 18:02:25,386 - config - INFO - Epoch [61/200], Train Loss: 0.4667
2024-03-28 18:02:25,390 - config - INFO - Validation Loss: 0.3868
2024-03-28 18:02:25,409 - config - INFO - Epoch [62/200], Train Loss: 0.4655
2024-03-28 18:02:25,413 - config - INFO - Validation Loss: 0.3878
2024-03-28 18:02:25,432 - config - INFO - Epoch [63/200], Train Loss: 0.4654
2024-03-28 18:02:25,436 - config - INFO - Validation Loss: 0.3859
2024-03-28 18:02:25,454 - config - INFO - Epoch [64/200], Train Loss: 0.4657
2024-03-28 18:02:25,459 - config - INFO - Validation Loss: 0.3857
2024-03-28 18:02:25,477 - config - INFO - Epoch [65/200], Train Loss: 0.4649
2024-03-28 18:02:25,481 - config - INFO - Validation Loss: 0.3874
2024-03-28 18:02:25,500 - config - INFO - Epoch [66/200], Train Loss: 0.4645
2024-03-28 18:02:25,504 - config - INFO - Validation Loss: 0.3874
2024-03-28 18:02:25,523 - config - INFO - Epoch [67/200], Train Loss: 0.4646
2024-03-28 18:02:25,527 - config - INFO - Validation Loss: 0.3873
2024-03-28 18:02:25,546 - config - INFO - Epoch [68/200], Train Loss: 0.4646
2024-03-28 18:02:25,550 - config - INFO - Validation Loss: 0.3869
2024-03-28 18:02:25,568 - config - INFO - Epoch [69/200], Train Loss: 0.4644
2024-03-28 18:02:25,572 - config - INFO - Validation Loss: 0.3867
2024-03-28 18:02:25,591 - config - INFO - Epoch [70/200], Train Loss: 0.4644
2024-03-28 18:02:25,595 - config - INFO - Validation Loss: 0.3864
2024-03-28 18:02:25,613 - config - INFO - Epoch [71/200], Train Loss: 0.4646
2024-03-28 18:02:25,618 - config - INFO - Validation Loss: 0.3875
2024-03-28 18:02:25,636 - config - INFO - Epoch [72/200], Train Loss: 0.4649
2024-03-28 18:02:25,641 - config - INFO - Validation Loss: 0.3860
2024-03-28 18:02:25,659 - config - INFO - Epoch [73/200], Train Loss: 0.4651
2024-03-28 18:02:25,663 - config - INFO - Validation Loss: 0.3887
2024-03-28 18:02:25,682 - config - INFO - Epoch [74/200], Train Loss: 0.4646
2024-03-28 18:02:25,686 - config - INFO - Validation Loss: 0.3864
2024-03-28 18:02:25,705 - config - INFO - Epoch [75/200], Train Loss: 0.4644
2024-03-28 18:02:25,709 - config - INFO - Validation Loss: 0.3881
2024-03-28 18:02:25,727 - config - INFO - Epoch [76/200], Train Loss: 0.4641
2024-03-28 18:02:25,731 - config - INFO - Validation Loss: 0.3878
2024-03-28 18:02:25,750 - config - INFO - Epoch [77/200], Train Loss: 0.4651
2024-03-28 18:02:25,754 - config - INFO - Validation Loss: 0.3857
2024-03-28 18:02:25,772 - config - INFO - Epoch [78/200], Train Loss: 0.4641
2024-03-28 18:02:25,776 - config - INFO - Validation Loss: 0.3862
2024-03-28 18:02:25,795 - config - INFO - Epoch [79/200], Train Loss: 0.4638
2024-03-28 18:02:25,799 - config - INFO - Validation Loss: 0.3863
2024-03-28 18:02:25,818 - config - INFO - Epoch [80/200], Train Loss: 0.4639
2024-03-28 18:02:25,822 - config - INFO - Validation Loss: 0.3862
2024-03-28 18:02:25,840 - config - INFO - Epoch [81/200], Train Loss: 0.4641
2024-03-28 18:02:25,844 - config - INFO - Validation Loss: 0.3853
2024-03-28 18:02:25,863 - config - INFO - Epoch [82/200], Train Loss: 0.4640
2024-03-28 18:02:25,867 - config - INFO - Validation Loss: 0.3863
2024-03-28 18:02:25,885 - config - INFO - Epoch [83/200], Train Loss: 0.4636
2024-03-28 18:02:25,889 - config - INFO - Validation Loss: 0.3855
2024-03-28 18:02:25,908 - config - INFO - Epoch [84/200], Train Loss: 0.4634
2024-03-28 18:02:25,912 - config - INFO - Validation Loss: 0.3852
2024-03-28 18:02:25,931 - config - INFO - Epoch [85/200], Train Loss: 0.4634
2024-03-28 18:02:25,935 - config - INFO - Validation Loss: 0.3855
2024-03-28 18:02:25,953 - config - INFO - Epoch [86/200], Train Loss: 0.4637
2024-03-28 18:02:25,963 - config - INFO - Validation Loss: 0.3878
2024-03-28 18:02:25,982 - config - INFO - Epoch [87/200], Train Loss: 0.4642
2024-03-28 18:02:25,986 - config - INFO - Validation Loss: 0.3881
2024-03-28 18:02:26,004 - config - INFO - Epoch [88/200], Train Loss: 0.4635
2024-03-28 18:02:26,008 - config - INFO - Validation Loss: 0.3850
2024-03-28 18:02:26,027 - config - INFO - Epoch [89/200], Train Loss: 0.4641
2024-03-28 18:02:26,031 - config - INFO - Validation Loss: 0.3847
2024-03-28 18:02:26,050 - config - INFO - Epoch [90/200], Train Loss: 0.4631
2024-03-28 18:02:26,054 - config - INFO - Validation Loss: 0.3856
2024-03-28 18:02:26,072 - config - INFO - Epoch [91/200], Train Loss: 0.4634
2024-03-28 18:02:26,076 - config - INFO - Validation Loss: 0.3889
2024-03-28 18:02:26,095 - config - INFO - Epoch [92/200], Train Loss: 0.4638
2024-03-28 18:02:26,099 - config - INFO - Validation Loss: 0.3887
2024-03-28 18:02:26,117 - config - INFO - Epoch [93/200], Train Loss: 0.4627
2024-03-28 18:02:26,121 - config - INFO - Validation Loss: 0.3859
2024-03-28 18:02:26,140 - config - INFO - Epoch [94/200], Train Loss: 0.4639
2024-03-28 18:02:26,144 - config - INFO - Validation Loss: 0.3843
2024-03-28 18:02:26,163 - config - INFO - Epoch [95/200], Train Loss: 0.4632
2024-03-28 18:02:26,167 - config - INFO - Validation Loss: 0.3854
2024-03-28 18:02:26,185 - config - INFO - Epoch [96/200], Train Loss: 0.4624
2024-03-28 18:02:26,189 - config - INFO - Validation Loss: 0.3875
2024-03-28 18:02:26,208 - config - INFO - Epoch [97/200], Train Loss: 0.4632
2024-03-28 18:02:26,212 - config - INFO - Validation Loss: 0.3856
2024-03-28 18:02:26,230 - config - INFO - Epoch [98/200], Train Loss: 0.4623
2024-03-28 18:02:26,234 - config - INFO - Validation Loss: 0.3850
2024-03-28 18:02:26,253 - config - INFO - Epoch [99/200], Train Loss: 0.4626
2024-03-28 18:02:26,257 - config - INFO - Validation Loss: 0.3855
2024-03-28 18:02:26,276 - config - INFO - Epoch [100/200], Train Loss: 0.4623
2024-03-28 18:02:26,280 - config - INFO - Validation Loss: 0.3862
2024-03-28 18:02:26,298 - config - INFO - Epoch [101/200], Train Loss: 0.4623
2024-03-28 18:02:26,302 - config - INFO - Validation Loss: 0.3862
2024-03-28 18:02:26,321 - config - INFO - Epoch [102/200], Train Loss: 0.4622
2024-03-28 18:02:26,325 - config - INFO - Validation Loss: 0.3858
2024-03-28 18:02:26,343 - config - INFO - Epoch [103/200], Train Loss: 0.4625
2024-03-28 18:02:26,348 - config - INFO - Validation Loss: 0.3857
2024-03-28 18:02:26,366 - config - INFO - Epoch [104/200], Train Loss: 0.4621
2024-03-28 18:02:26,370 - config - INFO - Validation Loss: 0.3871
2024-03-28 18:02:26,389 - config - INFO - Epoch [105/200], Train Loss: 0.4620
2024-03-28 18:02:26,393 - config - INFO - Validation Loss: 0.3857
2024-03-28 18:02:26,411 - config - INFO - Epoch [106/200], Train Loss: 0.4619
2024-03-28 18:02:26,415 - config - INFO - Validation Loss: 0.3865
2024-03-28 18:02:26,434 - config - INFO - Epoch [107/200], Train Loss: 0.4617
2024-03-28 18:02:26,438 - config - INFO - Validation Loss: 0.3857
2024-03-28 18:02:26,457 - config - INFO - Epoch [108/200], Train Loss: 0.4621
2024-03-28 18:02:26,461 - config - INFO - Validation Loss: 0.3855
2024-03-28 18:02:26,479 - config - INFO - Epoch [109/200], Train Loss: 0.4618
2024-03-28 18:02:26,483 - config - INFO - Validation Loss: 0.3856
2024-03-28 18:02:26,502 - config - INFO - Epoch [110/200], Train Loss: 0.4617
2024-03-28 18:02:26,506 - config - INFO - Validation Loss: 0.3854
2024-03-28 18:02:26,524 - config - INFO - Epoch [111/200], Train Loss: 0.4620
2024-03-28 18:02:26,528 - config - INFO - Validation Loss: 0.3842
2024-03-28 18:02:26,547 - config - INFO - Epoch [112/200], Train Loss: 0.4615
2024-03-28 18:02:26,551 - config - INFO - Validation Loss: 0.3855
2024-03-28 18:02:26,570 - config - INFO - Epoch [113/200], Train Loss: 0.4613
2024-03-28 18:02:26,574 - config - INFO - Validation Loss: 0.3855
2024-03-28 18:02:26,592 - config - INFO - Epoch [114/200], Train Loss: 0.4627
2024-03-28 18:02:26,596 - config - INFO - Validation Loss: 0.3877
2024-03-28 18:02:26,615 - config - INFO - Epoch [115/200], Train Loss: 0.4609
2024-03-28 18:02:26,619 - config - INFO - Validation Loss: 0.3860
2024-03-28 18:02:26,638 - config - INFO - Epoch [116/200], Train Loss: 0.4607
2024-03-28 18:02:26,642 - config - INFO - Validation Loss: 0.3853
2024-03-28 18:02:26,660 - config - INFO - Epoch [117/200], Train Loss: 0.4609
2024-03-28 18:02:26,664 - config - INFO - Validation Loss: 0.3859
2024-03-28 18:02:26,683 - config - INFO - Epoch [118/200], Train Loss: 0.4609
2024-03-28 18:02:26,687 - config - INFO - Validation Loss: 0.3865
2024-03-28 18:02:26,705 - config - INFO - Epoch [119/200], Train Loss: 0.4607
2024-03-28 18:02:26,709 - config - INFO - Validation Loss: 0.3862
2024-03-28 18:02:26,728 - config - INFO - Epoch [120/200], Train Loss: 0.4606
2024-03-28 18:02:26,732 - config - INFO - Validation Loss: 0.3864
2024-03-28 18:02:26,750 - config - INFO - Epoch [121/200], Train Loss: 0.4615
2024-03-28 18:02:26,754 - config - INFO - Validation Loss: 0.3874
2024-03-28 18:02:26,773 - config - INFO - Epoch [122/200], Train Loss: 0.4617
2024-03-28 18:02:26,777 - config - INFO - Validation Loss: 0.3849
2024-03-28 18:02:26,795 - config - INFO - Epoch [123/200], Train Loss: 0.4607
2024-03-28 18:02:26,799 - config - INFO - Validation Loss: 0.3853
2024-03-28 18:02:26,818 - config - INFO - Epoch [124/200], Train Loss: 0.4608
2024-03-28 18:02:26,822 - config - INFO - Validation Loss: 0.3876
2024-03-28 18:02:26,841 - config - INFO - Epoch [125/200], Train Loss: 0.4607
2024-03-28 18:02:26,845 - config - INFO - Validation Loss: 0.3870
2024-03-28 18:02:26,863 - config - INFO - Epoch [126/200], Train Loss: 0.4603
2024-03-28 18:02:26,867 - config - INFO - Validation Loss: 0.3852
2024-03-28 18:02:26,886 - config - INFO - Epoch [127/200], Train Loss: 0.4601
2024-03-28 18:02:26,890 - config - INFO - Validation Loss: 0.3849
2024-03-28 18:02:26,908 - config - INFO - Epoch [128/200], Train Loss: 0.4602
2024-03-28 18:02:26,912 - config - INFO - Validation Loss: 0.3854
2024-03-28 18:02:26,931 - config - INFO - Epoch [129/200], Train Loss: 0.4606
2024-03-28 18:02:26,935 - config - INFO - Validation Loss: 0.3841
2024-03-28 18:02:26,953 - config - INFO - Epoch [130/200], Train Loss: 0.4606
2024-03-28 18:02:26,972 - config - INFO - Validation Loss: 0.3843
2024-03-28 18:02:26,992 - config - INFO - Epoch [131/200], Train Loss: 0.4599
2024-03-28 18:02:26,996 - config - INFO - Validation Loss: 0.3866
2024-03-28 18:02:27,014 - config - INFO - Epoch [132/200], Train Loss: 0.4599
2024-03-28 18:02:27,018 - config - INFO - Validation Loss: 0.3868
2024-03-28 18:02:27,037 - config - INFO - Epoch [133/200], Train Loss: 0.4596
2024-03-28 18:02:27,040 - config - INFO - Validation Loss: 0.3860
2024-03-28 18:02:27,059 - config - INFO - Epoch [134/200], Train Loss: 0.4594
2024-03-28 18:02:27,063 - config - INFO - Validation Loss: 0.3852
2024-03-28 18:02:27,081 - config - INFO - Epoch [135/200], Train Loss: 0.4599
2024-03-28 18:02:27,085 - config - INFO - Validation Loss: 0.3847
2024-03-28 18:02:27,103 - config - INFO - Epoch [136/200], Train Loss: 0.4595
2024-03-28 18:02:27,107 - config - INFO - Validation Loss: 0.3842
2024-03-28 18:02:27,125 - config - INFO - Epoch [137/200], Train Loss: 0.4591
2024-03-28 18:02:27,129 - config - INFO - Validation Loss: 0.3844
2024-03-28 18:02:27,147 - config - INFO - Epoch [138/200], Train Loss: 0.4594
2024-03-28 18:02:27,151 - config - INFO - Validation Loss: 0.3850
2024-03-28 18:02:27,169 - config - INFO - Epoch [139/200], Train Loss: 0.4594
2024-03-28 18:02:27,173 - config - INFO - Validation Loss: 0.3867
2024-03-28 18:02:27,192 - config - INFO - Epoch [140/200], Train Loss: 0.4589
2024-03-28 18:02:27,195 - config - INFO - Validation Loss: 0.3855
2024-03-28 18:02:27,214 - config - INFO - Epoch [141/200], Train Loss: 0.4599
2024-03-28 18:02:27,218 - config - INFO - Validation Loss: 0.3856
2024-03-28 18:02:27,236 - config - INFO - Epoch [142/200], Train Loss: 0.4584
2024-03-28 18:02:27,240 - config - INFO - Validation Loss: 0.3838
2024-03-28 18:02:27,258 - config - INFO - Epoch [143/200], Train Loss: 0.4593
2024-03-28 18:02:27,262 - config - INFO - Validation Loss: 0.3840
2024-03-28 18:02:27,280 - config - INFO - Epoch [144/200], Train Loss: 0.4591
2024-03-28 18:02:27,284 - config - INFO - Validation Loss: 0.3863
2024-03-28 18:02:27,302 - config - INFO - Epoch [145/200], Train Loss: 0.4588
2024-03-28 18:02:27,306 - config - INFO - Validation Loss: 0.3847
2024-03-28 18:02:27,324 - config - INFO - Epoch [146/200], Train Loss: 0.4584
2024-03-28 18:02:27,328 - config - INFO - Validation Loss: 0.3845
2024-03-28 18:02:27,347 - config - INFO - Epoch [147/200], Train Loss: 0.4585
2024-03-28 18:02:27,350 - config - INFO - Validation Loss: 0.3853
2024-03-28 18:02:27,369 - config - INFO - Epoch [148/200], Train Loss: 0.4580
2024-03-28 18:02:27,373 - config - INFO - Validation Loss: 0.3849
2024-03-28 18:02:27,391 - config - INFO - Epoch [149/200], Train Loss: 0.4584
2024-03-28 18:02:27,395 - config - INFO - Validation Loss: 0.3852
2024-03-28 18:02:27,413 - config - INFO - Epoch [150/200], Train Loss: 0.4586
2024-03-28 18:02:27,417 - config - INFO - Validation Loss: 0.3842
2024-03-28 18:02:27,435 - config - INFO - Epoch [151/200], Train Loss: 0.4583
2024-03-28 18:02:27,439 - config - INFO - Validation Loss: 0.3864
2024-03-28 18:02:27,457 - config - INFO - Epoch [152/200], Train Loss: 0.4579
2024-03-28 18:02:27,461 - config - INFO - Validation Loss: 0.3856
2024-03-28 18:02:27,479 - config - INFO - Epoch [153/200], Train Loss: 0.4578
2024-03-28 18:02:27,483 - config - INFO - Validation Loss: 0.3850
2024-03-28 18:02:27,502 - config - INFO - Epoch [154/200], Train Loss: 0.4577
2024-03-28 18:02:27,505 - config - INFO - Validation Loss: 0.3829
2024-03-28 18:02:27,524 - config - INFO - Epoch [155/200], Train Loss: 0.4577
2024-03-28 18:02:27,528 - config - INFO - Validation Loss: 0.3827
2024-03-28 18:02:27,546 - config - INFO - Epoch [156/200], Train Loss: 0.4570
2024-03-28 18:02:27,550 - config - INFO - Validation Loss: 0.3848
2024-03-28 18:02:27,568 - config - INFO - Epoch [157/200], Train Loss: 0.4575
2024-03-28 18:02:27,572 - config - INFO - Validation Loss: 0.3850
2024-03-28 18:02:27,590 - config - INFO - Epoch [158/200], Train Loss: 0.4577
2024-03-28 18:02:27,594 - config - INFO - Validation Loss: 0.3828
2024-03-28 18:02:27,612 - config - INFO - Epoch [159/200], Train Loss: 0.4572
2024-03-28 18:02:27,616 - config - INFO - Validation Loss: 0.3837
2024-03-28 18:02:27,634 - config - INFO - Epoch [160/200], Train Loss: 0.4573
2024-03-28 18:02:27,638 - config - INFO - Validation Loss: 0.3829
2024-03-28 18:02:27,656 - config - INFO - Epoch [161/200], Train Loss: 0.4573
2024-03-28 18:02:27,660 - config - INFO - Validation Loss: 0.3833
2024-03-28 18:02:27,678 - config - INFO - Epoch [162/200], Train Loss: 0.4564
2024-03-28 18:02:27,682 - config - INFO - Validation Loss: 0.3851
2024-03-28 18:02:27,700 - config - INFO - Epoch [163/200], Train Loss: 0.4567
2024-03-28 18:02:27,704 - config - INFO - Validation Loss: 0.3847
2024-03-28 18:02:27,723 - config - INFO - Epoch [164/200], Train Loss: 0.4570
2024-03-28 18:02:27,727 - config - INFO - Validation Loss: 0.3843
2024-03-28 18:02:27,745 - config - INFO - Epoch [165/200], Train Loss: 0.4572
2024-03-28 18:02:27,749 - config - INFO - Validation Loss: 0.3860
2024-03-28 18:02:27,767 - config - INFO - Epoch [166/200], Train Loss: 0.4564
2024-03-28 18:02:27,771 - config - INFO - Validation Loss: 0.3855
2024-03-28 18:02:27,789 - config - INFO - Epoch [167/200], Train Loss: 0.4565
2024-03-28 18:02:27,793 - config - INFO - Validation Loss: 0.3845
2024-03-28 18:02:27,811 - config - INFO - Epoch [168/200], Train Loss: 0.4566
2024-03-28 18:02:27,815 - config - INFO - Validation Loss: 0.3851
2024-03-28 18:02:27,833 - config - INFO - Epoch [169/200], Train Loss: 0.4557
2024-03-28 18:02:27,837 - config - INFO - Validation Loss: 0.3847
2024-03-28 18:02:27,856 - config - INFO - Epoch [170/200], Train Loss: 0.4564
2024-03-28 18:02:27,859 - config - INFO - Validation Loss: 0.3851
2024-03-28 18:02:27,878 - config - INFO - Epoch [171/200], Train Loss: 0.4557
2024-03-28 18:02:27,882 - config - INFO - Validation Loss: 0.3854
2024-03-28 18:02:27,900 - config - INFO - Epoch [172/200], Train Loss: 0.4555
2024-03-28 18:02:27,904 - config - INFO - Validation Loss: 0.3855
2024-03-28 18:02:27,922 - config - INFO - Epoch [173/200], Train Loss: 0.4555
2024-03-28 18:02:27,926 - config - INFO - Validation Loss: 0.3854
2024-03-28 18:02:27,944 - config - INFO - Epoch [174/200], Train Loss: 0.4558
2024-03-28 18:02:27,948 - config - INFO - Validation Loss: 0.3846
2024-03-28 18:02:27,966 - config - INFO - Epoch [175/200], Train Loss: 0.4562
2024-03-28 18:02:27,970 - config - INFO - Validation Loss: 0.3867
2024-03-28 18:02:27,988 - config - INFO - Epoch [176/200], Train Loss: 0.4555
2024-03-28 18:02:27,992 - config - INFO - Validation Loss: 0.3873
2024-03-28 18:02:28,011 - config - INFO - Epoch [177/200], Train Loss: 0.4556
2024-03-28 18:02:28,015 - config - INFO - Validation Loss: 0.3873
2024-03-28 18:02:28,033 - config - INFO - Epoch [178/200], Train Loss: 0.4551
2024-03-28 18:02:28,037 - config - INFO - Validation Loss: 0.3848
2024-03-28 18:02:28,055 - config - INFO - Epoch [179/200], Train Loss: 0.4549
2024-03-28 18:02:28,059 - config - INFO - Validation Loss: 0.3844
2024-03-28 18:02:28,077 - config - INFO - Epoch [180/200], Train Loss: 0.4550
2024-03-28 18:02:28,081 - config - INFO - Validation Loss: 0.3850
2024-03-28 18:02:28,099 - config - INFO - Epoch [181/200], Train Loss: 0.4546
2024-03-28 18:02:28,103 - config - INFO - Validation Loss: 0.3851
2024-03-28 18:02:28,121 - config - INFO - Epoch [182/200], Train Loss: 0.4548
2024-03-28 18:02:28,125 - config - INFO - Validation Loss: 0.3857
2024-03-28 18:02:28,144 - config - INFO - Epoch [183/200], Train Loss: 0.4547
2024-03-28 18:02:28,148 - config - INFO - Validation Loss: 0.3859
2024-03-28 18:02:28,166 - config - INFO - Epoch [184/200], Train Loss: 0.4546
2024-03-28 18:02:28,170 - config - INFO - Validation Loss: 0.3862
2024-03-28 18:02:28,188 - config - INFO - Epoch [185/200], Train Loss: 0.4540
2024-03-28 18:02:28,192 - config - INFO - Validation Loss: 0.3868
2024-03-28 18:02:28,210 - config - INFO - Epoch [186/200], Train Loss: 0.4538
2024-03-28 18:02:28,214 - config - INFO - Validation Loss: 0.3867
2024-03-28 18:02:28,232 - config - INFO - Epoch [187/200], Train Loss: 0.4551
2024-03-28 18:02:28,236 - config - INFO - Validation Loss: 0.3879
2024-03-28 18:02:28,254 - config - INFO - Epoch [188/200], Train Loss: 0.4546
2024-03-28 18:02:28,258 - config - INFO - Validation Loss: 0.3848
2024-03-28 18:02:28,277 - config - INFO - Epoch [189/200], Train Loss: 0.4538
2024-03-28 18:02:28,281 - config - INFO - Validation Loss: 0.3859
2024-03-28 18:02:28,299 - config - INFO - Epoch [190/200], Train Loss: 0.4539
2024-03-28 18:02:28,303 - config - INFO - Validation Loss: 0.3847
2024-03-28 18:02:28,321 - config - INFO - Epoch [191/200], Train Loss: 0.4539
2024-03-28 18:02:28,325 - config - INFO - Validation Loss: 0.3851
2024-03-28 18:02:28,343 - config - INFO - Epoch [192/200], Train Loss: 0.4535
2024-03-28 18:02:28,347 - config - INFO - Validation Loss: 0.3861
2024-03-28 18:02:28,365 - config - INFO - Epoch [193/200], Train Loss: 0.4534
2024-03-28 18:02:28,369 - config - INFO - Validation Loss: 0.3866
2024-03-28 18:02:28,388 - config - INFO - Epoch [194/200], Train Loss: 0.4538
2024-03-28 18:02:28,391 - config - INFO - Validation Loss: 0.3848
2024-03-28 18:02:28,410 - config - INFO - Epoch [195/200], Train Loss: 0.4532
2024-03-28 18:02:28,414 - config - INFO - Validation Loss: 0.3846
2024-03-28 18:02:28,432 - config - INFO - Epoch [196/200], Train Loss: 0.4529
2024-03-28 18:02:28,436 - config - INFO - Validation Loss: 0.3856
2024-03-28 18:02:28,454 - config - INFO - Epoch [197/200], Train Loss: 0.4527
2024-03-28 18:02:28,458 - config - INFO - Validation Loss: 0.3853
2024-03-28 18:02:28,476 - config - INFO - Epoch [198/200], Train Loss: 0.4531
2024-03-28 18:02:28,480 - config - INFO - Validation Loss: 0.3849
2024-03-28 18:02:28,499 - config - INFO - Epoch [199/200], Train Loss: 0.4520
2024-03-28 18:02:28,502 - config - INFO - Validation Loss: 0.3843
2024-03-28 18:02:28,521 - config - INFO - Epoch [200/200], Train Loss: 0.4526
2024-03-28 18:02:28,525 - config - INFO - Validation Loss: 0.3845
2024-03-28 18:02:54,372 - config - INFO - resume: None
2024-03-28 18:02:54,372 - config - INFO - device: cpu
2024-03-28 18:02:54,372 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-28 18:02:54,372 - config - INFO - learning_rate: 0.001
2024-03-28 18:02:54,372 - config - INFO - num_epochs: 2000
2024-03-28 18:02:54,372 - config - INFO - batch_size: 64
2024-03-28 18:02:54,372 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = None
        self.prev_val_loss = float('inf')
        self.tolerance = 0.03

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 18:02:54,386 - config - INFO - Dataset size: 891
2024-03-28 18:02:54,411 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.6 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()

    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 18:02:54,411 - config - INFO - Training start
2024-03-28 18:02:56,748 - config - INFO - Epoch [1/2000], Train Loss: 0.6835
2024-03-28 18:02:56,755 - config - INFO - Validation Loss: 0.6704
2024-03-28 18:02:56,789 - config - INFO - Epoch [2/2000], Train Loss: 0.6482
2024-03-28 18:02:56,794 - config - INFO - Validation Loss: 0.6648
2024-03-28 18:02:56,819 - config - INFO - Epoch [3/2000], Train Loss: 0.6332
2024-03-28 18:02:56,824 - config - INFO - Validation Loss: 0.6508
2024-03-28 18:02:56,848 - config - INFO - Epoch [4/2000], Train Loss: 0.6202
2024-03-28 18:02:56,853 - config - INFO - Validation Loss: 0.6373
2024-03-28 18:02:56,878 - config - INFO - Epoch [5/2000], Train Loss: 0.6081
2024-03-28 18:02:56,883 - config - INFO - Validation Loss: 0.6249
2024-03-28 18:02:56,907 - config - INFO - Epoch [6/2000], Train Loss: 0.5963
2024-03-28 18:02:56,912 - config - INFO - Validation Loss: 0.6129
2024-03-28 18:02:56,937 - config - INFO - Epoch [7/2000], Train Loss: 0.5854
2024-03-28 18:02:56,942 - config - INFO - Validation Loss: 0.5994
2024-03-28 18:02:56,965 - config - INFO - Epoch [8/2000], Train Loss: 0.5736
2024-03-28 18:02:56,970 - config - INFO - Validation Loss: 0.5898
2024-03-28 18:02:56,994 - config - INFO - Epoch [9/2000], Train Loss: 0.5629
2024-03-28 18:02:56,999 - config - INFO - Validation Loss: 0.5797
2024-03-28 18:02:57,023 - config - INFO - Epoch [10/2000], Train Loss: 0.5531
2024-03-28 18:02:57,028 - config - INFO - Validation Loss: 0.5695
2024-03-28 18:02:57,054 - config - INFO - Epoch [11/2000], Train Loss: 0.5430
2024-03-28 18:02:57,059 - config - INFO - Validation Loss: 0.5619
2024-03-28 18:02:57,083 - config - INFO - Epoch [12/2000], Train Loss: 0.5339
2024-03-28 18:02:57,088 - config - INFO - Validation Loss: 0.5508
2024-03-28 18:02:57,110 - config - INFO - Epoch [13/2000], Train Loss: 0.5249
2024-03-28 18:02:57,115 - config - INFO - Validation Loss: 0.5415
2024-03-28 18:02:57,138 - config - INFO - Epoch [14/2000], Train Loss: 0.5166
2024-03-28 18:02:57,143 - config - INFO - Validation Loss: 0.5349
2024-03-28 18:02:57,166 - config - INFO - Epoch [15/2000], Train Loss: 0.5088
2024-03-28 18:02:57,171 - config - INFO - Validation Loss: 0.5278
2024-03-28 18:02:57,193 - config - INFO - Epoch [16/2000], Train Loss: 0.5019
2024-03-28 18:02:57,198 - config - INFO - Validation Loss: 0.5224
2024-03-28 18:02:57,221 - config - INFO - Epoch [17/2000], Train Loss: 0.4951
2024-03-28 18:02:57,225 - config - INFO - Validation Loss: 0.5148
2024-03-28 18:02:57,247 - config - INFO - Epoch [18/2000], Train Loss: 0.4887
2024-03-28 18:02:57,252 - config - INFO - Validation Loss: 0.5075
2024-03-28 18:02:57,274 - config - INFO - Epoch [19/2000], Train Loss: 0.4835
2024-03-28 18:02:57,278 - config - INFO - Validation Loss: 0.5024
2024-03-28 18:02:57,300 - config - INFO - Epoch [20/2000], Train Loss: 0.4786
2024-03-28 18:02:57,305 - config - INFO - Validation Loss: 0.4987
2024-03-28 18:02:57,326 - config - INFO - Epoch [21/2000], Train Loss: 0.4735
2024-03-28 18:02:57,331 - config - INFO - Validation Loss: 0.4936
2024-03-28 18:02:57,352 - config - INFO - Epoch [22/2000], Train Loss: 0.4686
2024-03-28 18:02:57,357 - config - INFO - Validation Loss: 0.4882
2024-03-28 18:02:57,379 - config - INFO - Epoch [23/2000], Train Loss: 0.4668
2024-03-28 18:02:57,383 - config - INFO - Validation Loss: 0.4845
2024-03-28 18:02:57,405 - config - INFO - Epoch [24/2000], Train Loss: 0.4634
2024-03-28 18:02:57,409 - config - INFO - Validation Loss: 0.4812
2024-03-28 18:02:57,431 - config - INFO - Epoch [25/2000], Train Loss: 0.4588
2024-03-28 18:02:57,436 - config - INFO - Validation Loss: 0.4803
2024-03-28 18:02:57,457 - config - INFO - Epoch [26/2000], Train Loss: 0.4566
2024-03-28 18:02:57,462 - config - INFO - Validation Loss: 0.4775
2024-03-28 18:02:57,483 - config - INFO - Epoch [27/2000], Train Loss: 0.4547
2024-03-28 18:02:57,488 - config - INFO - Validation Loss: 0.4763
2024-03-28 18:02:57,509 - config - INFO - Epoch [28/2000], Train Loss: 0.4522
2024-03-28 18:02:57,514 - config - INFO - Validation Loss: 0.4713
2024-03-28 18:02:57,552 - config - INFO - Epoch [29/2000], Train Loss: 0.4500
2024-03-28 18:02:57,558 - config - INFO - Validation Loss: 0.4693
2024-03-28 18:02:57,579 - config - INFO - Epoch [30/2000], Train Loss: 0.4470
2024-03-28 18:02:57,584 - config - INFO - Validation Loss: 0.4685
2024-03-28 18:02:57,605 - config - INFO - Epoch [31/2000], Train Loss: 0.4457
2024-03-28 18:02:57,610 - config - INFO - Validation Loss: 0.4678
2024-03-28 18:02:57,631 - config - INFO - Epoch [32/2000], Train Loss: 0.4447
2024-03-28 18:02:57,635 - config - INFO - Validation Loss: 0.4657
2024-03-28 18:02:57,657 - config - INFO - Epoch [33/2000], Train Loss: 0.4434
2024-03-28 18:02:57,661 - config - INFO - Validation Loss: 0.4627
2024-03-28 18:02:57,683 - config - INFO - Epoch [34/2000], Train Loss: 0.4420
2024-03-28 18:02:57,687 - config - INFO - Validation Loss: 0.4623
2024-03-28 18:02:57,708 - config - INFO - Epoch [35/2000], Train Loss: 0.4408
2024-03-28 18:02:57,713 - config - INFO - Validation Loss: 0.4613
2024-03-28 18:02:57,734 - config - INFO - Epoch [36/2000], Train Loss: 0.4404
2024-03-28 18:02:57,739 - config - INFO - Validation Loss: 0.4614
2024-03-28 18:02:57,760 - config - INFO - Epoch [37/2000], Train Loss: 0.4394
2024-03-28 18:02:57,765 - config - INFO - Validation Loss: 0.4601
2024-03-28 18:02:57,786 - config - INFO - Epoch [38/2000], Train Loss: 0.4388
2024-03-28 18:02:57,791 - config - INFO - Validation Loss: 0.4590
2024-03-28 18:02:57,812 - config - INFO - Epoch [39/2000], Train Loss: 0.4385
2024-03-28 18:02:57,817 - config - INFO - Validation Loss: 0.4585
2024-03-28 18:02:57,838 - config - INFO - Epoch [40/2000], Train Loss: 0.4380
2024-03-28 18:02:57,843 - config - INFO - Validation Loss: 0.4575
2024-03-28 18:02:57,864 - config - INFO - Epoch [41/2000], Train Loss: 0.4375
2024-03-28 18:02:57,869 - config - INFO - Validation Loss: 0.4579
2024-03-28 18:02:57,890 - config - INFO - Epoch [42/2000], Train Loss: 0.4367
2024-03-28 18:02:57,895 - config - INFO - Validation Loss: 0.4566
2024-03-28 18:02:57,916 - config - INFO - Epoch [43/2000], Train Loss: 0.4375
2024-03-28 18:02:57,921 - config - INFO - Validation Loss: 0.4557
2024-03-28 18:02:57,942 - config - INFO - Epoch [44/2000], Train Loss: 0.4369
2024-03-28 18:02:57,946 - config - INFO - Validation Loss: 0.4575
2024-03-28 18:02:57,965 - config - INFO - Epoch [45/2000], Train Loss: 0.4363
2024-03-28 18:02:57,969 - config - INFO - Validation Loss: 0.4567
2024-03-28 18:02:57,988 - config - INFO - Epoch [46/2000], Train Loss: 0.4356
2024-03-28 18:02:57,992 - config - INFO - Validation Loss: 0.4553
2024-03-28 18:02:58,010 - config - INFO - Epoch [47/2000], Train Loss: 0.4355
2024-03-28 18:02:58,014 - config - INFO - Validation Loss: 0.4551
2024-03-28 18:02:58,033 - config - INFO - Epoch [48/2000], Train Loss: 0.4351
2024-03-28 18:02:58,037 - config - INFO - Validation Loss: 0.4553
2024-03-28 18:02:58,055 - config - INFO - Epoch [49/2000], Train Loss: 0.4351
2024-03-28 18:02:58,059 - config - INFO - Validation Loss: 0.4549
2024-03-28 18:02:58,078 - config - INFO - Epoch [50/2000], Train Loss: 0.4354
2024-03-28 18:02:58,082 - config - INFO - Validation Loss: 0.4554
2024-03-28 18:02:58,100 - config - INFO - Epoch [51/2000], Train Loss: 0.4347
2024-03-28 18:02:58,104 - config - INFO - Validation Loss: 0.4549
2024-03-28 18:02:58,123 - config - INFO - Epoch [52/2000], Train Loss: 0.4349
2024-03-28 18:02:58,127 - config - INFO - Validation Loss: 0.4540
2024-03-28 18:02:58,145 - config - INFO - Epoch [53/2000], Train Loss: 0.4346
2024-03-28 18:02:58,149 - config - INFO - Validation Loss: 0.4542
2024-03-28 18:02:58,168 - config - INFO - Epoch [54/2000], Train Loss: 0.4345
2024-03-28 18:02:58,172 - config - INFO - Validation Loss: 0.4546
2024-03-28 18:02:58,190 - config - INFO - Epoch [55/2000], Train Loss: 0.4347
2024-03-28 18:02:58,194 - config - INFO - Validation Loss: 0.4549
2024-03-28 18:02:58,212 - config - INFO - Epoch [56/2000], Train Loss: 0.4351
2024-03-28 18:02:58,216 - config - INFO - Validation Loss: 0.4533
2024-03-28 18:02:58,235 - config - INFO - Epoch [57/2000], Train Loss: 0.4346
2024-03-28 18:02:58,239 - config - INFO - Validation Loss: 0.4538
2024-03-28 18:02:58,257 - config - INFO - Epoch [58/2000], Train Loss: 0.4343
2024-03-28 18:02:58,261 - config - INFO - Validation Loss: 0.4535
2024-03-28 18:02:58,279 - config - INFO - Epoch [59/2000], Train Loss: 0.4338
2024-03-28 18:02:58,283 - config - INFO - Validation Loss: 0.4541
2024-03-28 18:02:58,302 - config - INFO - Epoch [60/2000], Train Loss: 0.4344
2024-03-28 18:02:58,306 - config - INFO - Validation Loss: 0.4564
2024-03-28 18:02:58,324 - config - INFO - Epoch [61/2000], Train Loss: 0.4346
2024-03-28 18:02:58,328 - config - INFO - Validation Loss: 0.4539
2024-03-28 18:02:58,348 - config - INFO - Epoch [62/2000], Train Loss: 0.4349
2024-03-28 18:02:58,352 - config - INFO - Validation Loss: 0.4516
2024-03-28 18:02:58,374 - config - INFO - Epoch [63/2000], Train Loss: 0.4338
2024-03-28 18:02:58,378 - config - INFO - Validation Loss: 0.4516
2024-03-28 18:02:58,399 - config - INFO - Epoch [64/2000], Train Loss: 0.4339
2024-03-28 18:02:58,404 - config - INFO - Validation Loss: 0.4530
2024-03-28 18:02:58,425 - config - INFO - Epoch [65/2000], Train Loss: 0.4339
2024-03-28 18:02:58,430 - config - INFO - Validation Loss: 0.4530
2024-03-28 18:02:58,451 - config - INFO - Epoch [66/2000], Train Loss: 0.4343
2024-03-28 18:02:58,456 - config - INFO - Validation Loss: 0.4509
2024-03-28 18:02:58,477 - config - INFO - Epoch [67/2000], Train Loss: 0.4333
2024-03-28 18:02:58,481 - config - INFO - Validation Loss: 0.4513
2024-03-28 18:02:58,503 - config - INFO - Epoch [68/2000], Train Loss: 0.4335
2024-03-28 18:02:58,507 - config - INFO - Validation Loss: 0.4522
2024-03-28 18:02:58,528 - config - INFO - Epoch [69/2000], Train Loss: 0.4331
2024-03-28 18:02:58,534 - config - INFO - Validation Loss: 0.4514
2024-03-28 18:02:58,555 - config - INFO - Epoch [70/2000], Train Loss: 0.4332
2024-03-28 18:02:58,560 - config - INFO - Validation Loss: 0.4513
2024-03-28 18:02:58,581 - config - INFO - Epoch [71/2000], Train Loss: 0.4330
2024-03-28 18:02:58,586 - config - INFO - Validation Loss: 0.4516
2024-03-28 18:02:58,607 - config - INFO - Epoch [72/2000], Train Loss: 0.4334
2024-03-28 18:02:58,612 - config - INFO - Validation Loss: 0.4503
2024-03-28 18:02:58,633 - config - INFO - Epoch [73/2000], Train Loss: 0.4329
2024-03-28 18:02:58,638 - config - INFO - Validation Loss: 0.4505
2024-03-28 18:02:58,659 - config - INFO - Epoch [74/2000], Train Loss: 0.4330
2024-03-28 18:02:58,663 - config - INFO - Validation Loss: 0.4516
2024-03-28 18:02:58,684 - config - INFO - Epoch [75/2000], Train Loss: 0.4329
2024-03-28 18:02:58,689 - config - INFO - Validation Loss: 0.4512
2024-03-28 18:02:58,710 - config - INFO - Epoch [76/2000], Train Loss: 0.4327
2024-03-28 18:02:58,715 - config - INFO - Validation Loss: 0.4506
2024-03-28 18:02:58,736 - config - INFO - Epoch [77/2000], Train Loss: 0.4328
2024-03-28 18:02:58,741 - config - INFO - Validation Loss: 0.4505
2024-03-28 18:02:58,762 - config - INFO - Epoch [78/2000], Train Loss: 0.4327
2024-03-28 18:02:58,767 - config - INFO - Validation Loss: 0.4509
2024-03-28 18:02:58,788 - config - INFO - Epoch [79/2000], Train Loss: 0.4324
2024-03-28 18:02:58,792 - config - INFO - Validation Loss: 0.4501
2024-03-28 18:02:58,814 - config - INFO - Epoch [80/2000], Train Loss: 0.4336
2024-03-28 18:02:58,818 - config - INFO - Validation Loss: 0.4494
2024-03-28 18:02:58,841 - config - INFO - Epoch [81/2000], Train Loss: 0.4327
2024-03-28 18:02:58,846 - config - INFO - Validation Loss: 0.4504
2024-03-28 18:02:58,867 - config - INFO - Epoch [82/2000], Train Loss: 0.4324
2024-03-28 18:02:58,872 - config - INFO - Validation Loss: 0.4514
2024-03-28 18:02:58,893 - config - INFO - Epoch [83/2000], Train Loss: 0.4330
2024-03-28 18:02:58,898 - config - INFO - Validation Loss: 0.4502
2024-03-28 18:02:58,919 - config - INFO - Epoch [84/2000], Train Loss: 0.4323
2024-03-28 18:02:58,923 - config - INFO - Validation Loss: 0.4503
2024-03-28 18:02:58,945 - config - INFO - Epoch [85/2000], Train Loss: 0.4323
2024-03-28 18:02:58,949 - config - INFO - Validation Loss: 0.4502
2024-03-28 18:02:58,970 - config - INFO - Epoch [86/2000], Train Loss: 0.4327
2024-03-28 18:02:58,975 - config - INFO - Validation Loss: 0.4513
2024-03-28 18:02:58,996 - config - INFO - Epoch [87/2000], Train Loss: 0.4322
2024-03-28 18:02:59,001 - config - INFO - Validation Loss: 0.4513
2024-03-28 18:02:59,022 - config - INFO - Epoch [88/2000], Train Loss: 0.4324
2024-03-28 18:02:59,027 - config - INFO - Validation Loss: 0.4493
2024-03-28 18:02:59,053 - config - INFO - Epoch [89/2000], Train Loss: 0.4320
2024-03-28 18:02:59,058 - config - INFO - Validation Loss: 0.4499
2024-03-28 18:02:59,079 - config - INFO - Epoch [90/2000], Train Loss: 0.4320
2024-03-28 18:02:59,084 - config - INFO - Validation Loss: 0.4508
2024-03-28 18:02:59,105 - config - INFO - Epoch [91/2000], Train Loss: 0.4320
2024-03-28 18:02:59,109 - config - INFO - Validation Loss: 0.4497
2024-03-28 18:02:59,131 - config - INFO - Epoch [92/2000], Train Loss: 0.4321
2024-03-28 18:02:59,135 - config - INFO - Validation Loss: 0.4508
2024-03-28 18:02:59,156 - config - INFO - Epoch [93/2000], Train Loss: 0.4316
2024-03-28 18:02:59,161 - config - INFO - Validation Loss: 0.4492
2024-03-28 18:02:59,182 - config - INFO - Epoch [94/2000], Train Loss: 0.4320
2024-03-28 18:02:59,187 - config - INFO - Validation Loss: 0.4490
2024-03-28 18:02:59,208 - config - INFO - Epoch [95/2000], Train Loss: 0.4320
2024-03-28 18:02:59,213 - config - INFO - Validation Loss: 0.4491
2024-03-28 18:02:59,234 - config - INFO - Epoch [96/2000], Train Loss: 0.4315
2024-03-28 18:02:59,238 - config - INFO - Validation Loss: 0.4505
2024-03-28 18:02:59,260 - config - INFO - Epoch [97/2000], Train Loss: 0.4313
2024-03-28 18:02:59,264 - config - INFO - Validation Loss: 0.4493
2024-03-28 18:02:59,285 - config - INFO - Epoch [98/2000], Train Loss: 0.4316
2024-03-28 18:02:59,290 - config - INFO - Validation Loss: 0.4494
2024-03-28 18:02:59,308 - config - INFO - Epoch [99/2000], Train Loss: 0.4315
2024-03-28 18:02:59,312 - config - INFO - Validation Loss: 0.4507
2024-03-28 18:02:59,330 - config - INFO - Epoch [100/2000], Train Loss: 0.4318
2024-03-28 18:02:59,334 - config - INFO - Validation Loss: 0.4493
2024-03-28 18:02:59,352 - config - INFO - Epoch [101/2000], Train Loss: 0.4309
2024-03-28 18:02:59,356 - config - INFO - Validation Loss: 0.4498
2024-03-28 18:02:59,375 - config - INFO - Epoch [102/2000], Train Loss: 0.4314
2024-03-28 18:02:59,387 - config - INFO - Validation Loss: 0.4495
2024-03-28 18:02:59,405 - config - INFO - Epoch [103/2000], Train Loss: 0.4310
2024-03-28 18:02:59,409 - config - INFO - Validation Loss: 0.4500
2024-03-28 18:02:59,427 - config - INFO - Epoch [104/2000], Train Loss: 0.4309
2024-03-28 18:02:59,431 - config - INFO - Validation Loss: 0.4502
2024-03-28 18:02:59,449 - config - INFO - Epoch [105/2000], Train Loss: 0.4312
2024-03-28 18:02:59,453 - config - INFO - Validation Loss: 0.4501
2024-03-28 18:02:59,472 - config - INFO - Epoch [106/2000], Train Loss: 0.4310
2024-03-28 18:02:59,476 - config - INFO - Validation Loss: 0.4512
2024-03-28 18:02:59,494 - config - INFO - Epoch [107/2000], Train Loss: 0.4311
2024-03-28 18:02:59,498 - config - INFO - Validation Loss: 0.4503
2024-03-28 18:02:59,516 - config - INFO - Epoch [108/2000], Train Loss: 0.4307
2024-03-28 18:02:59,520 - config - INFO - Validation Loss: 0.4497
2024-03-28 18:02:59,554 - config - INFO - Epoch [109/2000], Train Loss: 0.4305
2024-03-28 18:02:59,559 - config - INFO - Validation Loss: 0.4492
2024-03-28 18:02:59,581 - config - INFO - Epoch [110/2000], Train Loss: 0.4305
2024-03-28 18:02:59,586 - config - INFO - Validation Loss: 0.4483
2024-03-28 18:02:59,607 - config - INFO - Epoch [111/2000], Train Loss: 0.4309
2024-03-28 18:02:59,611 - config - INFO - Validation Loss: 0.4481
2024-03-28 18:02:59,632 - config - INFO - Epoch [112/2000], Train Loss: 0.4310
2024-03-28 18:02:59,637 - config - INFO - Validation Loss: 0.4494
2024-03-28 18:02:59,658 - config - INFO - Epoch [113/2000], Train Loss: 0.4306
2024-03-28 18:02:59,662 - config - INFO - Validation Loss: 0.4506
2024-03-28 18:02:59,684 - config - INFO - Epoch [114/2000], Train Loss: 0.4302
2024-03-28 18:02:59,688 - config - INFO - Validation Loss: 0.4495
2024-03-28 18:02:59,709 - config - INFO - Epoch [115/2000], Train Loss: 0.4302
2024-03-28 18:02:59,714 - config - INFO - Validation Loss: 0.4490
2024-03-28 18:02:59,735 - config - INFO - Epoch [116/2000], Train Loss: 0.4302
2024-03-28 18:02:59,739 - config - INFO - Validation Loss: 0.4498
2024-03-28 18:02:59,760 - config - INFO - Epoch [117/2000], Train Loss: 0.4304
2024-03-28 18:02:59,765 - config - INFO - Validation Loss: 0.4494
2024-03-28 18:02:59,786 - config - INFO - Epoch [118/2000], Train Loss: 0.4305
2024-03-28 18:02:59,791 - config - INFO - Validation Loss: 0.4485
2024-03-28 18:02:59,812 - config - INFO - Epoch [119/2000], Train Loss: 0.4301
2024-03-28 18:02:59,816 - config - INFO - Validation Loss: 0.4485
2024-03-28 18:02:59,837 - config - INFO - Epoch [120/2000], Train Loss: 0.4309
2024-03-28 18:02:59,842 - config - INFO - Validation Loss: 0.4510
2024-03-28 18:02:59,863 - config - INFO - Epoch [121/2000], Train Loss: 0.4297
2024-03-28 18:02:59,867 - config - INFO - Validation Loss: 0.4489
2024-03-28 18:02:59,888 - config - INFO - Epoch [122/2000], Train Loss: 0.4299
2024-03-28 18:02:59,893 - config - INFO - Validation Loss: 0.4481
2024-03-28 18:02:59,914 - config - INFO - Epoch [123/2000], Train Loss: 0.4297
2024-03-28 18:02:59,919 - config - INFO - Validation Loss: 0.4490
2024-03-28 18:02:59,940 - config - INFO - Epoch [124/2000], Train Loss: 0.4297
2024-03-28 18:02:59,944 - config - INFO - Validation Loss: 0.4496
2024-03-28 18:02:59,965 - config - INFO - Epoch [125/2000], Train Loss: 0.4297
2024-03-28 18:02:59,970 - config - INFO - Validation Loss: 0.4488
2024-03-28 18:02:59,991 - config - INFO - Epoch [126/2000], Train Loss: 0.4295
2024-03-28 18:02:59,995 - config - INFO - Validation Loss: 0.4487
2024-03-28 18:03:00,016 - config - INFO - Epoch [127/2000], Train Loss: 0.4300
2024-03-28 18:03:00,021 - config - INFO - Validation Loss: 0.4479
2024-03-28 18:03:00,042 - config - INFO - Epoch [128/2000], Train Loss: 0.4300
2024-03-28 18:03:00,047 - config - INFO - Validation Loss: 0.4478
2024-03-28 18:03:00,068 - config - INFO - Epoch [129/2000], Train Loss: 0.4297
2024-03-28 18:03:00,072 - config - INFO - Validation Loss: 0.4495
2024-03-28 18:03:00,093 - config - INFO - Epoch [130/2000], Train Loss: 0.4297
2024-03-28 18:03:00,098 - config - INFO - Validation Loss: 0.4501
2024-03-28 18:03:00,119 - config - INFO - Epoch [131/2000], Train Loss: 0.4286
2024-03-28 18:03:00,123 - config - INFO - Validation Loss: 0.4485
2024-03-28 18:03:00,144 - config - INFO - Epoch [132/2000], Train Loss: 0.4290
2024-03-28 18:03:00,149 - config - INFO - Validation Loss: 0.4479
2024-03-28 18:03:00,170 - config - INFO - Epoch [133/2000], Train Loss: 0.4295
2024-03-28 18:03:00,175 - config - INFO - Validation Loss: 0.4480
2024-03-28 18:03:00,196 - config - INFO - Epoch [134/2000], Train Loss: 0.4287
2024-03-28 18:03:00,200 - config - INFO - Validation Loss: 0.4487
2024-03-28 18:03:00,221 - config - INFO - Epoch [135/2000], Train Loss: 0.4286
2024-03-28 18:03:00,226 - config - INFO - Validation Loss: 0.4489
2024-03-28 18:03:00,247 - config - INFO - Epoch [136/2000], Train Loss: 0.4283
2024-03-28 18:03:00,252 - config - INFO - Validation Loss: 0.4491
2024-03-28 18:03:00,272 - config - INFO - Epoch [137/2000], Train Loss: 0.4289
2024-03-28 18:03:00,277 - config - INFO - Validation Loss: 0.4501
2024-03-28 18:03:00,298 - config - INFO - Epoch [138/2000], Train Loss: 0.4292
2024-03-28 18:03:00,303 - config - INFO - Validation Loss: 0.4503
2024-03-28 18:03:00,324 - config - INFO - Epoch [139/2000], Train Loss: 0.4276
2024-03-28 18:03:00,328 - config - INFO - Validation Loss: 0.4479
2024-03-28 18:03:00,349 - config - INFO - Epoch [140/2000], Train Loss: 0.4281
2024-03-28 18:03:00,354 - config - INFO - Validation Loss: 0.4476
2024-03-28 18:03:00,375 - config - INFO - Epoch [141/2000], Train Loss: 0.4283
2024-03-28 18:03:00,379 - config - INFO - Validation Loss: 0.4476
2024-03-28 18:03:00,401 - config - INFO - Epoch [142/2000], Train Loss: 0.4280
2024-03-28 18:03:00,405 - config - INFO - Validation Loss: 0.4486
2024-03-28 18:03:00,426 - config - INFO - Epoch [143/2000], Train Loss: 0.4276
2024-03-28 18:03:00,431 - config - INFO - Validation Loss: 0.4497
2024-03-28 18:03:00,452 - config - INFO - Epoch [144/2000], Train Loss: 0.4281
2024-03-28 18:03:00,456 - config - INFO - Validation Loss: 0.4508
2024-03-28 18:03:00,477 - config - INFO - Epoch [145/2000], Train Loss: 0.4287
2024-03-28 18:03:00,482 - config - INFO - Validation Loss: 0.4511
2024-03-28 18:03:00,503 - config - INFO - Epoch [146/2000], Train Loss: 0.4281
2024-03-28 18:03:00,508 - config - INFO - Validation Loss: 0.4485
2024-03-28 18:03:00,529 - config - INFO - Epoch [147/2000], Train Loss: 0.4280
2024-03-28 18:03:00,533 - config - INFO - Validation Loss: 0.4478
2024-03-28 18:03:00,560 - config - INFO - Epoch [148/2000], Train Loss: 0.4277
2024-03-28 18:03:00,564 - config - INFO - Validation Loss: 0.4479
2024-03-28 18:03:00,583 - config - INFO - Epoch [149/2000], Train Loss: 0.4275
2024-03-28 18:03:00,587 - config - INFO - Validation Loss: 0.4493
2024-03-28 18:03:00,606 - config - INFO - Epoch [150/2000], Train Loss: 0.4284
2024-03-28 18:03:00,610 - config - INFO - Validation Loss: 0.4499
2024-03-28 18:03:00,629 - config - INFO - Epoch [151/2000], Train Loss: 0.4272
2024-03-28 18:03:00,633 - config - INFO - Validation Loss: 0.4483
2024-03-28 18:03:00,651 - config - INFO - Epoch [152/2000], Train Loss: 0.4289
2024-03-28 18:03:00,655 - config - INFO - Validation Loss: 0.4475
2024-03-28 18:03:00,673 - config - INFO - Epoch [153/2000], Train Loss: 0.4284
2024-03-28 18:03:00,677 - config - INFO - Validation Loss: 0.4478
2024-03-28 18:03:00,696 - config - INFO - Epoch [154/2000], Train Loss: 0.4269
2024-03-28 18:03:00,700 - config - INFO - Validation Loss: 0.4484
2024-03-28 18:03:00,718 - config - INFO - Epoch [155/2000], Train Loss: 0.4273
2024-03-28 18:03:00,722 - config - INFO - Validation Loss: 0.4488
2024-03-28 18:03:00,740 - config - INFO - Epoch [156/2000], Train Loss: 0.4270
2024-03-28 18:03:00,744 - config - INFO - Validation Loss: 0.4477
2024-03-28 18:03:00,763 - config - INFO - Epoch [157/2000], Train Loss: 0.4272
2024-03-28 18:03:00,767 - config - INFO - Validation Loss: 0.4479
2024-03-28 18:03:00,785 - config - INFO - Epoch [158/2000], Train Loss: 0.4268
2024-03-28 18:03:00,789 - config - INFO - Validation Loss: 0.4478
2024-03-28 18:03:00,807 - config - INFO - Epoch [159/2000], Train Loss: 0.4267
2024-03-28 18:03:00,811 - config - INFO - Validation Loss: 0.4479
2024-03-28 18:03:00,830 - config - INFO - Epoch [160/2000], Train Loss: 0.4263
2024-03-28 18:03:00,834 - config - INFO - Validation Loss: 0.4482
2024-03-28 18:03:00,852 - config - INFO - Epoch [161/2000], Train Loss: 0.4263
2024-03-28 18:03:00,856 - config - INFO - Validation Loss: 0.4492
2024-03-28 18:03:00,874 - config - INFO - Epoch [162/2000], Train Loss: 0.4263
2024-03-28 18:03:00,878 - config - INFO - Validation Loss: 0.4496
2024-03-28 18:03:00,896 - config - INFO - Epoch [163/2000], Train Loss: 0.4261
2024-03-28 18:03:00,900 - config - INFO - Validation Loss: 0.4482
2024-03-28 18:03:00,918 - config - INFO - Epoch [164/2000], Train Loss: 0.4263
2024-03-28 18:03:00,922 - config - INFO - Validation Loss: 0.4482
2024-03-28 18:03:00,941 - config - INFO - Epoch [165/2000], Train Loss: 0.4265
2024-03-28 18:03:00,945 - config - INFO - Validation Loss: 0.4476
2024-03-28 18:03:00,963 - config - INFO - Epoch [166/2000], Train Loss: 0.4263
2024-03-28 18:03:00,967 - config - INFO - Validation Loss: 0.4479
2024-03-28 18:03:00,985 - config - INFO - Epoch [167/2000], Train Loss: 0.4261
2024-03-28 18:03:00,989 - config - INFO - Validation Loss: 0.4485
2024-03-28 18:03:01,008 - config - INFO - Epoch [168/2000], Train Loss: 0.4255
2024-03-28 18:03:01,012 - config - INFO - Validation Loss: 0.4484
2024-03-28 18:03:01,030 - config - INFO - Epoch [169/2000], Train Loss: 0.4257
2024-03-28 18:03:01,034 - config - INFO - Validation Loss: 0.4481
2024-03-28 18:03:01,052 - config - INFO - Epoch [170/2000], Train Loss: 0.4255
2024-03-28 18:03:01,056 - config - INFO - Validation Loss: 0.4477
2024-03-28 18:03:01,074 - config - INFO - Epoch [171/2000], Train Loss: 0.4258
2024-03-28 18:03:01,078 - config - INFO - Validation Loss: 0.4488
2024-03-28 18:03:01,097 - config - INFO - Epoch [172/2000], Train Loss: 0.4251
2024-03-28 18:03:01,101 - config - INFO - Validation Loss: 0.4478
2024-03-28 18:03:01,119 - config - INFO - Epoch [173/2000], Train Loss: 0.4248
2024-03-28 18:03:01,123 - config - INFO - Validation Loss: 0.4474
2024-03-28 18:03:01,141 - config - INFO - Epoch [174/2000], Train Loss: 0.4252
2024-03-28 18:03:01,145 - config - INFO - Validation Loss: 0.4476
2024-03-28 18:03:01,164 - config - INFO - Epoch [175/2000], Train Loss: 0.4250
2024-03-28 18:03:01,168 - config - INFO - Validation Loss: 0.4472
2024-03-28 18:03:01,186 - config - INFO - Epoch [176/2000], Train Loss: 0.4251
2024-03-28 18:03:01,190 - config - INFO - Validation Loss: 0.4471
2024-03-28 18:03:01,208 - config - INFO - Epoch [177/2000], Train Loss: 0.4250
2024-03-28 18:03:01,212 - config - INFO - Validation Loss: 0.4471
2024-03-28 18:03:01,230 - config - INFO - Epoch [178/2000], Train Loss: 0.4245
2024-03-28 18:03:01,234 - config - INFO - Validation Loss: 0.4483
2024-03-28 18:03:01,252 - config - INFO - Epoch [179/2000], Train Loss: 0.4249
2024-03-28 18:03:01,256 - config - INFO - Validation Loss: 0.4482
2024-03-28 18:03:01,275 - config - INFO - Epoch [180/2000], Train Loss: 0.4246
2024-03-28 18:03:01,279 - config - INFO - Validation Loss: 0.4485
2024-03-28 18:03:01,297 - config - INFO - Epoch [181/2000], Train Loss: 0.4242
2024-03-28 18:03:01,301 - config - INFO - Validation Loss: 0.4482
2024-03-28 18:03:01,319 - config - INFO - Epoch [182/2000], Train Loss: 0.4245
2024-03-28 18:03:01,323 - config - INFO - Validation Loss: 0.4483
2024-03-28 18:03:01,342 - config - INFO - Epoch [183/2000], Train Loss: 0.4241
2024-03-28 18:03:01,346 - config - INFO - Validation Loss: 0.4470
2024-03-28 18:03:01,364 - config - INFO - Epoch [184/2000], Train Loss: 0.4237
2024-03-28 18:03:01,368 - config - INFO - Validation Loss: 0.4473
2024-03-28 18:03:01,386 - config - INFO - Epoch [185/2000], Train Loss: 0.4240
2024-03-28 18:03:01,390 - config - INFO - Validation Loss: 0.4472
2024-03-28 18:03:01,409 - config - INFO - Epoch [186/2000], Train Loss: 0.4253
2024-03-28 18:03:01,413 - config - INFO - Validation Loss: 0.4495
2024-03-28 18:03:01,431 - config - INFO - Epoch [187/2000], Train Loss: 0.4238
2024-03-28 18:03:01,435 - config - INFO - Validation Loss: 0.4471
2024-03-28 18:03:01,453 - config - INFO - Epoch [188/2000], Train Loss: 0.4245
2024-03-28 18:03:01,457 - config - INFO - Validation Loss: 0.4458
2024-03-28 18:03:01,475 - config - INFO - Epoch [189/2000], Train Loss: 0.4234
2024-03-28 18:03:01,479 - config - INFO - Validation Loss: 0.4464
2024-03-28 18:03:01,498 - config - INFO - Epoch [190/2000], Train Loss: 0.4230
2024-03-28 18:03:01,502 - config - INFO - Validation Loss: 0.4473
2024-03-28 18:03:01,520 - config - INFO - Epoch [191/2000], Train Loss: 0.4237
2024-03-28 18:03:01,524 - config - INFO - Validation Loss: 0.4483
2024-03-28 18:03:01,542 - config - INFO - Epoch [192/2000], Train Loss: 0.4232
2024-03-28 18:03:01,546 - config - INFO - Validation Loss: 0.4473
2024-03-28 18:03:01,564 - config - INFO - Epoch [193/2000], Train Loss: 0.4230
2024-03-28 18:03:01,568 - config - INFO - Validation Loss: 0.4460
2024-03-28 18:03:01,589 - config - INFO - Epoch [194/2000], Train Loss: 0.4235
2024-03-28 18:03:01,593 - config - INFO - Validation Loss: 0.4457
2024-03-28 18:03:01,611 - config - INFO - Epoch [195/2000], Train Loss: 0.4225
2024-03-28 18:03:01,615 - config - INFO - Validation Loss: 0.4476
2024-03-28 18:03:01,633 - config - INFO - Epoch [196/2000], Train Loss: 0.4229
2024-03-28 18:03:01,637 - config - INFO - Validation Loss: 0.4471
2024-03-28 18:03:01,655 - config - INFO - Epoch [197/2000], Train Loss: 0.4228
2024-03-28 18:03:01,659 - config - INFO - Validation Loss: 0.4459
2024-03-28 18:03:01,678 - config - INFO - Epoch [198/2000], Train Loss: 0.4225
2024-03-28 18:03:01,682 - config - INFO - Validation Loss: 0.4461
2024-03-28 18:03:01,700 - config - INFO - Epoch [199/2000], Train Loss: 0.4223
2024-03-28 18:03:01,704 - config - INFO - Validation Loss: 0.4467
2024-03-28 18:03:01,722 - config - INFO - Epoch [200/2000], Train Loss: 0.4224
2024-03-28 18:03:01,726 - config - INFO - Validation Loss: 0.4464
2024-03-28 18:03:01,744 - config - INFO - Epoch [201/2000], Train Loss: 0.4222
2024-03-28 18:03:01,748 - config - INFO - Validation Loss: 0.4459
2024-03-28 18:03:01,766 - config - INFO - Epoch [202/2000], Train Loss: 0.4221
2024-03-28 18:03:01,770 - config - INFO - Validation Loss: 0.4462
2024-03-28 18:03:01,788 - config - INFO - Epoch [203/2000], Train Loss: 0.4218
2024-03-28 18:03:01,792 - config - INFO - Validation Loss: 0.4460
2024-03-28 18:03:01,811 - config - INFO - Epoch [204/2000], Train Loss: 0.4220
2024-03-28 18:03:01,815 - config - INFO - Validation Loss: 0.4468
2024-03-28 18:03:01,833 - config - INFO - Epoch [205/2000], Train Loss: 0.4218
2024-03-28 18:03:01,837 - config - INFO - Validation Loss: 0.4458
2024-03-28 18:03:01,855 - config - INFO - Epoch [206/2000], Train Loss: 0.4219
2024-03-28 18:03:01,859 - config - INFO - Validation Loss: 0.4469
2024-03-28 18:03:01,877 - config - INFO - Epoch [207/2000], Train Loss: 0.4211
2024-03-28 18:03:01,881 - config - INFO - Validation Loss: 0.4464
2024-03-28 18:03:01,899 - config - INFO - Epoch [208/2000], Train Loss: 0.4213
2024-03-28 18:03:01,903 - config - INFO - Validation Loss: 0.4463
2024-03-28 18:03:01,922 - config - INFO - Epoch [209/2000], Train Loss: 0.4214
2024-03-28 18:03:01,925 - config - INFO - Validation Loss: 0.4470
2024-03-28 18:03:01,944 - config - INFO - Epoch [210/2000], Train Loss: 0.4208
2024-03-28 18:03:01,948 - config - INFO - Validation Loss: 0.4473
2024-03-28 18:03:01,966 - config - INFO - Epoch [211/2000], Train Loss: 0.4209
2024-03-28 18:03:01,970 - config - INFO - Validation Loss: 0.4465
2024-03-28 18:03:01,988 - config - INFO - Epoch [212/2000], Train Loss: 0.4209
2024-03-28 18:03:01,992 - config - INFO - Validation Loss: 0.4465
2024-03-28 18:03:02,011 - config - INFO - Epoch [213/2000], Train Loss: 0.4207
2024-03-28 18:03:02,014 - config - INFO - Validation Loss: 0.4459
2024-03-28 18:03:02,033 - config - INFO - Epoch [214/2000], Train Loss: 0.4206
2024-03-28 18:03:02,037 - config - INFO - Validation Loss: 0.4451
2024-03-28 18:03:02,055 - config - INFO - Epoch [215/2000], Train Loss: 0.4212
2024-03-28 18:03:02,059 - config - INFO - Validation Loss: 0.4450
2024-03-28 18:03:02,077 - config - INFO - Epoch [216/2000], Train Loss: 0.4212
2024-03-28 18:03:02,081 - config - INFO - Validation Loss: 0.4451
2024-03-28 18:03:02,099 - config - INFO - Epoch [217/2000], Train Loss: 0.4206
2024-03-28 18:03:02,103 - config - INFO - Validation Loss: 0.4479
2024-03-28 18:03:02,122 - config - INFO - Epoch [218/2000], Train Loss: 0.4205
2024-03-28 18:03:02,126 - config - INFO - Validation Loss: 0.4485
2024-03-28 18:03:02,144 - config - INFO - Epoch [219/2000], Train Loss: 0.4197
2024-03-28 18:03:02,148 - config - INFO - Validation Loss: 0.4466
2024-03-28 18:03:02,166 - config - INFO - Epoch [220/2000], Train Loss: 0.4197
2024-03-28 18:03:02,170 - config - INFO - Validation Loss: 0.4460
2024-03-28 18:03:02,188 - config - INFO - Epoch [221/2000], Train Loss: 0.4197
2024-03-28 18:03:02,192 - config - INFO - Validation Loss: 0.4460
2024-03-28 18:03:02,210 - config - INFO - Epoch [222/2000], Train Loss: 0.4198
2024-03-28 18:03:02,214 - config - INFO - Validation Loss: 0.4457
2024-03-28 18:03:02,233 - config - INFO - Epoch [223/2000], Train Loss: 0.4194
2024-03-28 18:03:02,237 - config - INFO - Validation Loss: 0.4460
2024-03-28 18:03:02,255 - config - INFO - Epoch [224/2000], Train Loss: 0.4191
2024-03-28 18:03:02,259 - config - INFO - Validation Loss: 0.4470
2024-03-28 18:03:02,277 - config - INFO - Epoch [225/2000], Train Loss: 0.4190
2024-03-28 18:03:02,281 - config - INFO - Validation Loss: 0.4465
2024-03-28 18:03:02,299 - config - INFO - Epoch [226/2000], Train Loss: 0.4193
2024-03-28 18:03:02,303 - config - INFO - Validation Loss: 0.4453
2024-03-28 18:03:02,322 - config - INFO - Epoch [227/2000], Train Loss: 0.4184
2024-03-28 18:03:02,326 - config - INFO - Validation Loss: 0.4462
2024-03-28 18:03:02,344 - config - INFO - Epoch [228/2000], Train Loss: 0.4184
2024-03-28 18:03:02,348 - config - INFO - Validation Loss: 0.4464
2024-03-28 18:03:02,366 - config - INFO - Epoch [229/2000], Train Loss: 0.4183
2024-03-28 18:03:02,370 - config - INFO - Validation Loss: 0.4466
2024-03-28 18:03:02,388 - config - INFO - Epoch [230/2000], Train Loss: 0.4186
2024-03-28 18:03:02,392 - config - INFO - Validation Loss: 0.4455
2024-03-28 18:03:02,411 - config - INFO - Epoch [231/2000], Train Loss: 0.4186
2024-03-28 18:03:02,414 - config - INFO - Validation Loss: 0.4450
2024-03-28 18:03:02,433 - config - INFO - Epoch [232/2000], Train Loss: 0.4176
2024-03-28 18:03:02,437 - config - INFO - Validation Loss: 0.4467
2024-03-28 18:03:02,455 - config - INFO - Epoch [233/2000], Train Loss: 0.4182
2024-03-28 18:03:02,459 - config - INFO - Validation Loss: 0.4471
2024-03-28 18:03:02,477 - config - INFO - Epoch [234/2000], Train Loss: 0.4179
2024-03-28 18:03:02,481 - config - INFO - Validation Loss: 0.4456
2024-03-28 18:03:02,499 - config - INFO - Epoch [235/2000], Train Loss: 0.4175
2024-03-28 18:03:02,503 - config - INFO - Validation Loss: 0.4454
2024-03-28 18:03:02,521 - config - INFO - Epoch [236/2000], Train Loss: 0.4176
2024-03-28 18:03:02,525 - config - INFO - Validation Loss: 0.4462
2024-03-28 18:03:02,544 - config - INFO - Epoch [237/2000], Train Loss: 0.4178
2024-03-28 18:03:02,548 - config - INFO - Validation Loss: 0.4443
2024-03-28 18:03:02,566 - config - INFO - Epoch [238/2000], Train Loss: 0.4169
2024-03-28 18:03:02,570 - config - INFO - Validation Loss: 0.4449
2024-03-28 18:03:02,598 - config - INFO - Epoch [239/2000], Train Loss: 0.4174
2024-03-28 18:03:02,603 - config - INFO - Validation Loss: 0.4457
2024-03-28 18:03:02,621 - config - INFO - Epoch [240/2000], Train Loss: 0.4182
2024-03-28 18:03:02,625 - config - INFO - Validation Loss: 0.4442
2024-03-28 18:03:02,643 - config - INFO - Epoch [241/2000], Train Loss: 0.4166
2024-03-28 18:03:02,647 - config - INFO - Validation Loss: 0.4443
2024-03-28 18:03:02,666 - config - INFO - Epoch [242/2000], Train Loss: 0.4166
2024-03-28 18:03:02,669 - config - INFO - Validation Loss: 0.4443
2024-03-28 18:03:02,688 - config - INFO - Epoch [243/2000], Train Loss: 0.4170
2024-03-28 18:03:02,692 - config - INFO - Validation Loss: 0.4460
2024-03-28 18:03:02,710 - config - INFO - Epoch [244/2000], Train Loss: 0.4164
2024-03-28 18:03:02,714 - config - INFO - Validation Loss: 0.4446
2024-03-28 18:03:02,732 - config - INFO - Epoch [245/2000], Train Loss: 0.4160
2024-03-28 18:03:02,736 - config - INFO - Validation Loss: 0.4441
2024-03-28 18:03:02,754 - config - INFO - Epoch [246/2000], Train Loss: 0.4162
2024-03-28 18:03:02,758 - config - INFO - Validation Loss: 0.4446
2024-03-28 18:03:02,776 - config - INFO - Epoch [247/2000], Train Loss: 0.4156
2024-03-28 18:03:02,780 - config - INFO - Validation Loss: 0.4444
2024-03-28 18:03:02,798 - config - INFO - Epoch [248/2000], Train Loss: 0.4156
2024-03-28 18:03:02,802 - config - INFO - Validation Loss: 0.4444
2024-03-28 18:03:02,821 - config - INFO - Epoch [249/2000], Train Loss: 0.4161
2024-03-28 18:03:02,825 - config - INFO - Validation Loss: 0.4445
2024-03-28 18:03:02,843 - config - INFO - Epoch [250/2000], Train Loss: 0.4160
2024-03-28 18:03:02,847 - config - INFO - Validation Loss: 0.4460
2024-03-28 18:03:02,865 - config - INFO - Epoch [251/2000], Train Loss: 0.4154
2024-03-28 18:03:02,869 - config - INFO - Validation Loss: 0.4454
2024-03-28 18:03:02,887 - config - INFO - Epoch [252/2000], Train Loss: 0.4150
2024-03-28 18:03:02,891 - config - INFO - Validation Loss: 0.4441
2024-03-28 18:03:02,909 - config - INFO - Epoch [253/2000], Train Loss: 0.4157
2024-03-28 18:03:02,913 - config - INFO - Validation Loss: 0.4442
2024-03-28 18:03:02,931 - config - INFO - Epoch [254/2000], Train Loss: 0.4152
2024-03-28 18:03:02,935 - config - INFO - Validation Loss: 0.4458
2024-03-28 18:03:02,953 - config - INFO - Epoch [255/2000], Train Loss: 0.4147
2024-03-28 18:03:02,957 - config - INFO - Validation Loss: 0.4464
2024-03-28 18:03:02,976 - config - INFO - Epoch [256/2000], Train Loss: 0.4150
2024-03-28 18:03:02,980 - config - INFO - Validation Loss: 0.4474
2024-03-28 18:03:02,998 - config - INFO - Epoch [257/2000], Train Loss: 0.4150
2024-03-28 18:03:03,002 - config - INFO - Validation Loss: 0.4456
2024-03-28 18:03:03,020 - config - INFO - Epoch [258/2000], Train Loss: 0.4146
2024-03-28 18:03:03,024 - config - INFO - Validation Loss: 0.4462
2024-03-28 18:03:03,042 - config - INFO - Epoch [259/2000], Train Loss: 0.4137
2024-03-28 18:03:03,046 - config - INFO - Validation Loss: 0.4449
2024-03-28 18:03:03,064 - config - INFO - Epoch [260/2000], Train Loss: 0.4136
2024-03-28 18:03:03,068 - config - INFO - Validation Loss: 0.4445
2024-03-28 18:03:03,086 - config - INFO - Epoch [261/2000], Train Loss: 0.4151
2024-03-28 18:03:03,090 - config - INFO - Validation Loss: 0.4441
2024-03-28 18:03:03,109 - config - INFO - Epoch [262/2000], Train Loss: 0.4136
2024-03-28 18:03:03,113 - config - INFO - Validation Loss: 0.4449
2024-03-28 18:03:03,131 - config - INFO - Epoch [263/2000], Train Loss: 0.4130
2024-03-28 18:03:03,135 - config - INFO - Validation Loss: 0.4449
2024-03-28 18:03:03,153 - config - INFO - Epoch [264/2000], Train Loss: 0.4136
2024-03-28 18:03:03,157 - config - INFO - Validation Loss: 0.4458
2024-03-28 18:03:03,175 - config - INFO - Epoch [265/2000], Train Loss: 0.4134
2024-03-28 18:03:03,179 - config - INFO - Validation Loss: 0.4443
2024-03-28 18:03:03,197 - config - INFO - Epoch [266/2000], Train Loss: 0.4129
2024-03-28 18:03:03,201 - config - INFO - Validation Loss: 0.4444
2024-03-28 18:03:03,220 - config - INFO - Epoch [267/2000], Train Loss: 0.4132
2024-03-28 18:03:03,223 - config - INFO - Validation Loss: 0.4447
2024-03-28 18:03:03,242 - config - INFO - Epoch [268/2000], Train Loss: 0.4130
2024-03-28 18:03:03,246 - config - INFO - Validation Loss: 0.4451
2024-03-28 18:03:03,264 - config - INFO - Epoch [269/2000], Train Loss: 0.4123
2024-03-28 18:03:03,268 - config - INFO - Validation Loss: 0.4455
2024-03-28 18:03:03,286 - config - INFO - Epoch [270/2000], Train Loss: 0.4117
2024-03-28 18:03:03,290 - config - INFO - Validation Loss: 0.4438
2024-03-28 18:03:03,308 - config - INFO - Epoch [271/2000], Train Loss: 0.4127
2024-03-28 18:03:03,312 - config - INFO - Validation Loss: 0.4435
2024-03-28 18:03:03,330 - config - INFO - Epoch [272/2000], Train Loss: 0.4122
2024-03-28 18:03:03,334 - config - INFO - Validation Loss: 0.4440
2024-03-28 18:03:03,352 - config - INFO - Epoch [273/2000], Train Loss: 0.4120
2024-03-28 18:03:03,356 - config - INFO - Validation Loss: 0.4437
2024-03-28 18:03:03,375 - config - INFO - Epoch [274/2000], Train Loss: 0.4117
2024-03-28 18:03:03,379 - config - INFO - Validation Loss: 0.4436
2024-03-28 18:03:03,397 - config - INFO - Epoch [275/2000], Train Loss: 0.4115
2024-03-28 18:03:03,401 - config - INFO - Validation Loss: 0.4441
2024-03-28 18:03:03,419 - config - INFO - Epoch [276/2000], Train Loss: 0.4108
2024-03-28 18:03:03,423 - config - INFO - Validation Loss: 0.4454
2024-03-28 18:03:03,441 - config - INFO - Epoch [277/2000], Train Loss: 0.4112
2024-03-28 18:03:03,445 - config - INFO - Validation Loss: 0.4452
2024-03-28 18:03:03,463 - config - INFO - Epoch [278/2000], Train Loss: 0.4106
2024-03-28 18:03:03,467 - config - INFO - Validation Loss: 0.4443
2024-03-28 18:03:03,485 - config - INFO - Epoch [279/2000], Train Loss: 0.4106
2024-03-28 18:03:03,490 - config - INFO - Validation Loss: 0.4445
2024-03-28 18:03:03,508 - config - INFO - Epoch [280/2000], Train Loss: 0.4117
2024-03-28 18:03:03,512 - config - INFO - Validation Loss: 0.4461
2024-03-28 18:03:03,530 - config - INFO - Epoch [281/2000], Train Loss: 0.4099
2024-03-28 18:03:03,534 - config - INFO - Validation Loss: 0.4445
2024-03-28 18:03:03,552 - config - INFO - Epoch [282/2000], Train Loss: 0.4112
2024-03-28 18:03:03,556 - config - INFO - Validation Loss: 0.4440
2024-03-28 18:03:03,574 - config - INFO - Epoch [283/2000], Train Loss: 0.4094
2024-03-28 18:03:03,578 - config - INFO - Validation Loss: 0.4451
2024-03-28 18:03:03,596 - config - INFO - Epoch [284/2000], Train Loss: 0.4107
2024-03-28 18:03:03,600 - config - INFO - Validation Loss: 0.4467
2024-03-28 18:03:03,618 - config - INFO - Epoch [285/2000], Train Loss: 0.4102
2024-03-28 18:03:03,622 - config - INFO - Validation Loss: 0.4464
2024-03-28 18:03:03,641 - config - INFO - Epoch [286/2000], Train Loss: 0.4096
2024-03-28 18:03:03,645 - config - INFO - Validation Loss: 0.4445
2024-03-28 18:03:03,669 - config - INFO - Epoch [287/2000], Train Loss: 0.4097
2024-03-28 18:03:03,673 - config - INFO - Validation Loss: 0.4437
2024-03-28 18:03:03,692 - config - INFO - Epoch [288/2000], Train Loss: 0.4090
2024-03-28 18:03:03,696 - config - INFO - Validation Loss: 0.4443
2024-03-28 18:03:03,714 - config - INFO - Epoch [289/2000], Train Loss: 0.4091
2024-03-28 18:03:03,718 - config - INFO - Validation Loss: 0.4451
2024-03-28 18:03:03,737 - config - INFO - Epoch [290/2000], Train Loss: 0.4093
2024-03-28 18:03:03,741 - config - INFO - Validation Loss: 0.4446
2024-03-28 18:03:03,759 - config - INFO - Epoch [291/2000], Train Loss: 0.4084
2024-03-28 18:03:03,763 - config - INFO - Validation Loss: 0.4434
2024-03-28 18:03:03,782 - config - INFO - Epoch [292/2000], Train Loss: 0.4084
2024-03-28 18:03:03,786 - config - INFO - Validation Loss: 0.4432
2024-03-28 18:03:03,804 - config - INFO - Epoch [293/2000], Train Loss: 0.4090
2024-03-28 18:03:03,808 - config - INFO - Validation Loss: 0.4446
2024-03-28 18:03:03,826 - config - INFO - Epoch [294/2000], Train Loss: 0.4083
2024-03-28 18:03:03,830 - config - INFO - Validation Loss: 0.4446
2024-03-28 18:03:03,849 - config - INFO - Epoch [295/2000], Train Loss: 0.4084
2024-03-28 18:03:03,853 - config - INFO - Validation Loss: 0.4452
2024-03-28 18:03:03,871 - config - INFO - Epoch [296/2000], Train Loss: 0.4078
2024-03-28 18:03:03,875 - config - INFO - Validation Loss: 0.4435
2024-03-28 18:03:03,893 - config - INFO - Epoch [297/2000], Train Loss: 0.4076
2024-03-28 18:03:03,897 - config - INFO - Validation Loss: 0.4433
2024-03-28 18:03:03,916 - config - INFO - Epoch [298/2000], Train Loss: 0.4075
2024-03-28 18:03:03,920 - config - INFO - Validation Loss: 0.4432
2024-03-28 18:03:03,938 - config - INFO - Epoch [299/2000], Train Loss: 0.4076
2024-03-28 18:03:03,942 - config - INFO - Validation Loss: 0.4432
2024-03-28 18:03:03,960 - config - INFO - Epoch [300/2000], Train Loss: 0.4072
2024-03-28 18:03:03,964 - config - INFO - Validation Loss: 0.4429
2024-03-28 18:03:03,983 - config - INFO - Epoch [301/2000], Train Loss: 0.4068
2024-03-28 18:03:03,987 - config - INFO - Validation Loss: 0.4436
2024-03-28 18:03:04,005 - config - INFO - Epoch [302/2000], Train Loss: 0.4066
2024-03-28 18:03:04,009 - config - INFO - Validation Loss: 0.4441
2024-03-28 18:03:04,027 - config - INFO - Epoch [303/2000], Train Loss: 0.4071
2024-03-28 18:03:04,031 - config - INFO - Validation Loss: 0.4440
2024-03-28 18:03:04,050 - config - INFO - Epoch [304/2000], Train Loss: 0.4071
2024-03-28 18:03:04,054 - config - INFO - Validation Loss: 0.4425
2024-03-28 18:03:04,072 - config - INFO - Epoch [305/2000], Train Loss: 0.4067
2024-03-28 18:03:04,076 - config - INFO - Validation Loss: 0.4425
2024-03-28 18:03:04,094 - config - INFO - Epoch [306/2000], Train Loss: 0.4055
2024-03-28 18:03:04,098 - config - INFO - Validation Loss: 0.4438
2024-03-28 18:03:04,116 - config - INFO - Epoch [307/2000], Train Loss: 0.4063
2024-03-28 18:03:04,120 - config - INFO - Validation Loss: 0.4445
2024-03-28 18:03:04,139 - config - INFO - Epoch [308/2000], Train Loss: 0.4063
2024-03-28 18:03:04,143 - config - INFO - Validation Loss: 0.4426
2024-03-28 18:03:04,161 - config - INFO - Epoch [309/2000], Train Loss: 0.4057
2024-03-28 18:03:04,165 - config - INFO - Validation Loss: 0.4431
2024-03-28 18:03:04,183 - config - INFO - Epoch [310/2000], Train Loss: 0.4051
2024-03-28 18:03:04,187 - config - INFO - Validation Loss: 0.4428
2024-03-28 18:03:04,205 - config - INFO - Epoch [311/2000], Train Loss: 0.4052
2024-03-28 18:03:04,209 - config - INFO - Validation Loss: 0.4427
2024-03-28 18:03:04,228 - config - INFO - Epoch [312/2000], Train Loss: 0.4051
2024-03-28 18:03:04,232 - config - INFO - Validation Loss: 0.4434
2024-03-28 18:03:04,250 - config - INFO - Epoch [313/2000], Train Loss: 0.4047
2024-03-28 18:03:04,254 - config - INFO - Validation Loss: 0.4437
2024-03-28 18:03:04,272 - config - INFO - Epoch [314/2000], Train Loss: 0.4055
2024-03-28 18:03:04,276 - config - INFO - Validation Loss: 0.4447
2024-03-28 18:03:04,295 - config - INFO - Epoch [315/2000], Train Loss: 0.4049
2024-03-28 18:03:04,299 - config - INFO - Validation Loss: 0.4434
2024-03-28 18:03:04,317 - config - INFO - Epoch [316/2000], Train Loss: 0.4045
2024-03-28 18:03:04,321 - config - INFO - Validation Loss: 0.4433
2024-03-28 18:03:04,339 - config - INFO - Epoch [317/2000], Train Loss: 0.4045
2024-03-28 18:03:04,343 - config - INFO - Validation Loss: 0.4424
2024-03-28 18:03:04,362 - config - INFO - Epoch [318/2000], Train Loss: 0.4051
2024-03-28 18:03:04,366 - config - INFO - Validation Loss: 0.4429
2024-03-28 18:03:04,384 - config - INFO - Epoch [319/2000], Train Loss: 0.4037
2024-03-28 18:03:04,388 - config - INFO - Validation Loss: 0.4426
2024-03-28 18:03:04,415 - config - INFO - Epoch [320/2000], Train Loss: 0.4034
2024-03-28 18:03:04,419 - config - INFO - Validation Loss: 0.4432
2024-03-28 18:03:04,438 - config - INFO - Epoch [321/2000], Train Loss: 0.4035
2024-03-28 18:03:04,442 - config - INFO - Validation Loss: 0.4432
2024-03-28 18:03:04,460 - config - INFO - Epoch [322/2000], Train Loss: 0.4034
2024-03-28 18:03:04,464 - config - INFO - Validation Loss: 0.4433
2024-03-28 18:03:04,482 - config - INFO - Epoch [323/2000], Train Loss: 0.4032
2024-03-28 18:03:04,486 - config - INFO - Validation Loss: 0.4428
2024-03-28 18:03:04,504 - config - INFO - Epoch [324/2000], Train Loss: 0.4031
2024-03-28 18:03:04,508 - config - INFO - Validation Loss: 0.4422
2024-03-28 18:03:04,527 - config - INFO - Epoch [325/2000], Train Loss: 0.4031
2024-03-28 18:03:04,531 - config - INFO - Validation Loss: 0.4433
2024-03-28 18:03:04,549 - config - INFO - Epoch [326/2000], Train Loss: 0.4024
2024-03-28 18:03:04,553 - config - INFO - Validation Loss: 0.4431
2024-03-28 18:03:04,571 - config - INFO - Epoch [327/2000], Train Loss: 0.4027
2024-03-28 18:03:04,575 - config - INFO - Validation Loss: 0.4423
2024-03-28 18:03:04,594 - config - INFO - Epoch [328/2000], Train Loss: 0.4026
2024-03-28 18:03:04,598 - config - INFO - Validation Loss: 0.4427
2024-03-28 18:03:04,616 - config - INFO - Epoch [329/2000], Train Loss: 0.4024
2024-03-28 18:03:04,620 - config - INFO - Validation Loss: 0.4428
2024-03-28 18:03:04,638 - config - INFO - Epoch [330/2000], Train Loss: 0.4021
2024-03-28 18:03:04,642 - config - INFO - Validation Loss: 0.4424
2024-03-28 18:03:04,660 - config - INFO - Epoch [331/2000], Train Loss: 0.4018
2024-03-28 18:03:04,664 - config - INFO - Validation Loss: 0.4423
2024-03-28 18:03:04,683 - config - INFO - Epoch [332/2000], Train Loss: 0.4016
2024-03-28 18:03:04,687 - config - INFO - Validation Loss: 0.4419
2024-03-28 18:03:04,705 - config - INFO - Epoch [333/2000], Train Loss: 0.4013
2024-03-28 18:03:04,709 - config - INFO - Validation Loss: 0.4421
2024-03-28 18:03:04,727 - config - INFO - Epoch [334/2000], Train Loss: 0.4010
2024-03-28 18:03:04,731 - config - INFO - Validation Loss: 0.4424
2024-03-28 18:03:04,749 - config - INFO - Epoch [335/2000], Train Loss: 0.4007
2024-03-28 18:03:04,753 - config - INFO - Validation Loss: 0.4424
2024-03-28 18:03:04,772 - config - INFO - Epoch [336/2000], Train Loss: 0.4006
2024-03-28 18:03:04,776 - config - INFO - Validation Loss: 0.4422
2024-03-28 18:03:04,794 - config - INFO - Epoch [337/2000], Train Loss: 0.4004
2024-03-28 18:03:04,798 - config - INFO - Validation Loss: 0.4423
2024-03-28 18:03:04,816 - config - INFO - Epoch [338/2000], Train Loss: 0.4002
2024-03-28 18:03:04,820 - config - INFO - Validation Loss: 0.4428
2024-03-28 18:03:04,839 - config - INFO - Epoch [339/2000], Train Loss: 0.4003
2024-03-28 18:03:04,843 - config - INFO - Validation Loss: 0.4424
2024-03-28 18:03:04,861 - config - INFO - Epoch [340/2000], Train Loss: 0.4001
2024-03-28 18:03:04,865 - config - INFO - Validation Loss: 0.4423
2024-03-28 18:03:04,883 - config - INFO - Epoch [341/2000], Train Loss: 0.4001
2024-03-28 18:03:04,887 - config - INFO - Validation Loss: 0.4427
2024-03-28 18:03:04,905 - config - INFO - Epoch [342/2000], Train Loss: 0.3995
2024-03-28 18:03:04,909 - config - INFO - Validation Loss: 0.4427
2024-03-28 18:03:04,928 - config - INFO - Epoch [343/2000], Train Loss: 0.3997
2024-03-28 18:03:04,932 - config - INFO - Validation Loss: 0.4420
2024-03-28 18:03:04,950 - config - INFO - Epoch [344/2000], Train Loss: 0.3997
2024-03-28 18:03:04,954 - config - INFO - Validation Loss: 0.4421
2024-03-28 18:03:04,972 - config - INFO - Epoch [345/2000], Train Loss: 0.3992
2024-03-28 18:03:04,976 - config - INFO - Validation Loss: 0.4422
2024-03-28 18:03:04,995 - config - INFO - Epoch [346/2000], Train Loss: 0.3996
2024-03-28 18:03:04,998 - config - INFO - Validation Loss: 0.4427
2024-03-28 18:03:05,017 - config - INFO - Epoch [347/2000], Train Loss: 0.3993
2024-03-28 18:03:05,021 - config - INFO - Validation Loss: 0.4414
2024-03-28 18:03:05,039 - config - INFO - Epoch [348/2000], Train Loss: 0.3987
2024-03-28 18:03:05,043 - config - INFO - Validation Loss: 0.4413
2024-03-28 18:03:05,061 - config - INFO - Epoch [349/2000], Train Loss: 0.3983
2024-03-28 18:03:05,065 - config - INFO - Validation Loss: 0.4420
2024-03-28 18:03:05,084 - config - INFO - Epoch [350/2000], Train Loss: 0.3985
2024-03-28 18:03:05,088 - config - INFO - Validation Loss: 0.4419
2024-03-28 18:03:05,106 - config - INFO - Epoch [351/2000], Train Loss: 0.3983
2024-03-28 18:03:05,110 - config - INFO - Validation Loss: 0.4425
2024-03-28 18:03:05,128 - config - INFO - Epoch [352/2000], Train Loss: 0.3979
2024-03-28 18:03:05,132 - config - INFO - Validation Loss: 0.4423
2024-03-28 18:03:05,151 - config - INFO - Epoch [353/2000], Train Loss: 0.3976
2024-03-28 18:03:05,155 - config - INFO - Validation Loss: 0.4415
2024-03-28 18:03:05,173 - config - INFO - Epoch [354/2000], Train Loss: 0.3977
2024-03-28 18:03:05,177 - config - INFO - Validation Loss: 0.4419
2024-03-28 18:03:05,195 - config - INFO - Epoch [355/2000], Train Loss: 0.3972
2024-03-28 18:03:05,199 - config - INFO - Validation Loss: 0.4429
2024-03-28 18:03:05,218 - config - INFO - Epoch [356/2000], Train Loss: 0.3972
2024-03-28 18:03:05,222 - config - INFO - Validation Loss: 0.4444
2024-03-28 18:03:05,240 - config - INFO - Epoch [357/2000], Train Loss: 0.3972
2024-03-28 18:03:05,244 - config - INFO - Validation Loss: 0.4429
2024-03-28 18:03:05,262 - config - INFO - Epoch [358/2000], Train Loss: 0.3971
2024-03-28 18:03:05,266 - config - INFO - Validation Loss: 0.4417
2024-03-28 18:03:05,285 - config - INFO - Epoch [359/2000], Train Loss: 0.3966
2024-03-28 18:03:05,289 - config - INFO - Validation Loss: 0.4414
2024-03-28 18:03:05,307 - config - INFO - Epoch [360/2000], Train Loss: 0.3963
2024-03-28 18:03:05,311 - config - INFO - Validation Loss: 0.4415
2024-03-28 18:03:05,329 - config - INFO - Epoch [361/2000], Train Loss: 0.3965
2024-03-28 18:03:05,333 - config - INFO - Validation Loss: 0.4422
2024-03-28 18:03:05,351 - config - INFO - Epoch [362/2000], Train Loss: 0.3962
2024-03-28 18:03:05,355 - config - INFO - Validation Loss: 0.4420
2024-03-28 18:03:05,374 - config - INFO - Epoch [363/2000], Train Loss: 0.3967
2024-03-28 18:03:05,378 - config - INFO - Validation Loss: 0.4414
2024-03-28 18:03:05,396 - config - INFO - Epoch [364/2000], Train Loss: 0.3953
2024-03-28 18:03:05,400 - config - INFO - Validation Loss: 0.4426
2024-03-28 18:03:05,418 - config - INFO - Epoch [365/2000], Train Loss: 0.3959
2024-03-28 18:03:05,422 - config - INFO - Validation Loss: 0.4426
2024-03-28 18:03:05,441 - config - INFO - Epoch [366/2000], Train Loss: 0.3951
2024-03-28 18:03:05,445 - config - INFO - Validation Loss: 0.4413
2024-03-28 18:03:05,463 - config - INFO - Epoch [367/2000], Train Loss: 0.3954
2024-03-28 18:03:05,467 - config - INFO - Validation Loss: 0.4407
2024-03-28 18:03:05,485 - config - INFO - Epoch [368/2000], Train Loss: 0.3952
2024-03-28 18:03:05,489 - config - INFO - Validation Loss: 0.4411
2024-03-28 18:03:05,507 - config - INFO - Epoch [369/2000], Train Loss: 0.3963
2024-03-28 18:03:05,511 - config - INFO - Validation Loss: 0.4428
2024-03-28 18:03:05,530 - config - INFO - Epoch [370/2000], Train Loss: 0.3947
2024-03-28 18:03:05,534 - config - INFO - Validation Loss: 0.4419
2024-03-28 18:03:05,552 - config - INFO - Epoch [371/2000], Train Loss: 0.3946
2024-03-28 18:03:05,556 - config - INFO - Validation Loss: 0.4413
2024-03-28 18:03:05,574 - config - INFO - Epoch [372/2000], Train Loss: 0.3955
2024-03-28 18:03:05,578 - config - INFO - Validation Loss: 0.4412
2024-03-28 18:03:05,596 - config - INFO - Epoch [373/2000], Train Loss: 0.3947
2024-03-28 18:03:05,600 - config - INFO - Validation Loss: 0.4420
2024-03-28 18:03:05,619 - config - INFO - Epoch [374/2000], Train Loss: 0.3942
2024-03-28 18:03:05,623 - config - INFO - Validation Loss: 0.4414
2024-03-28 18:03:05,641 - config - INFO - Epoch [375/2000], Train Loss: 0.3938
2024-03-28 18:03:05,645 - config - INFO - Validation Loss: 0.4420
2024-03-28 18:03:05,663 - config - INFO - Epoch [376/2000], Train Loss: 0.3941
2024-03-28 18:03:05,667 - config - INFO - Validation Loss: 0.4427
2024-03-28 18:03:05,689 - config - INFO - Epoch [377/2000], Train Loss: 0.3936
2024-03-28 18:03:05,693 - config - INFO - Validation Loss: 0.4420
2024-03-28 18:03:05,711 - config - INFO - Epoch [378/2000], Train Loss: 0.3932
2024-03-28 18:03:05,716 - config - INFO - Validation Loss: 0.4417
2024-03-28 18:03:05,734 - config - INFO - Epoch [379/2000], Train Loss: 0.3932
2024-03-28 18:03:05,738 - config - INFO - Validation Loss: 0.4420
2024-03-28 18:03:05,756 - config - INFO - Epoch [380/2000], Train Loss: 0.3926
2024-03-28 18:03:05,760 - config - INFO - Validation Loss: 0.4411
2024-03-28 18:03:05,778 - config - INFO - Epoch [381/2000], Train Loss: 0.3928
2024-03-28 18:03:05,782 - config - INFO - Validation Loss: 0.4409
2024-03-28 18:03:05,801 - config - INFO - Epoch [382/2000], Train Loss: 0.3930
2024-03-28 18:03:05,805 - config - INFO - Validation Loss: 0.4419
2024-03-28 18:03:05,823 - config - INFO - Epoch [383/2000], Train Loss: 0.3924
2024-03-28 18:03:05,827 - config - INFO - Validation Loss: 0.4419
2024-03-28 18:03:05,845 - config - INFO - Epoch [384/2000], Train Loss: 0.3923
2024-03-28 18:03:05,849 - config - INFO - Validation Loss: 0.4419
2024-03-28 18:03:05,867 - config - INFO - Epoch [385/2000], Train Loss: 0.3920
2024-03-28 18:03:05,871 - config - INFO - Validation Loss: 0.4425
2024-03-28 18:03:05,890 - config - INFO - Epoch [386/2000], Train Loss: 0.3919
2024-03-28 18:03:05,894 - config - INFO - Validation Loss: 0.4421
2024-03-28 18:03:05,912 - config - INFO - Epoch [387/2000], Train Loss: 0.3919
2024-03-28 18:03:05,916 - config - INFO - Validation Loss: 0.4418
2024-03-28 18:03:05,934 - config - INFO - Epoch [388/2000], Train Loss: 0.3913
2024-03-28 18:03:05,938 - config - INFO - Validation Loss: 0.4428
2024-03-28 18:03:05,956 - config - INFO - Epoch [389/2000], Train Loss: 0.3913
2024-03-28 18:03:05,960 - config - INFO - Validation Loss: 0.4428
2024-03-28 18:03:05,979 - config - INFO - Epoch [390/2000], Train Loss: 0.3911
2024-03-28 18:03:05,983 - config - INFO - Validation Loss: 0.4420
2024-03-28 18:03:06,001 - config - INFO - Epoch [391/2000], Train Loss: 0.3908
2024-03-28 18:03:06,005 - config - INFO - Validation Loss: 0.4419
2024-03-28 18:03:06,023 - config - INFO - Epoch [392/2000], Train Loss: 0.3920
2024-03-28 18:03:06,027 - config - INFO - Validation Loss: 0.4414
2024-03-28 18:03:06,046 - config - INFO - Epoch [393/2000], Train Loss: 0.3905
2024-03-28 18:03:06,050 - config - INFO - Validation Loss: 0.4420
2024-03-28 18:03:06,068 - config - INFO - Epoch [394/2000], Train Loss: 0.3904
2024-03-28 18:03:06,072 - config - INFO - Validation Loss: 0.4421
2024-03-28 18:03:06,090 - config - INFO - Epoch [395/2000], Train Loss: 0.3918
2024-03-28 18:03:06,094 - config - INFO - Validation Loss: 0.4436
2024-03-28 18:03:06,112 - config - INFO - Epoch [396/2000], Train Loss: 0.3896
2024-03-28 18:03:06,116 - config - INFO - Validation Loss: 0.4418
2024-03-28 18:03:06,134 - config - INFO - Epoch [397/2000], Train Loss: 0.3900
2024-03-28 18:03:06,138 - config - INFO - Validation Loss: 0.4416
2024-03-28 18:03:06,157 - config - INFO - Epoch [398/2000], Train Loss: 0.3904
2024-03-28 18:03:06,161 - config - INFO - Validation Loss: 0.4417
2024-03-28 18:03:06,179 - config - INFO - Epoch [399/2000], Train Loss: 0.3901
2024-03-28 18:03:06,183 - config - INFO - Validation Loss: 0.4424
2024-03-28 18:03:06,201 - config - INFO - Epoch [400/2000], Train Loss: 0.3896
2024-03-28 18:03:06,205 - config - INFO - Validation Loss: 0.4428
2024-03-28 18:03:06,223 - config - INFO - Epoch [401/2000], Train Loss: 0.3891
2024-03-28 18:03:06,227 - config - INFO - Validation Loss: 0.4423
2024-03-28 18:03:06,246 - config - INFO - Epoch [402/2000], Train Loss: 0.3897
2024-03-28 18:03:06,250 - config - INFO - Validation Loss: 0.4427
2024-03-28 18:03:06,268 - config - INFO - Epoch [403/2000], Train Loss: 0.3903
2024-03-28 18:03:06,272 - config - INFO - Validation Loss: 0.4415
2024-03-28 18:03:06,290 - config - INFO - Epoch [404/2000], Train Loss: 0.3897
2024-03-28 18:03:06,294 - config - INFO - Validation Loss: 0.4426
2024-03-28 18:03:06,313 - config - INFO - Epoch [405/2000], Train Loss: 0.3886
2024-03-28 18:03:06,317 - config - INFO - Validation Loss: 0.4426
2024-03-28 18:03:06,335 - config - INFO - Epoch [406/2000], Train Loss: 0.3885
2024-03-28 18:03:06,339 - config - INFO - Validation Loss: 0.4423
2024-03-28 18:03:06,357 - config - INFO - Epoch [407/2000], Train Loss: 0.3885
2024-03-28 18:03:06,361 - config - INFO - Validation Loss: 0.4424
2024-03-28 18:03:06,379 - config - INFO - Epoch [408/2000], Train Loss: 0.3880
2024-03-28 18:03:06,383 - config - INFO - Validation Loss: 0.4429
2024-03-28 18:03:06,402 - config - INFO - Epoch [409/2000], Train Loss: 0.3877
2024-03-28 18:03:06,406 - config - INFO - Validation Loss: 0.4426
2024-03-28 18:03:06,424 - config - INFO - Epoch [410/2000], Train Loss: 0.3877
2024-03-28 18:03:06,428 - config - INFO - Validation Loss: 0.4424
2024-03-28 18:03:06,446 - config - INFO - Epoch [411/2000], Train Loss: 0.3876
2024-03-28 18:03:06,450 - config - INFO - Validation Loss: 0.4423
2024-03-28 18:03:06,468 - config - INFO - Epoch [412/2000], Train Loss: 0.3880
2024-03-28 18:03:06,472 - config - INFO - Validation Loss: 0.4427
2024-03-28 18:03:06,491 - config - INFO - Epoch [413/2000], Train Loss: 0.3877
2024-03-28 18:03:06,495 - config - INFO - Validation Loss: 0.4421
2024-03-28 18:03:06,513 - config - INFO - Epoch [414/2000], Train Loss: 0.3874
2024-03-28 18:03:06,517 - config - INFO - Validation Loss: 0.4424
2024-03-28 18:03:06,535 - config - INFO - Epoch [415/2000], Train Loss: 0.3880
2024-03-28 18:03:06,539 - config - INFO - Validation Loss: 0.4419
2024-03-28 18:03:06,558 - config - INFO - Epoch [416/2000], Train Loss: 0.3878
2024-03-28 18:03:06,562 - config - INFO - Validation Loss: 0.4427
2024-03-28 18:03:06,580 - config - INFO - Epoch [417/2000], Train Loss: 0.3872
2024-03-28 18:03:06,584 - config - INFO - Validation Loss: 0.4422
2024-03-28 18:03:06,602 - config - INFO - Epoch [418/2000], Train Loss: 0.3866
2024-03-28 18:03:06,606 - config - INFO - Validation Loss: 0.4432
2024-03-28 18:03:06,624 - config - INFO - Epoch [419/2000], Train Loss: 0.3867
2024-03-28 18:03:06,628 - config - INFO - Validation Loss: 0.4431
2024-03-28 18:03:06,647 - config - INFO - Epoch [420/2000], Train Loss: 0.3878
2024-03-28 18:03:06,651 - config - INFO - Validation Loss: 0.4438
2024-03-28 18:03:06,669 - config - INFO - Epoch [421/2000], Train Loss: 0.3868
2024-03-28 18:03:06,673 - config - INFO - Validation Loss: 0.4422
2024-03-28 18:03:06,691 - config - INFO - Epoch [422/2000], Train Loss: 0.3866
2024-03-28 18:03:06,695 - config - INFO - Validation Loss: 0.4422
2024-03-28 18:03:06,714 - config - INFO - Epoch [423/2000], Train Loss: 0.3858
2024-03-28 18:03:06,718 - config - INFO - Validation Loss: 0.4422
2024-03-28 18:03:06,736 - config - INFO - Epoch [424/2000], Train Loss: 0.3855
2024-03-28 18:03:06,740 - config - INFO - Validation Loss: 0.4423
2024-03-28 18:03:06,758 - config - INFO - Epoch [425/2000], Train Loss: 0.3853
2024-03-28 18:03:06,762 - config - INFO - Validation Loss: 0.4421
2024-03-28 18:03:06,780 - config - INFO - Epoch [426/2000], Train Loss: 0.3852
2024-03-28 18:03:06,784 - config - INFO - Validation Loss: 0.4426
2024-03-28 18:03:06,802 - config - INFO - Epoch [427/2000], Train Loss: 0.3851
2024-03-28 18:03:06,806 - config - INFO - Validation Loss: 0.4433
2024-03-28 18:03:06,825 - config - INFO - Epoch [428/2000], Train Loss: 0.3855
2024-03-28 18:03:06,829 - config - INFO - Validation Loss: 0.4427
2024-03-28 18:03:06,847 - config - INFO - Epoch [429/2000], Train Loss: 0.3848
2024-03-28 18:03:06,851 - config - INFO - Validation Loss: 0.4435
2024-03-28 18:03:06,869 - config - INFO - Epoch [430/2000], Train Loss: 0.3847
2024-03-28 18:03:06,873 - config - INFO - Validation Loss: 0.4427
2024-03-28 18:03:06,891 - config - INFO - Epoch [431/2000], Train Loss: 0.3844
2024-03-28 18:03:06,895 - config - INFO - Validation Loss: 0.4427
2024-03-28 18:03:06,914 - config - INFO - Epoch [432/2000], Train Loss: 0.3847
2024-03-28 18:03:06,918 - config - INFO - Validation Loss: 0.4422
2024-03-28 18:03:06,936 - config - INFO - Epoch [433/2000], Train Loss: 0.3842
2024-03-28 18:03:06,940 - config - INFO - Validation Loss: 0.4428
2024-03-28 18:03:06,958 - config - INFO - Epoch [434/2000], Train Loss: 0.3838
2024-03-28 18:03:06,962 - config - INFO - Validation Loss: 0.4432
2024-03-28 18:03:06,981 - config - INFO - Epoch [435/2000], Train Loss: 0.3837
2024-03-28 18:03:06,984 - config - INFO - Validation Loss: 0.4432
2024-03-28 18:03:07,009 - config - INFO - Epoch [436/2000], Train Loss: 0.3836
2024-03-28 18:03:07,013 - config - INFO - Validation Loss: 0.4429
2024-03-28 18:03:07,032 - config - INFO - Epoch [437/2000], Train Loss: 0.3838
2024-03-28 18:03:07,035 - config - INFO - Validation Loss: 0.4431
2024-03-28 18:03:07,054 - config - INFO - Epoch [438/2000], Train Loss: 0.3837
2024-03-28 18:03:07,058 - config - INFO - Validation Loss: 0.4435
2024-03-28 18:03:07,076 - config - INFO - Epoch [439/2000], Train Loss: 0.3831
2024-03-28 18:03:07,080 - config - INFO - Validation Loss: 0.4421
2024-03-28 18:03:07,098 - config - INFO - Epoch [440/2000], Train Loss: 0.3835
2024-03-28 18:03:07,102 - config - INFO - Validation Loss: 0.4418
2024-03-28 18:03:07,121 - config - INFO - Epoch [441/2000], Train Loss: 0.3834
2024-03-28 18:03:07,125 - config - INFO - Validation Loss: 0.4426
2024-03-28 18:03:07,143 - config - INFO - Epoch [442/2000], Train Loss: 0.3827
2024-03-28 18:03:07,147 - config - INFO - Validation Loss: 0.4429
2024-03-28 18:03:07,165 - config - INFO - Epoch [443/2000], Train Loss: 0.3828
2024-03-28 18:03:07,169 - config - INFO - Validation Loss: 0.4431
2024-03-28 18:03:07,187 - config - INFO - Epoch [444/2000], Train Loss: 0.3835
2024-03-28 18:03:07,191 - config - INFO - Validation Loss: 0.4423
2024-03-28 18:03:07,210 - config - INFO - Epoch [445/2000], Train Loss: 0.3840
2024-03-28 18:03:07,214 - config - INFO - Validation Loss: 0.4436
2024-03-28 18:03:07,232 - config - INFO - Epoch [446/2000], Train Loss: 0.3821
2024-03-28 18:03:07,236 - config - INFO - Validation Loss: 0.4420
2024-03-28 18:03:07,254 - config - INFO - Epoch [447/2000], Train Loss: 0.3819
2024-03-28 18:03:07,258 - config - INFO - Validation Loss: 0.4422
2024-03-28 18:03:07,276 - config - INFO - Epoch [448/2000], Train Loss: 0.3820
2024-03-28 18:03:07,280 - config - INFO - Validation Loss: 0.4421
2024-03-28 18:03:07,299 - config - INFO - Epoch [449/2000], Train Loss: 0.3814
2024-03-28 18:03:07,303 - config - INFO - Validation Loss: 0.4422
2024-03-28 18:03:07,321 - config - INFO - Epoch [450/2000], Train Loss: 0.3817
2024-03-28 18:03:07,325 - config - INFO - Validation Loss: 0.4433
2024-03-28 18:03:07,343 - config - INFO - Epoch [451/2000], Train Loss: 0.3816
2024-03-28 18:03:07,347 - config - INFO - Validation Loss: 0.4433
2024-03-28 18:03:07,365 - config - INFO - Epoch [452/2000], Train Loss: 0.3812
2024-03-28 18:03:07,369 - config - INFO - Validation Loss: 0.4424
2024-03-28 18:03:07,388 - config - INFO - Epoch [453/2000], Train Loss: 0.3809
2024-03-28 18:03:07,392 - config - INFO - Validation Loss: 0.4419
2024-03-28 18:03:07,410 - config - INFO - Epoch [454/2000], Train Loss: 0.3809
2024-03-28 18:03:07,414 - config - INFO - Validation Loss: 0.4421
2024-03-28 18:03:07,432 - config - INFO - Epoch [455/2000], Train Loss: 0.3807
2024-03-28 18:03:07,436 - config - INFO - Validation Loss: 0.4420
2024-03-28 18:03:07,455 - config - INFO - Epoch [456/2000], Train Loss: 0.3808
2024-03-28 18:03:07,459 - config - INFO - Validation Loss: 0.4418
2024-03-28 18:03:07,477 - config - INFO - Epoch [457/2000], Train Loss: 0.3806
2024-03-28 18:03:07,481 - config - INFO - Validation Loss: 0.4412
2024-03-28 18:03:07,499 - config - INFO - Epoch [458/2000], Train Loss: 0.3802
2024-03-28 18:03:07,503 - config - INFO - Validation Loss: 0.4413
2024-03-28 18:03:07,521 - config - INFO - Epoch [459/2000], Train Loss: 0.3801
2024-03-28 18:03:07,525 - config - INFO - Validation Loss: 0.4417
2024-03-28 18:03:07,544 - config - INFO - Epoch [460/2000], Train Loss: 0.3817
2024-03-28 18:03:07,548 - config - INFO - Validation Loss: 0.4429
2024-03-28 18:03:07,566 - config - INFO - Epoch [461/2000], Train Loss: 0.3796
2024-03-28 18:03:07,570 - config - INFO - Validation Loss: 0.4420
2024-03-28 18:03:07,588 - config - INFO - Epoch [462/2000], Train Loss: 0.3808
2024-03-28 18:03:07,592 - config - INFO - Validation Loss: 0.4418
2024-03-28 18:03:07,611 - config - INFO - Epoch [463/2000], Train Loss: 0.3803
2024-03-28 18:03:07,615 - config - INFO - Validation Loss: 0.4424
2024-03-28 18:03:07,633 - config - INFO - Epoch [464/2000], Train Loss: 0.3795
2024-03-28 18:03:07,637 - config - INFO - Validation Loss: 0.4426
2024-03-28 18:03:07,655 - config - INFO - Epoch [465/2000], Train Loss: 0.3791
2024-03-28 18:03:07,659 - config - INFO - Validation Loss: 0.4426
2024-03-28 18:03:07,677 - config - INFO - Epoch [466/2000], Train Loss: 0.3792
2024-03-28 18:03:07,681 - config - INFO - Validation Loss: 0.4425
2024-03-28 18:03:07,700 - config - INFO - Epoch [467/2000], Train Loss: 0.3802
2024-03-28 18:03:07,704 - config - INFO - Validation Loss: 0.4418
2024-03-28 18:03:07,722 - config - INFO - Epoch [468/2000], Train Loss: 0.3790
2024-03-28 18:03:07,726 - config - INFO - Validation Loss: 0.4423
2024-03-28 18:03:07,745 - config - INFO - Epoch [469/2000], Train Loss: 0.3790
2024-03-28 18:03:07,748 - config - INFO - Validation Loss: 0.4424
2024-03-28 18:03:07,767 - config - INFO - Epoch [470/2000], Train Loss: 0.3788
2024-03-28 18:03:07,771 - config - INFO - Validation Loss: 0.4421
2024-03-28 18:03:07,789 - config - INFO - Epoch [471/2000], Train Loss: 0.3789
2024-03-28 18:03:07,793 - config - INFO - Validation Loss: 0.4422
2024-03-28 18:03:07,811 - config - INFO - Epoch [472/2000], Train Loss: 0.3778
2024-03-28 18:03:07,815 - config - INFO - Validation Loss: 0.4434
2024-03-28 18:03:07,834 - config - INFO - Epoch [473/2000], Train Loss: 0.3789
2024-03-28 18:03:07,838 - config - INFO - Validation Loss: 0.4436
2024-03-28 18:03:07,856 - config - INFO - Epoch [474/2000], Train Loss: 0.3781
2024-03-28 18:03:07,860 - config - INFO - Validation Loss: 0.4433
2024-03-28 18:03:07,878 - config - INFO - Epoch [475/2000], Train Loss: 0.3779
2024-03-28 18:03:07,882 - config - INFO - Validation Loss: 0.4433
2024-03-28 18:03:07,900 - config - INFO - Epoch [476/2000], Train Loss: 0.3777
2024-03-28 18:03:07,904 - config - INFO - Validation Loss: 0.4429
2024-03-28 18:03:07,923 - config - INFO - Epoch [477/2000], Train Loss: 0.3781
2024-03-28 18:03:07,927 - config - INFO - Validation Loss: 0.4422
2024-03-28 18:03:07,945 - config - INFO - Epoch [478/2000], Train Loss: 0.3773
2024-03-28 18:03:07,949 - config - INFO - Validation Loss: 0.4425
2024-03-28 18:03:07,967 - config - INFO - Epoch [479/2000], Train Loss: 0.3771
2024-03-28 18:03:07,971 - config - INFO - Validation Loss: 0.4429
2024-03-28 18:03:07,989 - config - INFO - Epoch [480/2000], Train Loss: 0.3770
2024-03-28 18:03:07,993 - config - INFO - Validation Loss: 0.4434
2024-03-28 18:03:08,011 - config - INFO - Epoch [481/2000], Train Loss: 0.3768
2024-03-28 18:03:08,016 - config - INFO - Validation Loss: 0.4428
2024-03-28 18:03:08,034 - config - INFO - Epoch [482/2000], Train Loss: 0.3773
2024-03-28 18:03:08,038 - config - INFO - Validation Loss: 0.4425
2024-03-28 18:03:08,056 - config - INFO - Epoch [483/2000], Train Loss: 0.3767
2024-03-28 18:03:08,060 - config - INFO - Validation Loss: 0.4425
2024-03-28 18:03:08,078 - config - INFO - Epoch [484/2000], Train Loss: 0.3764
2024-03-28 18:03:08,082 - config - INFO - Validation Loss: 0.4424
2024-03-28 18:03:08,101 - config - INFO - Epoch [485/2000], Train Loss: 0.3765
2024-03-28 18:03:08,104 - config - INFO - Validation Loss: 0.4429
2024-03-28 18:03:08,123 - config - INFO - Epoch [486/2000], Train Loss: 0.3771
2024-03-28 18:03:08,127 - config - INFO - Validation Loss: 0.4441
2024-03-28 18:03:08,145 - config - INFO - Epoch [487/2000], Train Loss: 0.3762
2024-03-28 18:03:08,149 - config - INFO - Validation Loss: 0.4432
2024-03-28 18:03:08,167 - config - INFO - Epoch [488/2000], Train Loss: 0.3759
2024-03-28 18:03:08,171 - config - INFO - Validation Loss: 0.4429
2024-03-28 18:03:08,190 - config - INFO - Epoch [489/2000], Train Loss: 0.3756
2024-03-28 18:03:08,194 - config - INFO - Validation Loss: 0.4431
2024-03-28 18:03:08,212 - config - INFO - Epoch [490/2000], Train Loss: 0.3765
2024-03-28 18:03:08,216 - config - INFO - Validation Loss: 0.4428
2024-03-28 18:03:08,234 - config - INFO - Epoch [491/2000], Train Loss: 0.3753
2024-03-28 18:03:08,238 - config - INFO - Validation Loss: 0.4426
2024-03-28 18:03:08,257 - config - INFO - Epoch [492/2000], Train Loss: 0.3759
2024-03-28 18:03:08,261 - config - INFO - Validation Loss: 0.4429
2024-03-28 18:03:08,279 - config - INFO - Epoch [493/2000], Train Loss: 0.3765
2024-03-28 18:03:08,283 - config - INFO - Validation Loss: 0.4443
2024-03-28 18:03:08,301 - config - INFO - Epoch [494/2000], Train Loss: 0.3748
2024-03-28 18:03:08,305 - config - INFO - Validation Loss: 0.4434
2024-03-28 18:03:08,323 - config - INFO - Epoch [495/2000], Train Loss: 0.3754
2024-03-28 18:03:08,327 - config - INFO - Validation Loss: 0.4432
2024-03-28 18:03:08,346 - config - INFO - Epoch [496/2000], Train Loss: 0.3756
2024-03-28 18:03:08,350 - config - INFO - Validation Loss: 0.4429
2024-03-28 18:03:08,368 - config - INFO - Epoch [497/2000], Train Loss: 0.3756
2024-03-28 18:03:08,372 - config - INFO - Validation Loss: 0.4429
2024-03-28 18:03:08,390 - config - INFO - Epoch [498/2000], Train Loss: 0.3746
2024-03-28 18:03:08,394 - config - INFO - Validation Loss: 0.4429
2024-03-28 18:03:08,412 - config - INFO - Epoch [499/2000], Train Loss: 0.3754
2024-03-28 18:03:08,416 - config - INFO - Validation Loss: 0.4436
2024-03-28 18:03:08,435 - config - INFO - Epoch [500/2000], Train Loss: 0.3745
2024-03-28 18:03:08,439 - config - INFO - Validation Loss: 0.4444
2024-03-28 18:03:08,457 - config - INFO - Epoch [501/2000], Train Loss: 0.3747
2024-03-28 18:03:08,461 - config - INFO - Validation Loss: 0.4439
2024-03-28 18:03:08,479 - config - INFO - Epoch [502/2000], Train Loss: 0.3742
2024-03-28 18:03:08,483 - config - INFO - Validation Loss: 0.4444
2024-03-28 18:03:08,501 - config - INFO - Epoch [503/2000], Train Loss: 0.3740
2024-03-28 18:03:08,505 - config - INFO - Validation Loss: 0.4447
2024-03-28 18:03:08,524 - config - INFO - Epoch [504/2000], Train Loss: 0.3740
2024-03-28 18:03:08,528 - config - INFO - Validation Loss: 0.4440
2024-03-28 18:03:08,546 - config - INFO - Epoch [505/2000], Train Loss: 0.3735
2024-03-28 18:03:08,550 - config - INFO - Validation Loss: 0.4440
2024-03-28 18:03:08,568 - config - INFO - Epoch [506/2000], Train Loss: 0.3735
2024-03-28 18:03:08,572 - config - INFO - Validation Loss: 0.4435
2024-03-28 18:03:08,591 - config - INFO - Epoch [507/2000], Train Loss: 0.3733
2024-03-28 18:03:08,595 - config - INFO - Validation Loss: 0.4431
2024-03-28 18:03:08,613 - config - INFO - Epoch [508/2000], Train Loss: 0.3737
2024-03-28 18:03:08,617 - config - INFO - Validation Loss: 0.4433
2024-03-28 18:03:08,635 - config - INFO - Epoch [509/2000], Train Loss: 0.3732
2024-03-28 18:03:08,639 - config - INFO - Validation Loss: 0.4432
2024-03-28 18:03:08,657 - config - INFO - Epoch [510/2000], Train Loss: 0.3734
2024-03-28 18:03:08,661 - config - INFO - Validation Loss: 0.4430
2024-03-28 18:03:08,679 - config - INFO - Epoch [511/2000], Train Loss: 0.3731
2024-03-28 18:03:08,683 - config - INFO - Validation Loss: 0.4435
2024-03-28 18:03:08,702 - config - INFO - Epoch [512/2000], Train Loss: 0.3732
2024-03-28 18:03:08,705 - config - INFO - Validation Loss: 0.4446
2024-03-28 18:03:08,724 - config - INFO - Epoch [513/2000], Train Loss: 0.3732
2024-03-28 18:03:08,728 - config - INFO - Validation Loss: 0.4438
2024-03-28 18:03:08,746 - config - INFO - Epoch [514/2000], Train Loss: 0.3726
2024-03-28 18:03:08,750 - config - INFO - Validation Loss: 0.4443
2024-03-28 18:03:08,768 - config - INFO - Epoch [515/2000], Train Loss: 0.3726
2024-03-28 18:03:08,772 - config - INFO - Validation Loss: 0.4441
2024-03-28 18:03:08,790 - config - INFO - Epoch [516/2000], Train Loss: 0.3724
2024-03-28 18:03:08,794 - config - INFO - Validation Loss: 0.4442
2024-03-28 18:03:08,812 - config - INFO - Epoch [517/2000], Train Loss: 0.3720
2024-03-28 18:03:08,816 - config - INFO - Validation Loss: 0.4447
2024-03-28 18:03:08,835 - config - INFO - Epoch [518/2000], Train Loss: 0.3725
2024-03-28 18:03:08,838 - config - INFO - Validation Loss: 0.4438
2024-03-28 18:03:08,857 - config - INFO - Epoch [519/2000], Train Loss: 0.3718
2024-03-28 18:03:08,861 - config - INFO - Validation Loss: 0.4438
2024-03-28 18:03:08,879 - config - INFO - Epoch [520/2000], Train Loss: 0.3714
2024-03-28 18:03:08,883 - config - INFO - Validation Loss: 0.4434
2024-03-28 18:03:08,901 - config - INFO - Epoch [521/2000], Train Loss: 0.3715
2024-03-28 18:03:08,905 - config - INFO - Validation Loss: 0.4434
2024-03-28 18:03:08,923 - config - INFO - Epoch [522/2000], Train Loss: 0.3715
2024-03-28 18:03:08,927 - config - INFO - Validation Loss: 0.4441
2024-03-28 18:03:08,945 - config - INFO - Epoch [523/2000], Train Loss: 0.3714
2024-03-28 18:03:08,949 - config - INFO - Validation Loss: 0.4445
2024-03-28 18:03:08,968 - config - INFO - Epoch [524/2000], Train Loss: 0.3715
2024-03-28 18:03:08,972 - config - INFO - Validation Loss: 0.4442
2024-03-28 18:03:08,990 - config - INFO - Epoch [525/2000], Train Loss: 0.3711
2024-03-28 18:03:08,994 - config - INFO - Validation Loss: 0.4440
2024-03-28 18:03:09,012 - config - INFO - Epoch [526/2000], Train Loss: 0.3708
2024-03-28 18:03:09,016 - config - INFO - Validation Loss: 0.4446
2024-03-28 18:03:09,034 - config - INFO - Epoch [527/2000], Train Loss: 0.3704
2024-03-28 18:03:09,038 - config - INFO - Validation Loss: 0.4445
2024-03-28 18:03:09,056 - config - INFO - Epoch [528/2000], Train Loss: 0.3732
2024-03-28 18:03:09,060 - config - INFO - Validation Loss: 0.4453
2024-03-28 18:03:09,079 - config - INFO - Epoch [529/2000], Train Loss: 0.3711
2024-03-28 18:03:09,083 - config - INFO - Validation Loss: 0.4450
2024-03-28 18:03:09,105 - config - INFO - Epoch [530/2000], Train Loss: 0.3703
2024-03-28 18:03:09,110 - config - INFO - Validation Loss: 0.4455
2024-03-28 18:03:09,128 - config - INFO - Epoch [531/2000], Train Loss: 0.3711
2024-03-28 18:03:09,132 - config - INFO - Validation Loss: 0.4451
2024-03-28 18:03:09,151 - config - INFO - Epoch [532/2000], Train Loss: 0.3701
2024-03-28 18:03:09,155 - config - INFO - Validation Loss: 0.4451
2024-03-28 18:03:09,173 - config - INFO - Epoch [533/2000], Train Loss: 0.3702
2024-03-28 18:03:09,177 - config - INFO - Validation Loss: 0.4447
2024-03-28 18:03:09,195 - config - INFO - Epoch [534/2000], Train Loss: 0.3703
2024-03-28 18:03:09,199 - config - INFO - Validation Loss: 0.4444
2024-03-28 18:03:09,217 - config - INFO - Epoch [535/2000], Train Loss: 0.3697
2024-03-28 18:03:09,221 - config - INFO - Validation Loss: 0.4444
2024-03-28 18:03:09,240 - config - INFO - Epoch [536/2000], Train Loss: 0.3696
2024-03-28 18:03:09,243 - config - INFO - Validation Loss: 0.4445
2024-03-28 18:03:09,262 - config - INFO - Epoch [537/2000], Train Loss: 0.3692
2024-03-28 18:03:09,266 - config - INFO - Validation Loss: 0.4445
2024-03-28 18:03:09,284 - config - INFO - Epoch [538/2000], Train Loss: 0.3698
2024-03-28 18:03:09,288 - config - INFO - Validation Loss: 0.4444
2024-03-28 18:03:09,306 - config - INFO - Epoch [539/2000], Train Loss: 0.3692
2024-03-28 18:03:09,310 - config - INFO - Validation Loss: 0.4446
2024-03-28 18:03:09,329 - config - INFO - Epoch [540/2000], Train Loss: 0.3696
2024-03-28 18:03:09,332 - config - INFO - Validation Loss: 0.4440
2024-03-28 18:03:09,351 - config - INFO - Epoch [541/2000], Train Loss: 0.3711
2024-03-28 18:03:09,355 - config - INFO - Validation Loss: 0.4457
2024-03-28 18:03:09,373 - config - INFO - Epoch [542/2000], Train Loss: 0.3692
2024-03-28 18:03:09,377 - config - INFO - Validation Loss: 0.4443
2024-03-28 18:03:09,395 - config - INFO - Epoch [543/2000], Train Loss: 0.3689
2024-03-28 18:03:09,399 - config - INFO - Validation Loss: 0.4439
2024-03-28 18:03:09,428 - config - INFO - Epoch [544/2000], Train Loss: 0.3691
2024-03-28 18:03:09,432 - config - INFO - Validation Loss: 0.4448
2024-03-28 18:03:09,450 - config - INFO - Epoch [545/2000], Train Loss: 0.3685
2024-03-28 18:03:09,454 - config - INFO - Validation Loss: 0.4451
2024-03-28 18:03:09,472 - config - INFO - Epoch [546/2000], Train Loss: 0.3686
2024-03-28 18:03:09,476 - config - INFO - Validation Loss: 0.4454
2024-03-28 18:03:09,494 - config - INFO - Epoch [547/2000], Train Loss: 0.3681
2024-03-28 18:03:09,498 - config - INFO - Validation Loss: 0.4451
2024-03-28 18:03:09,517 - config - INFO - Epoch [548/2000], Train Loss: 0.3680
2024-03-28 18:03:09,521 - config - INFO - Validation Loss: 0.4445
2024-03-28 18:03:09,539 - config - INFO - Epoch [549/2000], Train Loss: 0.3683
2024-03-28 18:03:09,543 - config - INFO - Validation Loss: 0.4441
2024-03-28 18:03:09,561 - config - INFO - Epoch [550/2000], Train Loss: 0.3678
2024-03-28 18:03:09,565 - config - INFO - Validation Loss: 0.4444
2024-03-28 18:03:09,583 - config - INFO - Epoch [551/2000], Train Loss: 0.3683
2024-03-28 18:03:09,587 - config - INFO - Validation Loss: 0.4455
2024-03-28 18:03:09,605 - config - INFO - Epoch [552/2000], Train Loss: 0.3677
2024-03-28 18:03:09,609 - config - INFO - Validation Loss: 0.4453
2024-03-28 18:03:09,627 - config - INFO - Epoch [553/2000], Train Loss: 0.3683
2024-03-28 18:03:09,631 - config - INFO - Validation Loss: 0.4455
2024-03-28 18:03:09,650 - config - INFO - Epoch [554/2000], Train Loss: 0.3685
2024-03-28 18:03:09,654 - config - INFO - Validation Loss: 0.4455
2024-03-28 18:03:09,672 - config - INFO - Epoch [555/2000], Train Loss: 0.3678
2024-03-28 18:03:09,676 - config - INFO - Validation Loss: 0.4460
2024-03-28 18:03:09,694 - config - INFO - Epoch [556/2000], Train Loss: 0.3674
2024-03-28 18:03:09,698 - config - INFO - Validation Loss: 0.4459
2024-03-28 18:03:09,718 - config - INFO - Epoch [557/2000], Train Loss: 0.3670
2024-03-28 18:03:09,722 - config - INFO - Validation Loss: 0.4451
2024-03-28 18:03:09,740 - config - INFO - Epoch [558/2000], Train Loss: 0.3669
2024-03-28 18:03:09,744 - config - INFO - Validation Loss: 0.4446
2024-03-28 18:03:09,762 - config - INFO - Epoch [559/2000], Train Loss: 0.3670
2024-03-28 18:03:09,766 - config - INFO - Validation Loss: 0.4441
2024-03-28 18:03:09,784 - config - INFO - Epoch [560/2000], Train Loss: 0.3666
2024-03-28 18:03:09,788 - config - INFO - Validation Loss: 0.4442
2024-03-28 18:03:09,807 - config - INFO - Epoch [561/2000], Train Loss: 0.3666
2024-03-28 18:03:09,811 - config - INFO - Validation Loss: 0.4441
2024-03-28 18:03:09,829 - config - INFO - Epoch [562/2000], Train Loss: 0.3668
2024-03-28 18:03:09,833 - config - INFO - Validation Loss: 0.4441
2024-03-28 18:03:09,851 - config - INFO - Epoch [563/2000], Train Loss: 0.3664
2024-03-28 18:03:09,855 - config - INFO - Validation Loss: 0.4438
2024-03-28 18:03:09,873 - config - INFO - Epoch [564/2000], Train Loss: 0.3664
2024-03-28 18:03:09,877 - config - INFO - Validation Loss: 0.4444
2024-03-28 18:03:09,895 - config - INFO - Epoch [565/2000], Train Loss: 0.3660
2024-03-28 18:03:09,899 - config - INFO - Validation Loss: 0.4451
2024-03-28 18:03:09,918 - config - INFO - Epoch [566/2000], Train Loss: 0.3668
2024-03-28 18:03:09,922 - config - INFO - Validation Loss: 0.4459
2024-03-28 18:03:09,940 - config - INFO - Epoch [567/2000], Train Loss: 0.3661
2024-03-28 18:03:09,944 - config - INFO - Validation Loss: 0.4455
2024-03-28 18:03:09,962 - config - INFO - Epoch [568/2000], Train Loss: 0.3660
2024-03-28 18:03:09,966 - config - INFO - Validation Loss: 0.4452
2024-03-28 18:03:09,984 - config - INFO - Epoch [569/2000], Train Loss: 0.3661
2024-03-28 18:03:09,988 - config - INFO - Validation Loss: 0.4453
2024-03-28 18:03:10,006 - config - INFO - Epoch [570/2000], Train Loss: 0.3658
2024-03-28 18:03:10,010 - config - INFO - Validation Loss: 0.4461
2024-03-28 18:03:10,029 - config - INFO - Epoch [571/2000], Train Loss: 0.3656
2024-03-28 18:03:10,033 - config - INFO - Validation Loss: 0.4462
2024-03-28 18:03:10,051 - config - INFO - Epoch [572/2000], Train Loss: 0.3659
2024-03-28 18:03:10,055 - config - INFO - Validation Loss: 0.4473
2024-03-28 18:03:10,073 - config - INFO - Epoch [573/2000], Train Loss: 0.3660
2024-03-28 18:03:10,077 - config - INFO - Validation Loss: 0.4465
2024-03-28 18:03:10,095 - config - INFO - Epoch [574/2000], Train Loss: 0.3650
2024-03-28 18:03:10,099 - config - INFO - Validation Loss: 0.4459
2024-03-28 18:03:10,117 - config - INFO - Epoch [575/2000], Train Loss: 0.3652
2024-03-28 18:03:10,121 - config - INFO - Validation Loss: 0.4466
2024-03-28 18:03:10,140 - config - INFO - Epoch [576/2000], Train Loss: 0.3650
2024-03-28 18:03:10,144 - config - INFO - Validation Loss: 0.4465
2024-03-28 18:03:10,162 - config - INFO - Epoch [577/2000], Train Loss: 0.3646
2024-03-28 18:03:10,166 - config - INFO - Validation Loss: 0.4464
2024-03-28 18:03:10,184 - config - INFO - Epoch [578/2000], Train Loss: 0.3646
2024-03-28 18:03:10,188 - config - INFO - Validation Loss: 0.4459
2024-03-28 18:03:10,206 - config - INFO - Epoch [579/2000], Train Loss: 0.3645
2024-03-28 18:03:10,210 - config - INFO - Validation Loss: 0.4460
2024-03-28 18:03:10,229 - config - INFO - Epoch [580/2000], Train Loss: 0.3648
2024-03-28 18:03:10,235 - config - INFO - Validation Loss: 0.4450
2024-03-28 18:03:10,253 - config - INFO - Epoch [581/2000], Train Loss: 0.3643
2024-03-28 18:03:10,257 - config - INFO - Validation Loss: 0.4455
2024-03-28 18:03:10,275 - config - INFO - Epoch [582/2000], Train Loss: 0.3645
2024-03-28 18:03:10,279 - config - INFO - Validation Loss: 0.4452
2024-03-28 18:03:10,298 - config - INFO - Epoch [583/2000], Train Loss: 0.3641
2024-03-28 18:03:10,302 - config - INFO - Validation Loss: 0.4454
2024-03-28 18:03:10,320 - config - INFO - Epoch [584/2000], Train Loss: 0.3638
2024-03-28 18:03:10,324 - config - INFO - Validation Loss: 0.4455
2024-03-28 18:03:10,342 - config - INFO - Epoch [585/2000], Train Loss: 0.3637
2024-03-28 18:03:10,346 - config - INFO - Validation Loss: 0.4456
2024-03-28 18:03:10,364 - config - INFO - Epoch [586/2000], Train Loss: 0.3635
2024-03-28 18:03:10,368 - config - INFO - Validation Loss: 0.4456
2024-03-28 18:03:10,387 - config - INFO - Epoch [587/2000], Train Loss: 0.3634
2024-03-28 18:03:10,391 - config - INFO - Validation Loss: 0.4458
2024-03-28 18:03:10,409 - config - INFO - Epoch [588/2000], Train Loss: 0.3637
2024-03-28 18:03:10,413 - config - INFO - Validation Loss: 0.4457
2024-03-28 18:03:10,431 - config - INFO - Epoch [589/2000], Train Loss: 0.3633
2024-03-28 18:03:10,435 - config - INFO - Validation Loss: 0.4456
2024-03-28 18:03:10,453 - config - INFO - Epoch [590/2000], Train Loss: 0.3636
2024-03-28 18:03:10,457 - config - INFO - Validation Loss: 0.4473
2024-03-28 18:03:10,475 - config - INFO - Epoch [591/2000], Train Loss: 0.3633
2024-03-28 18:03:10,479 - config - INFO - Validation Loss: 0.4469
2024-03-28 18:03:10,498 - config - INFO - Epoch [592/2000], Train Loss: 0.3630
2024-03-28 18:03:10,501 - config - INFO - Validation Loss: 0.4468
2024-03-28 18:03:10,520 - config - INFO - Epoch [593/2000], Train Loss: 0.3630
2024-03-28 18:03:10,524 - config - INFO - Validation Loss: 0.4471
2024-03-28 18:03:10,542 - config - INFO - Epoch [594/2000], Train Loss: 0.3622
2024-03-28 18:03:10,546 - config - INFO - Validation Loss: 0.4470
2024-03-28 18:03:10,564 - config - INFO - Epoch [595/2000], Train Loss: 0.3629
2024-03-28 18:03:10,568 - config - INFO - Validation Loss: 0.4467
2024-03-28 18:03:10,587 - config - INFO - Epoch [596/2000], Train Loss: 0.3646
2024-03-28 18:03:10,591 - config - INFO - Validation Loss: 0.4474
2024-03-28 18:03:10,609 - config - INFO - Epoch [597/2000], Train Loss: 0.3648
2024-03-28 18:03:10,613 - config - INFO - Validation Loss: 0.4460
2024-03-28 18:03:10,631 - config - INFO - Epoch [598/2000], Train Loss: 0.3623
2024-03-28 18:03:10,635 - config - INFO - Validation Loss: 0.4463
2024-03-28 18:03:10,653 - config - INFO - Epoch [599/2000], Train Loss: 0.3620
2024-03-28 18:03:10,657 - config - INFO - Validation Loss: 0.4460
2024-03-28 18:03:10,676 - config - INFO - Epoch [600/2000], Train Loss: 0.3620
2024-03-28 18:03:10,679 - config - INFO - Validation Loss: 0.4457
2024-03-28 18:03:10,698 - config - INFO - Epoch [601/2000], Train Loss: 0.3619
2024-03-28 18:03:10,702 - config - INFO - Validation Loss: 0.4456
2024-03-28 18:03:10,720 - config - INFO - Epoch [602/2000], Train Loss: 0.3621
2024-03-28 18:03:10,724 - config - INFO - Validation Loss: 0.4457
2024-03-28 18:03:10,742 - config - INFO - Epoch [603/2000], Train Loss: 0.3626
2024-03-28 18:03:10,746 - config - INFO - Validation Loss: 0.4463
2024-03-28 18:03:10,764 - config - INFO - Epoch [604/2000], Train Loss: 0.3615
2024-03-28 18:03:10,768 - config - INFO - Validation Loss: 0.4464
2024-03-28 18:03:10,786 - config - INFO - Epoch [605/2000], Train Loss: 0.3614
2024-03-28 18:03:10,790 - config - INFO - Validation Loss: 0.4466
2024-03-28 18:03:10,809 - config - INFO - Epoch [606/2000], Train Loss: 0.3613
2024-03-28 18:03:10,813 - config - INFO - Validation Loss: 0.4470
2024-03-28 18:03:10,831 - config - INFO - Epoch [607/2000], Train Loss: 0.3624
2024-03-28 18:03:10,835 - config - INFO - Validation Loss: 0.4481
2024-03-28 18:03:10,853 - config - INFO - Epoch [608/2000], Train Loss: 0.3615
2024-03-28 18:03:10,857 - config - INFO - Validation Loss: 0.4474
2024-03-28 18:03:10,875 - config - INFO - Epoch [609/2000], Train Loss: 0.3613
2024-03-28 18:03:10,879 - config - INFO - Validation Loss: 0.4481
2024-03-28 18:03:10,897 - config - INFO - Epoch [610/2000], Train Loss: 0.3612
2024-03-28 18:03:10,901 - config - INFO - Validation Loss: 0.4483
2024-03-28 18:03:10,919 - config - INFO - Epoch [611/2000], Train Loss: 0.3611
2024-03-28 18:03:10,923 - config - INFO - Validation Loss: 0.4479
2024-03-28 18:03:10,942 - config - INFO - Epoch [612/2000], Train Loss: 0.3611
2024-03-28 18:03:10,945 - config - INFO - Validation Loss: 0.4477
2024-03-28 18:03:10,964 - config - INFO - Epoch [613/2000], Train Loss: 0.3610
2024-03-28 18:03:10,968 - config - INFO - Validation Loss: 0.4473
2024-03-28 18:03:10,986 - config - INFO - Epoch [614/2000], Train Loss: 0.3605
2024-03-28 18:03:10,990 - config - INFO - Validation Loss: 0.4472
2024-03-28 18:03:11,008 - config - INFO - Epoch [615/2000], Train Loss: 0.3601
2024-03-28 18:03:11,012 - config - INFO - Validation Loss: 0.4468
2024-03-28 18:03:11,030 - config - INFO - Epoch [616/2000], Train Loss: 0.3605
2024-03-28 18:03:11,034 - config - INFO - Validation Loss: 0.4463
2024-03-28 18:03:11,052 - config - INFO - Epoch [617/2000], Train Loss: 0.3604
2024-03-28 18:03:11,056 - config - INFO - Validation Loss: 0.4461
2024-03-28 18:03:11,075 - config - INFO - Epoch [618/2000], Train Loss: 0.3601
2024-03-28 18:03:11,078 - config - INFO - Validation Loss: 0.4467
2024-03-28 18:03:11,097 - config - INFO - Epoch [619/2000], Train Loss: 0.3599
2024-03-28 18:03:11,101 - config - INFO - Validation Loss: 0.4470
2024-03-28 18:03:11,119 - config - INFO - Epoch [620/2000], Train Loss: 0.3599
2024-03-28 18:03:11,123 - config - INFO - Validation Loss: 0.4467
2024-03-28 18:03:11,141 - config - INFO - Epoch [621/2000], Train Loss: 0.3598
2024-03-28 18:03:11,145 - config - INFO - Validation Loss: 0.4471
2024-03-28 18:03:11,163 - config - INFO - Epoch [622/2000], Train Loss: 0.3595
2024-03-28 18:03:11,167 - config - INFO - Validation Loss: 0.4468
2024-03-28 18:03:11,185 - config - INFO - Epoch [623/2000], Train Loss: 0.3593
2024-03-28 18:03:11,189 - config - INFO - Validation Loss: 0.4463
2024-03-28 18:03:11,207 - config - INFO - Epoch [624/2000], Train Loss: 0.3592
2024-03-28 18:03:11,211 - config - INFO - Validation Loss: 0.4465
2024-03-28 18:03:11,230 - config - INFO - Epoch [625/2000], Train Loss: 0.3593
2024-03-28 18:03:11,234 - config - INFO - Validation Loss: 0.4462
2024-03-28 18:03:11,252 - config - INFO - Epoch [626/2000], Train Loss: 0.3588
2024-03-28 18:03:11,256 - config - INFO - Validation Loss: 0.4462
2024-03-28 18:03:11,274 - config - INFO - Epoch [627/2000], Train Loss: 0.3589
2024-03-28 18:03:11,278 - config - INFO - Validation Loss: 0.4464
2024-03-28 18:03:11,296 - config - INFO - Epoch [628/2000], Train Loss: 0.3589
2024-03-28 18:03:11,300 - config - INFO - Validation Loss: 0.4468
2024-03-28 18:03:11,318 - config - INFO - Epoch [629/2000], Train Loss: 0.3589
2024-03-28 18:03:11,322 - config - INFO - Validation Loss: 0.4473
2024-03-28 18:03:11,340 - config - INFO - Epoch [630/2000], Train Loss: 0.3602
2024-03-28 18:03:11,344 - config - INFO - Validation Loss: 0.4480
2024-03-28 18:03:11,363 - config - INFO - Epoch [631/2000], Train Loss: 0.3595
2024-03-28 18:03:11,366 - config - INFO - Validation Loss: 0.4477
2024-03-28 18:03:11,385 - config - INFO - Epoch [632/2000], Train Loss: 0.3594
2024-03-28 18:03:11,389 - config - INFO - Validation Loss: 0.4479
2024-03-28 18:03:11,407 - config - INFO - Epoch [633/2000], Train Loss: 0.3583
2024-03-28 18:03:11,411 - config - INFO - Validation Loss: 0.4476
2024-03-28 18:03:11,429 - config - INFO - Epoch [634/2000], Train Loss: 0.3582
2024-03-28 18:03:11,433 - config - INFO - Validation Loss: 0.4477
2024-03-28 18:03:11,451 - config - INFO - Epoch [635/2000], Train Loss: 0.3582
2024-03-28 18:03:11,455 - config - INFO - Validation Loss: 0.4481
2024-03-28 18:03:11,473 - config - INFO - Epoch [636/2000], Train Loss: 0.3583
2024-03-28 18:03:11,477 - config - INFO - Validation Loss: 0.4484
2024-03-28 18:03:11,495 - config - INFO - Epoch [637/2000], Train Loss: 0.3579
2024-03-28 18:03:11,499 - config - INFO - Validation Loss: 0.4481
2024-03-28 18:03:11,518 - config - INFO - Epoch [638/2000], Train Loss: 0.3583
2024-03-28 18:03:11,522 - config - INFO - Validation Loss: 0.4485
2024-03-28 18:03:11,540 - config - INFO - Epoch [639/2000], Train Loss: 0.3578
2024-03-28 18:03:11,544 - config - INFO - Validation Loss: 0.4479
2024-03-28 18:03:11,562 - config - INFO - Epoch [640/2000], Train Loss: 0.3575
2024-03-28 18:03:11,566 - config - INFO - Validation Loss: 0.4476
2024-03-28 18:03:11,584 - config - INFO - Epoch [641/2000], Train Loss: 0.3582
2024-03-28 18:03:11,588 - config - INFO - Validation Loss: 0.4469
2024-03-28 18:03:11,606 - config - INFO - Epoch [642/2000], Train Loss: 0.3572
2024-03-28 18:03:11,610 - config - INFO - Validation Loss: 0.4473
2024-03-28 18:03:11,628 - config - INFO - Epoch [643/2000], Train Loss: 0.3575
2024-03-28 18:03:11,632 - config - INFO - Validation Loss: 0.4482
2024-03-28 18:03:11,650 - config - INFO - Epoch [644/2000], Train Loss: 0.3578
2024-03-28 18:03:11,654 - config - INFO - Validation Loss: 0.4473
2024-03-28 18:03:11,673 - config - INFO - Epoch [645/2000], Train Loss: 0.3569
2024-03-28 18:03:11,677 - config - INFO - Validation Loss: 0.4470
2024-03-28 18:03:11,695 - config - INFO - Epoch [646/2000], Train Loss: 0.3573
2024-03-28 18:03:11,699 - config - INFO - Validation Loss: 0.4475
2024-03-28 18:03:11,717 - config - INFO - Epoch [647/2000], Train Loss: 0.3568
2024-03-28 18:03:11,721 - config - INFO - Validation Loss: 0.4482
2024-03-28 18:03:11,739 - config - INFO - Epoch [648/2000], Train Loss: 0.3567
2024-03-28 18:03:11,743 - config - INFO - Validation Loss: 0.4483
2024-03-28 18:03:11,761 - config - INFO - Epoch [649/2000], Train Loss: 0.3571
2024-03-28 18:03:11,765 - config - INFO - Validation Loss: 0.4485
2024-03-28 18:03:11,783 - config - INFO - Epoch [650/2000], Train Loss: 0.3562
2024-03-28 18:03:11,787 - config - INFO - Validation Loss: 0.4489
2024-03-28 18:03:11,806 - config - INFO - Epoch [651/2000], Train Loss: 0.3568
2024-03-28 18:03:11,810 - config - INFO - Validation Loss: 0.4497
2024-03-28 18:03:11,828 - config - INFO - Epoch [652/2000], Train Loss: 0.3567
2024-03-28 18:03:11,832 - config - INFO - Validation Loss: 0.4495
2024-03-28 18:03:11,850 - config - INFO - Epoch [653/2000], Train Loss: 0.3561
2024-03-28 18:03:11,854 - config - INFO - Validation Loss: 0.4496
2024-03-28 18:03:11,872 - config - INFO - Epoch [654/2000], Train Loss: 0.3559
2024-03-28 18:03:11,876 - config - INFO - Validation Loss: 0.4501
2024-03-28 18:03:11,894 - config - INFO - Epoch [655/2000], Train Loss: 0.3563
2024-03-28 18:03:11,898 - config - INFO - Validation Loss: 0.4506
2024-03-28 18:03:11,916 - config - INFO - Epoch [656/2000], Train Loss: 0.3560
2024-03-28 18:03:11,920 - config - INFO - Validation Loss: 0.4502
2024-03-28 18:03:11,938 - config - INFO - Epoch [657/2000], Train Loss: 0.3558
2024-03-28 18:03:11,942 - config - INFO - Validation Loss: 0.4501
2024-03-28 18:03:11,961 - config - INFO - Epoch [658/2000], Train Loss: 0.3555
2024-03-28 18:03:11,965 - config - INFO - Validation Loss: 0.4495
2024-03-28 18:03:11,983 - config - INFO - Epoch [659/2000], Train Loss: 0.3554
2024-03-28 18:03:11,987 - config - INFO - Validation Loss: 0.4496
2024-03-28 18:03:12,005 - config - INFO - Epoch [660/2000], Train Loss: 0.3554
2024-03-28 18:03:12,009 - config - INFO - Validation Loss: 0.4492
2024-03-28 18:03:12,027 - config - INFO - Epoch [661/2000], Train Loss: 0.3556
2024-03-28 18:03:12,031 - config - INFO - Validation Loss: 0.4487
2024-03-28 18:03:12,049 - config - INFO - Epoch [662/2000], Train Loss: 0.3555
2024-03-28 18:03:12,053 - config - INFO - Validation Loss: 0.4496
2024-03-28 18:03:12,071 - config - INFO - Epoch [663/2000], Train Loss: 0.3553
2024-03-28 18:03:12,075 - config - INFO - Validation Loss: 0.4494
2024-03-28 18:03:12,094 - config - INFO - Epoch [664/2000], Train Loss: 0.3550
2024-03-28 18:03:12,098 - config - INFO - Validation Loss: 0.4497
2024-03-28 18:03:12,116 - config - INFO - Epoch [665/2000], Train Loss: 0.3547
2024-03-28 18:03:12,120 - config - INFO - Validation Loss: 0.4499
2024-03-28 18:03:12,138 - config - INFO - Epoch [666/2000], Train Loss: 0.3550
2024-03-28 18:03:12,142 - config - INFO - Validation Loss: 0.4491
2024-03-28 18:03:12,160 - config - INFO - Epoch [667/2000], Train Loss: 0.3546
2024-03-28 18:03:12,164 - config - INFO - Validation Loss: 0.4498
2024-03-28 18:03:12,182 - config - INFO - Epoch [668/2000], Train Loss: 0.3548
2024-03-28 18:03:12,186 - config - INFO - Validation Loss: 0.4493
2024-03-28 18:03:12,204 - config - INFO - Epoch [669/2000], Train Loss: 0.3545
2024-03-28 18:03:12,208 - config - INFO - Validation Loss: 0.4493
2024-03-28 18:03:12,226 - config - INFO - Epoch [670/2000], Train Loss: 0.3544
2024-03-28 18:03:12,230 - config - INFO - Validation Loss: 0.4492
2024-03-28 18:03:12,248 - config - INFO - Epoch [671/2000], Train Loss: 0.3540
2024-03-28 18:03:12,252 - config - INFO - Validation Loss: 0.4493
2024-03-28 18:03:12,271 - config - INFO - Epoch [672/2000], Train Loss: 0.3542
2024-03-28 18:03:12,275 - config - INFO - Validation Loss: 0.4497
2024-03-28 18:03:12,293 - config - INFO - Epoch [673/2000], Train Loss: 0.3539
2024-03-28 18:03:12,297 - config - INFO - Validation Loss: 0.4496
2024-03-28 18:03:12,315 - config - INFO - Epoch [674/2000], Train Loss: 0.3540
2024-03-28 18:03:12,319 - config - INFO - Validation Loss: 0.4502
2024-03-28 18:03:12,337 - config - INFO - Epoch [675/2000], Train Loss: 0.3537
2024-03-28 18:03:12,341 - config - INFO - Validation Loss: 0.4496
2024-03-28 18:03:12,359 - config - INFO - Epoch [676/2000], Train Loss: 0.3537
2024-03-28 18:03:12,363 - config - INFO - Validation Loss: 0.4493
2024-03-28 18:03:12,381 - config - INFO - Epoch [677/2000], Train Loss: 0.3536
2024-03-28 18:03:12,385 - config - INFO - Validation Loss: 0.4494
2024-03-28 18:03:12,403 - config - INFO - Epoch [678/2000], Train Loss: 0.3534
2024-03-28 18:03:12,407 - config - INFO - Validation Loss: 0.4494
2024-03-28 18:03:12,425 - config - INFO - Epoch [679/2000], Train Loss: 0.3533
2024-03-28 18:03:12,429 - config - INFO - Validation Loss: 0.4499
2024-03-28 18:03:12,448 - config - INFO - Epoch [680/2000], Train Loss: 0.3530
2024-03-28 18:03:12,452 - config - INFO - Validation Loss: 0.4498
2024-03-28 18:03:12,470 - config - INFO - Epoch [681/2000], Train Loss: 0.3532
2024-03-28 18:03:12,474 - config - INFO - Validation Loss: 0.4495
2024-03-28 18:03:12,492 - config - INFO - Epoch [682/2000], Train Loss: 0.3532
2024-03-28 18:03:12,496 - config - INFO - Validation Loss: 0.4497
2024-03-28 18:03:12,514 - config - INFO - Epoch [683/2000], Train Loss: 0.3527
2024-03-28 18:03:12,518 - config - INFO - Validation Loss: 0.4496
2024-03-28 18:03:12,536 - config - INFO - Epoch [684/2000], Train Loss: 0.3538
2024-03-28 18:03:12,540 - config - INFO - Validation Loss: 0.4506
2024-03-28 18:03:12,558 - config - INFO - Epoch [685/2000], Train Loss: 0.3535
2024-03-28 18:03:12,562 - config - INFO - Validation Loss: 0.4508
2024-03-28 18:03:12,580 - config - INFO - Epoch [686/2000], Train Loss: 0.3532
2024-03-28 18:03:12,584 - config - INFO - Validation Loss: 0.4516
2024-03-28 18:03:12,603 - config - INFO - Epoch [687/2000], Train Loss: 0.3536
2024-03-28 18:03:12,607 - config - INFO - Validation Loss: 0.4516
2024-03-28 18:03:12,625 - config - INFO - Epoch [688/2000], Train Loss: 0.3523
2024-03-28 18:03:12,629 - config - INFO - Validation Loss: 0.4520
2024-03-28 18:03:12,647 - config - INFO - Epoch [689/2000], Train Loss: 0.3525
2024-03-28 18:03:12,651 - config - INFO - Validation Loss: 0.4528
2024-03-28 18:03:12,669 - config - INFO - Epoch [690/2000], Train Loss: 0.3522
2024-03-28 18:03:12,673 - config - INFO - Validation Loss: 0.4520
2024-03-28 18:03:12,691 - config - INFO - Epoch [691/2000], Train Loss: 0.3518
2024-03-28 18:03:12,695 - config - INFO - Validation Loss: 0.4515
2024-03-28 18:03:12,714 - config - INFO - Epoch [692/2000], Train Loss: 0.3520
2024-03-28 18:03:12,718 - config - INFO - Validation Loss: 0.4513
2024-03-28 18:03:12,736 - config - INFO - Epoch [693/2000], Train Loss: 0.3524
2024-03-28 18:03:12,740 - config - INFO - Validation Loss: 0.4515
2024-03-28 18:03:12,758 - config - INFO - Epoch [694/2000], Train Loss: 0.3521
2024-03-28 18:03:12,762 - config - INFO - Validation Loss: 0.4515
2024-03-28 18:03:12,780 - config - INFO - Epoch [695/2000], Train Loss: 0.3517
2024-03-28 18:03:12,784 - config - INFO - Validation Loss: 0.4515
2024-03-28 18:03:12,802 - config - INFO - Epoch [696/2000], Train Loss: 0.3520
2024-03-28 18:03:12,806 - config - INFO - Validation Loss: 0.4513
2024-03-28 18:03:12,824 - config - INFO - Epoch [697/2000], Train Loss: 0.3521
2024-03-28 18:03:12,828 - config - INFO - Validation Loss: 0.4516
2024-03-28 18:03:12,847 - config - INFO - Epoch [698/2000], Train Loss: 0.3528
2024-03-28 18:03:12,851 - config - INFO - Validation Loss: 0.4514
2024-03-28 18:03:12,869 - config - INFO - Epoch [699/2000], Train Loss: 0.3514
2024-03-28 18:03:12,873 - config - INFO - Validation Loss: 0.4519
2024-03-28 18:03:12,891 - config - INFO - Epoch [700/2000], Train Loss: 0.3511
2024-03-28 18:03:12,895 - config - INFO - Validation Loss: 0.4524
2024-03-28 18:03:12,913 - config - INFO - Epoch [701/2000], Train Loss: 0.3517
2024-03-28 18:03:12,917 - config - INFO - Validation Loss: 0.4504
2024-03-28 18:03:12,935 - config - INFO - Epoch [702/2000], Train Loss: 0.3512
2024-03-28 18:03:12,939 - config - INFO - Validation Loss: 0.4503
2024-03-28 18:03:12,957 - config - INFO - Epoch [703/2000], Train Loss: 0.3510
2024-03-28 18:03:12,961 - config - INFO - Validation Loss: 0.4500
2024-03-28 18:03:12,980 - config - INFO - Epoch [704/2000], Train Loss: 0.3511
2024-03-28 18:03:12,984 - config - INFO - Validation Loss: 0.4511
2024-03-28 18:03:13,002 - config - INFO - Epoch [705/2000], Train Loss: 0.3505
2024-03-28 18:03:13,006 - config - INFO - Validation Loss: 0.4509
2024-03-28 18:03:13,024 - config - INFO - Epoch [706/2000], Train Loss: 0.3506
2024-03-28 18:03:13,028 - config - INFO - Validation Loss: 0.4509
2024-03-28 18:03:13,046 - config - INFO - Epoch [707/2000], Train Loss: 0.3506
2024-03-28 18:03:13,050 - config - INFO - Validation Loss: 0.4508
2024-03-28 18:03:13,069 - config - INFO - Epoch [708/2000], Train Loss: 0.3502
2024-03-28 18:03:13,072 - config - INFO - Validation Loss: 0.4510
2024-03-28 18:03:13,091 - config - INFO - Epoch [709/2000], Train Loss: 0.3504
2024-03-28 18:03:13,095 - config - INFO - Validation Loss: 0.4513
2024-03-28 18:03:13,113 - config - INFO - Epoch [710/2000], Train Loss: 0.3504
2024-03-28 18:03:13,119 - config - INFO - Validation Loss: 0.4512
2024-03-28 18:03:13,137 - config - INFO - Epoch [711/2000], Train Loss: 0.3501
2024-03-28 18:03:13,141 - config - INFO - Validation Loss: 0.4505
2024-03-28 18:03:13,159 - config - INFO - Epoch [712/2000], Train Loss: 0.3496
2024-03-28 18:03:13,163 - config - INFO - Validation Loss: 0.4496
2024-03-28 18:03:13,181 - config - INFO - Epoch [713/2000], Train Loss: 0.3498
2024-03-28 18:03:13,185 - config - INFO - Validation Loss: 0.4503
2024-03-28 18:03:13,203 - config - INFO - Epoch [714/2000], Train Loss: 0.3497
2024-03-28 18:03:13,207 - config - INFO - Validation Loss: 0.4504
2024-03-28 18:03:13,226 - config - INFO - Epoch [715/2000], Train Loss: 0.3496
2024-03-28 18:03:13,230 - config - INFO - Validation Loss: 0.4507
2024-03-28 18:03:13,248 - config - INFO - Epoch [716/2000], Train Loss: 0.3497
2024-03-28 18:03:13,252 - config - INFO - Validation Loss: 0.4508
2024-03-28 18:03:13,270 - config - INFO - Epoch [717/2000], Train Loss: 0.3499
2024-03-28 18:03:13,274 - config - INFO - Validation Loss: 0.4518
2024-03-28 18:03:13,292 - config - INFO - Epoch [718/2000], Train Loss: 0.3492
2024-03-28 18:03:13,296 - config - INFO - Validation Loss: 0.4514
2024-03-28 18:03:13,314 - config - INFO - Epoch [719/2000], Train Loss: 0.3497
2024-03-28 18:03:13,318 - config - INFO - Validation Loss: 0.4512
2024-03-28 18:03:13,336 - config - INFO - Epoch [720/2000], Train Loss: 0.3488
2024-03-28 18:03:13,340 - config - INFO - Validation Loss: 0.4514
2024-03-28 18:03:13,358 - config - INFO - Epoch [721/2000], Train Loss: 0.3490
2024-03-28 18:03:13,362 - config - INFO - Validation Loss: 0.4525
2024-03-28 18:03:13,380 - config - INFO - Epoch [722/2000], Train Loss: 0.3490
2024-03-28 18:03:13,384 - config - INFO - Validation Loss: 0.4515
2024-03-28 18:03:13,403 - config - INFO - Epoch [723/2000], Train Loss: 0.3484
2024-03-28 18:03:13,407 - config - INFO - Validation Loss: 0.4514
2024-03-28 18:03:13,425 - config - INFO - Epoch [724/2000], Train Loss: 0.3491
2024-03-28 18:03:13,429 - config - INFO - Validation Loss: 0.4516
2024-03-28 18:03:13,447 - config - INFO - Epoch [725/2000], Train Loss: 0.3486
2024-03-28 18:03:13,451 - config - INFO - Validation Loss: 0.4517
2024-03-28 18:03:13,469 - config - INFO - Epoch [726/2000], Train Loss: 0.3483
2024-03-28 18:03:13,473 - config - INFO - Validation Loss: 0.4512
2024-03-28 18:03:13,491 - config - INFO - Epoch [727/2000], Train Loss: 0.3487
2024-03-28 18:03:13,495 - config - INFO - Validation Loss: 0.4506
2024-03-28 18:03:13,514 - config - INFO - Epoch [728/2000], Train Loss: 0.3482
2024-03-28 18:03:13,517 - config - INFO - Validation Loss: 0.4509
2024-03-28 18:03:13,536 - config - INFO - Epoch [729/2000], Train Loss: 0.3482
2024-03-28 18:03:13,540 - config - INFO - Validation Loss: 0.4516
2024-03-28 18:03:13,558 - config - INFO - Epoch [730/2000], Train Loss: 0.3480
2024-03-28 18:03:13,562 - config - INFO - Validation Loss: 0.4526
2024-03-28 18:03:13,580 - config - INFO - Epoch [731/2000], Train Loss: 0.3480
2024-03-28 18:03:13,584 - config - INFO - Validation Loss: 0.4523
2024-03-28 18:03:13,602 - config - INFO - Epoch [732/2000], Train Loss: 0.3481
2024-03-28 18:03:13,606 - config - INFO - Validation Loss: 0.4524
2024-03-28 18:03:13,625 - config - INFO - Epoch [733/2000], Train Loss: 0.3479
2024-03-28 18:03:13,628 - config - INFO - Validation Loss: 0.4521
2024-03-28 18:03:13,647 - config - INFO - Epoch [734/2000], Train Loss: 0.3478
2024-03-28 18:03:13,651 - config - INFO - Validation Loss: 0.4519
2024-03-28 18:03:13,669 - config - INFO - Epoch [735/2000], Train Loss: 0.3477
2024-03-28 18:03:13,673 - config - INFO - Validation Loss: 0.4532
2024-03-28 18:03:13,691 - config - INFO - Epoch [736/2000], Train Loss: 0.3476
2024-03-28 18:03:13,695 - config - INFO - Validation Loss: 0.4536
2024-03-28 18:03:13,716 - config - INFO - Epoch [737/2000], Train Loss: 0.3474
2024-03-28 18:03:13,720 - config - INFO - Validation Loss: 0.4531
2024-03-28 18:03:13,738 - config - INFO - Epoch [738/2000], Train Loss: 0.3470
2024-03-28 18:03:13,742 - config - INFO - Validation Loss: 0.4526
2024-03-28 18:03:13,760 - config - INFO - Epoch [739/2000], Train Loss: 0.3471
2024-03-28 18:03:13,764 - config - INFO - Validation Loss: 0.4531
2024-03-28 18:03:13,782 - config - INFO - Epoch [740/2000], Train Loss: 0.3470
2024-03-28 18:03:13,786 - config - INFO - Validation Loss: 0.4530
2024-03-28 18:03:13,804 - config - INFO - Epoch [741/2000], Train Loss: 0.3475
2024-03-28 18:03:13,808 - config - INFO - Validation Loss: 0.4518
2024-03-28 18:03:13,826 - config - INFO - Epoch [742/2000], Train Loss: 0.3471
2024-03-28 18:03:13,830 - config - INFO - Validation Loss: 0.4520
2024-03-28 18:03:13,849 - config - INFO - Epoch [743/2000], Train Loss: 0.3473
2024-03-28 18:03:13,853 - config - INFO - Validation Loss: 0.4518
2024-03-28 18:03:13,871 - config - INFO - Epoch [744/2000], Train Loss: 0.3470
2024-03-28 18:03:13,875 - config - INFO - Validation Loss: 0.4516
2024-03-28 18:03:13,893 - config - INFO - Epoch [745/2000], Train Loss: 0.3465
2024-03-28 18:03:13,897 - config - INFO - Validation Loss: 0.4516
2024-03-28 18:03:13,915 - config - INFO - Epoch [746/2000], Train Loss: 0.3476
2024-03-28 18:03:13,919 - config - INFO - Validation Loss: 0.4521
2024-03-28 18:03:13,937 - config - INFO - Epoch [747/2000], Train Loss: 0.3462
2024-03-28 18:03:13,941 - config - INFO - Validation Loss: 0.4531
2024-03-28 18:03:13,960 - config - INFO - Epoch [748/2000], Train Loss: 0.3460
2024-03-28 18:03:13,964 - config - INFO - Validation Loss: 0.4539
2024-03-28 18:03:13,982 - config - INFO - Epoch [749/2000], Train Loss: 0.3461
2024-03-28 18:03:13,986 - config - INFO - Validation Loss: 0.4541
2024-03-28 18:03:14,004 - config - INFO - Epoch [750/2000], Train Loss: 0.3462
2024-03-28 18:03:14,008 - config - INFO - Validation Loss: 0.4541
2024-03-28 18:03:14,026 - config - INFO - Epoch [751/2000], Train Loss: 0.3460
2024-03-28 18:03:14,030 - config - INFO - Validation Loss: 0.4545
2024-03-28 18:03:14,048 - config - INFO - Epoch [752/2000], Train Loss: 0.3461
2024-03-28 18:03:14,052 - config - INFO - Validation Loss: 0.4538
2024-03-28 18:03:14,071 - config - INFO - Epoch [753/2000], Train Loss: 0.3462
2024-03-28 18:03:14,075 - config - INFO - Validation Loss: 0.4534
2024-03-28 18:03:14,093 - config - INFO - Epoch [754/2000], Train Loss: 0.3461
2024-03-28 18:03:14,097 - config - INFO - Validation Loss: 0.4531
2024-03-28 18:03:14,115 - config - INFO - Epoch [755/2000], Train Loss: 0.3456
2024-03-28 18:03:14,119 - config - INFO - Validation Loss: 0.4530
2024-03-28 18:03:14,137 - config - INFO - Epoch [756/2000], Train Loss: 0.3454
2024-03-28 18:03:14,141 - config - INFO - Validation Loss: 0.4536
2024-03-28 18:03:14,159 - config - INFO - Epoch [757/2000], Train Loss: 0.3454
2024-03-28 18:03:14,163 - config - INFO - Validation Loss: 0.4534
2024-03-28 18:03:14,182 - config - INFO - Epoch [758/2000], Train Loss: 0.3454
2024-03-28 18:03:14,185 - config - INFO - Validation Loss: 0.4533
2024-03-28 18:03:14,204 - config - INFO - Epoch [759/2000], Train Loss: 0.3454
2024-03-28 18:03:14,208 - config - INFO - Validation Loss: 0.4530
2024-03-28 18:03:14,226 - config - INFO - Epoch [760/2000], Train Loss: 0.3452
2024-03-28 18:03:14,230 - config - INFO - Validation Loss: 0.4532
2024-03-28 18:03:14,248 - config - INFO - Epoch [761/2000], Train Loss: 0.3447
2024-03-28 18:03:14,252 - config - INFO - Validation Loss: 0.4538
2024-03-28 18:03:14,270 - config - INFO - Epoch [762/2000], Train Loss: 0.3455
2024-03-28 18:03:14,274 - config - INFO - Validation Loss: 0.4545
2024-03-28 18:03:14,292 - config - INFO - Epoch [763/2000], Train Loss: 0.3455
2024-03-28 18:03:14,296 - config - INFO - Validation Loss: 0.4537
2024-03-28 18:03:14,315 - config - INFO - Epoch [764/2000], Train Loss: 0.3447
2024-03-28 18:03:14,319 - config - INFO - Validation Loss: 0.4529
2024-03-28 18:03:14,337 - config - INFO - Epoch [765/2000], Train Loss: 0.3445
2024-03-28 18:03:14,341 - config - INFO - Validation Loss: 0.4531
2024-03-28 18:03:14,359 - config - INFO - Epoch [766/2000], Train Loss: 0.3448
2024-03-28 18:03:14,363 - config - INFO - Validation Loss: 0.4537
2024-03-28 18:03:14,381 - config - INFO - Epoch [767/2000], Train Loss: 0.3447
2024-03-28 18:03:14,385 - config - INFO - Validation Loss: 0.4533
2024-03-28 18:03:14,404 - config - INFO - Epoch [768/2000], Train Loss: 0.3444
2024-03-28 18:03:14,408 - config - INFO - Validation Loss: 0.4539
2024-03-28 18:03:14,435 - config - INFO - Epoch [769/2000], Train Loss: 0.3440
2024-03-28 18:03:14,439 - config - INFO - Validation Loss: 0.4541
2024-03-28 18:03:14,457 - config - INFO - Epoch [770/2000], Train Loss: 0.3440
2024-03-28 18:03:14,461 - config - INFO - Validation Loss: 0.4534
2024-03-28 18:03:14,479 - config - INFO - Epoch [771/2000], Train Loss: 0.3442
2024-03-28 18:03:14,483 - config - INFO - Validation Loss: 0.4535
2024-03-28 18:03:14,502 - config - INFO - Epoch [772/2000], Train Loss: 0.3449
2024-03-28 18:03:14,506 - config - INFO - Validation Loss: 0.4535
2024-03-28 18:03:14,524 - config - INFO - Epoch [773/2000], Train Loss: 0.3437
2024-03-28 18:03:14,528 - config - INFO - Validation Loss: 0.4523
2024-03-28 18:03:14,546 - config - INFO - Epoch [774/2000], Train Loss: 0.3439
2024-03-28 18:03:14,550 - config - INFO - Validation Loss: 0.4525
2024-03-28 18:03:14,568 - config - INFO - Epoch [775/2000], Train Loss: 0.3447
2024-03-28 18:03:14,572 - config - INFO - Validation Loss: 0.4532
2024-03-28 18:03:14,591 - config - INFO - Epoch [776/2000], Train Loss: 0.3438
2024-03-28 18:03:14,595 - config - INFO - Validation Loss: 0.4523
2024-03-28 18:03:14,613 - config - INFO - Epoch [777/2000], Train Loss: 0.3436
2024-03-28 18:03:14,617 - config - INFO - Validation Loss: 0.4536
2024-03-28 18:03:14,635 - config - INFO - Epoch [778/2000], Train Loss: 0.3442
2024-03-28 18:03:14,639 - config - INFO - Validation Loss: 0.4544
2024-03-28 18:03:14,657 - config - INFO - Epoch [779/2000], Train Loss: 0.3431
2024-03-28 18:03:14,661 - config - INFO - Validation Loss: 0.4546
2024-03-28 18:03:14,679 - config - INFO - Epoch [780/2000], Train Loss: 0.3433
2024-03-28 18:03:14,683 - config - INFO - Validation Loss: 0.4543
2024-03-28 18:03:14,701 - config - INFO - Epoch [781/2000], Train Loss: 0.3431
2024-03-28 18:03:14,705 - config - INFO - Validation Loss: 0.4542
2024-03-28 18:03:14,724 - config - INFO - Epoch [782/2000], Train Loss: 0.3430
2024-03-28 18:03:14,728 - config - INFO - Validation Loss: 0.4541
2024-03-28 18:03:14,746 - config - INFO - Epoch [783/2000], Train Loss: 0.3427
2024-03-28 18:03:14,750 - config - INFO - Validation Loss: 0.4535
2024-03-28 18:03:14,768 - config - INFO - Epoch [784/2000], Train Loss: 0.3433
2024-03-28 18:03:14,772 - config - INFO - Validation Loss: 0.4537
2024-03-28 18:03:14,790 - config - INFO - Epoch [785/2000], Train Loss: 0.3427
2024-03-28 18:03:14,794 - config - INFO - Validation Loss: 0.4524
2024-03-28 18:03:14,812 - config - INFO - Epoch [786/2000], Train Loss: 0.3422
2024-03-28 18:03:14,816 - config - INFO - Validation Loss: 0.4525
2024-03-28 18:03:14,834 - config - INFO - Epoch [787/2000], Train Loss: 0.3427
2024-03-28 18:03:14,838 - config - INFO - Validation Loss: 0.4528
2024-03-28 18:03:14,857 - config - INFO - Epoch [788/2000], Train Loss: 0.3425
2024-03-28 18:03:14,861 - config - INFO - Validation Loss: 0.4533
2024-03-28 18:03:14,879 - config - INFO - Epoch [789/2000], Train Loss: 0.3421
2024-03-28 18:03:14,883 - config - INFO - Validation Loss: 0.4544
2024-03-28 18:03:14,901 - config - INFO - Epoch [790/2000], Train Loss: 0.3423
2024-03-28 18:03:14,905 - config - INFO - Validation Loss: 0.4553
2024-03-28 18:03:14,923 - config - INFO - Epoch [791/2000], Train Loss: 0.3421
2024-03-28 18:03:14,927 - config - INFO - Validation Loss: 0.4548
2024-03-28 18:03:14,945 - config - INFO - Epoch [792/2000], Train Loss: 0.3427
2024-03-28 18:03:14,949 - config - INFO - Validation Loss: 0.4548
2024-03-28 18:03:14,967 - config - INFO - Epoch [793/2000], Train Loss: 0.3418
2024-03-28 18:03:14,971 - config - INFO - Validation Loss: 0.4548
2024-03-28 18:03:14,990 - config - INFO - Epoch [794/2000], Train Loss: 0.3418
2024-03-28 18:03:14,993 - config - INFO - Validation Loss: 0.4546
2024-03-28 18:03:15,012 - config - INFO - Epoch [795/2000], Train Loss: 0.3421
2024-03-28 18:03:15,016 - config - INFO - Validation Loss: 0.4545
2024-03-28 18:03:15,034 - config - INFO - Epoch [796/2000], Train Loss: 0.3418
2024-03-28 18:03:15,038 - config - INFO - Validation Loss: 0.4550
2024-03-28 18:03:15,056 - config - INFO - Epoch [797/2000], Train Loss: 0.3420
2024-03-28 18:03:15,060 - config - INFO - Validation Loss: 0.4554
2024-03-28 18:03:15,078 - config - INFO - Epoch [798/2000], Train Loss: 0.3414
2024-03-28 18:03:15,082 - config - INFO - Validation Loss: 0.4550
2024-03-28 18:03:15,100 - config - INFO - Epoch [799/2000], Train Loss: 0.3414
2024-03-28 18:03:15,104 - config - INFO - Validation Loss: 0.4543
2024-03-28 18:03:15,123 - config - INFO - Epoch [800/2000], Train Loss: 0.3411
2024-03-28 18:03:15,127 - config - INFO - Validation Loss: 0.4551
2024-03-28 18:03:15,145 - config - INFO - Epoch [801/2000], Train Loss: 0.3413
2024-03-28 18:03:15,149 - config - INFO - Validation Loss: 0.4548
2024-03-28 18:03:15,167 - config - INFO - Epoch [802/2000], Train Loss: 0.3411
2024-03-28 18:03:15,171 - config - INFO - Validation Loss: 0.4543
2024-03-28 18:03:15,189 - config - INFO - Epoch [803/2000], Train Loss: 0.3409
2024-03-28 18:03:15,193 - config - INFO - Validation Loss: 0.4544
2024-03-28 18:03:15,211 - config - INFO - Epoch [804/2000], Train Loss: 0.3410
2024-03-28 18:03:15,215 - config - INFO - Validation Loss: 0.4548
2024-03-28 18:03:15,233 - config - INFO - Epoch [805/2000], Train Loss: 0.3410
2024-03-28 18:03:15,237 - config - INFO - Validation Loss: 0.4546
2024-03-28 18:03:15,256 - config - INFO - Epoch [806/2000], Train Loss: 0.3406
2024-03-28 18:03:15,260 - config - INFO - Validation Loss: 0.4544
2024-03-28 18:03:15,278 - config - INFO - Epoch [807/2000], Train Loss: 0.3410
2024-03-28 18:03:15,282 - config - INFO - Validation Loss: 0.4549
2024-03-28 18:03:15,300 - config - INFO - Epoch [808/2000], Train Loss: 0.3406
2024-03-28 18:03:15,304 - config - INFO - Validation Loss: 0.4543
2024-03-28 18:03:15,322 - config - INFO - Epoch [809/2000], Train Loss: 0.3403
2024-03-28 18:03:15,326 - config - INFO - Validation Loss: 0.4534
2024-03-28 18:03:15,344 - config - INFO - Epoch [810/2000], Train Loss: 0.3405
2024-03-28 18:03:15,348 - config - INFO - Validation Loss: 0.4545
2024-03-28 18:03:15,366 - config - INFO - Epoch [811/2000], Train Loss: 0.3409
2024-03-28 18:03:15,370 - config - INFO - Validation Loss: 0.4542
2024-03-28 18:03:15,389 - config - INFO - Epoch [812/2000], Train Loss: 0.3404
2024-03-28 18:03:15,393 - config - INFO - Validation Loss: 0.4550
2024-03-28 18:03:15,411 - config - INFO - Epoch [813/2000], Train Loss: 0.3402
2024-03-28 18:03:15,415 - config - INFO - Validation Loss: 0.4550
2024-03-28 18:03:15,433 - config - INFO - Epoch [814/2000], Train Loss: 0.3403
2024-03-28 18:03:15,437 - config - INFO - Validation Loss: 0.4552
2024-03-28 18:03:15,455 - config - INFO - Epoch [815/2000], Train Loss: 0.3404
2024-03-28 18:03:15,459 - config - INFO - Validation Loss: 0.4552
2024-03-28 18:03:15,478 - config - INFO - Epoch [816/2000], Train Loss: 0.3399
2024-03-28 18:03:15,482 - config - INFO - Validation Loss: 0.4558
2024-03-28 18:03:15,500 - config - INFO - Epoch [817/2000], Train Loss: 0.3398
2024-03-28 18:03:15,504 - config - INFO - Validation Loss: 0.4554
2024-03-28 18:03:15,522 - config - INFO - Epoch [818/2000], Train Loss: 0.3394
2024-03-28 18:03:15,526 - config - INFO - Validation Loss: 0.4551
2024-03-28 18:03:15,544 - config - INFO - Epoch [819/2000], Train Loss: 0.3396
2024-03-28 18:03:15,548 - config - INFO - Validation Loss: 0.4550
2024-03-28 18:03:15,566 - config - INFO - Epoch [820/2000], Train Loss: 0.3393
2024-03-28 18:03:15,570 - config - INFO - Validation Loss: 0.4553
2024-03-28 18:03:15,588 - config - INFO - Epoch [821/2000], Train Loss: 0.3396
2024-03-28 18:03:15,592 - config - INFO - Validation Loss: 0.4547
2024-03-28 18:03:15,611 - config - INFO - Epoch [822/2000], Train Loss: 0.3393
2024-03-28 18:03:15,615 - config - INFO - Validation Loss: 0.4544
2024-03-28 18:03:15,633 - config - INFO - Epoch [823/2000], Train Loss: 0.3403
2024-03-28 18:03:15,637 - config - INFO - Validation Loss: 0.4546
2024-03-28 18:03:15,655 - config - INFO - Epoch [824/2000], Train Loss: 0.3392
2024-03-28 18:03:15,659 - config - INFO - Validation Loss: 0.4556
2024-03-28 18:03:15,677 - config - INFO - Epoch [825/2000], Train Loss: 0.3395
2024-03-28 18:03:15,681 - config - INFO - Validation Loss: 0.4558
2024-03-28 18:03:15,699 - config - INFO - Epoch [826/2000], Train Loss: 0.3410
2024-03-28 18:03:15,703 - config - INFO - Validation Loss: 0.4566
2024-03-28 18:03:15,721 - config - INFO - Epoch [827/2000], Train Loss: 0.3389
2024-03-28 18:03:15,725 - config - INFO - Validation Loss: 0.4562
2024-03-28 18:03:15,750 - config - INFO - Epoch [828/2000], Train Loss: 0.3385
2024-03-28 18:03:15,754 - config - INFO - Validation Loss: 0.4566
2024-03-28 18:03:15,772 - config - INFO - Epoch [829/2000], Train Loss: 0.3386
2024-03-28 18:03:15,776 - config - INFO - Validation Loss: 0.4564
2024-03-28 18:03:15,794 - config - INFO - Epoch [830/2000], Train Loss: 0.3383
2024-03-28 18:03:15,798 - config - INFO - Validation Loss: 0.4561
2024-03-28 18:03:15,816 - config - INFO - Epoch [831/2000], Train Loss: 0.3381
2024-03-28 18:03:15,820 - config - INFO - Validation Loss: 0.4565
2024-03-28 18:03:15,839 - config - INFO - Epoch [832/2000], Train Loss: 0.3388
2024-03-28 18:03:15,842 - config - INFO - Validation Loss: 0.4571
2024-03-28 18:03:15,861 - config - INFO - Epoch [833/2000], Train Loss: 0.3385
2024-03-28 18:03:15,865 - config - INFO - Validation Loss: 0.4582
2024-03-28 18:03:15,883 - config - INFO - Epoch [834/2000], Train Loss: 0.3381
2024-03-28 18:03:15,887 - config - INFO - Validation Loss: 0.4579
2024-03-28 18:03:15,905 - config - INFO - Epoch [835/2000], Train Loss: 0.3378
2024-03-28 18:03:15,909 - config - INFO - Validation Loss: 0.4576
2024-03-28 18:03:15,927 - config - INFO - Epoch [836/2000], Train Loss: 0.3383
2024-03-28 18:03:15,931 - config - INFO - Validation Loss: 0.4570
2024-03-28 18:03:15,949 - config - INFO - Epoch [837/2000], Train Loss: 0.3376
2024-03-28 18:03:15,953 - config - INFO - Validation Loss: 0.4572
2024-03-28 18:03:15,971 - config - INFO - Epoch [838/2000], Train Loss: 0.3374
2024-03-28 18:03:15,975 - config - INFO - Validation Loss: 0.4570
2024-03-28 18:03:15,994 - config - INFO - Epoch [839/2000], Train Loss: 0.3382
2024-03-28 18:03:15,998 - config - INFO - Validation Loss: 0.4564
2024-03-28 18:03:16,016 - config - INFO - Epoch [840/2000], Train Loss: 0.3384
2024-03-28 18:03:16,020 - config - INFO - Validation Loss: 0.4555
2024-03-28 18:03:16,038 - config - INFO - Epoch [841/2000], Train Loss: 0.3375
2024-03-28 18:03:16,042 - config - INFO - Validation Loss: 0.4563
2024-03-28 18:03:16,060 - config - INFO - Epoch [842/2000], Train Loss: 0.3373
2024-03-28 18:03:16,064 - config - INFO - Validation Loss: 0.4566
2024-03-28 18:03:16,082 - config - INFO - Epoch [843/2000], Train Loss: 0.3373
2024-03-28 18:03:16,086 - config - INFO - Validation Loss: 0.4576
2024-03-28 18:03:16,105 - config - INFO - Epoch [844/2000], Train Loss: 0.3374
2024-03-28 18:03:16,109 - config - INFO - Validation Loss: 0.4576
2024-03-28 18:03:16,127 - config - INFO - Epoch [845/2000], Train Loss: 0.3373
2024-03-28 18:03:16,131 - config - INFO - Validation Loss: 0.4572
2024-03-28 18:03:16,149 - config - INFO - Epoch [846/2000], Train Loss: 0.3370
2024-03-28 18:03:16,153 - config - INFO - Validation Loss: 0.4565
2024-03-28 18:03:16,171 - config - INFO - Epoch [847/2000], Train Loss: 0.3371
2024-03-28 18:03:16,175 - config - INFO - Validation Loss: 0.4567
2024-03-28 18:03:16,193 - config - INFO - Epoch [848/2000], Train Loss: 0.3367
2024-03-28 18:03:16,197 - config - INFO - Validation Loss: 0.4569
2024-03-28 18:03:16,215 - config - INFO - Epoch [849/2000], Train Loss: 0.3367
2024-03-28 18:03:16,219 - config - INFO - Validation Loss: 0.4566
2024-03-28 18:03:16,237 - config - INFO - Epoch [850/2000], Train Loss: 0.3364
2024-03-28 18:03:16,241 - config - INFO - Validation Loss: 0.4570
2024-03-28 18:03:16,260 - config - INFO - Epoch [851/2000], Train Loss: 0.3371
2024-03-28 18:03:16,263 - config - INFO - Validation Loss: 0.4579
2024-03-28 18:03:16,282 - config - INFO - Epoch [852/2000], Train Loss: 0.3360
2024-03-28 18:03:16,286 - config - INFO - Validation Loss: 0.4572
2024-03-28 18:03:16,304 - config - INFO - Epoch [853/2000], Train Loss: 0.3378
2024-03-28 18:03:16,308 - config - INFO - Validation Loss: 0.4566
2024-03-28 18:03:16,326 - config - INFO - Epoch [854/2000], Train Loss: 0.3371
2024-03-28 18:03:16,330 - config - INFO - Validation Loss: 0.4562
2024-03-28 18:03:16,348 - config - INFO - Epoch [855/2000], Train Loss: 0.3366
2024-03-28 18:03:16,352 - config - INFO - Validation Loss: 0.4572
2024-03-28 18:03:16,371 - config - INFO - Epoch [856/2000], Train Loss: 0.3367
2024-03-28 18:03:16,374 - config - INFO - Validation Loss: 0.4573
2024-03-28 18:03:16,393 - config - INFO - Epoch [857/2000], Train Loss: 0.3371
2024-03-28 18:03:16,397 - config - INFO - Validation Loss: 0.4569
2024-03-28 18:03:16,415 - config - INFO - Epoch [858/2000], Train Loss: 0.3360
2024-03-28 18:03:16,419 - config - INFO - Validation Loss: 0.4568
2024-03-28 18:03:16,437 - config - INFO - Epoch [859/2000], Train Loss: 0.3361
2024-03-28 18:03:16,441 - config - INFO - Validation Loss: 0.4572
2024-03-28 18:03:16,459 - config - INFO - Epoch [860/2000], Train Loss: 0.3370
2024-03-28 18:03:16,463 - config - INFO - Validation Loss: 0.4579
2024-03-28 18:03:16,482 - config - INFO - Epoch [861/2000], Train Loss: 0.3356
2024-03-28 18:03:16,485 - config - INFO - Validation Loss: 0.4578
2024-03-28 18:03:16,504 - config - INFO - Epoch [862/2000], Train Loss: 0.3356
2024-03-28 18:03:16,508 - config - INFO - Validation Loss: 0.4574
2024-03-28 18:03:16,526 - config - INFO - Epoch [863/2000], Train Loss: 0.3364
2024-03-28 18:03:16,530 - config - INFO - Validation Loss: 0.4580
2024-03-28 18:03:16,548 - config - INFO - Epoch [864/2000], Train Loss: 0.3352
2024-03-28 18:03:16,552 - config - INFO - Validation Loss: 0.4592
2024-03-28 18:03:16,570 - config - INFO - Epoch [865/2000], Train Loss: 0.3357
2024-03-28 18:03:16,574 - config - INFO - Validation Loss: 0.4596
2024-03-28 18:03:16,592 - config - INFO - Epoch [866/2000], Train Loss: 0.3359
2024-03-28 18:03:16,596 - config - INFO - Validation Loss: 0.4600
2024-03-28 18:03:16,615 - config - INFO - Epoch [867/2000], Train Loss: 0.3354
2024-03-28 18:03:16,619 - config - INFO - Validation Loss: 0.4591
2024-03-28 18:03:16,637 - config - INFO - Epoch [868/2000], Train Loss: 0.3349
2024-03-28 18:03:16,641 - config - INFO - Validation Loss: 0.4591
2024-03-28 18:03:16,659 - config - INFO - Epoch [869/2000], Train Loss: 0.3349
2024-03-28 18:03:16,663 - config - INFO - Validation Loss: 0.4594
2024-03-28 18:03:16,681 - config - INFO - Epoch [870/2000], Train Loss: 0.3348
2024-03-28 18:03:16,685 - config - INFO - Validation Loss: 0.4582
2024-03-28 18:03:16,703 - config - INFO - Epoch [871/2000], Train Loss: 0.3349
2024-03-28 18:03:16,707 - config - INFO - Validation Loss: 0.4581
2024-03-28 18:03:16,726 - config - INFO - Epoch [872/2000], Train Loss: 0.3343
2024-03-28 18:03:16,729 - config - INFO - Validation Loss: 0.4579
2024-03-28 18:03:16,748 - config - INFO - Epoch [873/2000], Train Loss: 0.3345
2024-03-28 18:03:16,752 - config - INFO - Validation Loss: 0.4581
2024-03-28 18:03:16,770 - config - INFO - Epoch [874/2000], Train Loss: 0.3348
2024-03-28 18:03:16,774 - config - INFO - Validation Loss: 0.4586
2024-03-28 18:03:16,792 - config - INFO - Epoch [875/2000], Train Loss: 0.3341
2024-03-28 18:03:16,796 - config - INFO - Validation Loss: 0.4582
2024-03-28 18:03:16,814 - config - INFO - Epoch [876/2000], Train Loss: 0.3342
2024-03-28 18:03:16,818 - config - INFO - Validation Loss: 0.4588
2024-03-28 18:03:16,836 - config - INFO - Epoch [877/2000], Train Loss: 0.3346
2024-03-28 18:03:16,840 - config - INFO - Validation Loss: 0.4599
2024-03-28 18:03:16,858 - config - INFO - Epoch [878/2000], Train Loss: 0.3355
2024-03-28 18:03:16,862 - config - INFO - Validation Loss: 0.4611
2024-03-28 18:03:16,880 - config - INFO - Epoch [879/2000], Train Loss: 0.3340
2024-03-28 18:03:16,884 - config - INFO - Validation Loss: 0.4604
2024-03-28 18:03:16,903 - config - INFO - Epoch [880/2000], Train Loss: 0.3352
2024-03-28 18:03:16,906 - config - INFO - Validation Loss: 0.4602
2024-03-28 18:03:16,925 - config - INFO - Epoch [881/2000], Train Loss: 0.3341
2024-03-28 18:03:16,929 - config - INFO - Validation Loss: 0.4604
2024-03-28 18:03:16,947 - config - INFO - Epoch [882/2000], Train Loss: 0.3334
2024-03-28 18:03:16,951 - config - INFO - Validation Loss: 0.4612
2024-03-28 18:03:16,969 - config - INFO - Epoch [883/2000], Train Loss: 0.3342
2024-03-28 18:03:16,973 - config - INFO - Validation Loss: 0.4618
2024-03-28 18:03:16,991 - config - INFO - Epoch [884/2000], Train Loss: 0.3335
2024-03-28 18:03:16,995 - config - INFO - Validation Loss: 0.4611
2024-03-28 18:03:17,013 - config - INFO - Epoch [885/2000], Train Loss: 0.3333
2024-03-28 18:03:17,017 - config - INFO - Validation Loss: 0.4607
2024-03-28 18:03:17,036 - config - INFO - Epoch [886/2000], Train Loss: 0.3345
2024-03-28 18:03:17,040 - config - INFO - Validation Loss: 0.4611
2024-03-28 18:03:17,058 - config - INFO - Epoch [887/2000], Train Loss: 0.3332
2024-03-28 18:03:17,062 - config - INFO - Validation Loss: 0.4607
2024-03-28 18:03:17,080 - config - INFO - Epoch [888/2000], Train Loss: 0.3332
2024-03-28 18:03:17,084 - config - INFO - Validation Loss: 0.4611
2024-03-28 18:03:17,102 - config - INFO - Epoch [889/2000], Train Loss: 0.3336
2024-03-28 18:03:17,106 - config - INFO - Validation Loss: 0.4623
2024-03-28 18:03:17,124 - config - INFO - Epoch [890/2000], Train Loss: 0.3339
2024-03-28 18:03:17,128 - config - INFO - Validation Loss: 0.4613
2024-03-28 18:03:17,146 - config - INFO - Epoch [891/2000], Train Loss: 0.3337
2024-03-28 18:03:17,150 - config - INFO - Validation Loss: 0.4602
2024-03-28 18:03:17,169 - config - INFO - Epoch [892/2000], Train Loss: 0.3323
2024-03-28 18:03:17,173 - config - INFO - Validation Loss: 0.4595
2024-03-28 18:03:17,191 - config - INFO - Epoch [893/2000], Train Loss: 0.3340
2024-03-28 18:03:17,195 - config - INFO - Validation Loss: 0.4598
2024-03-28 18:03:17,213 - config - INFO - Epoch [894/2000], Train Loss: 0.3335
2024-03-28 18:03:17,217 - config - INFO - Validation Loss: 0.4599
2024-03-28 18:03:17,235 - config - INFO - Epoch [895/2000], Train Loss: 0.3324
2024-03-28 18:03:17,239 - config - INFO - Validation Loss: 0.4606
2024-03-28 18:03:17,257 - config - INFO - Epoch [896/2000], Train Loss: 0.3334
2024-03-28 18:03:17,261 - config - INFO - Validation Loss: 0.4609
2024-03-28 18:03:17,279 - config - INFO - Epoch [897/2000], Train Loss: 0.3323
2024-03-28 18:03:17,283 - config - INFO - Validation Loss: 0.4612
2024-03-28 18:03:17,302 - config - INFO - Epoch [898/2000], Train Loss: 0.3323
2024-03-28 18:03:17,306 - config - INFO - Validation Loss: 0.4616
2024-03-28 18:03:17,324 - config - INFO - Epoch [899/2000], Train Loss: 0.3328
2024-03-28 18:03:17,328 - config - INFO - Validation Loss: 0.4607
2024-03-28 18:03:17,346 - config - INFO - Epoch [900/2000], Train Loss: 0.3326
2024-03-28 18:03:17,350 - config - INFO - Validation Loss: 0.4612
2024-03-28 18:03:17,368 - config - INFO - Epoch [901/2000], Train Loss: 0.3326
2024-03-28 18:03:17,372 - config - INFO - Validation Loss: 0.4612
2024-03-28 18:03:17,391 - config - INFO - Epoch [902/2000], Train Loss: 0.3324
2024-03-28 18:03:17,395 - config - INFO - Validation Loss: 0.4615
2024-03-28 18:03:17,413 - config - INFO - Epoch [903/2000], Train Loss: 0.3323
2024-03-28 18:03:17,417 - config - INFO - Validation Loss: 0.4627
2024-03-28 18:03:17,435 - config - INFO - Epoch [904/2000], Train Loss: 0.3317
2024-03-28 18:03:17,439 - config - INFO - Validation Loss: 0.4619
2024-03-28 18:03:17,457 - config - INFO - Epoch [905/2000], Train Loss: 0.3322
2024-03-28 18:03:17,461 - config - INFO - Validation Loss: 0.4624
2024-03-28 18:03:17,479 - config - INFO - Epoch [906/2000], Train Loss: 0.3324
2024-03-28 18:03:17,483 - config - INFO - Validation Loss: 0.4611
2024-03-28 18:03:17,501 - config - INFO - Epoch [907/2000], Train Loss: 0.3321
2024-03-28 18:03:17,505 - config - INFO - Validation Loss: 0.4611
2024-03-28 18:03:17,524 - config - INFO - Epoch [908/2000], Train Loss: 0.3316
2024-03-28 18:03:17,528 - config - INFO - Validation Loss: 0.4616
2024-03-28 18:03:17,546 - config - INFO - Epoch [909/2000], Train Loss: 0.3317
2024-03-28 18:03:17,550 - config - INFO - Validation Loss: 0.4616
2024-03-28 18:03:17,568 - config - INFO - Epoch [910/2000], Train Loss: 0.3317
2024-03-28 18:03:17,572 - config - INFO - Validation Loss: 0.4626
2024-03-28 18:03:17,590 - config - INFO - Epoch [911/2000], Train Loss: 0.3312
2024-03-28 18:03:17,594 - config - INFO - Validation Loss: 0.4625
2024-03-28 18:03:17,613 - config - INFO - Epoch [912/2000], Train Loss: 0.3315
2024-03-28 18:03:17,616 - config - INFO - Validation Loss: 0.4622
2024-03-28 18:03:17,635 - config - INFO - Epoch [913/2000], Train Loss: 0.3318
2024-03-28 18:03:17,639 - config - INFO - Validation Loss: 0.4621
2024-03-28 18:03:17,657 - config - INFO - Epoch [914/2000], Train Loss: 0.3313
2024-03-28 18:03:17,661 - config - INFO - Validation Loss: 0.4608
2024-03-28 18:03:17,679 - config - INFO - Epoch [915/2000], Train Loss: 0.3311
2024-03-28 18:03:17,683 - config - INFO - Validation Loss: 0.4616
2024-03-28 18:03:17,701 - config - INFO - Epoch [916/2000], Train Loss: 0.3310
2024-03-28 18:03:17,705 - config - INFO - Validation Loss: 0.4627
2024-03-28 18:03:17,726 - config - INFO - Epoch [917/2000], Train Loss: 0.3308
2024-03-28 18:03:17,730 - config - INFO - Validation Loss: 0.4631
2024-03-28 18:03:17,748 - config - INFO - Epoch [918/2000], Train Loss: 0.3308
2024-03-28 18:03:17,752 - config - INFO - Validation Loss: 0.4627
2024-03-28 18:03:17,770 - config - INFO - Epoch [919/2000], Train Loss: 0.3322
2024-03-28 18:03:17,774 - config - INFO - Validation Loss: 0.4641
2024-03-28 18:03:17,792 - config - INFO - Epoch [920/2000], Train Loss: 0.3311
2024-03-28 18:03:17,796 - config - INFO - Validation Loss: 0.4642
2024-03-28 18:03:17,815 - config - INFO - Epoch [921/2000], Train Loss: 0.3305
2024-03-28 18:03:17,818 - config - INFO - Validation Loss: 0.4624
2024-03-28 18:03:17,837 - config - INFO - Epoch [922/2000], Train Loss: 0.3302
2024-03-28 18:03:17,841 - config - INFO - Validation Loss: 0.4627
2024-03-28 18:03:17,859 - config - INFO - Epoch [923/2000], Train Loss: 0.3306
2024-03-28 18:03:17,863 - config - INFO - Validation Loss: 0.4632
2024-03-28 18:03:17,881 - config - INFO - Epoch [924/2000], Train Loss: 0.3308
2024-03-28 18:03:17,885 - config - INFO - Validation Loss: 0.4643
2024-03-28 18:03:17,903 - config - INFO - Epoch [925/2000], Train Loss: 0.3303
2024-03-28 18:03:17,907 - config - INFO - Validation Loss: 0.4641
2024-03-28 18:03:17,925 - config - INFO - Epoch [926/2000], Train Loss: 0.3307
2024-03-28 18:03:17,929 - config - INFO - Validation Loss: 0.4636
2024-03-28 18:03:17,947 - config - INFO - Epoch [927/2000], Train Loss: 0.3302
2024-03-28 18:03:17,951 - config - INFO - Validation Loss: 0.4623
2024-03-28 18:03:17,970 - config - INFO - Epoch [928/2000], Train Loss: 0.3302
2024-03-28 18:03:17,974 - config - INFO - Validation Loss: 0.4625
2024-03-28 18:03:17,992 - config - INFO - Epoch [929/2000], Train Loss: 0.3306
2024-03-28 18:03:17,996 - config - INFO - Validation Loss: 0.4638
2024-03-28 18:03:18,014 - config - INFO - Epoch [930/2000], Train Loss: 0.3299
2024-03-28 18:03:18,018 - config - INFO - Validation Loss: 0.4634
2024-03-28 18:03:18,036 - config - INFO - Epoch [931/2000], Train Loss: 0.3298
2024-03-28 18:03:18,040 - config - INFO - Validation Loss: 0.4632
2024-03-28 18:03:18,058 - config - INFO - Epoch [932/2000], Train Loss: 0.3297
2024-03-28 18:03:18,062 - config - INFO - Validation Loss: 0.4632
2024-03-28 18:03:18,081 - config - INFO - Epoch [933/2000], Train Loss: 0.3307
2024-03-28 18:03:18,084 - config - INFO - Validation Loss: 0.4647
2024-03-28 18:03:18,103 - config - INFO - Epoch [934/2000], Train Loss: 0.3300
2024-03-28 18:03:18,107 - config - INFO - Validation Loss: 0.4639
2024-03-28 18:03:18,125 - config - INFO - Epoch [935/2000], Train Loss: 0.3294
2024-03-28 18:03:18,129 - config - INFO - Validation Loss: 0.4635
2024-03-28 18:03:18,147 - config - INFO - Epoch [936/2000], Train Loss: 0.3299
2024-03-28 18:03:18,151 - config - INFO - Validation Loss: 0.4644
2024-03-28 18:03:18,169 - config - INFO - Epoch [937/2000], Train Loss: 0.3295
2024-03-28 18:03:18,173 - config - INFO - Validation Loss: 0.4639
2024-03-28 18:03:18,191 - config - INFO - Epoch [938/2000], Train Loss: 0.3292
2024-03-28 18:03:18,195 - config - INFO - Validation Loss: 0.4641
2024-03-28 18:03:18,214 - config - INFO - Epoch [939/2000], Train Loss: 0.3295
2024-03-28 18:03:18,218 - config - INFO - Validation Loss: 0.4637
2024-03-28 18:03:18,236 - config - INFO - Epoch [940/2000], Train Loss: 0.3288
2024-03-28 18:03:18,240 - config - INFO - Validation Loss: 0.4643
2024-03-28 18:03:18,258 - config - INFO - Epoch [941/2000], Train Loss: 0.3291
2024-03-28 18:03:18,262 - config - INFO - Validation Loss: 0.4650
2024-03-28 18:03:18,280 - config - INFO - Epoch [942/2000], Train Loss: 0.3286
2024-03-28 18:03:18,284 - config - INFO - Validation Loss: 0.4650
2024-03-28 18:03:18,302 - config - INFO - Epoch [943/2000], Train Loss: 0.3287
2024-03-28 18:03:18,306 - config - INFO - Validation Loss: 0.4656
2024-03-28 18:03:18,324 - config - INFO - Epoch [944/2000], Train Loss: 0.3295
2024-03-28 18:03:18,328 - config - INFO - Validation Loss: 0.4658
2024-03-28 18:03:18,347 - config - INFO - Epoch [945/2000], Train Loss: 0.3287
2024-03-28 18:03:18,351 - config - INFO - Validation Loss: 0.4671
2024-03-28 18:03:18,369 - config - INFO - Epoch [946/2000], Train Loss: 0.3286
2024-03-28 18:03:18,373 - config - INFO - Validation Loss: 0.4669
2024-03-28 18:03:18,391 - config - INFO - Epoch [947/2000], Train Loss: 0.3288
2024-03-28 18:03:18,395 - config - INFO - Validation Loss: 0.4667
2024-03-28 18:03:18,413 - config - INFO - Epoch [948/2000], Train Loss: 0.3285
2024-03-28 18:03:18,417 - config - INFO - Validation Loss: 0.4668
2024-03-28 18:03:18,435 - config - INFO - Epoch [949/2000], Train Loss: 0.3284
2024-03-28 18:03:18,439 - config - INFO - Validation Loss: 0.4663
2024-03-28 18:03:18,458 - config - INFO - Epoch [950/2000], Train Loss: 0.3282
2024-03-28 18:03:18,462 - config - INFO - Validation Loss: 0.4660
2024-03-28 18:03:18,480 - config - INFO - Epoch [951/2000], Train Loss: 0.3287
2024-03-28 18:03:18,484 - config - INFO - Validation Loss: 0.4659
2024-03-28 18:03:18,502 - config - INFO - Epoch [952/2000], Train Loss: 0.3282
2024-03-28 18:03:18,506 - config - INFO - Validation Loss: 0.4661
2024-03-28 18:03:18,524 - config - INFO - Epoch [953/2000], Train Loss: 0.3284
2024-03-28 18:03:18,528 - config - INFO - Validation Loss: 0.4667
2024-03-28 18:03:18,546 - config - INFO - Epoch [954/2000], Train Loss: 0.3281
2024-03-28 18:03:18,550 - config - INFO - Validation Loss: 0.4673
2024-03-28 18:03:18,568 - config - INFO - Epoch [955/2000], Train Loss: 0.3283
2024-03-28 18:03:18,572 - config - INFO - Validation Loss: 0.4661
2024-03-28 18:03:18,591 - config - INFO - Epoch [956/2000], Train Loss: 0.3278
2024-03-28 18:03:18,595 - config - INFO - Validation Loss: 0.4663
2024-03-28 18:03:18,613 - config - INFO - Epoch [957/2000], Train Loss: 0.3278
2024-03-28 18:03:18,617 - config - INFO - Validation Loss: 0.4661
2024-03-28 18:03:18,635 - config - INFO - Epoch [958/2000], Train Loss: 0.3284
2024-03-28 18:03:18,639 - config - INFO - Validation Loss: 0.4662
2024-03-28 18:03:18,657 - config - INFO - Epoch [959/2000], Train Loss: 0.3279
2024-03-28 18:03:18,661 - config - INFO - Validation Loss: 0.4666
2024-03-28 18:03:18,679 - config - INFO - Epoch [960/2000], Train Loss: 0.3280
2024-03-28 18:03:18,683 - config - INFO - Validation Loss: 0.4663
2024-03-28 18:03:18,702 - config - INFO - Epoch [961/2000], Train Loss: 0.3282
2024-03-28 18:03:18,706 - config - INFO - Validation Loss: 0.4665
2024-03-28 18:03:18,724 - config - INFO - Epoch [962/2000], Train Loss: 0.3274
2024-03-28 18:03:18,728 - config - INFO - Validation Loss: 0.4674
2024-03-28 18:03:18,746 - config - INFO - Epoch [963/2000], Train Loss: 0.3272
2024-03-28 18:03:18,750 - config - INFO - Validation Loss: 0.4667
2024-03-28 18:03:18,768 - config - INFO - Epoch [964/2000], Train Loss: 0.3278
2024-03-28 18:03:18,772 - config - INFO - Validation Loss: 0.4677
2024-03-28 18:03:18,790 - config - INFO - Epoch [965/2000], Train Loss: 0.3273
2024-03-28 18:03:18,794 - config - INFO - Validation Loss: 0.4681
2024-03-28 18:03:18,813 - config - INFO - Epoch [966/2000], Train Loss: 0.3273
2024-03-28 18:03:18,816 - config - INFO - Validation Loss: 0.4680
2024-03-28 18:03:18,835 - config - INFO - Epoch [967/2000], Train Loss: 0.3273
2024-03-28 18:03:18,839 - config - INFO - Validation Loss: 0.4671
2024-03-28 18:03:18,857 - config - INFO - Epoch [968/2000], Train Loss: 0.3268
2024-03-28 18:03:18,861 - config - INFO - Validation Loss: 0.4663
2024-03-28 18:03:18,879 - config - INFO - Epoch [969/2000], Train Loss: 0.3270
2024-03-28 18:03:18,883 - config - INFO - Validation Loss: 0.4665
2024-03-28 18:03:18,901 - config - INFO - Epoch [970/2000], Train Loss: 0.3275
2024-03-28 18:03:18,905 - config - INFO - Validation Loss: 0.4653
2024-03-28 18:03:18,923 - config - INFO - Epoch [971/2000], Train Loss: 0.3269
2024-03-28 18:03:18,927 - config - INFO - Validation Loss: 0.4649
2024-03-28 18:03:18,946 - config - INFO - Epoch [972/2000], Train Loss: 0.3274
2024-03-28 18:03:18,950 - config - INFO - Validation Loss: 0.4652
2024-03-28 18:03:18,968 - config - INFO - Epoch [973/2000], Train Loss: 0.3267
2024-03-28 18:03:18,972 - config - INFO - Validation Loss: 0.4661
2024-03-28 18:03:18,990 - config - INFO - Epoch [974/2000], Train Loss: 0.3264
2024-03-28 18:03:18,994 - config - INFO - Validation Loss: 0.4656
2024-03-28 18:03:19,012 - config - INFO - Epoch [975/2000], Train Loss: 0.3264
2024-03-28 18:03:19,016 - config - INFO - Validation Loss: 0.4648
2024-03-28 18:03:19,034 - config - INFO - Epoch [976/2000], Train Loss: 0.3267
2024-03-28 18:03:19,038 - config - INFO - Validation Loss: 0.4650
2024-03-28 18:03:19,056 - config - INFO - Epoch [977/2000], Train Loss: 0.3262
2024-03-28 18:03:19,060 - config - INFO - Validation Loss: 0.4650
2024-03-28 18:03:19,078 - config - INFO - Epoch [978/2000], Train Loss: 0.3263
2024-03-28 18:03:19,082 - config - INFO - Validation Loss: 0.4648
2024-03-28 18:03:19,100 - config - INFO - Epoch [979/2000], Train Loss: 0.3264
2024-03-28 18:03:19,104 - config - INFO - Validation Loss: 0.4651
2024-03-28 18:03:19,123 - config - INFO - Epoch [980/2000], Train Loss: 0.3263
2024-03-28 18:03:19,127 - config - INFO - Validation Loss: 0.4658
2024-03-28 18:03:19,145 - config - INFO - Epoch [981/2000], Train Loss: 0.3262
2024-03-28 18:03:19,149 - config - INFO - Validation Loss: 0.4672
2024-03-28 18:03:19,167 - config - INFO - Epoch [982/2000], Train Loss: 0.3260
2024-03-28 18:03:19,171 - config - INFO - Validation Loss: 0.4674
2024-03-28 18:03:19,189 - config - INFO - Epoch [983/2000], Train Loss: 0.3259
2024-03-28 18:03:19,193 - config - INFO - Validation Loss: 0.4664
2024-03-28 18:03:19,211 - config - INFO - Epoch [984/2000], Train Loss: 0.3265
2024-03-28 18:03:19,215 - config - INFO - Validation Loss: 0.4667
2024-03-28 18:03:19,233 - config - INFO - Epoch [985/2000], Train Loss: 0.3259
2024-03-28 18:03:19,237 - config - INFO - Validation Loss: 0.4675
2024-03-28 18:03:19,255 - config - INFO - Epoch [986/2000], Train Loss: 0.3254
2024-03-28 18:03:19,259 - config - INFO - Validation Loss: 0.4682
2024-03-28 18:03:19,278 - config - INFO - Epoch [987/2000], Train Loss: 0.3257
2024-03-28 18:03:19,282 - config - INFO - Validation Loss: 0.4678
2024-03-28 18:03:19,300 - config - INFO - Epoch [988/2000], Train Loss: 0.3254
2024-03-28 18:03:19,304 - config - INFO - Validation Loss: 0.4676
2024-03-28 18:03:19,322 - config - INFO - Epoch [989/2000], Train Loss: 0.3252
2024-03-28 18:03:19,326 - config - INFO - Validation Loss: 0.4677
2024-03-28 18:03:19,344 - config - INFO - Epoch [990/2000], Train Loss: 0.3252
2024-03-28 18:03:19,348 - config - INFO - Validation Loss: 0.4680
2024-03-28 18:03:19,366 - config - INFO - Epoch [991/2000], Train Loss: 0.3252
2024-03-28 18:03:19,370 - config - INFO - Validation Loss: 0.4681
2024-03-28 18:03:19,388 - config - INFO - Epoch [992/2000], Train Loss: 0.3260
2024-03-28 18:03:19,392 - config - INFO - Validation Loss: 0.4687
2024-03-28 18:03:19,411 - config - INFO - Epoch [993/2000], Train Loss: 0.3251
2024-03-28 18:03:19,415 - config - INFO - Validation Loss: 0.4683
2024-03-28 18:03:19,444 - config - INFO - Epoch [994/2000], Train Loss: 0.3249
2024-03-28 18:03:19,448 - config - INFO - Validation Loss: 0.4681
2024-03-28 18:03:19,466 - config - INFO - Epoch [995/2000], Train Loss: 0.3250
2024-03-28 18:03:19,470 - config - INFO - Validation Loss: 0.4675
2024-03-28 18:03:19,488 - config - INFO - Epoch [996/2000], Train Loss: 0.3249
2024-03-28 18:03:19,492 - config - INFO - Validation Loss: 0.4677
2024-03-28 18:03:19,510 - config - INFO - Epoch [997/2000], Train Loss: 0.3249
2024-03-28 18:03:19,514 - config - INFO - Validation Loss: 0.4681
2024-03-28 18:03:19,532 - config - INFO - Epoch [998/2000], Train Loss: 0.3249
2024-03-28 18:03:19,536 - config - INFO - Validation Loss: 0.4677
2024-03-28 18:03:19,554 - config - INFO - Epoch [999/2000], Train Loss: 0.3244
2024-03-28 18:03:19,558 - config - INFO - Validation Loss: 0.4673
2024-03-28 18:03:19,577 - config - INFO - Epoch [1000/2000], Train Loss: 0.3247
2024-03-28 18:03:19,580 - config - INFO - Validation Loss: 0.4677
2024-03-28 18:03:19,599 - config - INFO - Epoch [1001/2000], Train Loss: 0.3242
2024-03-28 18:03:19,603 - config - INFO - Validation Loss: 0.4676
2024-03-28 18:03:19,621 - config - INFO - Epoch [1002/2000], Train Loss: 0.3244
2024-03-28 18:03:19,625 - config - INFO - Validation Loss: 0.4678
2024-03-28 18:03:19,643 - config - INFO - Epoch [1003/2000], Train Loss: 0.3249
2024-03-28 18:03:19,647 - config - INFO - Validation Loss: 0.4681
2024-03-28 18:03:19,665 - config - INFO - Epoch [1004/2000], Train Loss: 0.3252
2024-03-28 18:03:19,669 - config - INFO - Validation Loss: 0.4683
2024-03-28 18:03:19,687 - config - INFO - Epoch [1005/2000], Train Loss: 0.3242
2024-03-28 18:03:19,691 - config - INFO - Validation Loss: 0.4678
2024-03-28 18:03:19,710 - config - INFO - Epoch [1006/2000], Train Loss: 0.3246
2024-03-28 18:03:19,714 - config - INFO - Validation Loss: 0.4670
2024-03-28 18:03:19,732 - config - INFO - Epoch [1007/2000], Train Loss: 0.3242
2024-03-28 18:03:19,736 - config - INFO - Validation Loss: 0.4684
2024-03-28 18:03:19,756 - config - INFO - Epoch [1008/2000], Train Loss: 0.3243
2024-03-28 18:03:19,761 - config - INFO - Validation Loss: 0.4685
2024-03-28 18:03:19,780 - config - INFO - Epoch [1009/2000], Train Loss: 0.3246
2024-03-28 18:03:19,784 - config - INFO - Validation Loss: 0.4680
2024-03-28 18:03:19,802 - config - INFO - Epoch [1010/2000], Train Loss: 0.3239
2024-03-28 18:03:19,806 - config - INFO - Validation Loss: 0.4681
2024-03-28 18:03:19,824 - config - INFO - Epoch [1011/2000], Train Loss: 0.3238
2024-03-28 18:03:19,828 - config - INFO - Validation Loss: 0.4676
2024-03-28 18:03:19,847 - config - INFO - Epoch [1012/2000], Train Loss: 0.3235
2024-03-28 18:03:19,851 - config - INFO - Validation Loss: 0.4681
2024-03-28 18:03:19,869 - config - INFO - Epoch [1013/2000], Train Loss: 0.3238
2024-03-28 18:03:19,873 - config - INFO - Validation Loss: 0.4689
2024-03-28 18:03:19,891 - config - INFO - Epoch [1014/2000], Train Loss: 0.3240
2024-03-28 18:03:19,895 - config - INFO - Validation Loss: 0.4695
2024-03-28 18:03:19,913 - config - INFO - Epoch [1015/2000], Train Loss: 0.3235
2024-03-28 18:03:19,917 - config - INFO - Validation Loss: 0.4691
2024-03-28 18:03:19,935 - config - INFO - Epoch [1016/2000], Train Loss: 0.3234
2024-03-28 18:03:19,939 - config - INFO - Validation Loss: 0.4693
2024-03-28 18:03:19,957 - config - INFO - Epoch [1017/2000], Train Loss: 0.3237
2024-03-28 18:03:19,961 - config - INFO - Validation Loss: 0.4693
2024-03-28 18:03:19,979 - config - INFO - Epoch [1018/2000], Train Loss: 0.3252
2024-03-28 18:03:19,983 - config - INFO - Validation Loss: 0.4696
2024-03-28 18:03:20,001 - config - INFO - Epoch [1019/2000], Train Loss: 0.3230
2024-03-28 18:03:20,005 - config - INFO - Validation Loss: 0.4687
2024-03-28 18:03:20,024 - config - INFO - Epoch [1020/2000], Train Loss: 0.3239
2024-03-28 18:03:20,027 - config - INFO - Validation Loss: 0.4687
2024-03-28 18:03:20,046 - config - INFO - Epoch [1021/2000], Train Loss: 0.3237
2024-03-28 18:03:20,049 - config - INFO - Validation Loss: 0.4683
2024-03-28 18:03:20,068 - config - INFO - Epoch [1022/2000], Train Loss: 0.3233
2024-03-28 18:03:20,072 - config - INFO - Validation Loss: 0.4693
2024-03-28 18:03:20,090 - config - INFO - Epoch [1023/2000], Train Loss: 0.3229
2024-03-28 18:03:20,094 - config - INFO - Validation Loss: 0.4695
2024-03-28 18:03:20,112 - config - INFO - Epoch [1024/2000], Train Loss: 0.3231
2024-03-28 18:03:20,116 - config - INFO - Validation Loss: 0.4693
2024-03-28 18:03:20,134 - config - INFO - Epoch [1025/2000], Train Loss: 0.3228
2024-03-28 18:03:20,138 - config - INFO - Validation Loss: 0.4692
2024-03-28 18:03:20,156 - config - INFO - Epoch [1026/2000], Train Loss: 0.3231
2024-03-28 18:03:20,160 - config - INFO - Validation Loss: 0.4696
2024-03-28 18:03:20,179 - config - INFO - Epoch [1027/2000], Train Loss: 0.3225
2024-03-28 18:03:20,182 - config - INFO - Validation Loss: 0.4694
2024-03-28 18:03:20,201 - config - INFO - Epoch [1028/2000], Train Loss: 0.3228
2024-03-28 18:03:20,205 - config - INFO - Validation Loss: 0.4692
2024-03-28 18:03:20,223 - config - INFO - Epoch [1029/2000], Train Loss: 0.3223
2024-03-28 18:03:20,227 - config - INFO - Validation Loss: 0.4698
2024-03-28 18:03:20,245 - config - INFO - Epoch [1030/2000], Train Loss: 0.3228
2024-03-28 18:03:20,249 - config - INFO - Validation Loss: 0.4700
2024-03-28 18:03:20,267 - config - INFO - Epoch [1031/2000], Train Loss: 0.3221
2024-03-28 18:03:20,271 - config - INFO - Validation Loss: 0.4704
2024-03-28 18:03:20,289 - config - INFO - Epoch [1032/2000], Train Loss: 0.3223
2024-03-28 18:03:20,293 - config - INFO - Validation Loss: 0.4706
2024-03-28 18:03:20,312 - config - INFO - Epoch [1033/2000], Train Loss: 0.3229
2024-03-28 18:03:20,316 - config - INFO - Validation Loss: 0.4702
2024-03-28 18:03:20,334 - config - INFO - Epoch [1034/2000], Train Loss: 0.3222
2024-03-28 18:03:20,338 - config - INFO - Validation Loss: 0.4713
2024-03-28 18:03:20,338 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 18:04:27,940 - config - INFO - resume: None
2024-03-28 18:04:27,940 - config - INFO - device: cpu
2024-03-28 18:04:27,940 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-28 18:04:27,940 - config - INFO - learning_rate: 0.001
2024-03-28 18:04:27,940 - config - INFO - num_epochs: 2000
2024-03-28 18:04:27,940 - config - INFO - batch_size: 64
2024-03-28 18:04:27,940 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = None
        self.prev_val_loss = float('inf')
        self.tolerance = 0.03

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 18:04:27,954 - config - INFO - Dataset size: 891
2024-03-28 18:04:27,994 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.6 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()

    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 18:04:27,995 - config - INFO - Training start
2024-03-28 18:04:30,936 - config - INFO - Epoch [1/2000], Train Loss: 32.6794
2024-03-28 18:04:30,990 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:31,597 - config - INFO - Epoch [2/2000], Train Loss: 38.0150
2024-03-28 18:04:31,641 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:32,210 - config - INFO - Epoch [3/2000], Train Loss: 38.0150
2024-03-28 18:04:32,252 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:32,819 - config - INFO - Epoch [4/2000], Train Loss: 38.0150
2024-03-28 18:04:32,904 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:33,431 - config - INFO - Epoch [5/2000], Train Loss: 38.0150
2024-03-28 18:04:33,473 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:33,907 - config - INFO - Epoch [6/2000], Train Loss: 38.0150
2024-03-28 18:04:33,955 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:34,449 - config - INFO - Epoch [7/2000], Train Loss: 38.0150
2024-03-28 18:04:34,490 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:34,989 - config - INFO - Epoch [8/2000], Train Loss: 38.0150
2024-03-28 18:04:35,030 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:35,477 - config - INFO - Epoch [9/2000], Train Loss: 38.0150
2024-03-28 18:04:35,517 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:36,043 - config - INFO - Epoch [10/2000], Train Loss: 38.0150
2024-03-28 18:04:36,087 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:36,579 - config - INFO - Epoch [11/2000], Train Loss: 38.0150
2024-03-28 18:04:36,627 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:37,085 - config - INFO - Epoch [12/2000], Train Loss: 38.0150
2024-03-28 18:04:37,123 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:37,579 - config - INFO - Epoch [13/2000], Train Loss: 38.0150
2024-03-28 18:04:37,627 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:38,066 - config - INFO - Epoch [14/2000], Train Loss: 38.0150
2024-03-28 18:04:38,103 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:38,584 - config - INFO - Epoch [15/2000], Train Loss: 38.0150
2024-03-28 18:04:38,624 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:39,121 - config - INFO - Epoch [16/2000], Train Loss: 38.0150
2024-03-28 18:04:39,161 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:39,646 - config - INFO - Epoch [17/2000], Train Loss: 38.0150
2024-03-28 18:04:39,686 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:40,179 - config - INFO - Epoch [18/2000], Train Loss: 38.0150
2024-03-28 18:04:40,218 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:40,728 - config - INFO - Epoch [19/2000], Train Loss: 38.0150
2024-03-28 18:04:40,767 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:41,230 - config - INFO - Epoch [20/2000], Train Loss: 38.0150
2024-03-28 18:04:41,268 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:41,718 - config - INFO - Epoch [21/2000], Train Loss: 38.0150
2024-03-28 18:04:41,774 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:42,236 - config - INFO - Epoch [22/2000], Train Loss: 38.0150
2024-03-28 18:04:42,274 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:42,730 - config - INFO - Epoch [23/2000], Train Loss: 38.0150
2024-03-28 18:04:42,767 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:43,190 - config - INFO - Epoch [24/2000], Train Loss: 38.0150
2024-03-28 18:04:43,231 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:43,630 - config - INFO - Epoch [25/2000], Train Loss: 38.0150
2024-03-28 18:04:43,671 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:44,045 - config - INFO - Epoch [26/2000], Train Loss: 38.0150
2024-03-28 18:04:44,094 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:44,518 - config - INFO - Epoch [27/2000], Train Loss: 38.0150
2024-03-28 18:04:44,553 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:44,963 - config - INFO - Epoch [28/2000], Train Loss: 38.0150
2024-03-28 18:04:45,013 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:45,402 - config - INFO - Epoch [29/2000], Train Loss: 38.0150
2024-03-28 18:04:45,444 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:45,864 - config - INFO - Epoch [30/2000], Train Loss: 38.0150
2024-03-28 18:04:45,905 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:46,340 - config - INFO - Epoch [31/2000], Train Loss: 38.0150
2024-03-28 18:04:46,390 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:46,820 - config - INFO - Epoch [32/2000], Train Loss: 38.0150
2024-03-28 18:04:46,871 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:47,271 - config - INFO - Epoch [33/2000], Train Loss: 38.0150
2024-03-28 18:04:47,313 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:47,699 - config - INFO - Epoch [34/2000], Train Loss: 38.0150
2024-03-28 18:04:47,740 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:48,186 - config - INFO - Epoch [35/2000], Train Loss: 38.0150
2024-03-28 18:04:48,226 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:48,646 - config - INFO - Epoch [36/2000], Train Loss: 38.0150
2024-03-28 18:04:48,686 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:49,128 - config - INFO - Epoch [37/2000], Train Loss: 38.0150
2024-03-28 18:04:49,169 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:49,560 - config - INFO - Epoch [38/2000], Train Loss: 38.0150
2024-03-28 18:04:49,597 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:50,011 - config - INFO - Epoch [39/2000], Train Loss: 38.0150
2024-03-28 18:04:50,050 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:50,481 - config - INFO - Epoch [40/2000], Train Loss: 38.0150
2024-03-28 18:04:50,520 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:50,945 - config - INFO - Epoch [41/2000], Train Loss: 38.0150
2024-03-28 18:04:50,986 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:51,364 - config - INFO - Epoch [42/2000], Train Loss: 38.0150
2024-03-28 18:04:51,404 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:51,807 - config - INFO - Epoch [43/2000], Train Loss: 38.0150
2024-03-28 18:04:51,845 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:52,228 - config - INFO - Epoch [44/2000], Train Loss: 38.0150
2024-03-28 18:04:52,267 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:52,654 - config - INFO - Epoch [45/2000], Train Loss: 38.0150
2024-03-28 18:04:52,692 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:53,070 - config - INFO - Epoch [46/2000], Train Loss: 38.0150
2024-03-28 18:04:53,108 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:53,493 - config - INFO - Epoch [47/2000], Train Loss: 38.0150
2024-03-28 18:04:53,538 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:53,946 - config - INFO - Epoch [48/2000], Train Loss: 38.0150
2024-03-28 18:04:53,986 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:54,362 - config - INFO - Epoch [49/2000], Train Loss: 38.0150
2024-03-28 18:04:54,401 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:54,759 - config - INFO - Epoch [50/2000], Train Loss: 38.0150
2024-03-28 18:04:54,805 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:55,199 - config - INFO - Epoch [51/2000], Train Loss: 38.0150
2024-03-28 18:04:55,238 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:55,634 - config - INFO - Epoch [52/2000], Train Loss: 38.0150
2024-03-28 18:04:55,671 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:56,075 - config - INFO - Epoch [53/2000], Train Loss: 38.0150
2024-03-28 18:04:56,116 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:56,475 - config - INFO - Epoch [54/2000], Train Loss: 38.0150
2024-03-28 18:04:56,512 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:56,859 - config - INFO - Epoch [55/2000], Train Loss: 38.0150
2024-03-28 18:04:56,906 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:57,276 - config - INFO - Epoch [56/2000], Train Loss: 38.0150
2024-03-28 18:04:57,314 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:57,749 - config - INFO - Epoch [57/2000], Train Loss: 38.0150
2024-03-28 18:04:57,787 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:58,169 - config - INFO - Epoch [58/2000], Train Loss: 38.0150
2024-03-28 18:04:58,216 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:58,621 - config - INFO - Epoch [59/2000], Train Loss: 38.0150
2024-03-28 18:04:58,660 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:59,063 - config - INFO - Epoch [60/2000], Train Loss: 38.0150
2024-03-28 18:04:59,107 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:59,494 - config - INFO - Epoch [61/2000], Train Loss: 38.0150
2024-03-28 18:04:59,539 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:04:59,971 - config - INFO - Epoch [62/2000], Train Loss: 38.0150
2024-03-28 18:05:00,009 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:00,410 - config - INFO - Epoch [63/2000], Train Loss: 38.0150
2024-03-28 18:05:00,448 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:00,858 - config - INFO - Epoch [64/2000], Train Loss: 38.0150
2024-03-28 18:05:00,897 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:01,320 - config - INFO - Epoch [65/2000], Train Loss: 38.0150
2024-03-28 18:05:01,358 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:01,779 - config - INFO - Epoch [66/2000], Train Loss: 38.0150
2024-03-28 18:05:01,818 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:02,227 - config - INFO - Epoch [67/2000], Train Loss: 38.0150
2024-03-28 18:05:02,273 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:02,697 - config - INFO - Epoch [68/2000], Train Loss: 38.0150
2024-03-28 18:05:02,737 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:03,188 - config - INFO - Epoch [69/2000], Train Loss: 38.0150
2024-03-28 18:05:03,226 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:03,642 - config - INFO - Epoch [70/2000], Train Loss: 38.0150
2024-03-28 18:05:03,688 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:04,095 - config - INFO - Epoch [71/2000], Train Loss: 38.0150
2024-03-28 18:05:04,132 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:04,516 - config - INFO - Epoch [72/2000], Train Loss: 38.0150
2024-03-28 18:05:04,558 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:04,943 - config - INFO - Epoch [73/2000], Train Loss: 38.0150
2024-03-28 18:05:04,983 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:05,410 - config - INFO - Epoch [74/2000], Train Loss: 38.0150
2024-03-28 18:05:05,447 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:05,863 - config - INFO - Epoch [75/2000], Train Loss: 38.0150
2024-03-28 18:05:05,900 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:06,283 - config - INFO - Epoch [76/2000], Train Loss: 38.0150
2024-03-28 18:05:06,328 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:06,773 - config - INFO - Epoch [77/2000], Train Loss: 38.0150
2024-03-28 18:05:06,811 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:07,237 - config - INFO - Epoch [78/2000], Train Loss: 38.0150
2024-03-28 18:05:07,275 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:07,646 - config - INFO - Epoch [79/2000], Train Loss: 38.0150
2024-03-28 18:05:07,683 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:08,130 - config - INFO - Epoch [80/2000], Train Loss: 38.0150
2024-03-28 18:05:08,176 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:08,614 - config - INFO - Epoch [81/2000], Train Loss: 38.0150
2024-03-28 18:05:08,653 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:09,072 - config - INFO - Epoch [82/2000], Train Loss: 38.0150
2024-03-28 18:05:09,111 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:09,533 - config - INFO - Epoch [83/2000], Train Loss: 38.0150
2024-03-28 18:05:09,568 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:09,988 - config - INFO - Epoch [84/2000], Train Loss: 38.0150
2024-03-28 18:05:10,041 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:10,436 - config - INFO - Epoch [85/2000], Train Loss: 38.0150
2024-03-28 18:05:10,473 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:10,836 - config - INFO - Epoch [86/2000], Train Loss: 38.0150
2024-03-28 18:05:10,873 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:11,239 - config - INFO - Epoch [87/2000], Train Loss: 38.0150
2024-03-28 18:05:11,283 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:11,710 - config - INFO - Epoch [88/2000], Train Loss: 38.0150
2024-03-28 18:05:11,749 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:12,147 - config - INFO - Epoch [89/2000], Train Loss: 38.0150
2024-03-28 18:05:12,191 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:12,597 - config - INFO - Epoch [90/2000], Train Loss: 38.0150
2024-03-28 18:05:12,634 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:12,981 - config - INFO - Epoch [91/2000], Train Loss: 38.0150
2024-03-28 18:05:13,021 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:13,364 - config - INFO - Epoch [92/2000], Train Loss: 38.0150
2024-03-28 18:05:13,400 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:13,812 - config - INFO - Epoch [93/2000], Train Loss: 38.0150
2024-03-28 18:05:13,850 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:14,315 - config - INFO - Epoch [94/2000], Train Loss: 38.0150
2024-03-28 18:05:14,352 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:14,838 - config - INFO - Epoch [95/2000], Train Loss: 38.0150
2024-03-28 18:05:14,876 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:15,354 - config - INFO - Epoch [96/2000], Train Loss: 38.0150
2024-03-28 18:05:15,391 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:15,796 - config - INFO - Epoch [97/2000], Train Loss: 38.0150
2024-03-28 18:05:15,833 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:16,312 - config - INFO - Epoch [98/2000], Train Loss: 38.0150
2024-03-28 18:05:16,349 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:16,830 - config - INFO - Epoch [99/2000], Train Loss: 38.0150
2024-03-28 18:05:16,867 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:17,311 - config - INFO - Epoch [100/2000], Train Loss: 38.0150
2024-03-28 18:05:17,347 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:17,788 - config - INFO - Epoch [101/2000], Train Loss: 38.0150
2024-03-28 18:05:17,825 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:18,249 - config - INFO - Epoch [102/2000], Train Loss: 38.0150
2024-03-28 18:05:18,293 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:18,758 - config - INFO - Epoch [103/2000], Train Loss: 38.0150
2024-03-28 18:05:18,795 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:19,242 - config - INFO - Epoch [104/2000], Train Loss: 38.0150
2024-03-28 18:05:19,279 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:19,716 - config - INFO - Epoch [105/2000], Train Loss: 38.0150
2024-03-28 18:05:19,754 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:20,202 - config - INFO - Epoch [106/2000], Train Loss: 38.0150
2024-03-28 18:05:20,238 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:20,706 - config - INFO - Epoch [107/2000], Train Loss: 38.0150
2024-03-28 18:05:20,743 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:21,139 - config - INFO - Epoch [108/2000], Train Loss: 38.0150
2024-03-28 18:05:21,176 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:21,653 - config - INFO - Epoch [109/2000], Train Loss: 38.0150
2024-03-28 18:05:21,690 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:22,102 - config - INFO - Epoch [110/2000], Train Loss: 38.0150
2024-03-28 18:05:22,138 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:22,618 - config - INFO - Epoch [111/2000], Train Loss: 38.0150
2024-03-28 18:05:22,655 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:23,105 - config - INFO - Epoch [112/2000], Train Loss: 38.0150
2024-03-28 18:05:23,148 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:23,635 - config - INFO - Epoch [113/2000], Train Loss: 38.0150
2024-03-28 18:05:23,671 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:24,154 - config - INFO - Epoch [114/2000], Train Loss: 38.0150
2024-03-28 18:05:24,191 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:24,656 - config - INFO - Epoch [115/2000], Train Loss: 38.0150
2024-03-28 18:05:24,695 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:25,147 - config - INFO - Epoch [116/2000], Train Loss: 38.0150
2024-03-28 18:05:25,185 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:25,641 - config - INFO - Epoch [117/2000], Train Loss: 38.0150
2024-03-28 18:05:25,678 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:26,165 - config - INFO - Epoch [118/2000], Train Loss: 38.0150
2024-03-28 18:05:26,202 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:26,664 - config - INFO - Epoch [119/2000], Train Loss: 38.0150
2024-03-28 18:05:26,702 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:27,146 - config - INFO - Epoch [120/2000], Train Loss: 38.0150
2024-03-28 18:05:27,183 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:27,632 - config - INFO - Epoch [121/2000], Train Loss: 38.0150
2024-03-28 18:05:27,668 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:28,104 - config - INFO - Epoch [122/2000], Train Loss: 38.0150
2024-03-28 18:05:28,141 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:28,593 - config - INFO - Epoch [123/2000], Train Loss: 38.0150
2024-03-28 18:05:28,630 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:29,118 - config - INFO - Epoch [124/2000], Train Loss: 38.0150
2024-03-28 18:05:29,156 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:29,583 - config - INFO - Epoch [125/2000], Train Loss: 38.0150
2024-03-28 18:05:29,630 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:30,075 - config - INFO - Epoch [126/2000], Train Loss: 38.0150
2024-03-28 18:05:30,112 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:30,517 - config - INFO - Epoch [127/2000], Train Loss: 38.0150
2024-03-28 18:05:30,555 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:31,008 - config - INFO - Epoch [128/2000], Train Loss: 38.0150
2024-03-28 18:05:31,046 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:31,476 - config - INFO - Epoch [129/2000], Train Loss: 38.0150
2024-03-28 18:05:31,514 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:31,973 - config - INFO - Epoch [130/2000], Train Loss: 38.0150
2024-03-28 18:05:32,010 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:32,466 - config - INFO - Epoch [131/2000], Train Loss: 38.0150
2024-03-28 18:05:32,503 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:32,950 - config - INFO - Epoch [132/2000], Train Loss: 38.0150
2024-03-28 18:05:32,987 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:33,448 - config - INFO - Epoch [133/2000], Train Loss: 38.0150
2024-03-28 18:05:33,485 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:33,971 - config - INFO - Epoch [134/2000], Train Loss: 38.0150
2024-03-28 18:05:34,008 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:34,441 - config - INFO - Epoch [135/2000], Train Loss: 38.0150
2024-03-28 18:05:34,479 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:34,929 - config - INFO - Epoch [136/2000], Train Loss: 38.0150
2024-03-28 18:05:34,966 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:35,427 - config - INFO - Epoch [137/2000], Train Loss: 38.0150
2024-03-28 18:05:35,464 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:35,955 - config - INFO - Epoch [138/2000], Train Loss: 38.0150
2024-03-28 18:05:35,993 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:36,463 - config - INFO - Epoch [139/2000], Train Loss: 38.0150
2024-03-28 18:05:36,500 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:36,950 - config - INFO - Epoch [140/2000], Train Loss: 38.0150
2024-03-28 18:05:36,988 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:37,450 - config - INFO - Epoch [141/2000], Train Loss: 38.0150
2024-03-28 18:05:37,493 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:37,949 - config - INFO - Epoch [142/2000], Train Loss: 38.0150
2024-03-28 18:05:37,986 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:38,426 - config - INFO - Epoch [143/2000], Train Loss: 38.0150
2024-03-28 18:05:38,463 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:38,945 - config - INFO - Epoch [144/2000], Train Loss: 38.0150
2024-03-28 18:05:38,982 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:39,438 - config - INFO - Epoch [145/2000], Train Loss: 38.0150
2024-03-28 18:05:39,487 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:39,951 - config - INFO - Epoch [146/2000], Train Loss: 38.0150
2024-03-28 18:05:39,989 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:40,463 - config - INFO - Epoch [147/2000], Train Loss: 38.0150
2024-03-28 18:05:40,500 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:40,992 - config - INFO - Epoch [148/2000], Train Loss: 38.0150
2024-03-28 18:05:41,029 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:41,513 - config - INFO - Epoch [149/2000], Train Loss: 38.0150
2024-03-28 18:05:41,552 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:42,051 - config - INFO - Epoch [150/2000], Train Loss: 38.0150
2024-03-28 18:05:42,090 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:42,585 - config - INFO - Epoch [151/2000], Train Loss: 38.0150
2024-03-28 18:05:42,631 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:43,054 - config - INFO - Epoch [152/2000], Train Loss: 38.0150
2024-03-28 18:05:43,092 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:43,569 - config - INFO - Epoch [153/2000], Train Loss: 38.0150
2024-03-28 18:05:43,606 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:44,033 - config - INFO - Epoch [154/2000], Train Loss: 38.0150
2024-03-28 18:05:44,071 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:44,533 - config - INFO - Epoch [155/2000], Train Loss: 38.0150
2024-03-28 18:05:44,570 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:44,998 - config - INFO - Epoch [156/2000], Train Loss: 38.0150
2024-03-28 18:05:45,035 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:45,472 - config - INFO - Epoch [157/2000], Train Loss: 38.0150
2024-03-28 18:05:45,508 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:45,965 - config - INFO - Epoch [158/2000], Train Loss: 38.0150
2024-03-28 18:05:46,001 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:46,445 - config - INFO - Epoch [159/2000], Train Loss: 38.0150
2024-03-28 18:05:46,482 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:46,944 - config - INFO - Epoch [160/2000], Train Loss: 38.0150
2024-03-28 18:05:46,981 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:47,414 - config - INFO - Epoch [161/2000], Train Loss: 38.0150
2024-03-28 18:05:47,451 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:47,884 - config - INFO - Epoch [162/2000], Train Loss: 38.0150
2024-03-28 18:05:47,925 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:48,282 - config - INFO - Epoch [163/2000], Train Loss: 38.0150
2024-03-28 18:05:48,324 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:48,714 - config - INFO - Epoch [164/2000], Train Loss: 38.0150
2024-03-28 18:05:48,755 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:49,204 - config - INFO - Epoch [165/2000], Train Loss: 38.0150
2024-03-28 18:05:49,244 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:49,593 - config - INFO - Epoch [166/2000], Train Loss: 38.0150
2024-03-28 18:05:49,632 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:49,975 - config - INFO - Epoch [167/2000], Train Loss: 38.0150
2024-03-28 18:05:50,017 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:50,379 - config - INFO - Epoch [168/2000], Train Loss: 38.0150
2024-03-28 18:05:50,416 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:50,762 - config - INFO - Epoch [169/2000], Train Loss: 38.0150
2024-03-28 18:05:50,799 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:51,148 - config - INFO - Epoch [170/2000], Train Loss: 38.0150
2024-03-28 18:05:51,185 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:51,536 - config - INFO - Epoch [171/2000], Train Loss: 38.0150
2024-03-28 18:05:51,576 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:51,921 - config - INFO - Epoch [172/2000], Train Loss: 38.0150
2024-03-28 18:05:51,958 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:52,308 - config - INFO - Epoch [173/2000], Train Loss: 38.0150
2024-03-28 18:05:52,349 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:52,715 - config - INFO - Epoch [174/2000], Train Loss: 38.0150
2024-03-28 18:05:52,753 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:53,096 - config - INFO - Epoch [175/2000], Train Loss: 38.0150
2024-03-28 18:05:53,135 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:53,457 - config - INFO - Epoch [176/2000], Train Loss: 38.0150
2024-03-28 18:05:53,490 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:53,851 - config - INFO - Epoch [177/2000], Train Loss: 38.0150
2024-03-28 18:05:53,895 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:54,258 - config - INFO - Epoch [178/2000], Train Loss: 38.0150
2024-03-28 18:05:54,292 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:54,649 - config - INFO - Epoch [179/2000], Train Loss: 38.0150
2024-03-28 18:05:54,687 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:55,061 - config - INFO - Epoch [180/2000], Train Loss: 38.0150
2024-03-28 18:05:55,102 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:55,499 - config - INFO - Epoch [181/2000], Train Loss: 38.0150
2024-03-28 18:05:55,535 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:55,885 - config - INFO - Epoch [182/2000], Train Loss: 38.0150
2024-03-28 18:05:55,923 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:56,271 - config - INFO - Epoch [183/2000], Train Loss: 38.0150
2024-03-28 18:05:56,306 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:56,668 - config - INFO - Epoch [184/2000], Train Loss: 38.0150
2024-03-28 18:05:56,705 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:57,088 - config - INFO - Epoch [185/2000], Train Loss: 38.0150
2024-03-28 18:05:57,135 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:57,530 - config - INFO - Epoch [186/2000], Train Loss: 38.0150
2024-03-28 18:05:57,568 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:57,959 - config - INFO - Epoch [187/2000], Train Loss: 38.0150
2024-03-28 18:05:57,993 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:58,410 - config - INFO - Epoch [188/2000], Train Loss: 38.0150
2024-03-28 18:05:58,458 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:58,812 - config - INFO - Epoch [189/2000], Train Loss: 38.0150
2024-03-28 18:05:58,851 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:59,209 - config - INFO - Epoch [190/2000], Train Loss: 38.0150
2024-03-28 18:05:59,255 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:05:59,603 - config - INFO - Epoch [191/2000], Train Loss: 38.0150
2024-03-28 18:05:59,643 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:00,045 - config - INFO - Epoch [192/2000], Train Loss: 38.0150
2024-03-28 18:06:00,083 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:00,471 - config - INFO - Epoch [193/2000], Train Loss: 38.0150
2024-03-28 18:06:00,511 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:00,880 - config - INFO - Epoch [194/2000], Train Loss: 38.0150
2024-03-28 18:06:00,932 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:01,291 - config - INFO - Epoch [195/2000], Train Loss: 38.0150
2024-03-28 18:06:01,332 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:01,723 - config - INFO - Epoch [196/2000], Train Loss: 38.0150
2024-03-28 18:06:01,756 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:02,105 - config - INFO - Epoch [197/2000], Train Loss: 38.0150
2024-03-28 18:06:02,144 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:02,510 - config - INFO - Epoch [198/2000], Train Loss: 38.0150
2024-03-28 18:06:02,545 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:02,865 - config - INFO - Epoch [199/2000], Train Loss: 38.0150
2024-03-28 18:06:02,905 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:03,299 - config - INFO - Epoch [200/2000], Train Loss: 38.0150
2024-03-28 18:06:03,336 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:03,685 - config - INFO - Epoch [201/2000], Train Loss: 38.0150
2024-03-28 18:06:03,724 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:04,105 - config - INFO - Epoch [202/2000], Train Loss: 38.0150
2024-03-28 18:06:04,143 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:04,494 - config - INFO - Epoch [203/2000], Train Loss: 38.0150
2024-03-28 18:06:04,534 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:04,939 - config - INFO - Epoch [204/2000], Train Loss: 38.0150
2024-03-28 18:06:04,978 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:05,352 - config - INFO - Epoch [205/2000], Train Loss: 38.0150
2024-03-28 18:06:05,385 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:05,732 - config - INFO - Epoch [206/2000], Train Loss: 38.0150
2024-03-28 18:06:05,770 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:06,123 - config - INFO - Epoch [207/2000], Train Loss: 38.0150
2024-03-28 18:06:06,165 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:06,551 - config - INFO - Epoch [208/2000], Train Loss: 38.0150
2024-03-28 18:06:06,588 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:06,947 - config - INFO - Epoch [209/2000], Train Loss: 38.0150
2024-03-28 18:06:06,993 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:07,395 - config - INFO - Epoch [210/2000], Train Loss: 38.0150
2024-03-28 18:06:07,432 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:07,794 - config - INFO - Epoch [211/2000], Train Loss: 38.0150
2024-03-28 18:06:07,841 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:08,217 - config - INFO - Epoch [212/2000], Train Loss: 38.0150
2024-03-28 18:06:08,254 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:08,616 - config - INFO - Epoch [213/2000], Train Loss: 38.0150
2024-03-28 18:06:08,655 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:09,020 - config - INFO - Epoch [214/2000], Train Loss: 38.0150
2024-03-28 18:06:09,060 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:09,464 - config - INFO - Epoch [215/2000], Train Loss: 38.0150
2024-03-28 18:06:09,509 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:09,857 - config - INFO - Epoch [216/2000], Train Loss: 38.0150
2024-03-28 18:06:09,896 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:10,282 - config - INFO - Epoch [217/2000], Train Loss: 38.0150
2024-03-28 18:06:10,319 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:10,670 - config - INFO - Epoch [218/2000], Train Loss: 38.0150
2024-03-28 18:06:10,709 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:11,053 - config - INFO - Epoch [219/2000], Train Loss: 38.0150
2024-03-28 18:06:11,091 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:11,457 - config - INFO - Epoch [220/2000], Train Loss: 38.0150
2024-03-28 18:06:11,495 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:11,835 - config - INFO - Epoch [221/2000], Train Loss: 38.0150
2024-03-28 18:06:11,879 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:12,238 - config - INFO - Epoch [222/2000], Train Loss: 38.0150
2024-03-28 18:06:12,275 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:12,644 - config - INFO - Epoch [223/2000], Train Loss: 38.0150
2024-03-28 18:06:12,681 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:13,017 - config - INFO - Epoch [224/2000], Train Loss: 38.0150
2024-03-28 18:06:13,054 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:13,384 - config - INFO - Epoch [225/2000], Train Loss: 38.0150
2024-03-28 18:06:13,421 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:13,784 - config - INFO - Epoch [226/2000], Train Loss: 38.0150
2024-03-28 18:06:13,826 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:14,207 - config - INFO - Epoch [227/2000], Train Loss: 38.0150
2024-03-28 18:06:14,244 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:14,606 - config - INFO - Epoch [228/2000], Train Loss: 38.0150
2024-03-28 18:06:14,646 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:15,028 - config - INFO - Epoch [229/2000], Train Loss: 38.0150
2024-03-28 18:06:15,066 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:15,453 - config - INFO - Epoch [230/2000], Train Loss: 38.0150
2024-03-28 18:06:15,494 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:15,872 - config - INFO - Epoch [231/2000], Train Loss: 38.0150
2024-03-28 18:06:15,910 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:16,264 - config - INFO - Epoch [232/2000], Train Loss: 38.0150
2024-03-28 18:06:16,304 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:16,671 - config - INFO - Epoch [233/2000], Train Loss: 38.0150
2024-03-28 18:06:16,709 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:17,053 - config - INFO - Epoch [234/2000], Train Loss: 38.0150
2024-03-28 18:06:17,091 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:17,519 - config - INFO - Epoch [235/2000], Train Loss: 38.0150
2024-03-28 18:06:17,564 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:18,023 - config - INFO - Epoch [236/2000], Train Loss: 38.0150
2024-03-28 18:06:18,060 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:18,535 - config - INFO - Epoch [237/2000], Train Loss: 38.0150
2024-03-28 18:06:18,571 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:19,034 - config - INFO - Epoch [238/2000], Train Loss: 38.0150
2024-03-28 18:06:19,071 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:19,548 - config - INFO - Epoch [239/2000], Train Loss: 38.0150
2024-03-28 18:06:19,586 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:20,015 - config - INFO - Epoch [240/2000], Train Loss: 38.0150
2024-03-28 18:06:20,054 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:20,512 - config - INFO - Epoch [241/2000], Train Loss: 38.0150
2024-03-28 18:06:20,549 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:20,987 - config - INFO - Epoch [242/2000], Train Loss: 38.0150
2024-03-28 18:06:21,024 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:21,440 - config - INFO - Epoch [243/2000], Train Loss: 38.0150
2024-03-28 18:06:21,478 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:21,907 - config - INFO - Epoch [244/2000], Train Loss: 38.0150
2024-03-28 18:06:21,945 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:22,414 - config - INFO - Epoch [245/2000], Train Loss: 38.0150
2024-03-28 18:06:22,461 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:22,904 - config - INFO - Epoch [246/2000], Train Loss: 38.0150
2024-03-28 18:06:22,943 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:23,335 - config - INFO - Epoch [247/2000], Train Loss: 38.0150
2024-03-28 18:06:23,372 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:23,848 - config - INFO - Epoch [248/2000], Train Loss: 38.0150
2024-03-28 18:06:23,887 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:24,329 - config - INFO - Epoch [249/2000], Train Loss: 38.0150
2024-03-28 18:06:24,368 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:24,806 - config - INFO - Epoch [250/2000], Train Loss: 38.0150
2024-03-28 18:06:24,844 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:25,311 - config - INFO - Epoch [251/2000], Train Loss: 38.0150
2024-03-28 18:06:25,347 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:25,755 - config - INFO - Epoch [252/2000], Train Loss: 38.0150
2024-03-28 18:06:25,793 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:26,261 - config - INFO - Epoch [253/2000], Train Loss: 38.0150
2024-03-28 18:06:26,299 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:26,726 - config - INFO - Epoch [254/2000], Train Loss: 38.0150
2024-03-28 18:06:26,772 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:27,221 - config - INFO - Epoch [255/2000], Train Loss: 38.0150
2024-03-28 18:06:27,257 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:27,714 - config - INFO - Epoch [256/2000], Train Loss: 38.0150
2024-03-28 18:06:27,751 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:28,211 - config - INFO - Epoch [257/2000], Train Loss: 38.0150
2024-03-28 18:06:28,247 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:28,728 - config - INFO - Epoch [258/2000], Train Loss: 38.0150
2024-03-28 18:06:28,765 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:29,205 - config - INFO - Epoch [259/2000], Train Loss: 38.0150
2024-03-28 18:06:29,245 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:29,719 - config - INFO - Epoch [260/2000], Train Loss: 38.0150
2024-03-28 18:06:29,756 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:30,242 - config - INFO - Epoch [261/2000], Train Loss: 38.0150
2024-03-28 18:06:30,279 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:30,735 - config - INFO - Epoch [262/2000], Train Loss: 38.0150
2024-03-28 18:06:30,772 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:31,206 - config - INFO - Epoch [263/2000], Train Loss: 38.0150
2024-03-28 18:06:31,243 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:31,718 - config - INFO - Epoch [264/2000], Train Loss: 38.0150
2024-03-28 18:06:31,755 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:32,203 - config - INFO - Epoch [265/2000], Train Loss: 38.0150
2024-03-28 18:06:32,240 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:32,694 - config - INFO - Epoch [266/2000], Train Loss: 38.0150
2024-03-28 18:06:32,731 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:33,205 - config - INFO - Epoch [267/2000], Train Loss: 38.0150
2024-03-28 18:06:33,242 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:33,672 - config - INFO - Epoch [268/2000], Train Loss: 38.0150
2024-03-28 18:06:33,715 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:34,130 - config - INFO - Epoch [269/2000], Train Loss: 38.0150
2024-03-28 18:06:34,167 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:34,617 - config - INFO - Epoch [270/2000], Train Loss: 38.0150
2024-03-28 18:06:34,653 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:35,128 - config - INFO - Epoch [271/2000], Train Loss: 38.0150
2024-03-28 18:06:35,164 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:35,574 - config - INFO - Epoch [272/2000], Train Loss: 38.0150
2024-03-28 18:06:35,611 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:36,067 - config - INFO - Epoch [273/2000], Train Loss: 38.0150
2024-03-28 18:06:36,104 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:36,547 - config - INFO - Epoch [274/2000], Train Loss: 38.0150
2024-03-28 18:06:36,583 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:37,041 - config - INFO - Epoch [275/2000], Train Loss: 38.0150
2024-03-28 18:06:37,086 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:37,560 - config - INFO - Epoch [276/2000], Train Loss: 38.0150
2024-03-28 18:06:37,597 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:38,081 - config - INFO - Epoch [277/2000], Train Loss: 38.0150
2024-03-28 18:06:38,118 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:38,601 - config - INFO - Epoch [278/2000], Train Loss: 38.0150
2024-03-28 18:06:38,638 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:39,097 - config - INFO - Epoch [279/2000], Train Loss: 38.0150
2024-03-28 18:06:39,134 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:39,597 - config - INFO - Epoch [280/2000], Train Loss: 38.0150
2024-03-28 18:06:39,633 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:40,104 - config - INFO - Epoch [281/2000], Train Loss: 38.0150
2024-03-28 18:06:40,140 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:40,614 - config - INFO - Epoch [282/2000], Train Loss: 38.0150
2024-03-28 18:06:40,651 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:41,112 - config - INFO - Epoch [283/2000], Train Loss: 38.0150
2024-03-28 18:06:41,149 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:41,574 - config - INFO - Epoch [284/2000], Train Loss: 38.0150
2024-03-28 18:06:41,611 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:42,084 - config - INFO - Epoch [285/2000], Train Loss: 38.0150
2024-03-28 18:06:42,121 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:42,606 - config - INFO - Epoch [286/2000], Train Loss: 38.0150
2024-03-28 18:06:42,643 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:43,088 - config - INFO - Epoch [287/2000], Train Loss: 38.0150
2024-03-28 18:06:43,125 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:43,587 - config - INFO - Epoch [288/2000], Train Loss: 38.0150
2024-03-28 18:06:43,623 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:44,077 - config - INFO - Epoch [289/2000], Train Loss: 38.0150
2024-03-28 18:06:44,123 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:44,651 - config - INFO - Epoch [290/2000], Train Loss: 38.0150
2024-03-28 18:06:44,691 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:45,184 - config - INFO - Epoch [291/2000], Train Loss: 38.0150
2024-03-28 18:06:45,231 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:45,690 - config - INFO - Epoch [292/2000], Train Loss: 38.0150
2024-03-28 18:06:45,730 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:46,176 - config - INFO - Epoch [293/2000], Train Loss: 38.0150
2024-03-28 18:06:46,215 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:46,664 - config - INFO - Epoch [294/2000], Train Loss: 38.0150
2024-03-28 18:06:46,712 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:47,187 - config - INFO - Epoch [295/2000], Train Loss: 38.0150
2024-03-28 18:06:47,226 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:47,695 - config - INFO - Epoch [296/2000], Train Loss: 38.0150
2024-03-28 18:06:47,734 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:48,224 - config - INFO - Epoch [297/2000], Train Loss: 38.0150
2024-03-28 18:06:48,263 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:48,783 - config - INFO - Epoch [298/2000], Train Loss: 38.0150
2024-03-28 18:06:48,821 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:49,318 - config - INFO - Epoch [299/2000], Train Loss: 38.0150
2024-03-28 18:06:49,355 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:49,807 - config - INFO - Epoch [300/2000], Train Loss: 38.0150
2024-03-28 18:06:49,853 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:50,331 - config - INFO - Epoch [301/2000], Train Loss: 38.0150
2024-03-28 18:06:50,368 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:50,824 - config - INFO - Epoch [302/2000], Train Loss: 38.0150
2024-03-28 18:06:50,861 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:51,316 - config - INFO - Epoch [303/2000], Train Loss: 38.0150
2024-03-28 18:06:51,353 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:51,822 - config - INFO - Epoch [304/2000], Train Loss: 38.0150
2024-03-28 18:06:51,860 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:52,363 - config - INFO - Epoch [305/2000], Train Loss: 38.0150
2024-03-28 18:06:52,400 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:52,890 - config - INFO - Epoch [306/2000], Train Loss: 38.0150
2024-03-28 18:06:52,927 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:53,391 - config - INFO - Epoch [307/2000], Train Loss: 38.0150
2024-03-28 18:06:53,428 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:53,877 - config - INFO - Epoch [308/2000], Train Loss: 38.0150
2024-03-28 18:06:53,914 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:54,401 - config - INFO - Epoch [309/2000], Train Loss: 38.0150
2024-03-28 18:06:54,438 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:54,849 - config - INFO - Epoch [310/2000], Train Loss: 38.0150
2024-03-28 18:06:54,894 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:55,364 - config - INFO - Epoch [311/2000], Train Loss: 38.0150
2024-03-28 18:06:55,401 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:55,873 - config - INFO - Epoch [312/2000], Train Loss: 38.0150
2024-03-28 18:06:55,910 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:56,328 - config - INFO - Epoch [313/2000], Train Loss: 38.0150
2024-03-28 18:06:56,366 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:56,812 - config - INFO - Epoch [314/2000], Train Loss: 38.0150
2024-03-28 18:06:56,850 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:57,255 - config - INFO - Epoch [315/2000], Train Loss: 38.0150
2024-03-28 18:06:57,294 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:57,743 - config - INFO - Epoch [316/2000], Train Loss: 38.0150
2024-03-28 18:06:57,787 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:58,259 - config - INFO - Epoch [317/2000], Train Loss: 38.0150
2024-03-28 18:06:58,296 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:58,739 - config - INFO - Epoch [318/2000], Train Loss: 38.0150
2024-03-28 18:06:58,778 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:59,208 - config - INFO - Epoch [319/2000], Train Loss: 38.0150
2024-03-28 18:06:59,245 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:06:59,700 - config - INFO - Epoch [320/2000], Train Loss: 38.0150
2024-03-28 18:06:59,737 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:00,202 - config - INFO - Epoch [321/2000], Train Loss: 38.0150
2024-03-28 18:07:00,239 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:00,677 - config - INFO - Epoch [322/2000], Train Loss: 38.0150
2024-03-28 18:07:00,726 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:01,175 - config - INFO - Epoch [323/2000], Train Loss: 38.0150
2024-03-28 18:07:01,219 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:01,677 - config - INFO - Epoch [324/2000], Train Loss: 38.0150
2024-03-28 18:07:01,715 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:02,149 - config - INFO - Epoch [325/2000], Train Loss: 38.0150
2024-03-28 18:07:02,187 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:02,639 - config - INFO - Epoch [326/2000], Train Loss: 38.0150
2024-03-28 18:07:02,676 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:03,084 - config - INFO - Epoch [327/2000], Train Loss: 38.0150
2024-03-28 18:07:03,127 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:03,533 - config - INFO - Epoch [328/2000], Train Loss: 38.0150
2024-03-28 18:07:03,576 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:03,966 - config - INFO - Epoch [329/2000], Train Loss: 38.0150
2024-03-28 18:07:04,008 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:04,373 - config - INFO - Epoch [330/2000], Train Loss: 38.0150
2024-03-28 18:07:04,412 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:04,827 - config - INFO - Epoch [331/2000], Train Loss: 38.0150
2024-03-28 18:07:04,866 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:05,258 - config - INFO - Epoch [332/2000], Train Loss: 38.0150
2024-03-28 18:07:05,305 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:05,756 - config - INFO - Epoch [333/2000], Train Loss: 38.0150
2024-03-28 18:07:05,795 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:06,231 - config - INFO - Epoch [334/2000], Train Loss: 38.0150
2024-03-28 18:07:06,282 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:06,697 - config - INFO - Epoch [335/2000], Train Loss: 38.0150
2024-03-28 18:07:06,734 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:07,216 - config - INFO - Epoch [336/2000], Train Loss: 38.0150
2024-03-28 18:07:07,253 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:07,683 - config - INFO - Epoch [337/2000], Train Loss: 38.0150
2024-03-28 18:07:07,721 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:08,144 - config - INFO - Epoch [338/2000], Train Loss: 38.0150
2024-03-28 18:07:08,180 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:08,585 - config - INFO - Epoch [339/2000], Train Loss: 38.0150
2024-03-28 18:07:08,622 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:09,071 - config - INFO - Epoch [340/2000], Train Loss: 38.0150
2024-03-28 18:07:09,108 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:09,549 - config - INFO - Epoch [341/2000], Train Loss: 38.0150
2024-03-28 18:07:09,586 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:10,031 - config - INFO - Epoch [342/2000], Train Loss: 38.0150
2024-03-28 18:07:10,068 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:10,522 - config - INFO - Epoch [343/2000], Train Loss: 38.0150
2024-03-28 18:07:10,560 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:11,003 - config - INFO - Epoch [344/2000], Train Loss: 38.0150
2024-03-28 18:07:11,041 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:11,532 - config - INFO - Epoch [345/2000], Train Loss: 38.0150
2024-03-28 18:07:11,571 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:12,035 - config - INFO - Epoch [346/2000], Train Loss: 38.0150
2024-03-28 18:07:12,080 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:12,577 - config - INFO - Epoch [347/2000], Train Loss: 38.0150
2024-03-28 18:07:12,617 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:13,099 - config - INFO - Epoch [348/2000], Train Loss: 38.0150
2024-03-28 18:07:13,140 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:13,553 - config - INFO - Epoch [349/2000], Train Loss: 38.0150
2024-03-28 18:07:13,592 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:14,068 - config - INFO - Epoch [350/2000], Train Loss: 38.0150
2024-03-28 18:07:14,107 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:14,589 - config - INFO - Epoch [351/2000], Train Loss: 38.0150
2024-03-28 18:07:14,627 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:15,093 - config - INFO - Epoch [352/2000], Train Loss: 38.0150
2024-03-28 18:07:15,135 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:15,581 - config - INFO - Epoch [353/2000], Train Loss: 38.0150
2024-03-28 18:07:15,628 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:16,107 - config - INFO - Epoch [354/2000], Train Loss: 38.0150
2024-03-28 18:07:16,144 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:16,654 - config - INFO - Epoch [355/2000], Train Loss: 38.0150
2024-03-28 18:07:16,692 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:17,209 - config - INFO - Epoch [356/2000], Train Loss: 38.0150
2024-03-28 18:07:17,248 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:17,719 - config - INFO - Epoch [357/2000], Train Loss: 38.0150
2024-03-28 18:07:17,756 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:18,200 - config - INFO - Epoch [358/2000], Train Loss: 38.0150
2024-03-28 18:07:18,246 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:18,714 - config - INFO - Epoch [359/2000], Train Loss: 38.0150
2024-03-28 18:07:18,751 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:19,225 - config - INFO - Epoch [360/2000], Train Loss: 38.0150
2024-03-28 18:07:19,262 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:19,754 - config - INFO - Epoch [361/2000], Train Loss: 38.0150
2024-03-28 18:07:19,791 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:20,254 - config - INFO - Epoch [362/2000], Train Loss: 38.0150
2024-03-28 18:07:20,290 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:20,759 - config - INFO - Epoch [363/2000], Train Loss: 38.0150
2024-03-28 18:07:20,796 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:21,263 - config - INFO - Epoch [364/2000], Train Loss: 38.0150
2024-03-28 18:07:21,300 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:21,733 - config - INFO - Epoch [365/2000], Train Loss: 38.0150
2024-03-28 18:07:21,771 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:22,224 - config - INFO - Epoch [366/2000], Train Loss: 38.0150
2024-03-28 18:07:22,270 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:22,707 - config - INFO - Epoch [367/2000], Train Loss: 38.0150
2024-03-28 18:07:22,746 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:23,165 - config - INFO - Epoch [368/2000], Train Loss: 38.0150
2024-03-28 18:07:23,218 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:23,633 - config - INFO - Epoch [369/2000], Train Loss: 38.0150
2024-03-28 18:07:23,672 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:24,105 - config - INFO - Epoch [370/2000], Train Loss: 38.0150
2024-03-28 18:07:24,142 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:24,535 - config - INFO - Epoch [371/2000], Train Loss: 38.0150
2024-03-28 18:07:24,572 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:24,996 - config - INFO - Epoch [372/2000], Train Loss: 38.0150
2024-03-28 18:07:25,032 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:25,451 - config - INFO - Epoch [373/2000], Train Loss: 38.0150
2024-03-28 18:07:25,489 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:25,974 - config - INFO - Epoch [374/2000], Train Loss: 38.0150
2024-03-28 18:07:26,010 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:26,437 - config - INFO - Epoch [375/2000], Train Loss: 38.0150
2024-03-28 18:07:26,473 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:26,936 - config - INFO - Epoch [376/2000], Train Loss: 38.0150
2024-03-28 18:07:26,973 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:27,408 - config - INFO - Epoch [377/2000], Train Loss: 38.0150
2024-03-28 18:07:27,457 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:27,893 - config - INFO - Epoch [378/2000], Train Loss: 38.0150
2024-03-28 18:07:27,930 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:28,364 - config - INFO - Epoch [379/2000], Train Loss: 38.0150
2024-03-28 18:07:28,401 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:28,832 - config - INFO - Epoch [380/2000], Train Loss: 38.0150
2024-03-28 18:07:28,876 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:29,297 - config - INFO - Epoch [381/2000], Train Loss: 38.0150
2024-03-28 18:07:29,334 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:29,791 - config - INFO - Epoch [382/2000], Train Loss: 38.0150
2024-03-28 18:07:29,827 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:30,295 - config - INFO - Epoch [383/2000], Train Loss: 38.0150
2024-03-28 18:07:30,332 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:30,806 - config - INFO - Epoch [384/2000], Train Loss: 38.0150
2024-03-28 18:07:30,842 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:31,284 - config - INFO - Epoch [385/2000], Train Loss: 38.0150
2024-03-28 18:07:31,321 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:31,791 - config - INFO - Epoch [386/2000], Train Loss: 38.0150
2024-03-28 18:07:31,828 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:32,270 - config - INFO - Epoch [387/2000], Train Loss: 38.0150
2024-03-28 18:07:32,308 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:32,768 - config - INFO - Epoch [388/2000], Train Loss: 38.0150
2024-03-28 18:07:32,805 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:33,285 - config - INFO - Epoch [389/2000], Train Loss: 38.0150
2024-03-28 18:07:33,324 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:33,807 - config - INFO - Epoch [390/2000], Train Loss: 38.0150
2024-03-28 18:07:33,844 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:34,257 - config - INFO - Epoch [391/2000], Train Loss: 38.0150
2024-03-28 18:07:34,303 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:34,763 - config - INFO - Epoch [392/2000], Train Loss: 38.0150
2024-03-28 18:07:34,800 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:35,235 - config - INFO - Epoch [393/2000], Train Loss: 38.0150
2024-03-28 18:07:35,272 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:35,755 - config - INFO - Epoch [394/2000], Train Loss: 38.0150
2024-03-28 18:07:35,793 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:36,256 - config - INFO - Epoch [395/2000], Train Loss: 38.0150
2024-03-28 18:07:36,292 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:36,746 - config - INFO - Epoch [396/2000], Train Loss: 38.0150
2024-03-28 18:07:36,782 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:37,234 - config - INFO - Epoch [397/2000], Train Loss: 38.0150
2024-03-28 18:07:37,271 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:37,754 - config - INFO - Epoch [398/2000], Train Loss: 38.0150
2024-03-28 18:07:37,791 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:38,259 - config - INFO - Epoch [399/2000], Train Loss: 38.0150
2024-03-28 18:07:38,296 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:38,709 - config - INFO - Epoch [400/2000], Train Loss: 38.0150
2024-03-28 18:07:38,745 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:39,156 - config - INFO - Epoch [401/2000], Train Loss: 38.0150
2024-03-28 18:07:39,192 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:39,609 - config - INFO - Epoch [402/2000], Train Loss: 38.0150
2024-03-28 18:07:39,646 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:40,115 - config - INFO - Epoch [403/2000], Train Loss: 38.0150
2024-03-28 18:07:40,151 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:40,589 - config - INFO - Epoch [404/2000], Train Loss: 38.0150
2024-03-28 18:07:40,626 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:41,080 - config - INFO - Epoch [405/2000], Train Loss: 38.0150
2024-03-28 18:07:41,117 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:41,570 - config - INFO - Epoch [406/2000], Train Loss: 38.0150
2024-03-28 18:07:41,607 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:42,036 - config - INFO - Epoch [407/2000], Train Loss: 38.0150
2024-03-28 18:07:42,085 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:42,552 - config - INFO - Epoch [408/2000], Train Loss: 38.0150
2024-03-28 18:07:42,590 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:43,049 - config - INFO - Epoch [409/2000], Train Loss: 38.0150
2024-03-28 18:07:43,086 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:43,550 - config - INFO - Epoch [410/2000], Train Loss: 38.0150
2024-03-28 18:07:43,590 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:44,078 - config - INFO - Epoch [411/2000], Train Loss: 38.0150
2024-03-28 18:07:44,117 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:44,540 - config - INFO - Epoch [412/2000], Train Loss: 38.0150
2024-03-28 18:07:44,579 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:45,082 - config - INFO - Epoch [413/2000], Train Loss: 38.0150
2024-03-28 18:07:45,120 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:45,612 - config - INFO - Epoch [414/2000], Train Loss: 38.0150
2024-03-28 18:07:45,650 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:46,123 - config - INFO - Epoch [415/2000], Train Loss: 38.0150
2024-03-28 18:07:46,162 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:46,624 - config - INFO - Epoch [416/2000], Train Loss: 38.0150
2024-03-28 18:07:46,675 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:47,143 - config - INFO - Epoch [417/2000], Train Loss: 38.0150
2024-03-28 18:07:47,181 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:47,683 - config - INFO - Epoch [418/2000], Train Loss: 38.0150
2024-03-28 18:07:47,721 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:48,166 - config - INFO - Epoch [419/2000], Train Loss: 38.0150
2024-03-28 18:07:48,206 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:48,628 - config - INFO - Epoch [420/2000], Train Loss: 38.0150
2024-03-28 18:07:48,671 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:49,059 - config - INFO - Epoch [421/2000], Train Loss: 38.0150
2024-03-28 18:07:49,098 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:49,570 - config - INFO - Epoch [422/2000], Train Loss: 38.0150
2024-03-28 18:07:49,614 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:50,015 - config - INFO - Epoch [423/2000], Train Loss: 38.0150
2024-03-28 18:07:50,055 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:50,464 - config - INFO - Epoch [424/2000], Train Loss: 38.0150
2024-03-28 18:07:50,507 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:50,888 - config - INFO - Epoch [425/2000], Train Loss: 38.0150
2024-03-28 18:07:50,927 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:51,378 - config - INFO - Epoch [426/2000], Train Loss: 38.0150
2024-03-28 18:07:51,421 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:51,833 - config - INFO - Epoch [427/2000], Train Loss: 38.0150
2024-03-28 18:07:51,886 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:52,298 - config - INFO - Epoch [428/2000], Train Loss: 38.0150
2024-03-28 18:07:52,340 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:52,794 - config - INFO - Epoch [429/2000], Train Loss: 38.0150
2024-03-28 18:07:52,832 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:53,259 - config - INFO - Epoch [430/2000], Train Loss: 38.0150
2024-03-28 18:07:53,297 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:53,741 - config - INFO - Epoch [431/2000], Train Loss: 38.0150
2024-03-28 18:07:53,784 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:54,271 - config - INFO - Epoch [432/2000], Train Loss: 38.0150
2024-03-28 18:07:54,308 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:54,793 - config - INFO - Epoch [433/2000], Train Loss: 38.0150
2024-03-28 18:07:54,830 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:55,314 - config - INFO - Epoch [434/2000], Train Loss: 38.0150
2024-03-28 18:07:55,352 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:55,846 - config - INFO - Epoch [435/2000], Train Loss: 38.0150
2024-03-28 18:07:55,885 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:56,327 - config - INFO - Epoch [436/2000], Train Loss: 38.0150
2024-03-28 18:07:56,364 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:56,816 - config - INFO - Epoch [437/2000], Train Loss: 38.0150
2024-03-28 18:07:56,854 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:57,294 - config - INFO - Epoch [438/2000], Train Loss: 38.0150
2024-03-28 18:07:57,333 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:57,790 - config - INFO - Epoch [439/2000], Train Loss: 38.0150
2024-03-28 18:07:57,828 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:58,270 - config - INFO - Epoch [440/2000], Train Loss: 38.0150
2024-03-28 18:07:58,308 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:58,783 - config - INFO - Epoch [441/2000], Train Loss: 38.0150
2024-03-28 18:07:58,821 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:59,263 - config - INFO - Epoch [442/2000], Train Loss: 38.0150
2024-03-28 18:07:59,300 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:07:59,746 - config - INFO - Epoch [443/2000], Train Loss: 38.0150
2024-03-28 18:07:59,790 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:00,270 - config - INFO - Epoch [444/2000], Train Loss: 38.0150
2024-03-28 18:08:00,309 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:00,807 - config - INFO - Epoch [445/2000], Train Loss: 38.0150
2024-03-28 18:08:00,845 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:01,299 - config - INFO - Epoch [446/2000], Train Loss: 38.0150
2024-03-28 18:08:01,337 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:01,816 - config - INFO - Epoch [447/2000], Train Loss: 38.0150
2024-03-28 18:08:01,854 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:02,322 - config - INFO - Epoch [448/2000], Train Loss: 38.0150
2024-03-28 18:08:02,359 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:02,803 - config - INFO - Epoch [449/2000], Train Loss: 38.0150
2024-03-28 18:08:02,851 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:03,323 - config - INFO - Epoch [450/2000], Train Loss: 38.0150
2024-03-28 18:08:03,361 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:03,844 - config - INFO - Epoch [451/2000], Train Loss: 38.0150
2024-03-28 18:08:03,881 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:04,345 - config - INFO - Epoch [452/2000], Train Loss: 38.0150
2024-03-28 18:08:04,390 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:04,832 - config - INFO - Epoch [453/2000], Train Loss: 38.0150
2024-03-28 18:08:04,870 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:05,351 - config - INFO - Epoch [454/2000], Train Loss: 38.0150
2024-03-28 18:08:05,390 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:05,876 - config - INFO - Epoch [455/2000], Train Loss: 38.0150
2024-03-28 18:08:05,914 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:06,344 - config - INFO - Epoch [456/2000], Train Loss: 38.0150
2024-03-28 18:08:06,382 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:06,870 - config - INFO - Epoch [457/2000], Train Loss: 38.0150
2024-03-28 18:08:06,908 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:07,372 - config - INFO - Epoch [458/2000], Train Loss: 38.0150
2024-03-28 18:08:07,410 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:07,860 - config - INFO - Epoch [459/2000], Train Loss: 38.0150
2024-03-28 18:08:07,897 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:08,363 - config - INFO - Epoch [460/2000], Train Loss: 38.0150
2024-03-28 18:08:08,401 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:08,830 - config - INFO - Epoch [461/2000], Train Loss: 38.0150
2024-03-28 18:08:08,867 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:09,328 - config - INFO - Epoch [462/2000], Train Loss: 38.0150
2024-03-28 18:08:09,367 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:09,833 - config - INFO - Epoch [463/2000], Train Loss: 38.0150
2024-03-28 18:08:09,870 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:10,338 - config - INFO - Epoch [464/2000], Train Loss: 38.0150
2024-03-28 18:08:10,377 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:10,858 - config - INFO - Epoch [465/2000], Train Loss: 38.0150
2024-03-28 18:08:10,896 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:11,395 - config - INFO - Epoch [466/2000], Train Loss: 38.0150
2024-03-28 18:08:11,434 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:11,937 - config - INFO - Epoch [467/2000], Train Loss: 38.0150
2024-03-28 18:08:11,976 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:12,447 - config - INFO - Epoch [468/2000], Train Loss: 38.0150
2024-03-28 18:08:12,486 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:12,978 - config - INFO - Epoch [469/2000], Train Loss: 38.0150
2024-03-28 18:08:13,015 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:13,493 - config - INFO - Epoch [470/2000], Train Loss: 38.0150
2024-03-28 18:08:13,530 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:14,000 - config - INFO - Epoch [471/2000], Train Loss: 38.0150
2024-03-28 18:08:14,038 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:14,532 - config - INFO - Epoch [472/2000], Train Loss: 38.0150
2024-03-28 18:08:14,569 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:15,063 - config - INFO - Epoch [473/2000], Train Loss: 38.0150
2024-03-28 18:08:15,101 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:15,585 - config - INFO - Epoch [474/2000], Train Loss: 38.0150
2024-03-28 18:08:15,623 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:16,105 - config - INFO - Epoch [475/2000], Train Loss: 38.0150
2024-03-28 18:08:16,144 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:16,644 - config - INFO - Epoch [476/2000], Train Loss: 38.0150
2024-03-28 18:08:16,690 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:17,167 - config - INFO - Epoch [477/2000], Train Loss: 38.0150
2024-03-28 18:08:17,205 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:17,670 - config - INFO - Epoch [478/2000], Train Loss: 38.0150
2024-03-28 18:08:17,708 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:18,200 - config - INFO - Epoch [479/2000], Train Loss: 38.0150
2024-03-28 18:08:18,237 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:18,722 - config - INFO - Epoch [480/2000], Train Loss: 38.0150
2024-03-28 18:08:18,760 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:19,263 - config - INFO - Epoch [481/2000], Train Loss: 38.0150
2024-03-28 18:08:19,300 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:19,777 - config - INFO - Epoch [482/2000], Train Loss: 38.0150
2024-03-28 18:08:19,815 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:20,287 - config - INFO - Epoch [483/2000], Train Loss: 38.0150
2024-03-28 18:08:20,329 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:20,803 - config - INFO - Epoch [484/2000], Train Loss: 38.0150
2024-03-28 18:08:20,840 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:21,325 - config - INFO - Epoch [485/2000], Train Loss: 38.0150
2024-03-28 18:08:21,362 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:21,787 - config - INFO - Epoch [486/2000], Train Loss: 38.0150
2024-03-28 18:08:21,836 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:22,235 - config - INFO - Epoch [487/2000], Train Loss: 38.0150
2024-03-28 18:08:22,276 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:22,678 - config - INFO - Epoch [488/2000], Train Loss: 38.0150
2024-03-28 18:08:22,719 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:23,074 - config - INFO - Epoch [489/2000], Train Loss: 38.0150
2024-03-28 18:08:23,110 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:23,467 - config - INFO - Epoch [490/2000], Train Loss: 38.0150
2024-03-28 18:08:23,506 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:23,913 - config - INFO - Epoch [491/2000], Train Loss: 38.0150
2024-03-28 18:08:23,954 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:24,362 - config - INFO - Epoch [492/2000], Train Loss: 38.0150
2024-03-28 18:08:24,410 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:24,752 - config - INFO - Epoch [493/2000], Train Loss: 38.0150
2024-03-28 18:08:24,786 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:25,152 - config - INFO - Epoch [494/2000], Train Loss: 38.0150
2024-03-28 18:08:25,189 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:25,611 - config - INFO - Epoch [495/2000], Train Loss: 38.0150
2024-03-28 18:08:25,652 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:26,076 - config - INFO - Epoch [496/2000], Train Loss: 38.0150
2024-03-28 18:08:26,116 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:26,501 - config - INFO - Epoch [497/2000], Train Loss: 38.0150
2024-03-28 18:08:26,536 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:26,942 - config - INFO - Epoch [498/2000], Train Loss: 38.0150
2024-03-28 18:08:26,984 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:27,359 - config - INFO - Epoch [499/2000], Train Loss: 38.0150
2024-03-28 18:08:27,400 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:27,817 - config - INFO - Epoch [500/2000], Train Loss: 38.0150
2024-03-28 18:08:27,857 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:28,264 - config - INFO - Epoch [501/2000], Train Loss: 38.0150
2024-03-28 18:08:28,305 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:28,675 - config - INFO - Epoch [502/2000], Train Loss: 38.0150
2024-03-28 18:08:28,716 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:29,106 - config - INFO - Epoch [503/2000], Train Loss: 38.0150
2024-03-28 18:08:29,149 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:29,540 - config - INFO - Epoch [504/2000], Train Loss: 38.0150
2024-03-28 18:08:29,579 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:29,993 - config - INFO - Epoch [505/2000], Train Loss: 38.0150
2024-03-28 18:08:30,030 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:30,458 - config - INFO - Epoch [506/2000], Train Loss: 38.0150
2024-03-28 18:08:30,501 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:30,930 - config - INFO - Epoch [507/2000], Train Loss: 38.0150
2024-03-28 18:08:30,975 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:31,416 - config - INFO - Epoch [508/2000], Train Loss: 38.0150
2024-03-28 18:08:31,459 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:31,838 - config - INFO - Epoch [509/2000], Train Loss: 38.0150
2024-03-28 18:08:31,882 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:32,297 - config - INFO - Epoch [510/2000], Train Loss: 38.0150
2024-03-28 18:08:32,333 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:32,755 - config - INFO - Epoch [511/2000], Train Loss: 38.0150
2024-03-28 18:08:32,803 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:33,272 - config - INFO - Epoch [512/2000], Train Loss: 38.0150
2024-03-28 18:08:33,309 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:33,770 - config - INFO - Epoch [513/2000], Train Loss: 38.0150
2024-03-28 18:08:33,808 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:34,208 - config - INFO - Epoch [514/2000], Train Loss: 38.0150
2024-03-28 18:08:34,247 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:34,696 - config - INFO - Epoch [515/2000], Train Loss: 38.0150
2024-03-28 18:08:34,734 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:35,175 - config - INFO - Epoch [516/2000], Train Loss: 38.0150
2024-03-28 18:08:35,212 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:35,706 - config - INFO - Epoch [517/2000], Train Loss: 38.0150
2024-03-28 18:08:35,745 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:36,218 - config - INFO - Epoch [518/2000], Train Loss: 38.0150
2024-03-28 18:08:36,254 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:36,711 - config - INFO - Epoch [519/2000], Train Loss: 38.0150
2024-03-28 18:08:36,749 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:37,246 - config - INFO - Epoch [520/2000], Train Loss: 38.0150
2024-03-28 18:08:37,283 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:37,743 - config - INFO - Epoch [521/2000], Train Loss: 38.0150
2024-03-28 18:08:37,780 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:38,257 - config - INFO - Epoch [522/2000], Train Loss: 38.0150
2024-03-28 18:08:38,295 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:38,746 - config - INFO - Epoch [523/2000], Train Loss: 38.0150
2024-03-28 18:08:38,782 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:39,221 - config - INFO - Epoch [524/2000], Train Loss: 38.0150
2024-03-28 18:08:39,259 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:39,716 - config - INFO - Epoch [525/2000], Train Loss: 38.0150
2024-03-28 18:08:39,754 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:40,213 - config - INFO - Epoch [526/2000], Train Loss: 38.0150
2024-03-28 18:08:40,259 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:40,721 - config - INFO - Epoch [527/2000], Train Loss: 38.0150
2024-03-28 18:08:40,759 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:41,254 - config - INFO - Epoch [528/2000], Train Loss: 38.0150
2024-03-28 18:08:41,291 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:41,726 - config - INFO - Epoch [529/2000], Train Loss: 38.0150
2024-03-28 18:08:41,765 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:42,220 - config - INFO - Epoch [530/2000], Train Loss: 38.0150
2024-03-28 18:08:42,257 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:42,685 - config - INFO - Epoch [531/2000], Train Loss: 38.0150
2024-03-28 18:08:42,726 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:43,205 - config - INFO - Epoch [532/2000], Train Loss: 38.0150
2024-03-28 18:08:43,243 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:43,739 - config - INFO - Epoch [533/2000], Train Loss: 38.0150
2024-03-28 18:08:43,777 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:44,232 - config - INFO - Epoch [534/2000], Train Loss: 38.0150
2024-03-28 18:08:44,269 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:44,734 - config - INFO - Epoch [535/2000], Train Loss: 38.0150
2024-03-28 18:08:44,771 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:45,257 - config - INFO - Epoch [536/2000], Train Loss: 38.0150
2024-03-28 18:08:45,295 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:45,749 - config - INFO - Epoch [537/2000], Train Loss: 38.0150
2024-03-28 18:08:45,786 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:46,273 - config - INFO - Epoch [538/2000], Train Loss: 38.0150
2024-03-28 18:08:46,311 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:46,815 - config - INFO - Epoch [539/2000], Train Loss: 38.0150
2024-03-28 18:08:46,854 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:47,374 - config - INFO - Epoch [540/2000], Train Loss: 38.0150
2024-03-28 18:08:47,421 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:47,890 - config - INFO - Epoch [541/2000], Train Loss: 38.0150
2024-03-28 18:08:47,926 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:48,403 - config - INFO - Epoch [542/2000], Train Loss: 38.0150
2024-03-28 18:08:48,442 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:48,912 - config - INFO - Epoch [543/2000], Train Loss: 38.0150
2024-03-28 18:08:48,949 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:49,411 - config - INFO - Epoch [544/2000], Train Loss: 38.0150
2024-03-28 18:08:49,450 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:49,961 - config - INFO - Epoch [545/2000], Train Loss: 38.0150
2024-03-28 18:08:50,003 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:50,533 - config - INFO - Epoch [546/2000], Train Loss: 38.0150
2024-03-28 18:08:50,575 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:51,073 - config - INFO - Epoch [547/2000], Train Loss: 38.0150
2024-03-28 18:08:51,114 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:51,579 - config - INFO - Epoch [548/2000], Train Loss: 38.0150
2024-03-28 18:08:51,617 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:52,095 - config - INFO - Epoch [549/2000], Train Loss: 38.0150
2024-03-28 18:08:52,134 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:52,572 - config - INFO - Epoch [550/2000], Train Loss: 38.0150
2024-03-28 18:08:52,617 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:53,111 - config - INFO - Epoch [551/2000], Train Loss: 38.0150
2024-03-28 18:08:53,149 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:53,624 - config - INFO - Epoch [552/2000], Train Loss: 38.0150
2024-03-28 18:08:53,662 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:54,143 - config - INFO - Epoch [553/2000], Train Loss: 38.0150
2024-03-28 18:08:54,180 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:54,653 - config - INFO - Epoch [554/2000], Train Loss: 38.0150
2024-03-28 18:08:54,690 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:55,181 - config - INFO - Epoch [555/2000], Train Loss: 38.0150
2024-03-28 18:08:55,218 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:55,678 - config - INFO - Epoch [556/2000], Train Loss: 38.0150
2024-03-28 18:08:55,716 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:56,131 - config - INFO - Epoch [557/2000], Train Loss: 38.0150
2024-03-28 18:08:56,169 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:56,635 - config - INFO - Epoch [558/2000], Train Loss: 38.0150
2024-03-28 18:08:56,672 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:57,129 - config - INFO - Epoch [559/2000], Train Loss: 38.0150
2024-03-28 18:08:57,167 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:57,648 - config - INFO - Epoch [560/2000], Train Loss: 38.0150
2024-03-28 18:08:57,685 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:58,143 - config - INFO - Epoch [561/2000], Train Loss: 38.0150
2024-03-28 18:08:58,181 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:58,623 - config - INFO - Epoch [562/2000], Train Loss: 38.0150
2024-03-28 18:08:58,661 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:59,161 - config - INFO - Epoch [563/2000], Train Loss: 38.0150
2024-03-28 18:08:59,198 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:08:59,678 - config - INFO - Epoch [564/2000], Train Loss: 38.0150
2024-03-28 18:08:59,715 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:00,196 - config - INFO - Epoch [565/2000], Train Loss: 38.0150
2024-03-28 18:09:00,234 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:00,789 - config - INFO - Epoch [566/2000], Train Loss: 38.0150
2024-03-28 18:09:00,828 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:01,306 - config - INFO - Epoch [567/2000], Train Loss: 38.0150
2024-03-28 18:09:01,343 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:01,804 - config - INFO - Epoch [568/2000], Train Loss: 38.0150
2024-03-28 18:09:01,843 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:02,296 - config - INFO - Epoch [569/2000], Train Loss: 38.0150
2024-03-28 18:09:02,334 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:02,772 - config - INFO - Epoch [570/2000], Train Loss: 38.0150
2024-03-28 18:09:02,811 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:03,293 - config - INFO - Epoch [571/2000], Train Loss: 38.0150
2024-03-28 18:09:03,330 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:03,853 - config - INFO - Epoch [572/2000], Train Loss: 38.0150
2024-03-28 18:09:03,893 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:04,376 - config - INFO - Epoch [573/2000], Train Loss: 38.0150
2024-03-28 18:09:04,415 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:04,960 - config - INFO - Epoch [574/2000], Train Loss: 38.0150
2024-03-28 18:09:05,000 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:05,470 - config - INFO - Epoch [575/2000], Train Loss: 38.0150
2024-03-28 18:09:05,509 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:06,009 - config - INFO - Epoch [576/2000], Train Loss: 38.0150
2024-03-28 18:09:06,047 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:06,512 - config - INFO - Epoch [577/2000], Train Loss: 38.0150
2024-03-28 18:09:06,550 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:07,021 - config - INFO - Epoch [578/2000], Train Loss: 38.0150
2024-03-28 18:09:07,066 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:07,563 - config - INFO - Epoch [579/2000], Train Loss: 38.0150
2024-03-28 18:09:07,600 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:08,101 - config - INFO - Epoch [580/2000], Train Loss: 38.0150
2024-03-28 18:09:08,140 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:08,600 - config - INFO - Epoch [581/2000], Train Loss: 38.0150
2024-03-28 18:09:08,638 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:09,100 - config - INFO - Epoch [582/2000], Train Loss: 38.0150
2024-03-28 18:09:09,138 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:09,602 - config - INFO - Epoch [583/2000], Train Loss: 38.0150
2024-03-28 18:09:09,639 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:10,084 - config - INFO - Epoch [584/2000], Train Loss: 38.0150
2024-03-28 18:09:10,122 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:10,585 - config - INFO - Epoch [585/2000], Train Loss: 38.0150
2024-03-28 18:09:10,623 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:11,134 - config - INFO - Epoch [586/2000], Train Loss: 38.0150
2024-03-28 18:09:11,172 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:11,692 - config - INFO - Epoch [587/2000], Train Loss: 38.0150
2024-03-28 18:09:11,730 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:12,188 - config - INFO - Epoch [588/2000], Train Loss: 38.0150
2024-03-28 18:09:12,226 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:12,658 - config - INFO - Epoch [589/2000], Train Loss: 38.0150
2024-03-28 18:09:12,702 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:13,197 - config - INFO - Epoch [590/2000], Train Loss: 38.0150
2024-03-28 18:09:13,233 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:13,712 - config - INFO - Epoch [591/2000], Train Loss: 38.0150
2024-03-28 18:09:13,750 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:14,216 - config - INFO - Epoch [592/2000], Train Loss: 38.0150
2024-03-28 18:09:14,254 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:14,672 - config - INFO - Epoch [593/2000], Train Loss: 38.0150
2024-03-28 18:09:14,709 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:15,172 - config - INFO - Epoch [594/2000], Train Loss: 38.0150
2024-03-28 18:09:15,209 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:15,615 - config - INFO - Epoch [595/2000], Train Loss: 38.0150
2024-03-28 18:09:15,666 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:16,044 - config - INFO - Epoch [596/2000], Train Loss: 38.0150
2024-03-28 18:09:16,079 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:16,494 - config - INFO - Epoch [597/2000], Train Loss: 38.0150
2024-03-28 18:09:16,535 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:16,938 - config - INFO - Epoch [598/2000], Train Loss: 38.0150
2024-03-28 18:09:16,979 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:17,352 - config - INFO - Epoch [599/2000], Train Loss: 38.0150
2024-03-28 18:09:17,388 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:17,761 - config - INFO - Epoch [600/2000], Train Loss: 38.0150
2024-03-28 18:09:17,802 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:18,170 - config - INFO - Epoch [601/2000], Train Loss: 38.0150
2024-03-28 18:09:18,205 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:18,621 - config - INFO - Epoch [602/2000], Train Loss: 38.0150
2024-03-28 18:09:18,661 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:19,080 - config - INFO - Epoch [603/2000], Train Loss: 38.0150
2024-03-28 18:09:19,116 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:19,534 - config - INFO - Epoch [604/2000], Train Loss: 38.0150
2024-03-28 18:09:19,570 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:19,979 - config - INFO - Epoch [605/2000], Train Loss: 38.0150
2024-03-28 18:09:20,017 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:20,445 - config - INFO - Epoch [606/2000], Train Loss: 38.0150
2024-03-28 18:09:20,486 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:20,890 - config - INFO - Epoch [607/2000], Train Loss: 38.0150
2024-03-28 18:09:20,931 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:21,349 - config - INFO - Epoch [608/2000], Train Loss: 38.0150
2024-03-28 18:09:21,390 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:21,804 - config - INFO - Epoch [609/2000], Train Loss: 38.0150
2024-03-28 18:09:21,841 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:22,270 - config - INFO - Epoch [610/2000], Train Loss: 38.0150
2024-03-28 18:09:22,310 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:22,724 - config - INFO - Epoch [611/2000], Train Loss: 38.0150
2024-03-28 18:09:22,760 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:23,216 - config - INFO - Epoch [612/2000], Train Loss: 38.0150
2024-03-28 18:09:23,252 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:23,638 - config - INFO - Epoch [613/2000], Train Loss: 38.0150
2024-03-28 18:09:23,688 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:24,083 - config - INFO - Epoch [614/2000], Train Loss: 38.0150
2024-03-28 18:09:24,131 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:24,514 - config - INFO - Epoch [615/2000], Train Loss: 38.0150
2024-03-28 18:09:24,549 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:24,962 - config - INFO - Epoch [616/2000], Train Loss: 38.0150
2024-03-28 18:09:25,002 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:25,424 - config - INFO - Epoch [617/2000], Train Loss: 38.0150
2024-03-28 18:09:25,460 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:25,852 - config - INFO - Epoch [618/2000], Train Loss: 38.0150
2024-03-28 18:09:25,892 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:26,268 - config - INFO - Epoch [619/2000], Train Loss: 38.0150
2024-03-28 18:09:26,315 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:26,720 - config - INFO - Epoch [620/2000], Train Loss: 38.0150
2024-03-28 18:09:26,761 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:27,174 - config - INFO - Epoch [621/2000], Train Loss: 38.0150
2024-03-28 18:09:27,211 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:27,655 - config - INFO - Epoch [622/2000], Train Loss: 38.0150
2024-03-28 18:09:27,695 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:28,108 - config - INFO - Epoch [623/2000], Train Loss: 38.0150
2024-03-28 18:09:28,145 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:28,521 - config - INFO - Epoch [624/2000], Train Loss: 38.0150
2024-03-28 18:09:28,561 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:28,934 - config - INFO - Epoch [625/2000], Train Loss: 38.0150
2024-03-28 18:09:28,969 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:29,382 - config - INFO - Epoch [626/2000], Train Loss: 38.0150
2024-03-28 18:09:29,427 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:29,827 - config - INFO - Epoch [627/2000], Train Loss: 38.0150
2024-03-28 18:09:29,863 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:30,349 - config - INFO - Epoch [628/2000], Train Loss: 38.0150
2024-03-28 18:09:30,386 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:30,842 - config - INFO - Epoch [629/2000], Train Loss: 38.0150
2024-03-28 18:09:30,879 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:31,315 - config - INFO - Epoch [630/2000], Train Loss: 38.0150
2024-03-28 18:09:31,351 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:31,824 - config - INFO - Epoch [631/2000], Train Loss: 38.0150
2024-03-28 18:09:31,860 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:32,277 - config - INFO - Epoch [632/2000], Train Loss: 38.0150
2024-03-28 18:09:32,315 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:32,772 - config - INFO - Epoch [633/2000], Train Loss: 38.0150
2024-03-28 18:09:32,810 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:33,271 - config - INFO - Epoch [634/2000], Train Loss: 38.0150
2024-03-28 18:09:33,308 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:33,777 - config - INFO - Epoch [635/2000], Train Loss: 38.0150
2024-03-28 18:09:33,815 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:34,237 - config - INFO - Epoch [636/2000], Train Loss: 38.0150
2024-03-28 18:09:34,274 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:34,711 - config - INFO - Epoch [637/2000], Train Loss: 38.0150
2024-03-28 18:09:34,759 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:35,266 - config - INFO - Epoch [638/2000], Train Loss: 38.0150
2024-03-28 18:09:35,303 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:35,754 - config - INFO - Epoch [639/2000], Train Loss: 38.0150
2024-03-28 18:09:35,791 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:36,218 - config - INFO - Epoch [640/2000], Train Loss: 38.0150
2024-03-28 18:09:36,256 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:36,705 - config - INFO - Epoch [641/2000], Train Loss: 38.0150
2024-03-28 18:09:36,741 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:37,182 - config - INFO - Epoch [642/2000], Train Loss: 38.0150
2024-03-28 18:09:37,220 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:37,656 - config - INFO - Epoch [643/2000], Train Loss: 38.0150
2024-03-28 18:09:37,693 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:38,139 - config - INFO - Epoch [644/2000], Train Loss: 38.0150
2024-03-28 18:09:38,176 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:38,668 - config - INFO - Epoch [645/2000], Train Loss: 38.0150
2024-03-28 18:09:38,707 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:39,137 - config - INFO - Epoch [646/2000], Train Loss: 38.0150
2024-03-28 18:09:39,178 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:39,641 - config - INFO - Epoch [647/2000], Train Loss: 38.0150
2024-03-28 18:09:39,679 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:40,168 - config - INFO - Epoch [648/2000], Train Loss: 38.0150
2024-03-28 18:09:40,204 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:40,633 - config - INFO - Epoch [649/2000], Train Loss: 38.0150
2024-03-28 18:09:40,670 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:41,129 - config - INFO - Epoch [650/2000], Train Loss: 38.0150
2024-03-28 18:09:41,178 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:41,619 - config - INFO - Epoch [651/2000], Train Loss: 38.0150
2024-03-28 18:09:41,655 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:42,127 - config - INFO - Epoch [652/2000], Train Loss: 38.0150
2024-03-28 18:09:42,167 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:42,614 - config - INFO - Epoch [653/2000], Train Loss: 38.0150
2024-03-28 18:09:42,651 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:43,100 - config - INFO - Epoch [654/2000], Train Loss: 38.0150
2024-03-28 18:09:43,137 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:43,598 - config - INFO - Epoch [655/2000], Train Loss: 38.0150
2024-03-28 18:09:43,635 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:44,123 - config - INFO - Epoch [656/2000], Train Loss: 38.0150
2024-03-28 18:09:44,159 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:44,566 - config - INFO - Epoch [657/2000], Train Loss: 38.0150
2024-03-28 18:09:44,602 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:45,066 - config - INFO - Epoch [658/2000], Train Loss: 38.0150
2024-03-28 18:09:45,102 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:45,546 - config - INFO - Epoch [659/2000], Train Loss: 38.0150
2024-03-28 18:09:45,582 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:46,018 - config - INFO - Epoch [660/2000], Train Loss: 38.0150
2024-03-28 18:09:46,054 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:46,464 - config - INFO - Epoch [661/2000], Train Loss: 38.0150
2024-03-28 18:09:46,501 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:09:46,988 - config - INFO - Epoch [662/2000], Train Loss: 38.0150
2024-03-28 18:09:47,025 - config - INFO - Validation Loss: 36.5169
2024-03-28 18:12:09,155 - config - INFO - resume: None
2024-03-28 18:12:09,155 - config - INFO - device: cpu
2024-03-28 18:12:09,156 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-28 18:12:09,156 - config - INFO - learning_rate: 0.001
2024-03-28 18:12:09,156 - config - INFO - num_epochs: 2000
2024-03-28 18:12:09,156 - config - INFO - batch_size: 64
2024-03-28 18:12:09,156 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = None
        self.prev_val_loss = float('inf')
        self.tolerance = 0.03

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 18:12:09,169 - config - INFO - Dataset size: 891
2024-03-28 18:12:09,195 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.6 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()

    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 18:12:09,195 - config - INFO - Training start
2024-03-28 18:12:11,427 - config - INFO - Epoch [1/2000], Train Loss: 0.6626
2024-03-28 18:12:11,434 - config - INFO - Validation Loss: 0.6914
2024-03-28 18:12:11,434 - config - INFO - Validation Acc: 0.5600
2024-03-28 18:12:11,455 - config - INFO - Epoch [2/2000], Train Loss: 0.6477
2024-03-28 18:12:11,459 - config - INFO - Validation Loss: 0.6812
2024-03-28 18:12:11,459 - config - INFO - Validation Acc: 0.5600
2024-03-28 18:12:11,479 - config - INFO - Epoch [3/2000], Train Loss: 0.6337
2024-03-28 18:12:11,483 - config - INFO - Validation Loss: 0.6605
2024-03-28 18:12:11,483 - config - INFO - Validation Acc: 0.5600
2024-03-28 18:12:11,502 - config - INFO - Epoch [4/2000], Train Loss: 0.6216
2024-03-28 18:12:11,506 - config - INFO - Validation Loss: 0.6471
2024-03-28 18:12:11,507 - config - INFO - Validation Acc: 0.5600
2024-03-28 18:12:11,526 - config - INFO - Epoch [5/2000], Train Loss: 0.6110
2024-03-28 18:12:11,530 - config - INFO - Validation Loss: 0.6450
2024-03-28 18:12:11,530 - config - INFO - Validation Acc: 0.5600
2024-03-28 18:12:11,549 - config - INFO - Epoch [6/2000], Train Loss: 0.5987
2024-03-28 18:12:11,554 - config - INFO - Validation Loss: 0.6290
2024-03-28 18:12:11,554 - config - INFO - Validation Acc: 0.6400
2024-03-28 18:12:11,573 - config - INFO - Epoch [7/2000], Train Loss: 0.5874
2024-03-28 18:12:11,577 - config - INFO - Validation Loss: 0.6190
2024-03-28 18:12:11,578 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:12:11,597 - config - INFO - Epoch [8/2000], Train Loss: 0.5766
2024-03-28 18:12:11,601 - config - INFO - Validation Loss: 0.6152
2024-03-28 18:12:11,601 - config - INFO - Validation Acc: 0.6200
2024-03-28 18:12:11,620 - config - INFO - Epoch [9/2000], Train Loss: 0.5677
2024-03-28 18:12:11,625 - config - INFO - Validation Loss: 0.6051
2024-03-28 18:12:11,625 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:12:11,644 - config - INFO - Epoch [10/2000], Train Loss: 0.5578
2024-03-28 18:12:11,648 - config - INFO - Validation Loss: 0.5912
2024-03-28 18:12:11,648 - config - INFO - Validation Acc: 0.7000
2024-03-28 18:12:11,667 - config - INFO - Epoch [11/2000], Train Loss: 0.5480
2024-03-28 18:12:11,671 - config - INFO - Validation Loss: 0.5821
2024-03-28 18:12:11,672 - config - INFO - Validation Acc: 0.7400
2024-03-28 18:12:11,690 - config - INFO - Epoch [12/2000], Train Loss: 0.5384
2024-03-28 18:12:11,695 - config - INFO - Validation Loss: 0.5749
2024-03-28 18:12:11,695 - config - INFO - Validation Acc: 0.7600
2024-03-28 18:12:11,714 - config - INFO - Epoch [13/2000], Train Loss: 0.5298
2024-03-28 18:12:11,718 - config - INFO - Validation Loss: 0.5667
2024-03-28 18:12:11,718 - config - INFO - Validation Acc: 0.7600
2024-03-28 18:12:11,738 - config - INFO - Epoch [14/2000], Train Loss: 0.5212
2024-03-28 18:12:11,742 - config - INFO - Validation Loss: 0.5562
2024-03-28 18:12:11,742 - config - INFO - Validation Acc: 0.7800
2024-03-28 18:12:11,761 - config - INFO - Epoch [15/2000], Train Loss: 0.5134
2024-03-28 18:12:11,765 - config - INFO - Validation Loss: 0.5491
2024-03-28 18:12:11,765 - config - INFO - Validation Acc: 0.7800
2024-03-28 18:12:11,784 - config - INFO - Epoch [16/2000], Train Loss: 0.5056
2024-03-28 18:12:11,788 - config - INFO - Validation Loss: 0.5416
2024-03-28 18:12:11,789 - config - INFO - Validation Acc: 0.7800
2024-03-28 18:12:11,808 - config - INFO - Epoch [17/2000], Train Loss: 0.4985
2024-03-28 18:12:11,812 - config - INFO - Validation Loss: 0.5369
2024-03-28 18:12:11,812 - config - INFO - Validation Acc: 0.7800
2024-03-28 18:12:11,831 - config - INFO - Epoch [18/2000], Train Loss: 0.4921
2024-03-28 18:12:11,835 - config - INFO - Validation Loss: 0.5293
2024-03-28 18:12:11,836 - config - INFO - Validation Acc: 0.7800
2024-03-28 18:12:11,855 - config - INFO - Epoch [19/2000], Train Loss: 0.4863
2024-03-28 18:12:11,859 - config - INFO - Validation Loss: 0.5253
2024-03-28 18:12:11,859 - config - INFO - Validation Acc: 0.7800
2024-03-28 18:12:11,878 - config - INFO - Epoch [20/2000], Train Loss: 0.4807
2024-03-28 18:12:11,882 - config - INFO - Validation Loss: 0.5207
2024-03-28 18:12:11,882 - config - INFO - Validation Acc: 0.7800
2024-03-28 18:12:11,914 - config - INFO - Epoch [21/2000], Train Loss: 0.4757
2024-03-28 18:12:11,919 - config - INFO - Validation Loss: 0.5136
2024-03-28 18:12:11,919 - config - INFO - Validation Acc: 0.7800
2024-03-28 18:12:11,938 - config - INFO - Epoch [22/2000], Train Loss: 0.4712
2024-03-28 18:12:11,942 - config - INFO - Validation Loss: 0.5100
2024-03-28 18:12:11,942 - config - INFO - Validation Acc: 0.7800
2024-03-28 18:12:11,961 - config - INFO - Epoch [23/2000], Train Loss: 0.4672
2024-03-28 18:12:11,965 - config - INFO - Validation Loss: 0.5073
2024-03-28 18:12:11,966 - config - INFO - Validation Acc: 0.7800
2024-03-28 18:12:11,985 - config - INFO - Epoch [24/2000], Train Loss: 0.4636
2024-03-28 18:12:11,989 - config - INFO - Validation Loss: 0.5046
2024-03-28 18:12:11,989 - config - INFO - Validation Acc: 0.7800
2024-03-28 18:12:12,008 - config - INFO - Epoch [25/2000], Train Loss: 0.4599
2024-03-28 18:12:12,012 - config - INFO - Validation Loss: 0.4998
2024-03-28 18:12:12,013 - config - INFO - Validation Acc: 0.7800
2024-03-28 18:12:12,032 - config - INFO - Epoch [26/2000], Train Loss: 0.4575
2024-03-28 18:12:12,036 - config - INFO - Validation Loss: 0.4948
2024-03-28 18:12:12,036 - config - INFO - Validation Acc: 0.7600
2024-03-28 18:12:12,055 - config - INFO - Epoch [27/2000], Train Loss: 0.4541
2024-03-28 18:12:12,059 - config - INFO - Validation Loss: 0.4941
2024-03-28 18:12:12,059 - config - INFO - Validation Acc: 0.7600
2024-03-28 18:12:12,078 - config - INFO - Epoch [28/2000], Train Loss: 0.4514
2024-03-28 18:12:12,083 - config - INFO - Validation Loss: 0.4907
2024-03-28 18:12:12,083 - config - INFO - Validation Acc: 0.7600
2024-03-28 18:12:12,102 - config - INFO - Epoch [29/2000], Train Loss: 0.4492
2024-03-28 18:12:12,106 - config - INFO - Validation Loss: 0.4871
2024-03-28 18:12:12,106 - config - INFO - Validation Acc: 0.7600
2024-03-28 18:12:12,125 - config - INFO - Epoch [30/2000], Train Loss: 0.4479
2024-03-28 18:12:12,129 - config - INFO - Validation Loss: 0.4832
2024-03-28 18:12:12,129 - config - INFO - Validation Acc: 0.8000
2024-03-28 18:12:12,148 - config - INFO - Epoch [31/2000], Train Loss: 0.4456
2024-03-28 18:12:12,152 - config - INFO - Validation Loss: 0.4821
2024-03-28 18:12:12,153 - config - INFO - Validation Acc: 0.8000
2024-03-28 18:12:12,172 - config - INFO - Epoch [32/2000], Train Loss: 0.4443
2024-03-28 18:12:12,176 - config - INFO - Validation Loss: 0.4791
2024-03-28 18:12:12,176 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:12,195 - config - INFO - Epoch [33/2000], Train Loss: 0.4423
2024-03-28 18:12:12,199 - config - INFO - Validation Loss: 0.4783
2024-03-28 18:12:12,199 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:12,218 - config - INFO - Epoch [34/2000], Train Loss: 0.4406
2024-03-28 18:12:12,222 - config - INFO - Validation Loss: 0.4781
2024-03-28 18:12:12,223 - config - INFO - Validation Acc: 0.8000
2024-03-28 18:12:12,242 - config - INFO - Epoch [35/2000], Train Loss: 0.4398
2024-03-28 18:12:12,246 - config - INFO - Validation Loss: 0.4751
2024-03-28 18:12:12,246 - config - INFO - Validation Acc: 0.8000
2024-03-28 18:12:12,265 - config - INFO - Epoch [36/2000], Train Loss: 0.4383
2024-03-28 18:12:12,269 - config - INFO - Validation Loss: 0.4740
2024-03-28 18:12:12,269 - config - INFO - Validation Acc: 0.8000
2024-03-28 18:12:12,288 - config - INFO - Epoch [37/2000], Train Loss: 0.4372
2024-03-28 18:12:12,292 - config - INFO - Validation Loss: 0.4740
2024-03-28 18:12:12,292 - config - INFO - Validation Acc: 0.8000
2024-03-28 18:12:12,311 - config - INFO - Epoch [38/2000], Train Loss: 0.4361
2024-03-28 18:12:12,315 - config - INFO - Validation Loss: 0.4718
2024-03-28 18:12:12,315 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:12,334 - config - INFO - Epoch [39/2000], Train Loss: 0.4352
2024-03-28 18:12:12,338 - config - INFO - Validation Loss: 0.4707
2024-03-28 18:12:12,339 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:12,358 - config - INFO - Epoch [40/2000], Train Loss: 0.4345
2024-03-28 18:12:12,362 - config - INFO - Validation Loss: 0.4705
2024-03-28 18:12:12,362 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:12,381 - config - INFO - Epoch [41/2000], Train Loss: 0.4344
2024-03-28 18:12:12,385 - config - INFO - Validation Loss: 0.4704
2024-03-28 18:12:12,385 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:12,406 - config - INFO - Epoch [42/2000], Train Loss: 0.4342
2024-03-28 18:12:12,410 - config - INFO - Validation Loss: 0.4679
2024-03-28 18:12:12,410 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:12,429 - config - INFO - Epoch [43/2000], Train Loss: 0.4326
2024-03-28 18:12:12,433 - config - INFO - Validation Loss: 0.4706
2024-03-28 18:12:12,433 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:12,452 - config - INFO - Epoch [44/2000], Train Loss: 0.4327
2024-03-28 18:12:12,457 - config - INFO - Validation Loss: 0.4721
2024-03-28 18:12:12,457 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:12,476 - config - INFO - Epoch [45/2000], Train Loss: 0.4324
2024-03-28 18:12:12,480 - config - INFO - Validation Loss: 0.4707
2024-03-28 18:12:12,480 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:12,500 - config - INFO - Epoch [46/2000], Train Loss: 0.4319
2024-03-28 18:12:12,504 - config - INFO - Validation Loss: 0.4667
2024-03-28 18:12:12,504 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:12,523 - config - INFO - Epoch [47/2000], Train Loss: 0.4315
2024-03-28 18:12:12,527 - config - INFO - Validation Loss: 0.4683
2024-03-28 18:12:12,527 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:12,546 - config - INFO - Epoch [48/2000], Train Loss: 0.4312
2024-03-28 18:12:12,550 - config - INFO - Validation Loss: 0.4698
2024-03-28 18:12:12,550 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:12,569 - config - INFO - Epoch [49/2000], Train Loss: 0.4309
2024-03-28 18:12:12,573 - config - INFO - Validation Loss: 0.4674
2024-03-28 18:12:12,574 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:12,593 - config - INFO - Epoch [50/2000], Train Loss: 0.4316
2024-03-28 18:12:12,597 - config - INFO - Validation Loss: 0.4651
2024-03-28 18:12:12,597 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:12,616 - config - INFO - Epoch [51/2000], Train Loss: 0.4304
2024-03-28 18:12:12,620 - config - INFO - Validation Loss: 0.4692
2024-03-28 18:12:12,620 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:12,639 - config - INFO - Epoch [52/2000], Train Loss: 0.4304
2024-03-28 18:12:12,643 - config - INFO - Validation Loss: 0.4730
2024-03-28 18:12:12,643 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:12,662 - config - INFO - Epoch [53/2000], Train Loss: 0.4310
2024-03-28 18:12:12,666 - config - INFO - Validation Loss: 0.4719
2024-03-28 18:12:12,667 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:12,686 - config - INFO - Epoch [54/2000], Train Loss: 0.4307
2024-03-28 18:12:12,690 - config - INFO - Validation Loss: 0.4701
2024-03-28 18:12:12,690 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:12,709 - config - INFO - Epoch [55/2000], Train Loss: 0.4302
2024-03-28 18:12:12,713 - config - INFO - Validation Loss: 0.4681
2024-03-28 18:12:12,713 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:12,732 - config - INFO - Epoch [56/2000], Train Loss: 0.4301
2024-03-28 18:12:12,736 - config - INFO - Validation Loss: 0.4645
2024-03-28 18:12:12,737 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:12,756 - config - INFO - Epoch [57/2000], Train Loss: 0.4299
2024-03-28 18:12:12,760 - config - INFO - Validation Loss: 0.4660
2024-03-28 18:12:12,760 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:12,779 - config - INFO - Epoch [58/2000], Train Loss: 0.4301
2024-03-28 18:12:12,783 - config - INFO - Validation Loss: 0.4681
2024-03-28 18:12:12,783 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:12,802 - config - INFO - Epoch [59/2000], Train Loss: 0.4294
2024-03-28 18:12:12,806 - config - INFO - Validation Loss: 0.4661
2024-03-28 18:12:12,806 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:12,825 - config - INFO - Epoch [60/2000], Train Loss: 0.4296
2024-03-28 18:12:12,829 - config - INFO - Validation Loss: 0.4658
2024-03-28 18:12:12,830 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:12,849 - config - INFO - Epoch [61/2000], Train Loss: 0.4309
2024-03-28 18:12:12,853 - config - INFO - Validation Loss: 0.4699
2024-03-28 18:12:12,853 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:12,872 - config - INFO - Epoch [62/2000], Train Loss: 0.4294
2024-03-28 18:12:12,876 - config - INFO - Validation Loss: 0.4668
2024-03-28 18:12:12,876 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:12,895 - config - INFO - Epoch [63/2000], Train Loss: 0.4291
2024-03-28 18:12:12,899 - config - INFO - Validation Loss: 0.4660
2024-03-28 18:12:12,899 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:12,918 - config - INFO - Epoch [64/2000], Train Loss: 0.4291
2024-03-28 18:12:12,922 - config - INFO - Validation Loss: 0.4639
2024-03-28 18:12:12,922 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:12,941 - config - INFO - Epoch [65/2000], Train Loss: 0.4294
2024-03-28 18:12:12,945 - config - INFO - Validation Loss: 0.4647
2024-03-28 18:12:12,945 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:12,964 - config - INFO - Epoch [66/2000], Train Loss: 0.4294
2024-03-28 18:12:12,968 - config - INFO - Validation Loss: 0.4690
2024-03-28 18:12:12,969 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:12,988 - config - INFO - Epoch [67/2000], Train Loss: 0.4290
2024-03-28 18:12:12,992 - config - INFO - Validation Loss: 0.4672
2024-03-28 18:12:12,992 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,013 - config - INFO - Epoch [68/2000], Train Loss: 0.4285
2024-03-28 18:12:13,017 - config - INFO - Validation Loss: 0.4643
2024-03-28 18:12:13,017 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,036 - config - INFO - Epoch [69/2000], Train Loss: 0.4286
2024-03-28 18:12:13,040 - config - INFO - Validation Loss: 0.4637
2024-03-28 18:12:13,040 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,059 - config - INFO - Epoch [70/2000], Train Loss: 0.4287
2024-03-28 18:12:13,063 - config - INFO - Validation Loss: 0.4645
2024-03-28 18:12:13,063 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,082 - config - INFO - Epoch [71/2000], Train Loss: 0.4291
2024-03-28 18:12:13,086 - config - INFO - Validation Loss: 0.4683
2024-03-28 18:12:13,087 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,106 - config - INFO - Epoch [72/2000], Train Loss: 0.4290
2024-03-28 18:12:13,110 - config - INFO - Validation Loss: 0.4655
2024-03-28 18:12:13,110 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,129 - config - INFO - Epoch [73/2000], Train Loss: 0.4287
2024-03-28 18:12:13,133 - config - INFO - Validation Loss: 0.4678
2024-03-28 18:12:13,133 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,152 - config - INFO - Epoch [74/2000], Train Loss: 0.4283
2024-03-28 18:12:13,156 - config - INFO - Validation Loss: 0.4667
2024-03-28 18:12:13,156 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,175 - config - INFO - Epoch [75/2000], Train Loss: 0.4284
2024-03-28 18:12:13,179 - config - INFO - Validation Loss: 0.4669
2024-03-28 18:12:13,179 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,198 - config - INFO - Epoch [76/2000], Train Loss: 0.4284
2024-03-28 18:12:13,202 - config - INFO - Validation Loss: 0.4661
2024-03-28 18:12:13,202 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,221 - config - INFO - Epoch [77/2000], Train Loss: 0.4295
2024-03-28 18:12:13,225 - config - INFO - Validation Loss: 0.4691
2024-03-28 18:12:13,226 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,245 - config - INFO - Epoch [78/2000], Train Loss: 0.4279
2024-03-28 18:12:13,249 - config - INFO - Validation Loss: 0.4647
2024-03-28 18:12:13,249 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,268 - config - INFO - Epoch [79/2000], Train Loss: 0.4282
2024-03-28 18:12:13,272 - config - INFO - Validation Loss: 0.4639
2024-03-28 18:12:13,272 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:13,291 - config - INFO - Epoch [80/2000], Train Loss: 0.4284
2024-03-28 18:12:13,295 - config - INFO - Validation Loss: 0.4663
2024-03-28 18:12:13,295 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,314 - config - INFO - Epoch [81/2000], Train Loss: 0.4281
2024-03-28 18:12:13,318 - config - INFO - Validation Loss: 0.4664
2024-03-28 18:12:13,318 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,337 - config - INFO - Epoch [82/2000], Train Loss: 0.4279
2024-03-28 18:12:13,341 - config - INFO - Validation Loss: 0.4671
2024-03-28 18:12:13,341 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,360 - config - INFO - Epoch [83/2000], Train Loss: 0.4283
2024-03-28 18:12:13,364 - config - INFO - Validation Loss: 0.4681
2024-03-28 18:12:13,364 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,383 - config - INFO - Epoch [84/2000], Train Loss: 0.4278
2024-03-28 18:12:13,387 - config - INFO - Validation Loss: 0.4646
2024-03-28 18:12:13,387 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,413 - config - INFO - Epoch [85/2000], Train Loss: 0.4281
2024-03-28 18:12:13,417 - config - INFO - Validation Loss: 0.4639
2024-03-28 18:12:13,417 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:13,436 - config - INFO - Epoch [86/2000], Train Loss: 0.4284
2024-03-28 18:12:13,440 - config - INFO - Validation Loss: 0.4668
2024-03-28 18:12:13,441 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,459 - config - INFO - Epoch [87/2000], Train Loss: 0.4277
2024-03-28 18:12:13,463 - config - INFO - Validation Loss: 0.4659
2024-03-28 18:12:13,464 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,482 - config - INFO - Epoch [88/2000], Train Loss: 0.4280
2024-03-28 18:12:13,486 - config - INFO - Validation Loss: 0.4682
2024-03-28 18:12:13,487 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,506 - config - INFO - Epoch [89/2000], Train Loss: 0.4278
2024-03-28 18:12:13,510 - config - INFO - Validation Loss: 0.4668
2024-03-28 18:12:13,510 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,529 - config - INFO - Epoch [90/2000], Train Loss: 0.4276
2024-03-28 18:12:13,533 - config - INFO - Validation Loss: 0.4672
2024-03-28 18:12:13,533 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,552 - config - INFO - Epoch [91/2000], Train Loss: 0.4275
2024-03-28 18:12:13,556 - config - INFO - Validation Loss: 0.4668
2024-03-28 18:12:13,556 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,575 - config - INFO - Epoch [92/2000], Train Loss: 0.4277
2024-03-28 18:12:13,579 - config - INFO - Validation Loss: 0.4664
2024-03-28 18:12:13,579 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,598 - config - INFO - Epoch [93/2000], Train Loss: 0.4275
2024-03-28 18:12:13,602 - config - INFO - Validation Loss: 0.4658
2024-03-28 18:12:13,603 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,622 - config - INFO - Epoch [94/2000], Train Loss: 0.4274
2024-03-28 18:12:13,626 - config - INFO - Validation Loss: 0.4680
2024-03-28 18:12:13,626 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,645 - config - INFO - Epoch [95/2000], Train Loss: 0.4281
2024-03-28 18:12:13,649 - config - INFO - Validation Loss: 0.4688
2024-03-28 18:12:13,649 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,668 - config - INFO - Epoch [96/2000], Train Loss: 0.4274
2024-03-28 18:12:13,672 - config - INFO - Validation Loss: 0.4637
2024-03-28 18:12:13,672 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:13,691 - config - INFO - Epoch [97/2000], Train Loss: 0.4280
2024-03-28 18:12:13,695 - config - INFO - Validation Loss: 0.4644
2024-03-28 18:12:13,695 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:13,714 - config - INFO - Epoch [98/2000], Train Loss: 0.4272
2024-03-28 18:12:13,718 - config - INFO - Validation Loss: 0.4651
2024-03-28 18:12:13,718 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,737 - config - INFO - Epoch [99/2000], Train Loss: 0.4275
2024-03-28 18:12:13,741 - config - INFO - Validation Loss: 0.4655
2024-03-28 18:12:13,741 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,760 - config - INFO - Epoch [100/2000], Train Loss: 0.4275
2024-03-28 18:12:13,764 - config - INFO - Validation Loss: 0.4638
2024-03-28 18:12:13,764 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:13,783 - config - INFO - Epoch [101/2000], Train Loss: 0.4275
2024-03-28 18:12:13,787 - config - INFO - Validation Loss: 0.4663
2024-03-28 18:12:13,787 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,806 - config - INFO - Epoch [102/2000], Train Loss: 0.4269
2024-03-28 18:12:13,810 - config - INFO - Validation Loss: 0.4651
2024-03-28 18:12:13,810 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,829 - config - INFO - Epoch [103/2000], Train Loss: 0.4271
2024-03-28 18:12:13,833 - config - INFO - Validation Loss: 0.4630
2024-03-28 18:12:13,834 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:13,853 - config - INFO - Epoch [104/2000], Train Loss: 0.4267
2024-03-28 18:12:13,857 - config - INFO - Validation Loss: 0.4635
2024-03-28 18:12:13,857 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,876 - config - INFO - Epoch [105/2000], Train Loss: 0.4267
2024-03-28 18:12:13,880 - config - INFO - Validation Loss: 0.4633
2024-03-28 18:12:13,880 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,912 - config - INFO - Epoch [106/2000], Train Loss: 0.4266
2024-03-28 18:12:13,917 - config - INFO - Validation Loss: 0.4662
2024-03-28 18:12:13,917 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,936 - config - INFO - Epoch [107/2000], Train Loss: 0.4276
2024-03-28 18:12:13,940 - config - INFO - Validation Loss: 0.4672
2024-03-28 18:12:13,940 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:13,959 - config - INFO - Epoch [108/2000], Train Loss: 0.4265
2024-03-28 18:12:13,963 - config - INFO - Validation Loss: 0.4624
2024-03-28 18:12:13,963 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:13,982 - config - INFO - Epoch [109/2000], Train Loss: 0.4270
2024-03-28 18:12:13,986 - config - INFO - Validation Loss: 0.4630
2024-03-28 18:12:13,986 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:14,005 - config - INFO - Epoch [110/2000], Train Loss: 0.4272
2024-03-28 18:12:14,009 - config - INFO - Validation Loss: 0.4614
2024-03-28 18:12:14,009 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:14,028 - config - INFO - Epoch [111/2000], Train Loss: 0.4269
2024-03-28 18:12:14,032 - config - INFO - Validation Loss: 0.4650
2024-03-28 18:12:14,032 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:14,051 - config - INFO - Epoch [112/2000], Train Loss: 0.4272
2024-03-28 18:12:14,055 - config - INFO - Validation Loss: 0.4685
2024-03-28 18:12:14,056 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:14,074 - config - INFO - Epoch [113/2000], Train Loss: 0.4265
2024-03-28 18:12:14,079 - config - INFO - Validation Loss: 0.4664
2024-03-28 18:12:14,079 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:14,098 - config - INFO - Epoch [114/2000], Train Loss: 0.4261
2024-03-28 18:12:14,102 - config - INFO - Validation Loss: 0.4654
2024-03-28 18:12:14,102 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:14,120 - config - INFO - Epoch [115/2000], Train Loss: 0.4262
2024-03-28 18:12:14,124 - config - INFO - Validation Loss: 0.4648
2024-03-28 18:12:14,125 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:14,143 - config - INFO - Epoch [116/2000], Train Loss: 0.4260
2024-03-28 18:12:14,147 - config - INFO - Validation Loss: 0.4624
2024-03-28 18:12:14,147 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:14,166 - config - INFO - Epoch [117/2000], Train Loss: 0.4267
2024-03-28 18:12:14,170 - config - INFO - Validation Loss: 0.4626
2024-03-28 18:12:14,170 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:14,189 - config - INFO - Epoch [118/2000], Train Loss: 0.4269
2024-03-28 18:12:14,193 - config - INFO - Validation Loss: 0.4642
2024-03-28 18:12:14,193 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:14,212 - config - INFO - Epoch [119/2000], Train Loss: 0.4260
2024-03-28 18:12:14,216 - config - INFO - Validation Loss: 0.4704
2024-03-28 18:12:14,216 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:14,235 - config - INFO - Epoch [120/2000], Train Loss: 0.4270
2024-03-28 18:12:14,239 - config - INFO - Validation Loss: 0.4676
2024-03-28 18:12:14,239 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:14,258 - config - INFO - Epoch [121/2000], Train Loss: 0.4260
2024-03-28 18:12:14,262 - config - INFO - Validation Loss: 0.4679
2024-03-28 18:12:14,262 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:14,281 - config - INFO - Epoch [122/2000], Train Loss: 0.4269
2024-03-28 18:12:14,285 - config - INFO - Validation Loss: 0.4636
2024-03-28 18:12:14,285 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:14,304 - config - INFO - Epoch [123/2000], Train Loss: 0.4257
2024-03-28 18:12:14,308 - config - INFO - Validation Loss: 0.4646
2024-03-28 18:12:14,308 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:14,327 - config - INFO - Epoch [124/2000], Train Loss: 0.4256
2024-03-28 18:12:14,331 - config - INFO - Validation Loss: 0.4659
2024-03-28 18:12:14,331 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:14,350 - config - INFO - Epoch [125/2000], Train Loss: 0.4257
2024-03-28 18:12:14,354 - config - INFO - Validation Loss: 0.4680
2024-03-28 18:12:14,354 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:14,373 - config - INFO - Epoch [126/2000], Train Loss: 0.4260
2024-03-28 18:12:14,377 - config - INFO - Validation Loss: 0.4669
2024-03-28 18:12:14,377 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:14,396 - config - INFO - Epoch [127/2000], Train Loss: 0.4256
2024-03-28 18:12:14,400 - config - INFO - Validation Loss: 0.4672
2024-03-28 18:12:14,400 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:14,419 - config - INFO - Epoch [128/2000], Train Loss: 0.4253
2024-03-28 18:12:14,423 - config - INFO - Validation Loss: 0.4668
2024-03-28 18:12:14,423 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:14,442 - config - INFO - Epoch [129/2000], Train Loss: 0.4253
2024-03-28 18:12:14,446 - config - INFO - Validation Loss: 0.4673
2024-03-28 18:12:14,446 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:14,465 - config - INFO - Epoch [130/2000], Train Loss: 0.4253
2024-03-28 18:12:14,468 - config - INFO - Validation Loss: 0.4671
2024-03-28 18:12:14,469 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:14,487 - config - INFO - Epoch [131/2000], Train Loss: 0.4251
2024-03-28 18:12:14,491 - config - INFO - Validation Loss: 0.4647
2024-03-28 18:12:14,491 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:14,510 - config - INFO - Epoch [132/2000], Train Loss: 0.4252
2024-03-28 18:12:14,514 - config - INFO - Validation Loss: 0.4652
2024-03-28 18:12:14,514 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:14,533 - config - INFO - Epoch [133/2000], Train Loss: 0.4252
2024-03-28 18:12:14,537 - config - INFO - Validation Loss: 0.4645
2024-03-28 18:12:14,537 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:14,556 - config - INFO - Epoch [134/2000], Train Loss: 0.4247
2024-03-28 18:12:14,560 - config - INFO - Validation Loss: 0.4673
2024-03-28 18:12:14,560 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:14,579 - config - INFO - Epoch [135/2000], Train Loss: 0.4254
2024-03-28 18:12:14,583 - config - INFO - Validation Loss: 0.4662
2024-03-28 18:12:14,583 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:14,602 - config - INFO - Epoch [136/2000], Train Loss: 0.4247
2024-03-28 18:12:14,606 - config - INFO - Validation Loss: 0.4697
2024-03-28 18:12:14,606 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:14,625 - config - INFO - Epoch [137/2000], Train Loss: 0.4262
2024-03-28 18:12:14,629 - config - INFO - Validation Loss: 0.4723
2024-03-28 18:12:14,629 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:14,648 - config - INFO - Epoch [138/2000], Train Loss: 0.4253
2024-03-28 18:12:14,652 - config - INFO - Validation Loss: 0.4678
2024-03-28 18:12:14,652 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:14,670 - config - INFO - Epoch [139/2000], Train Loss: 0.4250
2024-03-28 18:12:14,674 - config - INFO - Validation Loss: 0.4638
2024-03-28 18:12:14,674 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:14,693 - config - INFO - Epoch [140/2000], Train Loss: 0.4250
2024-03-28 18:12:14,697 - config - INFO - Validation Loss: 0.4633
2024-03-28 18:12:14,697 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:14,716 - config - INFO - Epoch [141/2000], Train Loss: 0.4249
2024-03-28 18:12:14,720 - config - INFO - Validation Loss: 0.4640
2024-03-28 18:12:14,720 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:14,739 - config - INFO - Epoch [142/2000], Train Loss: 0.4250
2024-03-28 18:12:14,743 - config - INFO - Validation Loss: 0.4686
2024-03-28 18:12:14,743 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:14,762 - config - INFO - Epoch [143/2000], Train Loss: 0.4242
2024-03-28 18:12:14,766 - config - INFO - Validation Loss: 0.4646
2024-03-28 18:12:14,766 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:14,785 - config - INFO - Epoch [144/2000], Train Loss: 0.4244
2024-03-28 18:12:14,789 - config - INFO - Validation Loss: 0.4640
2024-03-28 18:12:14,789 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:14,808 - config - INFO - Epoch [145/2000], Train Loss: 0.4245
2024-03-28 18:12:14,812 - config - INFO - Validation Loss: 0.4639
2024-03-28 18:12:14,812 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:14,831 - config - INFO - Epoch [146/2000], Train Loss: 0.4260
2024-03-28 18:12:14,835 - config - INFO - Validation Loss: 0.4693
2024-03-28 18:12:14,835 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:14,854 - config - INFO - Epoch [147/2000], Train Loss: 0.4245
2024-03-28 18:12:14,858 - config - INFO - Validation Loss: 0.4650
2024-03-28 18:12:14,858 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:14,876 - config - INFO - Epoch [148/2000], Train Loss: 0.4242
2024-03-28 18:12:14,880 - config - INFO - Validation Loss: 0.4646
2024-03-28 18:12:14,881 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:14,904 - config - INFO - Epoch [149/2000], Train Loss: 0.4248
2024-03-28 18:12:14,909 - config - INFO - Validation Loss: 0.4633
2024-03-28 18:12:14,909 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:14,928 - config - INFO - Epoch [150/2000], Train Loss: 0.4242
2024-03-28 18:12:14,932 - config - INFO - Validation Loss: 0.4682
2024-03-28 18:12:14,932 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:14,951 - config - INFO - Epoch [151/2000], Train Loss: 0.4246
2024-03-28 18:12:14,955 - config - INFO - Validation Loss: 0.4690
2024-03-28 18:12:14,955 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:14,974 - config - INFO - Epoch [152/2000], Train Loss: 0.4243
2024-03-28 18:12:14,978 - config - INFO - Validation Loss: 0.4680
2024-03-28 18:12:14,978 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:14,997 - config - INFO - Epoch [153/2000], Train Loss: 0.4239
2024-03-28 18:12:15,001 - config - INFO - Validation Loss: 0.4629
2024-03-28 18:12:15,001 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:15,019 - config - INFO - Epoch [154/2000], Train Loss: 0.4249
2024-03-28 18:12:15,023 - config - INFO - Validation Loss: 0.4652
2024-03-28 18:12:15,023 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:15,042 - config - INFO - Epoch [155/2000], Train Loss: 0.4238
2024-03-28 18:12:15,046 - config - INFO - Validation Loss: 0.4659
2024-03-28 18:12:15,046 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:15,064 - config - INFO - Epoch [156/2000], Train Loss: 0.4235
2024-03-28 18:12:15,068 - config - INFO - Validation Loss: 0.4651
2024-03-28 18:12:15,068 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:15,087 - config - INFO - Epoch [157/2000], Train Loss: 0.4234
2024-03-28 18:12:15,091 - config - INFO - Validation Loss: 0.4671
2024-03-28 18:12:15,091 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:15,109 - config - INFO - Epoch [158/2000], Train Loss: 0.4237
2024-03-28 18:12:15,113 - config - INFO - Validation Loss: 0.4672
2024-03-28 18:12:15,113 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:15,132 - config - INFO - Epoch [159/2000], Train Loss: 0.4236
2024-03-28 18:12:15,136 - config - INFO - Validation Loss: 0.4676
2024-03-28 18:12:15,136 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:15,154 - config - INFO - Epoch [160/2000], Train Loss: 0.4243
2024-03-28 18:12:15,158 - config - INFO - Validation Loss: 0.4682
2024-03-28 18:12:15,158 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:15,177 - config - INFO - Epoch [161/2000], Train Loss: 0.4233
2024-03-28 18:12:15,181 - config - INFO - Validation Loss: 0.4648
2024-03-28 18:12:15,181 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:15,200 - config - INFO - Epoch [162/2000], Train Loss: 0.4231
2024-03-28 18:12:15,203 - config - INFO - Validation Loss: 0.4636
2024-03-28 18:12:15,204 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:15,222 - config - INFO - Epoch [163/2000], Train Loss: 0.4230
2024-03-28 18:12:15,226 - config - INFO - Validation Loss: 0.4654
2024-03-28 18:12:15,226 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:15,245 - config - INFO - Epoch [164/2000], Train Loss: 0.4229
2024-03-28 18:12:15,249 - config - INFO - Validation Loss: 0.4642
2024-03-28 18:12:15,249 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:15,267 - config - INFO - Epoch [165/2000], Train Loss: 0.4230
2024-03-28 18:12:15,271 - config - INFO - Validation Loss: 0.4641
2024-03-28 18:12:15,271 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:15,290 - config - INFO - Epoch [166/2000], Train Loss: 0.4240
2024-03-28 18:12:15,294 - config - INFO - Validation Loss: 0.4620
2024-03-28 18:12:15,294 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:15,312 - config - INFO - Epoch [167/2000], Train Loss: 0.4242
2024-03-28 18:12:15,316 - config - INFO - Validation Loss: 0.4660
2024-03-28 18:12:15,316 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:15,335 - config - INFO - Epoch [168/2000], Train Loss: 0.4230
2024-03-28 18:12:15,339 - config - INFO - Validation Loss: 0.4640
2024-03-28 18:12:15,339 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:15,358 - config - INFO - Epoch [169/2000], Train Loss: 0.4225
2024-03-28 18:12:15,362 - config - INFO - Validation Loss: 0.4635
2024-03-28 18:12:15,362 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:15,380 - config - INFO - Epoch [170/2000], Train Loss: 0.4228
2024-03-28 18:12:15,384 - config - INFO - Validation Loss: 0.4629
2024-03-28 18:12:15,384 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:15,403 - config - INFO - Epoch [171/2000], Train Loss: 0.4234
2024-03-28 18:12:15,406 - config - INFO - Validation Loss: 0.4646
2024-03-28 18:12:15,407 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:15,425 - config - INFO - Epoch [172/2000], Train Loss: 0.4225
2024-03-28 18:12:15,429 - config - INFO - Validation Loss: 0.4644
2024-03-28 18:12:15,429 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:15,448 - config - INFO - Epoch [173/2000], Train Loss: 0.4229
2024-03-28 18:12:15,451 - config - INFO - Validation Loss: 0.4634
2024-03-28 18:12:15,452 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:15,470 - config - INFO - Epoch [174/2000], Train Loss: 0.4233
2024-03-28 18:12:15,474 - config - INFO - Validation Loss: 0.4679
2024-03-28 18:12:15,474 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:15,493 - config - INFO - Epoch [175/2000], Train Loss: 0.4225
2024-03-28 18:12:15,497 - config - INFO - Validation Loss: 0.4658
2024-03-28 18:12:15,497 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:15,515 - config - INFO - Epoch [176/2000], Train Loss: 0.4228
2024-03-28 18:12:15,519 - config - INFO - Validation Loss: 0.4636
2024-03-28 18:12:15,519 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:15,538 - config - INFO - Epoch [177/2000], Train Loss: 0.4221
2024-03-28 18:12:15,542 - config - INFO - Validation Loss: 0.4681
2024-03-28 18:12:15,542 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:15,560 - config - INFO - Epoch [178/2000], Train Loss: 0.4222
2024-03-28 18:12:15,564 - config - INFO - Validation Loss: 0.4666
2024-03-28 18:12:15,564 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:15,583 - config - INFO - Epoch [179/2000], Train Loss: 0.4220
2024-03-28 18:12:15,587 - config - INFO - Validation Loss: 0.4653
2024-03-28 18:12:15,587 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:15,605 - config - INFO - Epoch [180/2000], Train Loss: 0.4218
2024-03-28 18:12:15,609 - config - INFO - Validation Loss: 0.4635
2024-03-28 18:12:15,609 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:15,628 - config - INFO - Epoch [181/2000], Train Loss: 0.4219
2024-03-28 18:12:15,632 - config - INFO - Validation Loss: 0.4626
2024-03-28 18:12:15,632 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:15,650 - config - INFO - Epoch [182/2000], Train Loss: 0.4215
2024-03-28 18:12:15,654 - config - INFO - Validation Loss: 0.4658
2024-03-28 18:12:15,654 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:15,673 - config - INFO - Epoch [183/2000], Train Loss: 0.4217
2024-03-28 18:12:15,677 - config - INFO - Validation Loss: 0.4667
2024-03-28 18:12:15,677 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:15,695 - config - INFO - Epoch [184/2000], Train Loss: 0.4215
2024-03-28 18:12:15,699 - config - INFO - Validation Loss: 0.4663
2024-03-28 18:12:15,699 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:15,718 - config - INFO - Epoch [185/2000], Train Loss: 0.4215
2024-03-28 18:12:15,722 - config - INFO - Validation Loss: 0.4668
2024-03-28 18:12:15,722 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:15,741 - config - INFO - Epoch [186/2000], Train Loss: 0.4216
2024-03-28 18:12:15,744 - config - INFO - Validation Loss: 0.4659
2024-03-28 18:12:15,745 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:15,763 - config - INFO - Epoch [187/2000], Train Loss: 0.4212
2024-03-28 18:12:15,767 - config - INFO - Validation Loss: 0.4641
2024-03-28 18:12:15,767 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:15,786 - config - INFO - Epoch [188/2000], Train Loss: 0.4221
2024-03-28 18:12:15,790 - config - INFO - Validation Loss: 0.4623
2024-03-28 18:12:15,790 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:15,808 - config - INFO - Epoch [189/2000], Train Loss: 0.4210
2024-03-28 18:12:15,812 - config - INFO - Validation Loss: 0.4652
2024-03-28 18:12:15,812 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:15,831 - config - INFO - Epoch [190/2000], Train Loss: 0.4211
2024-03-28 18:12:15,835 - config - INFO - Validation Loss: 0.4647
2024-03-28 18:12:15,835 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:15,853 - config - INFO - Epoch [191/2000], Train Loss: 0.4211
2024-03-28 18:12:15,857 - config - INFO - Validation Loss: 0.4644
2024-03-28 18:12:15,857 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:15,876 - config - INFO - Epoch [192/2000], Train Loss: 0.4210
2024-03-28 18:12:15,880 - config - INFO - Validation Loss: 0.4639
2024-03-28 18:12:15,880 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:15,898 - config - INFO - Epoch [193/2000], Train Loss: 0.4215
2024-03-28 18:12:15,902 - config - INFO - Validation Loss: 0.4641
2024-03-28 18:12:15,902 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:15,923 - config - INFO - Epoch [194/2000], Train Loss: 0.4212
2024-03-28 18:12:15,927 - config - INFO - Validation Loss: 0.4674
2024-03-28 18:12:15,927 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:15,946 - config - INFO - Epoch [195/2000], Train Loss: 0.4210
2024-03-28 18:12:15,950 - config - INFO - Validation Loss: 0.4675
2024-03-28 18:12:15,950 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:15,968 - config - INFO - Epoch [196/2000], Train Loss: 0.4206
2024-03-28 18:12:15,972 - config - INFO - Validation Loss: 0.4680
2024-03-28 18:12:15,972 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:15,991 - config - INFO - Epoch [197/2000], Train Loss: 0.4208
2024-03-28 18:12:15,995 - config - INFO - Validation Loss: 0.4645
2024-03-28 18:12:15,995 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,013 - config - INFO - Epoch [198/2000], Train Loss: 0.4205
2024-03-28 18:12:16,017 - config - INFO - Validation Loss: 0.4638
2024-03-28 18:12:16,018 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,036 - config - INFO - Epoch [199/2000], Train Loss: 0.4208
2024-03-28 18:12:16,040 - config - INFO - Validation Loss: 0.4671
2024-03-28 18:12:16,040 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:16,058 - config - INFO - Epoch [200/2000], Train Loss: 0.4214
2024-03-28 18:12:16,062 - config - INFO - Validation Loss: 0.4680
2024-03-28 18:12:16,062 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:16,081 - config - INFO - Epoch [201/2000], Train Loss: 0.4204
2024-03-28 18:12:16,085 - config - INFO - Validation Loss: 0.4639
2024-03-28 18:12:16,085 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,103 - config - INFO - Epoch [202/2000], Train Loss: 0.4211
2024-03-28 18:12:16,107 - config - INFO - Validation Loss: 0.4594
2024-03-28 18:12:16,107 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,126 - config - INFO - Epoch [203/2000], Train Loss: 0.4212
2024-03-28 18:12:16,130 - config - INFO - Validation Loss: 0.4614
2024-03-28 18:12:16,130 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,148 - config - INFO - Epoch [204/2000], Train Loss: 0.4205
2024-03-28 18:12:16,152 - config - INFO - Validation Loss: 0.4622
2024-03-28 18:12:16,152 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,171 - config - INFO - Epoch [205/2000], Train Loss: 0.4205
2024-03-28 18:12:16,175 - config - INFO - Validation Loss: 0.4630
2024-03-28 18:12:16,175 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,193 - config - INFO - Epoch [206/2000], Train Loss: 0.4197
2024-03-28 18:12:16,197 - config - INFO - Validation Loss: 0.4640
2024-03-28 18:12:16,197 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,216 - config - INFO - Epoch [207/2000], Train Loss: 0.4199
2024-03-28 18:12:16,220 - config - INFO - Validation Loss: 0.4661
2024-03-28 18:12:16,220 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:16,238 - config - INFO - Epoch [208/2000], Train Loss: 0.4197
2024-03-28 18:12:16,242 - config - INFO - Validation Loss: 0.4641
2024-03-28 18:12:16,242 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,261 - config - INFO - Epoch [209/2000], Train Loss: 0.4195
2024-03-28 18:12:16,265 - config - INFO - Validation Loss: 0.4610
2024-03-28 18:12:16,265 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,283 - config - INFO - Epoch [210/2000], Train Loss: 0.4194
2024-03-28 18:12:16,287 - config - INFO - Validation Loss: 0.4628
2024-03-28 18:12:16,287 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,306 - config - INFO - Epoch [211/2000], Train Loss: 0.4196
2024-03-28 18:12:16,310 - config - INFO - Validation Loss: 0.4630
2024-03-28 18:12:16,310 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,328 - config - INFO - Epoch [212/2000], Train Loss: 0.4193
2024-03-28 18:12:16,332 - config - INFO - Validation Loss: 0.4626
2024-03-28 18:12:16,332 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,351 - config - INFO - Epoch [213/2000], Train Loss: 0.4196
2024-03-28 18:12:16,355 - config - INFO - Validation Loss: 0.4617
2024-03-28 18:12:16,355 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,373 - config - INFO - Epoch [214/2000], Train Loss: 0.4189
2024-03-28 18:12:16,377 - config - INFO - Validation Loss: 0.4632
2024-03-28 18:12:16,377 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,396 - config - INFO - Epoch [215/2000], Train Loss: 0.4191
2024-03-28 18:12:16,400 - config - INFO - Validation Loss: 0.4650
2024-03-28 18:12:16,400 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,418 - config - INFO - Epoch [216/2000], Train Loss: 0.4206
2024-03-28 18:12:16,422 - config - INFO - Validation Loss: 0.4693
2024-03-28 18:12:16,422 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:16,441 - config - INFO - Epoch [217/2000], Train Loss: 0.4193
2024-03-28 18:12:16,445 - config - INFO - Validation Loss: 0.4656
2024-03-28 18:12:16,451 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,473 - config - INFO - Epoch [218/2000], Train Loss: 0.4188
2024-03-28 18:12:16,477 - config - INFO - Validation Loss: 0.4640
2024-03-28 18:12:16,477 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,495 - config - INFO - Epoch [219/2000], Train Loss: 0.4197
2024-03-28 18:12:16,499 - config - INFO - Validation Loss: 0.4600
2024-03-28 18:12:16,500 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,518 - config - INFO - Epoch [220/2000], Train Loss: 0.4199
2024-03-28 18:12:16,522 - config - INFO - Validation Loss: 0.4610
2024-03-28 18:12:16,522 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,541 - config - INFO - Epoch [221/2000], Train Loss: 0.4187
2024-03-28 18:12:16,544 - config - INFO - Validation Loss: 0.4640
2024-03-28 18:12:16,545 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,563 - config - INFO - Epoch [222/2000], Train Loss: 0.4185
2024-03-28 18:12:16,567 - config - INFO - Validation Loss: 0.4651
2024-03-28 18:12:16,567 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,586 - config - INFO - Epoch [223/2000], Train Loss: 0.4185
2024-03-28 18:12:16,590 - config - INFO - Validation Loss: 0.4656
2024-03-28 18:12:16,590 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,608 - config - INFO - Epoch [224/2000], Train Loss: 0.4180
2024-03-28 18:12:16,612 - config - INFO - Validation Loss: 0.4643
2024-03-28 18:12:16,612 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,631 - config - INFO - Epoch [225/2000], Train Loss: 0.4191
2024-03-28 18:12:16,635 - config - INFO - Validation Loss: 0.4615
2024-03-28 18:12:16,635 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,653 - config - INFO - Epoch [226/2000], Train Loss: 0.4180
2024-03-28 18:12:16,657 - config - INFO - Validation Loss: 0.4655
2024-03-28 18:12:16,657 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,676 - config - INFO - Epoch [227/2000], Train Loss: 0.4185
2024-03-28 18:12:16,680 - config - INFO - Validation Loss: 0.4632
2024-03-28 18:12:16,680 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,698 - config - INFO - Epoch [228/2000], Train Loss: 0.4180
2024-03-28 18:12:16,702 - config - INFO - Validation Loss: 0.4633
2024-03-28 18:12:16,702 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,721 - config - INFO - Epoch [229/2000], Train Loss: 0.4178
2024-03-28 18:12:16,725 - config - INFO - Validation Loss: 0.4634
2024-03-28 18:12:16,725 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,743 - config - INFO - Epoch [230/2000], Train Loss: 0.4180
2024-03-28 18:12:16,747 - config - INFO - Validation Loss: 0.4631
2024-03-28 18:12:16,747 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,766 - config - INFO - Epoch [231/2000], Train Loss: 0.4176
2024-03-28 18:12:16,770 - config - INFO - Validation Loss: 0.4613
2024-03-28 18:12:16,770 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,788 - config - INFO - Epoch [232/2000], Train Loss: 0.4184
2024-03-28 18:12:16,792 - config - INFO - Validation Loss: 0.4632
2024-03-28 18:12:16,792 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,811 - config - INFO - Epoch [233/2000], Train Loss: 0.4176
2024-03-28 18:12:16,815 - config - INFO - Validation Loss: 0.4640
2024-03-28 18:12:16,815 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,833 - config - INFO - Epoch [234/2000], Train Loss: 0.4174
2024-03-28 18:12:16,837 - config - INFO - Validation Loss: 0.4645
2024-03-28 18:12:16,837 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,856 - config - INFO - Epoch [235/2000], Train Loss: 0.4176
2024-03-28 18:12:16,860 - config - INFO - Validation Loss: 0.4639
2024-03-28 18:12:16,860 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,878 - config - INFO - Epoch [236/2000], Train Loss: 0.4178
2024-03-28 18:12:16,882 - config - INFO - Validation Loss: 0.4634
2024-03-28 18:12:16,882 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,901 - config - INFO - Epoch [237/2000], Train Loss: 0.4172
2024-03-28 18:12:16,905 - config - INFO - Validation Loss: 0.4653
2024-03-28 18:12:16,905 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,933 - config - INFO - Epoch [238/2000], Train Loss: 0.4173
2024-03-28 18:12:16,938 - config - INFO - Validation Loss: 0.4679
2024-03-28 18:12:16,938 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,956 - config - INFO - Epoch [239/2000], Train Loss: 0.4173
2024-03-28 18:12:16,960 - config - INFO - Validation Loss: 0.4645
2024-03-28 18:12:16,960 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:16,979 - config - INFO - Epoch [240/2000], Train Loss: 0.4173
2024-03-28 18:12:16,983 - config - INFO - Validation Loss: 0.4649
2024-03-28 18:12:16,983 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,002 - config - INFO - Epoch [241/2000], Train Loss: 0.4169
2024-03-28 18:12:17,005 - config - INFO - Validation Loss: 0.4631
2024-03-28 18:12:17,006 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,024 - config - INFO - Epoch [242/2000], Train Loss: 0.4169
2024-03-28 18:12:17,028 - config - INFO - Validation Loss: 0.4641
2024-03-28 18:12:17,028 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,047 - config - INFO - Epoch [243/2000], Train Loss: 0.4167
2024-03-28 18:12:17,051 - config - INFO - Validation Loss: 0.4658
2024-03-28 18:12:17,051 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,069 - config - INFO - Epoch [244/2000], Train Loss: 0.4165
2024-03-28 18:12:17,073 - config - INFO - Validation Loss: 0.4633
2024-03-28 18:12:17,073 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,092 - config - INFO - Epoch [245/2000], Train Loss: 0.4170
2024-03-28 18:12:17,096 - config - INFO - Validation Loss: 0.4604
2024-03-28 18:12:17,096 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,114 - config - INFO - Epoch [246/2000], Train Loss: 0.4171
2024-03-28 18:12:17,118 - config - INFO - Validation Loss: 0.4606
2024-03-28 18:12:17,118 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,137 - config - INFO - Epoch [247/2000], Train Loss: 0.4166
2024-03-28 18:12:17,141 - config - INFO - Validation Loss: 0.4614
2024-03-28 18:12:17,141 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,159 - config - INFO - Epoch [248/2000], Train Loss: 0.4162
2024-03-28 18:12:17,163 - config - INFO - Validation Loss: 0.4596
2024-03-28 18:12:17,164 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,182 - config - INFO - Epoch [249/2000], Train Loss: 0.4164
2024-03-28 18:12:17,186 - config - INFO - Validation Loss: 0.4599
2024-03-28 18:12:17,186 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,204 - config - INFO - Epoch [250/2000], Train Loss: 0.4159
2024-03-28 18:12:17,208 - config - INFO - Validation Loss: 0.4621
2024-03-28 18:12:17,209 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,227 - config - INFO - Epoch [251/2000], Train Loss: 0.4161
2024-03-28 18:12:17,231 - config - INFO - Validation Loss: 0.4633
2024-03-28 18:12:17,231 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,250 - config - INFO - Epoch [252/2000], Train Loss: 0.4160
2024-03-28 18:12:17,254 - config - INFO - Validation Loss: 0.4639
2024-03-28 18:12:17,254 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,272 - config - INFO - Epoch [253/2000], Train Loss: 0.4160
2024-03-28 18:12:17,276 - config - INFO - Validation Loss: 0.4632
2024-03-28 18:12:17,276 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,295 - config - INFO - Epoch [254/2000], Train Loss: 0.4160
2024-03-28 18:12:17,299 - config - INFO - Validation Loss: 0.4639
2024-03-28 18:12:17,299 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,317 - config - INFO - Epoch [255/2000], Train Loss: 0.4156
2024-03-28 18:12:17,321 - config - INFO - Validation Loss: 0.4614
2024-03-28 18:12:17,321 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,340 - config - INFO - Epoch [256/2000], Train Loss: 0.4154
2024-03-28 18:12:17,344 - config - INFO - Validation Loss: 0.4613
2024-03-28 18:12:17,344 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,362 - config - INFO - Epoch [257/2000], Train Loss: 0.4164
2024-03-28 18:12:17,366 - config - INFO - Validation Loss: 0.4596
2024-03-28 18:12:17,366 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,385 - config - INFO - Epoch [258/2000], Train Loss: 0.4170
2024-03-28 18:12:17,389 - config - INFO - Validation Loss: 0.4664
2024-03-28 18:12:17,389 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,407 - config - INFO - Epoch [259/2000], Train Loss: 0.4155
2024-03-28 18:12:17,411 - config - INFO - Validation Loss: 0.4620
2024-03-28 18:12:17,411 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,430 - config - INFO - Epoch [260/2000], Train Loss: 0.4152
2024-03-28 18:12:17,434 - config - INFO - Validation Loss: 0.4633
2024-03-28 18:12:17,434 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,452 - config - INFO - Epoch [261/2000], Train Loss: 0.4150
2024-03-28 18:12:17,456 - config - INFO - Validation Loss: 0.4641
2024-03-28 18:12:17,456 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,475 - config - INFO - Epoch [262/2000], Train Loss: 0.4149
2024-03-28 18:12:17,479 - config - INFO - Validation Loss: 0.4642
2024-03-28 18:12:17,479 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,497 - config - INFO - Epoch [263/2000], Train Loss: 0.4150
2024-03-28 18:12:17,501 - config - INFO - Validation Loss: 0.4643
2024-03-28 18:12:17,501 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,520 - config - INFO - Epoch [264/2000], Train Loss: 0.4149
2024-03-28 18:12:17,524 - config - INFO - Validation Loss: 0.4610
2024-03-28 18:12:17,524 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,543 - config - INFO - Epoch [265/2000], Train Loss: 0.4151
2024-03-28 18:12:17,546 - config - INFO - Validation Loss: 0.4606
2024-03-28 18:12:17,547 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,565 - config - INFO - Epoch [266/2000], Train Loss: 0.4147
2024-03-28 18:12:17,569 - config - INFO - Validation Loss: 0.4643
2024-03-28 18:12:17,569 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,587 - config - INFO - Epoch [267/2000], Train Loss: 0.4146
2024-03-28 18:12:17,591 - config - INFO - Validation Loss: 0.4633
2024-03-28 18:12:17,592 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,610 - config - INFO - Epoch [268/2000], Train Loss: 0.4144
2024-03-28 18:12:17,614 - config - INFO - Validation Loss: 0.4644
2024-03-28 18:12:17,614 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,632 - config - INFO - Epoch [269/2000], Train Loss: 0.4144
2024-03-28 18:12:17,636 - config - INFO - Validation Loss: 0.4643
2024-03-28 18:12:17,637 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,655 - config - INFO - Epoch [270/2000], Train Loss: 0.4147
2024-03-28 18:12:17,659 - config - INFO - Validation Loss: 0.4663
2024-03-28 18:12:17,659 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,678 - config - INFO - Epoch [271/2000], Train Loss: 0.4145
2024-03-28 18:12:17,681 - config - INFO - Validation Loss: 0.4662
2024-03-28 18:12:17,682 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,700 - config - INFO - Epoch [272/2000], Train Loss: 0.4142
2024-03-28 18:12:17,704 - config - INFO - Validation Loss: 0.4640
2024-03-28 18:12:17,704 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,723 - config - INFO - Epoch [273/2000], Train Loss: 0.4137
2024-03-28 18:12:17,727 - config - INFO - Validation Loss: 0.4630
2024-03-28 18:12:17,727 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,745 - config - INFO - Epoch [274/2000], Train Loss: 0.4138
2024-03-28 18:12:17,749 - config - INFO - Validation Loss: 0.4636
2024-03-28 18:12:17,749 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,768 - config - INFO - Epoch [275/2000], Train Loss: 0.4139
2024-03-28 18:12:17,772 - config - INFO - Validation Loss: 0.4641
2024-03-28 18:12:17,772 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,790 - config - INFO - Epoch [276/2000], Train Loss: 0.4135
2024-03-28 18:12:17,794 - config - INFO - Validation Loss: 0.4625
2024-03-28 18:12:17,794 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,813 - config - INFO - Epoch [277/2000], Train Loss: 0.4133
2024-03-28 18:12:17,817 - config - INFO - Validation Loss: 0.4624
2024-03-28 18:12:17,817 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,835 - config - INFO - Epoch [278/2000], Train Loss: 0.4138
2024-03-28 18:12:17,839 - config - INFO - Validation Loss: 0.4606
2024-03-28 18:12:17,839 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,858 - config - INFO - Epoch [279/2000], Train Loss: 0.4139
2024-03-28 18:12:17,862 - config - INFO - Validation Loss: 0.4654
2024-03-28 18:12:17,862 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,880 - config - INFO - Epoch [280/2000], Train Loss: 0.4135
2024-03-28 18:12:17,884 - config - INFO - Validation Loss: 0.4648
2024-03-28 18:12:17,884 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,903 - config - INFO - Epoch [281/2000], Train Loss: 0.4131
2024-03-28 18:12:17,906 - config - INFO - Validation Loss: 0.4626
2024-03-28 18:12:17,907 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,925 - config - INFO - Epoch [282/2000], Train Loss: 0.4129
2024-03-28 18:12:17,929 - config - INFO - Validation Loss: 0.4608
2024-03-28 18:12:17,929 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,948 - config - INFO - Epoch [283/2000], Train Loss: 0.4131
2024-03-28 18:12:17,952 - config - INFO - Validation Loss: 0.4598
2024-03-28 18:12:17,952 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,970 - config - INFO - Epoch [284/2000], Train Loss: 0.4130
2024-03-28 18:12:17,974 - config - INFO - Validation Loss: 0.4603
2024-03-28 18:12:17,974 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:17,993 - config - INFO - Epoch [285/2000], Train Loss: 0.4128
2024-03-28 18:12:17,997 - config - INFO - Validation Loss: 0.4597
2024-03-28 18:12:17,997 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,015 - config - INFO - Epoch [286/2000], Train Loss: 0.4127
2024-03-28 18:12:18,019 - config - INFO - Validation Loss: 0.4611
2024-03-28 18:12:18,019 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,037 - config - INFO - Epoch [287/2000], Train Loss: 0.4127
2024-03-28 18:12:18,041 - config - INFO - Validation Loss: 0.4619
2024-03-28 18:12:18,042 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,060 - config - INFO - Epoch [288/2000], Train Loss: 0.4125
2024-03-28 18:12:18,064 - config - INFO - Validation Loss: 0.4612
2024-03-28 18:12:18,064 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,083 - config - INFO - Epoch [289/2000], Train Loss: 0.4122
2024-03-28 18:12:18,086 - config - INFO - Validation Loss: 0.4626
2024-03-28 18:12:18,087 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,105 - config - INFO - Epoch [290/2000], Train Loss: 0.4121
2024-03-28 18:12:18,109 - config - INFO - Validation Loss: 0.4642
2024-03-28 18:12:18,109 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,128 - config - INFO - Epoch [291/2000], Train Loss: 0.4121
2024-03-28 18:12:18,132 - config - INFO - Validation Loss: 0.4636
2024-03-28 18:12:18,132 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,150 - config - INFO - Epoch [292/2000], Train Loss: 0.4121
2024-03-28 18:12:18,154 - config - INFO - Validation Loss: 0.4622
2024-03-28 18:12:18,154 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,173 - config - INFO - Epoch [293/2000], Train Loss: 0.4118
2024-03-28 18:12:18,176 - config - INFO - Validation Loss: 0.4620
2024-03-28 18:12:18,177 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,195 - config - INFO - Epoch [294/2000], Train Loss: 0.4118
2024-03-28 18:12:18,199 - config - INFO - Validation Loss: 0.4623
2024-03-28 18:12:18,199 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,218 - config - INFO - Epoch [295/2000], Train Loss: 0.4119
2024-03-28 18:12:18,222 - config - INFO - Validation Loss: 0.4649
2024-03-28 18:12:18,222 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,240 - config - INFO - Epoch [296/2000], Train Loss: 0.4116
2024-03-28 18:12:18,244 - config - INFO - Validation Loss: 0.4639
2024-03-28 18:12:18,244 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,263 - config - INFO - Epoch [297/2000], Train Loss: 0.4118
2024-03-28 18:12:18,267 - config - INFO - Validation Loss: 0.4618
2024-03-28 18:12:18,267 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,285 - config - INFO - Epoch [298/2000], Train Loss: 0.4115
2024-03-28 18:12:18,289 - config - INFO - Validation Loss: 0.4635
2024-03-28 18:12:18,289 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,308 - config - INFO - Epoch [299/2000], Train Loss: 0.4117
2024-03-28 18:12:18,312 - config - INFO - Validation Loss: 0.4650
2024-03-28 18:12:18,312 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,331 - config - INFO - Epoch [300/2000], Train Loss: 0.4113
2024-03-28 18:12:18,334 - config - INFO - Validation Loss: 0.4609
2024-03-28 18:12:18,335 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,353 - config - INFO - Epoch [301/2000], Train Loss: 0.4114
2024-03-28 18:12:18,357 - config - INFO - Validation Loss: 0.4618
2024-03-28 18:12:18,358 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,376 - config - INFO - Epoch [302/2000], Train Loss: 0.4112
2024-03-28 18:12:18,381 - config - INFO - Validation Loss: 0.4617
2024-03-28 18:12:18,381 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,400 - config - INFO - Epoch [303/2000], Train Loss: 0.4108
2024-03-28 18:12:18,404 - config - INFO - Validation Loss: 0.4643
2024-03-28 18:12:18,404 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,422 - config - INFO - Epoch [304/2000], Train Loss: 0.4109
2024-03-28 18:12:18,426 - config - INFO - Validation Loss: 0.4625
2024-03-28 18:12:18,426 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,445 - config - INFO - Epoch [305/2000], Train Loss: 0.4117
2024-03-28 18:12:18,449 - config - INFO - Validation Loss: 0.4596
2024-03-28 18:12:18,449 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,467 - config - INFO - Epoch [306/2000], Train Loss: 0.4105
2024-03-28 18:12:18,471 - config - INFO - Validation Loss: 0.4618
2024-03-28 18:12:18,471 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,490 - config - INFO - Epoch [307/2000], Train Loss: 0.4105
2024-03-28 18:12:18,494 - config - INFO - Validation Loss: 0.4639
2024-03-28 18:12:18,494 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,512 - config - INFO - Epoch [308/2000], Train Loss: 0.4108
2024-03-28 18:12:18,516 - config - INFO - Validation Loss: 0.4644
2024-03-28 18:12:18,517 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,535 - config - INFO - Epoch [309/2000], Train Loss: 0.4104
2024-03-28 18:12:18,539 - config - INFO - Validation Loss: 0.4630
2024-03-28 18:12:18,539 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,557 - config - INFO - Epoch [310/2000], Train Loss: 0.4104
2024-03-28 18:12:18,561 - config - INFO - Validation Loss: 0.4611
2024-03-28 18:12:18,562 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,580 - config - INFO - Epoch [311/2000], Train Loss: 0.4103
2024-03-28 18:12:18,584 - config - INFO - Validation Loss: 0.4609
2024-03-28 18:12:18,584 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,602 - config - INFO - Epoch [312/2000], Train Loss: 0.4109
2024-03-28 18:12:18,606 - config - INFO - Validation Loss: 0.4597
2024-03-28 18:12:18,607 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,625 - config - INFO - Epoch [313/2000], Train Loss: 0.4102
2024-03-28 18:12:18,629 - config - INFO - Validation Loss: 0.4623
2024-03-28 18:12:18,629 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,648 - config - INFO - Epoch [314/2000], Train Loss: 0.4101
2024-03-28 18:12:18,651 - config - INFO - Validation Loss: 0.4620
2024-03-28 18:12:18,652 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,670 - config - INFO - Epoch [315/2000], Train Loss: 0.4099
2024-03-28 18:12:18,674 - config - INFO - Validation Loss: 0.4642
2024-03-28 18:12:18,674 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,692 - config - INFO - Epoch [316/2000], Train Loss: 0.4107
2024-03-28 18:12:18,696 - config - INFO - Validation Loss: 0.4633
2024-03-28 18:12:18,696 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,715 - config - INFO - Epoch [317/2000], Train Loss: 0.4096
2024-03-28 18:12:18,719 - config - INFO - Validation Loss: 0.4631
2024-03-28 18:12:18,719 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,737 - config - INFO - Epoch [318/2000], Train Loss: 0.4094
2024-03-28 18:12:18,741 - config - INFO - Validation Loss: 0.4617
2024-03-28 18:12:18,741 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,760 - config - INFO - Epoch [319/2000], Train Loss: 0.4097
2024-03-28 18:12:18,764 - config - INFO - Validation Loss: 0.4610
2024-03-28 18:12:18,764 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,782 - config - INFO - Epoch [320/2000], Train Loss: 0.4094
2024-03-28 18:12:18,786 - config - INFO - Validation Loss: 0.4632
2024-03-28 18:12:18,787 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,805 - config - INFO - Epoch [321/2000], Train Loss: 0.4090
2024-03-28 18:12:18,809 - config - INFO - Validation Loss: 0.4632
2024-03-28 18:12:18,809 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,827 - config - INFO - Epoch [322/2000], Train Loss: 0.4089
2024-03-28 18:12:18,831 - config - INFO - Validation Loss: 0.4630
2024-03-28 18:12:18,832 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,850 - config - INFO - Epoch [323/2000], Train Loss: 0.4088
2024-03-28 18:12:18,854 - config - INFO - Validation Loss: 0.4628
2024-03-28 18:12:18,854 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,872 - config - INFO - Epoch [324/2000], Train Loss: 0.4090
2024-03-28 18:12:18,876 - config - INFO - Validation Loss: 0.4619
2024-03-28 18:12:18,876 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,895 - config - INFO - Epoch [325/2000], Train Loss: 0.4091
2024-03-28 18:12:18,899 - config - INFO - Validation Loss: 0.4650
2024-03-28 18:12:18,899 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,917 - config - INFO - Epoch [326/2000], Train Loss: 0.4086
2024-03-28 18:12:18,921 - config - INFO - Validation Loss: 0.4651
2024-03-28 18:12:18,921 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,940 - config - INFO - Epoch [327/2000], Train Loss: 0.4087
2024-03-28 18:12:18,944 - config - INFO - Validation Loss: 0.4621
2024-03-28 18:12:18,944 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,962 - config - INFO - Epoch [328/2000], Train Loss: 0.4083
2024-03-28 18:12:18,966 - config - INFO - Validation Loss: 0.4621
2024-03-28 18:12:18,967 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:18,985 - config - INFO - Epoch [329/2000], Train Loss: 0.4084
2024-03-28 18:12:18,989 - config - INFO - Validation Loss: 0.4649
2024-03-28 18:12:18,989 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,007 - config - INFO - Epoch [330/2000], Train Loss: 0.4080
2024-03-28 18:12:19,011 - config - INFO - Validation Loss: 0.4637
2024-03-28 18:12:19,012 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,030 - config - INFO - Epoch [331/2000], Train Loss: 0.4078
2024-03-28 18:12:19,034 - config - INFO - Validation Loss: 0.4613
2024-03-28 18:12:19,034 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,053 - config - INFO - Epoch [332/2000], Train Loss: 0.4083
2024-03-28 18:12:19,058 - config - INFO - Validation Loss: 0.4611
2024-03-28 18:12:19,058 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,078 - config - INFO - Epoch [333/2000], Train Loss: 0.4085
2024-03-28 18:12:19,082 - config - INFO - Validation Loss: 0.4636
2024-03-28 18:12:19,082 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,101 - config - INFO - Epoch [334/2000], Train Loss: 0.4079
2024-03-28 18:12:19,104 - config - INFO - Validation Loss: 0.4609
2024-03-28 18:12:19,105 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,123 - config - INFO - Epoch [335/2000], Train Loss: 0.4070
2024-03-28 18:12:19,127 - config - INFO - Validation Loss: 0.4630
2024-03-28 18:12:19,127 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,146 - config - INFO - Epoch [336/2000], Train Loss: 0.4078
2024-03-28 18:12:19,150 - config - INFO - Validation Loss: 0.4651
2024-03-28 18:12:19,150 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,168 - config - INFO - Epoch [337/2000], Train Loss: 0.4079
2024-03-28 18:12:19,172 - config - INFO - Validation Loss: 0.4636
2024-03-28 18:12:19,173 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,191 - config - INFO - Epoch [338/2000], Train Loss: 0.4074
2024-03-28 18:12:19,195 - config - INFO - Validation Loss: 0.4605
2024-03-28 18:12:19,195 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,214 - config - INFO - Epoch [339/2000], Train Loss: 0.4074
2024-03-28 18:12:19,217 - config - INFO - Validation Loss: 0.4604
2024-03-28 18:12:19,218 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,236 - config - INFO - Epoch [340/2000], Train Loss: 0.4070
2024-03-28 18:12:19,240 - config - INFO - Validation Loss: 0.4604
2024-03-28 18:12:19,240 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,259 - config - INFO - Epoch [341/2000], Train Loss: 0.4069
2024-03-28 18:12:19,262 - config - INFO - Validation Loss: 0.4617
2024-03-28 18:12:19,263 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,282 - config - INFO - Epoch [342/2000], Train Loss: 0.4069
2024-03-28 18:12:19,286 - config - INFO - Validation Loss: 0.4597
2024-03-28 18:12:19,286 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,305 - config - INFO - Epoch [343/2000], Train Loss: 0.4072
2024-03-28 18:12:19,309 - config - INFO - Validation Loss: 0.4580
2024-03-28 18:12:19,309 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,327 - config - INFO - Epoch [344/2000], Train Loss: 0.4066
2024-03-28 18:12:19,331 - config - INFO - Validation Loss: 0.4614
2024-03-28 18:12:19,331 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:19,350 - config - INFO - Epoch [345/2000], Train Loss: 0.4075
2024-03-28 18:12:19,354 - config - INFO - Validation Loss: 0.4630
2024-03-28 18:12:19,354 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:19,372 - config - INFO - Epoch [346/2000], Train Loss: 0.4063
2024-03-28 18:12:19,376 - config - INFO - Validation Loss: 0.4593
2024-03-28 18:12:19,376 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,395 - config - INFO - Epoch [347/2000], Train Loss: 0.4066
2024-03-28 18:12:19,399 - config - INFO - Validation Loss: 0.4565
2024-03-28 18:12:19,399 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,417 - config - INFO - Epoch [348/2000], Train Loss: 0.4072
2024-03-28 18:12:19,421 - config - INFO - Validation Loss: 0.4568
2024-03-28 18:12:19,421 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,440 - config - INFO - Epoch [349/2000], Train Loss: 0.4072
2024-03-28 18:12:19,444 - config - INFO - Validation Loss: 0.4619
2024-03-28 18:12:19,444 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,462 - config - INFO - Epoch [350/2000], Train Loss: 0.4059
2024-03-28 18:12:19,466 - config - INFO - Validation Loss: 0.4602
2024-03-28 18:12:19,466 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,485 - config - INFO - Epoch [351/2000], Train Loss: 0.4062
2024-03-28 18:12:19,489 - config - INFO - Validation Loss: 0.4593
2024-03-28 18:12:19,489 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,507 - config - INFO - Epoch [352/2000], Train Loss: 0.4057
2024-03-28 18:12:19,511 - config - INFO - Validation Loss: 0.4613
2024-03-28 18:12:19,512 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,530 - config - INFO - Epoch [353/2000], Train Loss: 0.4059
2024-03-28 18:12:19,534 - config - INFO - Validation Loss: 0.4606
2024-03-28 18:12:19,534 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,553 - config - INFO - Epoch [354/2000], Train Loss: 0.4076
2024-03-28 18:12:19,556 - config - INFO - Validation Loss: 0.4648
2024-03-28 18:12:19,557 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,575 - config - INFO - Epoch [355/2000], Train Loss: 0.4054
2024-03-28 18:12:19,579 - config - INFO - Validation Loss: 0.4591
2024-03-28 18:12:19,579 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,598 - config - INFO - Epoch [356/2000], Train Loss: 0.4056
2024-03-28 18:12:19,602 - config - INFO - Validation Loss: 0.4577
2024-03-28 18:12:19,602 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,620 - config - INFO - Epoch [357/2000], Train Loss: 0.4053
2024-03-28 18:12:19,624 - config - INFO - Validation Loss: 0.4587
2024-03-28 18:12:19,624 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,643 - config - INFO - Epoch [358/2000], Train Loss: 0.4050
2024-03-28 18:12:19,647 - config - INFO - Validation Loss: 0.4594
2024-03-28 18:12:19,647 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,665 - config - INFO - Epoch [359/2000], Train Loss: 0.4045
2024-03-28 18:12:19,669 - config - INFO - Validation Loss: 0.4635
2024-03-28 18:12:19,669 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,688 - config - INFO - Epoch [360/2000], Train Loss: 0.4047
2024-03-28 18:12:19,692 - config - INFO - Validation Loss: 0.4631
2024-03-28 18:12:19,692 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,710 - config - INFO - Epoch [361/2000], Train Loss: 0.4048
2024-03-28 18:12:19,714 - config - INFO - Validation Loss: 0.4644
2024-03-28 18:12:19,714 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,733 - config - INFO - Epoch [362/2000], Train Loss: 0.4049
2024-03-28 18:12:19,737 - config - INFO - Validation Loss: 0.4624
2024-03-28 18:12:19,737 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,756 - config - INFO - Epoch [363/2000], Train Loss: 0.4044
2024-03-28 18:12:19,760 - config - INFO - Validation Loss: 0.4620
2024-03-28 18:12:19,760 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,779 - config - INFO - Epoch [364/2000], Train Loss: 0.4043
2024-03-28 18:12:19,782 - config - INFO - Validation Loss: 0.4632
2024-03-28 18:12:19,783 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,801 - config - INFO - Epoch [365/2000], Train Loss: 0.4039
2024-03-28 18:12:19,805 - config - INFO - Validation Loss: 0.4615
2024-03-28 18:12:19,805 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,824 - config - INFO - Epoch [366/2000], Train Loss: 0.4047
2024-03-28 18:12:19,828 - config - INFO - Validation Loss: 0.4620
2024-03-28 18:12:19,828 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,846 - config - INFO - Epoch [367/2000], Train Loss: 0.4040
2024-03-28 18:12:19,850 - config - INFO - Validation Loss: 0.4600
2024-03-28 18:12:19,850 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:19,869 - config - INFO - Epoch [368/2000], Train Loss: 0.4045
2024-03-28 18:12:19,873 - config - INFO - Validation Loss: 0.4619
2024-03-28 18:12:19,873 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,891 - config - INFO - Epoch [369/2000], Train Loss: 0.4052
2024-03-28 18:12:19,895 - config - INFO - Validation Loss: 0.4677
2024-03-28 18:12:19,895 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,914 - config - INFO - Epoch [370/2000], Train Loss: 0.4055
2024-03-28 18:12:19,918 - config - INFO - Validation Loss: 0.4695
2024-03-28 18:12:19,918 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:19,936 - config - INFO - Epoch [371/2000], Train Loss: 0.4042
2024-03-28 18:12:19,940 - config - INFO - Validation Loss: 0.4629
2024-03-28 18:12:19,941 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,959 - config - INFO - Epoch [372/2000], Train Loss: 0.4029
2024-03-28 18:12:19,963 - config - INFO - Validation Loss: 0.4600
2024-03-28 18:12:19,963 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:19,982 - config - INFO - Epoch [373/2000], Train Loss: 0.4036
2024-03-28 18:12:19,986 - config - INFO - Validation Loss: 0.4583
2024-03-28 18:12:19,986 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,004 - config - INFO - Epoch [374/2000], Train Loss: 0.4034
2024-03-28 18:12:20,008 - config - INFO - Validation Loss: 0.4576
2024-03-28 18:12:20,008 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,027 - config - INFO - Epoch [375/2000], Train Loss: 0.4034
2024-03-28 18:12:20,031 - config - INFO - Validation Loss: 0.4605
2024-03-28 18:12:20,031 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,049 - config - INFO - Epoch [376/2000], Train Loss: 0.4036
2024-03-28 18:12:20,053 - config - INFO - Validation Loss: 0.4644
2024-03-28 18:12:20,053 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,072 - config - INFO - Epoch [377/2000], Train Loss: 0.4036
2024-03-28 18:12:20,079 - config - INFO - Validation Loss: 0.4641
2024-03-28 18:12:20,079 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,097 - config - INFO - Epoch [378/2000], Train Loss: 0.4027
2024-03-28 18:12:20,101 - config - INFO - Validation Loss: 0.4607
2024-03-28 18:12:20,101 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,120 - config - INFO - Epoch [379/2000], Train Loss: 0.4051
2024-03-28 18:12:20,124 - config - INFO - Validation Loss: 0.4574
2024-03-28 18:12:20,124 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,142 - config - INFO - Epoch [380/2000], Train Loss: 0.4027
2024-03-28 18:12:20,146 - config - INFO - Validation Loss: 0.4617
2024-03-28 18:12:20,146 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,165 - config - INFO - Epoch [381/2000], Train Loss: 0.4024
2024-03-28 18:12:20,169 - config - INFO - Validation Loss: 0.4625
2024-03-28 18:12:20,169 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,187 - config - INFO - Epoch [382/2000], Train Loss: 0.4033
2024-03-28 18:12:20,191 - config - INFO - Validation Loss: 0.4654
2024-03-28 18:12:20,191 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:20,210 - config - INFO - Epoch [383/2000], Train Loss: 0.4023
2024-03-28 18:12:20,213 - config - INFO - Validation Loss: 0.4604
2024-03-28 18:12:20,214 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,232 - config - INFO - Epoch [384/2000], Train Loss: 0.4017
2024-03-28 18:12:20,236 - config - INFO - Validation Loss: 0.4586
2024-03-28 18:12:20,236 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,255 - config - INFO - Epoch [385/2000], Train Loss: 0.4025
2024-03-28 18:12:20,258 - config - INFO - Validation Loss: 0.4577
2024-03-28 18:12:20,259 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,277 - config - INFO - Epoch [386/2000], Train Loss: 0.4020
2024-03-28 18:12:20,281 - config - INFO - Validation Loss: 0.4599
2024-03-28 18:12:20,281 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,300 - config - INFO - Epoch [387/2000], Train Loss: 0.4014
2024-03-28 18:12:20,303 - config - INFO - Validation Loss: 0.4601
2024-03-28 18:12:20,304 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:20,322 - config - INFO - Epoch [388/2000], Train Loss: 0.4019
2024-03-28 18:12:20,326 - config - INFO - Validation Loss: 0.4615
2024-03-28 18:12:20,326 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:20,344 - config - INFO - Epoch [389/2000], Train Loss: 0.4016
2024-03-28 18:12:20,348 - config - INFO - Validation Loss: 0.4609
2024-03-28 18:12:20,349 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,367 - config - INFO - Epoch [390/2000], Train Loss: 0.4010
2024-03-28 18:12:20,371 - config - INFO - Validation Loss: 0.4575
2024-03-28 18:12:20,371 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,389 - config - INFO - Epoch [391/2000], Train Loss: 0.4016
2024-03-28 18:12:20,393 - config - INFO - Validation Loss: 0.4586
2024-03-28 18:12:20,393 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:20,412 - config - INFO - Epoch [392/2000], Train Loss: 0.4003
2024-03-28 18:12:20,416 - config - INFO - Validation Loss: 0.4633
2024-03-28 18:12:20,416 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,434 - config - INFO - Epoch [393/2000], Train Loss: 0.4018
2024-03-28 18:12:20,438 - config - INFO - Validation Loss: 0.4683
2024-03-28 18:12:20,438 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:20,457 - config - INFO - Epoch [394/2000], Train Loss: 0.4016
2024-03-28 18:12:20,461 - config - INFO - Validation Loss: 0.4651
2024-03-28 18:12:20,461 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,479 - config - INFO - Epoch [395/2000], Train Loss: 0.4010
2024-03-28 18:12:20,483 - config - INFO - Validation Loss: 0.4625
2024-03-28 18:12:20,483 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,502 - config - INFO - Epoch [396/2000], Train Loss: 0.4003
2024-03-28 18:12:20,506 - config - INFO - Validation Loss: 0.4625
2024-03-28 18:12:20,506 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,524 - config - INFO - Epoch [397/2000], Train Loss: 0.4004
2024-03-28 18:12:20,528 - config - INFO - Validation Loss: 0.4617
2024-03-28 18:12:20,528 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,547 - config - INFO - Epoch [398/2000], Train Loss: 0.4009
2024-03-28 18:12:20,551 - config - INFO - Validation Loss: 0.4624
2024-03-28 18:12:20,551 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,569 - config - INFO - Epoch [399/2000], Train Loss: 0.4003
2024-03-28 18:12:20,573 - config - INFO - Validation Loss: 0.4616
2024-03-28 18:12:20,574 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,592 - config - INFO - Epoch [400/2000], Train Loss: 0.4011
2024-03-28 18:12:20,596 - config - INFO - Validation Loss: 0.4583
2024-03-28 18:12:20,596 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,614 - config - INFO - Epoch [401/2000], Train Loss: 0.3998
2024-03-28 18:12:20,618 - config - INFO - Validation Loss: 0.4602
2024-03-28 18:12:20,618 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,637 - config - INFO - Epoch [402/2000], Train Loss: 0.4001
2024-03-28 18:12:20,641 - config - INFO - Validation Loss: 0.4626
2024-03-28 18:12:20,641 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:20,659 - config - INFO - Epoch [403/2000], Train Loss: 0.3999
2024-03-28 18:12:20,663 - config - INFO - Validation Loss: 0.4613
2024-03-28 18:12:20,663 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,682 - config - INFO - Epoch [404/2000], Train Loss: 0.3995
2024-03-28 18:12:20,686 - config - INFO - Validation Loss: 0.4597
2024-03-28 18:12:20,686 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,704 - config - INFO - Epoch [405/2000], Train Loss: 0.3995
2024-03-28 18:12:20,708 - config - INFO - Validation Loss: 0.4608
2024-03-28 18:12:20,708 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,727 - config - INFO - Epoch [406/2000], Train Loss: 0.4000
2024-03-28 18:12:20,731 - config - INFO - Validation Loss: 0.4603
2024-03-28 18:12:20,731 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,749 - config - INFO - Epoch [407/2000], Train Loss: 0.3991
2024-03-28 18:12:20,753 - config - INFO - Validation Loss: 0.4614
2024-03-28 18:12:20,753 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,772 - config - INFO - Epoch [408/2000], Train Loss: 0.3991
2024-03-28 18:12:20,776 - config - INFO - Validation Loss: 0.4623
2024-03-28 18:12:20,776 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,794 - config - INFO - Epoch [409/2000], Train Loss: 0.3990
2024-03-28 18:12:20,798 - config - INFO - Validation Loss: 0.4622
2024-03-28 18:12:20,798 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:20,817 - config - INFO - Epoch [410/2000], Train Loss: 0.3990
2024-03-28 18:12:20,821 - config - INFO - Validation Loss: 0.4627
2024-03-28 18:12:20,821 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:20,839 - config - INFO - Epoch [411/2000], Train Loss: 0.3990
2024-03-28 18:12:20,843 - config - INFO - Validation Loss: 0.4609
2024-03-28 18:12:20,843 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,862 - config - INFO - Epoch [412/2000], Train Loss: 0.3987
2024-03-28 18:12:20,866 - config - INFO - Validation Loss: 0.4618
2024-03-28 18:12:20,866 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:20,884 - config - INFO - Epoch [413/2000], Train Loss: 0.3990
2024-03-28 18:12:20,888 - config - INFO - Validation Loss: 0.4589
2024-03-28 18:12:20,888 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,907 - config - INFO - Epoch [414/2000], Train Loss: 0.3990
2024-03-28 18:12:20,910 - config - INFO - Validation Loss: 0.4614
2024-03-28 18:12:20,911 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,929 - config - INFO - Epoch [415/2000], Train Loss: 0.3986
2024-03-28 18:12:20,933 - config - INFO - Validation Loss: 0.4604
2024-03-28 18:12:20,933 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,951 - config - INFO - Epoch [416/2000], Train Loss: 0.3984
2024-03-28 18:12:20,955 - config - INFO - Validation Loss: 0.4621
2024-03-28 18:12:20,955 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,974 - config - INFO - Epoch [417/2000], Train Loss: 0.3977
2024-03-28 18:12:20,978 - config - INFO - Validation Loss: 0.4599
2024-03-28 18:12:20,978 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:20,996 - config - INFO - Epoch [418/2000], Train Loss: 0.3981
2024-03-28 18:12:21,000 - config - INFO - Validation Loss: 0.4594
2024-03-28 18:12:21,001 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:21,019 - config - INFO - Epoch [419/2000], Train Loss: 0.3985
2024-03-28 18:12:21,023 - config - INFO - Validation Loss: 0.4628
2024-03-28 18:12:21,023 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,041 - config - INFO - Epoch [420/2000], Train Loss: 0.3981
2024-03-28 18:12:21,045 - config - INFO - Validation Loss: 0.4589
2024-03-28 18:12:21,046 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,064 - config - INFO - Epoch [421/2000], Train Loss: 0.3978
2024-03-28 18:12:21,068 - config - INFO - Validation Loss: 0.4576
2024-03-28 18:12:21,068 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:21,086 - config - INFO - Epoch [422/2000], Train Loss: 0.3974
2024-03-28 18:12:21,090 - config - INFO - Validation Loss: 0.4579
2024-03-28 18:12:21,090 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:21,109 - config - INFO - Epoch [423/2000], Train Loss: 0.3976
2024-03-28 18:12:21,113 - config - INFO - Validation Loss: 0.4574
2024-03-28 18:12:21,113 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:21,131 - config - INFO - Epoch [424/2000], Train Loss: 0.3973
2024-03-28 18:12:21,135 - config - INFO - Validation Loss: 0.4591
2024-03-28 18:12:21,135 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,154 - config - INFO - Epoch [425/2000], Train Loss: 0.3969
2024-03-28 18:12:21,158 - config - INFO - Validation Loss: 0.4582
2024-03-28 18:12:21,158 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:21,176 - config - INFO - Epoch [426/2000], Train Loss: 0.3971
2024-03-28 18:12:21,180 - config - INFO - Validation Loss: 0.4562
2024-03-28 18:12:21,180 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:21,199 - config - INFO - Epoch [427/2000], Train Loss: 0.3969
2024-03-28 18:12:21,203 - config - INFO - Validation Loss: 0.4575
2024-03-28 18:12:21,203 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:21,221 - config - INFO - Epoch [428/2000], Train Loss: 0.3964
2024-03-28 18:12:21,225 - config - INFO - Validation Loss: 0.4602
2024-03-28 18:12:21,225 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,244 - config - INFO - Epoch [429/2000], Train Loss: 0.3965
2024-03-28 18:12:21,248 - config - INFO - Validation Loss: 0.4629
2024-03-28 18:12:21,248 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,266 - config - INFO - Epoch [430/2000], Train Loss: 0.3974
2024-03-28 18:12:21,270 - config - INFO - Validation Loss: 0.4616
2024-03-28 18:12:21,270 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,289 - config - INFO - Epoch [431/2000], Train Loss: 0.3967
2024-03-28 18:12:21,292 - config - INFO - Validation Loss: 0.4610
2024-03-28 18:12:21,293 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,311 - config - INFO - Epoch [432/2000], Train Loss: 0.3963
2024-03-28 18:12:21,315 - config - INFO - Validation Loss: 0.4627
2024-03-28 18:12:21,315 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,334 - config - INFO - Epoch [433/2000], Train Loss: 0.3964
2024-03-28 18:12:21,338 - config - INFO - Validation Loss: 0.4628
2024-03-28 18:12:21,338 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,356 - config - INFO - Epoch [434/2000], Train Loss: 0.3962
2024-03-28 18:12:21,360 - config - INFO - Validation Loss: 0.4601
2024-03-28 18:12:21,360 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,379 - config - INFO - Epoch [435/2000], Train Loss: 0.3961
2024-03-28 18:12:21,383 - config - INFO - Validation Loss: 0.4586
2024-03-28 18:12:21,383 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,401 - config - INFO - Epoch [436/2000], Train Loss: 0.3959
2024-03-28 18:12:21,405 - config - INFO - Validation Loss: 0.4585
2024-03-28 18:12:21,405 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,424 - config - INFO - Epoch [437/2000], Train Loss: 0.3958
2024-03-28 18:12:21,428 - config - INFO - Validation Loss: 0.4582
2024-03-28 18:12:21,428 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:21,446 - config - INFO - Epoch [438/2000], Train Loss: 0.3958
2024-03-28 18:12:21,450 - config - INFO - Validation Loss: 0.4574
2024-03-28 18:12:21,456 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:21,482 - config - INFO - Epoch [439/2000], Train Loss: 0.3959
2024-03-28 18:12:21,486 - config - INFO - Validation Loss: 0.4566
2024-03-28 18:12:21,486 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,504 - config - INFO - Epoch [440/2000], Train Loss: 0.3953
2024-03-28 18:12:21,508 - config - INFO - Validation Loss: 0.4580
2024-03-28 18:12:21,508 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:21,527 - config - INFO - Epoch [441/2000], Train Loss: 0.3950
2024-03-28 18:12:21,531 - config - INFO - Validation Loss: 0.4606
2024-03-28 18:12:21,531 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,549 - config - INFO - Epoch [442/2000], Train Loss: 0.3951
2024-03-28 18:12:21,553 - config - INFO - Validation Loss: 0.4615
2024-03-28 18:12:21,553 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,572 - config - INFO - Epoch [443/2000], Train Loss: 0.3958
2024-03-28 18:12:21,576 - config - INFO - Validation Loss: 0.4573
2024-03-28 18:12:21,576 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:21,594 - config - INFO - Epoch [444/2000], Train Loss: 0.3955
2024-03-28 18:12:21,598 - config - INFO - Validation Loss: 0.4601
2024-03-28 18:12:21,598 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,617 - config - INFO - Epoch [445/2000], Train Loss: 0.3948
2024-03-28 18:12:21,621 - config - INFO - Validation Loss: 0.4610
2024-03-28 18:12:21,621 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,639 - config - INFO - Epoch [446/2000], Train Loss: 0.3949
2024-03-28 18:12:21,643 - config - INFO - Validation Loss: 0.4575
2024-03-28 18:12:21,643 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:21,662 - config - INFO - Epoch [447/2000], Train Loss: 0.3946
2024-03-28 18:12:21,666 - config - INFO - Validation Loss: 0.4594
2024-03-28 18:12:21,666 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,684 - config - INFO - Epoch [448/2000], Train Loss: 0.3948
2024-03-28 18:12:21,688 - config - INFO - Validation Loss: 0.4609
2024-03-28 18:12:21,688 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,707 - config - INFO - Epoch [449/2000], Train Loss: 0.3941
2024-03-28 18:12:21,711 - config - INFO - Validation Loss: 0.4580
2024-03-28 18:12:21,711 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,729 - config - INFO - Epoch [450/2000], Train Loss: 0.3942
2024-03-28 18:12:21,733 - config - INFO - Validation Loss: 0.4587
2024-03-28 18:12:21,734 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,752 - config - INFO - Epoch [451/2000], Train Loss: 0.3942
2024-03-28 18:12:21,756 - config - INFO - Validation Loss: 0.4570
2024-03-28 18:12:21,756 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:21,774 - config - INFO - Epoch [452/2000], Train Loss: 0.3940
2024-03-28 18:12:21,778 - config - INFO - Validation Loss: 0.4575
2024-03-28 18:12:21,778 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,797 - config - INFO - Epoch [453/2000], Train Loss: 0.3952
2024-03-28 18:12:21,801 - config - INFO - Validation Loss: 0.4566
2024-03-28 18:12:21,801 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:21,819 - config - INFO - Epoch [454/2000], Train Loss: 0.3936
2024-03-28 18:12:21,823 - config - INFO - Validation Loss: 0.4566
2024-03-28 18:12:21,823 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:21,842 - config - INFO - Epoch [455/2000], Train Loss: 0.3933
2024-03-28 18:12:21,846 - config - INFO - Validation Loss: 0.4582
2024-03-28 18:12:21,846 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,864 - config - INFO - Epoch [456/2000], Train Loss: 0.3942
2024-03-28 18:12:21,868 - config - INFO - Validation Loss: 0.4591
2024-03-28 18:12:21,868 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,887 - config - INFO - Epoch [457/2000], Train Loss: 0.3941
2024-03-28 18:12:21,891 - config - INFO - Validation Loss: 0.4592
2024-03-28 18:12:21,891 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,910 - config - INFO - Epoch [458/2000], Train Loss: 0.3938
2024-03-28 18:12:21,913 - config - INFO - Validation Loss: 0.4562
2024-03-28 18:12:21,914 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:21,932 - config - INFO - Epoch [459/2000], Train Loss: 0.3933
2024-03-28 18:12:21,936 - config - INFO - Validation Loss: 0.4559
2024-03-28 18:12:21,936 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:21,954 - config - INFO - Epoch [460/2000], Train Loss: 0.3931
2024-03-28 18:12:21,958 - config - INFO - Validation Loss: 0.4580
2024-03-28 18:12:21,959 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:21,977 - config - INFO - Epoch [461/2000], Train Loss: 0.3930
2024-03-28 18:12:21,981 - config - INFO - Validation Loss: 0.4604
2024-03-28 18:12:21,981 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,000 - config - INFO - Epoch [462/2000], Train Loss: 0.3928
2024-03-28 18:12:22,003 - config - INFO - Validation Loss: 0.4586
2024-03-28 18:12:22,004 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,022 - config - INFO - Epoch [463/2000], Train Loss: 0.3926
2024-03-28 18:12:22,026 - config - INFO - Validation Loss: 0.4587
2024-03-28 18:12:22,026 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:22,045 - config - INFO - Epoch [464/2000], Train Loss: 0.3925
2024-03-28 18:12:22,049 - config - INFO - Validation Loss: 0.4594
2024-03-28 18:12:22,049 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:22,067 - config - INFO - Epoch [465/2000], Train Loss: 0.3923
2024-03-28 18:12:22,071 - config - INFO - Validation Loss: 0.4621
2024-03-28 18:12:22,071 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,090 - config - INFO - Epoch [466/2000], Train Loss: 0.3940
2024-03-28 18:12:22,099 - config - INFO - Validation Loss: 0.4637
2024-03-28 18:12:22,099 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,119 - config - INFO - Epoch [467/2000], Train Loss: 0.3934
2024-03-28 18:12:22,123 - config - INFO - Validation Loss: 0.4567
2024-03-28 18:12:22,123 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:22,141 - config - INFO - Epoch [468/2000], Train Loss: 0.3921
2024-03-28 18:12:22,145 - config - INFO - Validation Loss: 0.4560
2024-03-28 18:12:22,145 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:22,164 - config - INFO - Epoch [469/2000], Train Loss: 0.3919
2024-03-28 18:12:22,168 - config - INFO - Validation Loss: 0.4613
2024-03-28 18:12:22,168 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,186 - config - INFO - Epoch [470/2000], Train Loss: 0.3918
2024-03-28 18:12:22,190 - config - INFO - Validation Loss: 0.4593
2024-03-28 18:12:22,190 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:22,209 - config - INFO - Epoch [471/2000], Train Loss: 0.3916
2024-03-28 18:12:22,213 - config - INFO - Validation Loss: 0.4589
2024-03-28 18:12:22,213 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:22,232 - config - INFO - Epoch [472/2000], Train Loss: 0.3914
2024-03-28 18:12:22,235 - config - INFO - Validation Loss: 0.4573
2024-03-28 18:12:22,236 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:22,254 - config - INFO - Epoch [473/2000], Train Loss: 0.3920
2024-03-28 18:12:22,258 - config - INFO - Validation Loss: 0.4557
2024-03-28 18:12:22,258 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:22,276 - config - INFO - Epoch [474/2000], Train Loss: 0.3907
2024-03-28 18:12:22,280 - config - INFO - Validation Loss: 0.4605
2024-03-28 18:12:22,281 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,299 - config - INFO - Epoch [475/2000], Train Loss: 0.3936
2024-03-28 18:12:22,303 - config - INFO - Validation Loss: 0.4648
2024-03-28 18:12:22,303 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,321 - config - INFO - Epoch [476/2000], Train Loss: 0.3932
2024-03-28 18:12:22,325 - config - INFO - Validation Loss: 0.4543
2024-03-28 18:12:22,326 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:22,344 - config - INFO - Epoch [477/2000], Train Loss: 0.3920
2024-03-28 18:12:22,348 - config - INFO - Validation Loss: 0.4576
2024-03-28 18:12:22,348 - config - INFO - Validation Acc: 0.8800
2024-03-28 18:12:22,367 - config - INFO - Epoch [478/2000], Train Loss: 0.3910
2024-03-28 18:12:22,371 - config - INFO - Validation Loss: 0.4592
2024-03-28 18:12:22,371 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,389 - config - INFO - Epoch [479/2000], Train Loss: 0.3906
2024-03-28 18:12:22,393 - config - INFO - Validation Loss: 0.4569
2024-03-28 18:12:22,393 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,412 - config - INFO - Epoch [480/2000], Train Loss: 0.3906
2024-03-28 18:12:22,416 - config - INFO - Validation Loss: 0.4580
2024-03-28 18:12:22,416 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,434 - config - INFO - Epoch [481/2000], Train Loss: 0.3905
2024-03-28 18:12:22,438 - config - INFO - Validation Loss: 0.4593
2024-03-28 18:12:22,438 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,457 - config - INFO - Epoch [482/2000], Train Loss: 0.3905
2024-03-28 18:12:22,460 - config - INFO - Validation Loss: 0.4568
2024-03-28 18:12:22,461 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,479 - config - INFO - Epoch [483/2000], Train Loss: 0.3900
2024-03-28 18:12:22,483 - config - INFO - Validation Loss: 0.4570
2024-03-28 18:12:22,483 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,502 - config - INFO - Epoch [484/2000], Train Loss: 0.3898
2024-03-28 18:12:22,505 - config - INFO - Validation Loss: 0.4566
2024-03-28 18:12:22,506 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,524 - config - INFO - Epoch [485/2000], Train Loss: 0.3899
2024-03-28 18:12:22,528 - config - INFO - Validation Loss: 0.4573
2024-03-28 18:12:22,528 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,546 - config - INFO - Epoch [486/2000], Train Loss: 0.3897
2024-03-28 18:12:22,550 - config - INFO - Validation Loss: 0.4577
2024-03-28 18:12:22,551 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,569 - config - INFO - Epoch [487/2000], Train Loss: 0.3895
2024-03-28 18:12:22,573 - config - INFO - Validation Loss: 0.4578
2024-03-28 18:12:22,573 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,591 - config - INFO - Epoch [488/2000], Train Loss: 0.3894
2024-03-28 18:12:22,595 - config - INFO - Validation Loss: 0.4556
2024-03-28 18:12:22,595 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,614 - config - INFO - Epoch [489/2000], Train Loss: 0.3894
2024-03-28 18:12:22,618 - config - INFO - Validation Loss: 0.4549
2024-03-28 18:12:22,618 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,636 - config - INFO - Epoch [490/2000], Train Loss: 0.3892
2024-03-28 18:12:22,640 - config - INFO - Validation Loss: 0.4551
2024-03-28 18:12:22,640 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,659 - config - INFO - Epoch [491/2000], Train Loss: 0.3892
2024-03-28 18:12:22,663 - config - INFO - Validation Loss: 0.4556
2024-03-28 18:12:22,663 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,681 - config - INFO - Epoch [492/2000], Train Loss: 0.3894
2024-03-28 18:12:22,685 - config - INFO - Validation Loss: 0.4557
2024-03-28 18:12:22,685 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,704 - config - INFO - Epoch [493/2000], Train Loss: 0.3891
2024-03-28 18:12:22,708 - config - INFO - Validation Loss: 0.4549
2024-03-28 18:12:22,708 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,726 - config - INFO - Epoch [494/2000], Train Loss: 0.3890
2024-03-28 18:12:22,730 - config - INFO - Validation Loss: 0.4570
2024-03-28 18:12:22,731 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,749 - config - INFO - Epoch [495/2000], Train Loss: 0.3888
2024-03-28 18:12:22,753 - config - INFO - Validation Loss: 0.4580
2024-03-28 18:12:22,753 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,771 - config - INFO - Epoch [496/2000], Train Loss: 0.3885
2024-03-28 18:12:22,775 - config - INFO - Validation Loss: 0.4576
2024-03-28 18:12:22,775 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,794 - config - INFO - Epoch [497/2000], Train Loss: 0.3885
2024-03-28 18:12:22,798 - config - INFO - Validation Loss: 0.4586
2024-03-28 18:12:22,798 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,816 - config - INFO - Epoch [498/2000], Train Loss: 0.3882
2024-03-28 18:12:22,820 - config - INFO - Validation Loss: 0.4586
2024-03-28 18:12:22,820 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,839 - config - INFO - Epoch [499/2000], Train Loss: 0.3884
2024-03-28 18:12:22,843 - config - INFO - Validation Loss: 0.4614
2024-03-28 18:12:22,843 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,861 - config - INFO - Epoch [500/2000], Train Loss: 0.3884
2024-03-28 18:12:22,865 - config - INFO - Validation Loss: 0.4586
2024-03-28 18:12:22,865 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,884 - config - INFO - Epoch [501/2000], Train Loss: 0.3878
2024-03-28 18:12:22,888 - config - INFO - Validation Loss: 0.4591
2024-03-28 18:12:22,888 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,906 - config - INFO - Epoch [502/2000], Train Loss: 0.3878
2024-03-28 18:12:22,910 - config - INFO - Validation Loss: 0.4603
2024-03-28 18:12:22,910 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,929 - config - INFO - Epoch [503/2000], Train Loss: 0.3881
2024-03-28 18:12:22,933 - config - INFO - Validation Loss: 0.4616
2024-03-28 18:12:22,933 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,951 - config - INFO - Epoch [504/2000], Train Loss: 0.3899
2024-03-28 18:12:22,955 - config - INFO - Validation Loss: 0.4585
2024-03-28 18:12:22,955 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:22,974 - config - INFO - Epoch [505/2000], Train Loss: 0.3879
2024-03-28 18:12:22,978 - config - INFO - Validation Loss: 0.4603
2024-03-28 18:12:22,978 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:22,996 - config - INFO - Epoch [506/2000], Train Loss: 0.3873
2024-03-28 18:12:23,000 - config - INFO - Validation Loss: 0.4614
2024-03-28 18:12:23,001 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:23,019 - config - INFO - Epoch [507/2000], Train Loss: 0.3874
2024-03-28 18:12:23,023 - config - INFO - Validation Loss: 0.4627
2024-03-28 18:12:23,023 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,041 - config - INFO - Epoch [508/2000], Train Loss: 0.3874
2024-03-28 18:12:23,045 - config - INFO - Validation Loss: 0.4608
2024-03-28 18:12:23,046 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,064 - config - INFO - Epoch [509/2000], Train Loss: 0.3884
2024-03-28 18:12:23,068 - config - INFO - Validation Loss: 0.4592
2024-03-28 18:12:23,068 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,087 - config - INFO - Epoch [510/2000], Train Loss: 0.3873
2024-03-28 18:12:23,090 - config - INFO - Validation Loss: 0.4628
2024-03-28 18:12:23,091 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,109 - config - INFO - Epoch [511/2000], Train Loss: 0.3873
2024-03-28 18:12:23,113 - config - INFO - Validation Loss: 0.4608
2024-03-28 18:12:23,113 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,131 - config - INFO - Epoch [512/2000], Train Loss: 0.3870
2024-03-28 18:12:23,135 - config - INFO - Validation Loss: 0.4580
2024-03-28 18:12:23,136 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,154 - config - INFO - Epoch [513/2000], Train Loss: 0.3865
2024-03-28 18:12:23,158 - config - INFO - Validation Loss: 0.4570
2024-03-28 18:12:23,158 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,177 - config - INFO - Epoch [514/2000], Train Loss: 0.3873
2024-03-28 18:12:23,181 - config - INFO - Validation Loss: 0.4583
2024-03-28 18:12:23,181 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,199 - config - INFO - Epoch [515/2000], Train Loss: 0.3858
2024-03-28 18:12:23,203 - config - INFO - Validation Loss: 0.4571
2024-03-28 18:12:23,203 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,222 - config - INFO - Epoch [516/2000], Train Loss: 0.3867
2024-03-28 18:12:23,226 - config - INFO - Validation Loss: 0.4559
2024-03-28 18:12:23,226 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,244 - config - INFO - Epoch [517/2000], Train Loss: 0.3865
2024-03-28 18:12:23,248 - config - INFO - Validation Loss: 0.4596
2024-03-28 18:12:23,248 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,267 - config - INFO - Epoch [518/2000], Train Loss: 0.3860
2024-03-28 18:12:23,271 - config - INFO - Validation Loss: 0.4613
2024-03-28 18:12:23,271 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,290 - config - INFO - Epoch [519/2000], Train Loss: 0.3860
2024-03-28 18:12:23,293 - config - INFO - Validation Loss: 0.4605
2024-03-28 18:12:23,294 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,312 - config - INFO - Epoch [520/2000], Train Loss: 0.3871
2024-03-28 18:12:23,316 - config - INFO - Validation Loss: 0.4576
2024-03-28 18:12:23,316 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,335 - config - INFO - Epoch [521/2000], Train Loss: 0.3855
2024-03-28 18:12:23,338 - config - INFO - Validation Loss: 0.4597
2024-03-28 18:12:23,339 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,357 - config - INFO - Epoch [522/2000], Train Loss: 0.3858
2024-03-28 18:12:23,361 - config - INFO - Validation Loss: 0.4621
2024-03-28 18:12:23,361 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,380 - config - INFO - Epoch [523/2000], Train Loss: 0.3857
2024-03-28 18:12:23,384 - config - INFO - Validation Loss: 0.4600
2024-03-28 18:12:23,384 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,402 - config - INFO - Epoch [524/2000], Train Loss: 0.3854
2024-03-28 18:12:23,406 - config - INFO - Validation Loss: 0.4604
2024-03-28 18:12:23,406 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,425 - config - INFO - Epoch [525/2000], Train Loss: 0.3853
2024-03-28 18:12:23,429 - config - INFO - Validation Loss: 0.4573
2024-03-28 18:12:23,429 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,447 - config - INFO - Epoch [526/2000], Train Loss: 0.3855
2024-03-28 18:12:23,451 - config - INFO - Validation Loss: 0.4587
2024-03-28 18:12:23,451 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,470 - config - INFO - Epoch [527/2000], Train Loss: 0.3847
2024-03-28 18:12:23,474 - config - INFO - Validation Loss: 0.4579
2024-03-28 18:12:23,474 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,492 - config - INFO - Epoch [528/2000], Train Loss: 0.3848
2024-03-28 18:12:23,496 - config - INFO - Validation Loss: 0.4586
2024-03-28 18:12:23,496 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,515 - config - INFO - Epoch [529/2000], Train Loss: 0.3848
2024-03-28 18:12:23,519 - config - INFO - Validation Loss: 0.4558
2024-03-28 18:12:23,519 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,537 - config - INFO - Epoch [530/2000], Train Loss: 0.3849
2024-03-28 18:12:23,541 - config - INFO - Validation Loss: 0.4548
2024-03-28 18:12:23,542 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,560 - config - INFO - Epoch [531/2000], Train Loss: 0.3847
2024-03-28 18:12:23,564 - config - INFO - Validation Loss: 0.4541
2024-03-28 18:12:23,564 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,583 - config - INFO - Epoch [532/2000], Train Loss: 0.3852
2024-03-28 18:12:23,587 - config - INFO - Validation Loss: 0.4543
2024-03-28 18:12:23,587 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,605 - config - INFO - Epoch [533/2000], Train Loss: 0.3848
2024-03-28 18:12:23,609 - config - INFO - Validation Loss: 0.4576
2024-03-28 18:12:23,609 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,628 - config - INFO - Epoch [534/2000], Train Loss: 0.3842
2024-03-28 18:12:23,632 - config - INFO - Validation Loss: 0.4568
2024-03-28 18:12:23,632 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,650 - config - INFO - Epoch [535/2000], Train Loss: 0.3848
2024-03-28 18:12:23,654 - config - INFO - Validation Loss: 0.4588
2024-03-28 18:12:23,654 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,673 - config - INFO - Epoch [536/2000], Train Loss: 0.3848
2024-03-28 18:12:23,677 - config - INFO - Validation Loss: 0.4560
2024-03-28 18:12:23,677 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,695 - config - INFO - Epoch [537/2000], Train Loss: 0.3839
2024-03-28 18:12:23,699 - config - INFO - Validation Loss: 0.4577
2024-03-28 18:12:23,699 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,718 - config - INFO - Epoch [538/2000], Train Loss: 0.3840
2024-03-28 18:12:23,722 - config - INFO - Validation Loss: 0.4564
2024-03-28 18:12:23,722 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,740 - config - INFO - Epoch [539/2000], Train Loss: 0.3836
2024-03-28 18:12:23,744 - config - INFO - Validation Loss: 0.4571
2024-03-28 18:12:23,745 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,766 - config - INFO - Epoch [540/2000], Train Loss: 0.3844
2024-03-28 18:12:23,770 - config - INFO - Validation Loss: 0.4573
2024-03-28 18:12:23,771 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,789 - config - INFO - Epoch [541/2000], Train Loss: 0.3832
2024-03-28 18:12:23,793 - config - INFO - Validation Loss: 0.4602
2024-03-28 18:12:23,793 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,812 - config - INFO - Epoch [542/2000], Train Loss: 0.3835
2024-03-28 18:12:23,816 - config - INFO - Validation Loss: 0.4613
2024-03-28 18:12:23,816 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,834 - config - INFO - Epoch [543/2000], Train Loss: 0.3834
2024-03-28 18:12:23,838 - config - INFO - Validation Loss: 0.4597
2024-03-28 18:12:23,838 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,857 - config - INFO - Epoch [544/2000], Train Loss: 0.3831
2024-03-28 18:12:23,861 - config - INFO - Validation Loss: 0.4610
2024-03-28 18:12:23,861 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,879 - config - INFO - Epoch [545/2000], Train Loss: 0.3837
2024-03-28 18:12:23,883 - config - INFO - Validation Loss: 0.4578
2024-03-28 18:12:23,883 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,902 - config - INFO - Epoch [546/2000], Train Loss: 0.3826
2024-03-28 18:12:23,906 - config - INFO - Validation Loss: 0.4594
2024-03-28 18:12:23,906 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,924 - config - INFO - Epoch [547/2000], Train Loss: 0.3827
2024-03-28 18:12:23,928 - config - INFO - Validation Loss: 0.4597
2024-03-28 18:12:23,928 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,947 - config - INFO - Epoch [548/2000], Train Loss: 0.3830
2024-03-28 18:12:23,951 - config - INFO - Validation Loss: 0.4577
2024-03-28 18:12:23,951 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,970 - config - INFO - Epoch [549/2000], Train Loss: 0.3826
2024-03-28 18:12:23,973 - config - INFO - Validation Loss: 0.4566
2024-03-28 18:12:23,974 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:23,992 - config - INFO - Epoch [550/2000], Train Loss: 0.3821
2024-03-28 18:12:23,996 - config - INFO - Validation Loss: 0.4572
2024-03-28 18:12:23,996 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,015 - config - INFO - Epoch [551/2000], Train Loss: 0.3824
2024-03-28 18:12:24,019 - config - INFO - Validation Loss: 0.4573
2024-03-28 18:12:24,019 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,037 - config - INFO - Epoch [552/2000], Train Loss: 0.3823
2024-03-28 18:12:24,041 - config - INFO - Validation Loss: 0.4568
2024-03-28 18:12:24,041 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,060 - config - INFO - Epoch [553/2000], Train Loss: 0.3817
2024-03-28 18:12:24,064 - config - INFO - Validation Loss: 0.4564
2024-03-28 18:12:24,064 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,082 - config - INFO - Epoch [554/2000], Train Loss: 0.3821
2024-03-28 18:12:24,086 - config - INFO - Validation Loss: 0.4577
2024-03-28 18:12:24,087 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,105 - config - INFO - Epoch [555/2000], Train Loss: 0.3825
2024-03-28 18:12:24,109 - config - INFO - Validation Loss: 0.4599
2024-03-28 18:12:24,109 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,128 - config - INFO - Epoch [556/2000], Train Loss: 0.3818
2024-03-28 18:12:24,132 - config - INFO - Validation Loss: 0.4580
2024-03-28 18:12:24,132 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,150 - config - INFO - Epoch [557/2000], Train Loss: 0.3818
2024-03-28 18:12:24,154 - config - INFO - Validation Loss: 0.4577
2024-03-28 18:12:24,154 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,173 - config - INFO - Epoch [558/2000], Train Loss: 0.3816
2024-03-28 18:12:24,177 - config - INFO - Validation Loss: 0.4568
2024-03-28 18:12:24,177 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,195 - config - INFO - Epoch [559/2000], Train Loss: 0.3812
2024-03-28 18:12:24,199 - config - INFO - Validation Loss: 0.4572
2024-03-28 18:12:24,199 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,218 - config - INFO - Epoch [560/2000], Train Loss: 0.3814
2024-03-28 18:12:24,222 - config - INFO - Validation Loss: 0.4581
2024-03-28 18:12:24,222 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,240 - config - INFO - Epoch [561/2000], Train Loss: 0.3816
2024-03-28 18:12:24,244 - config - INFO - Validation Loss: 0.4563
2024-03-28 18:12:24,244 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,263 - config - INFO - Epoch [562/2000], Train Loss: 0.3809
2024-03-28 18:12:24,267 - config - INFO - Validation Loss: 0.4574
2024-03-28 18:12:24,267 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,285 - config - INFO - Epoch [563/2000], Train Loss: 0.3807
2024-03-28 18:12:24,289 - config - INFO - Validation Loss: 0.4602
2024-03-28 18:12:24,290 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,308 - config - INFO - Epoch [564/2000], Train Loss: 0.3820
2024-03-28 18:12:24,312 - config - INFO - Validation Loss: 0.4616
2024-03-28 18:12:24,312 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,330 - config - INFO - Epoch [565/2000], Train Loss: 0.3807
2024-03-28 18:12:24,334 - config - INFO - Validation Loss: 0.4552
2024-03-28 18:12:24,335 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,353 - config - INFO - Epoch [566/2000], Train Loss: 0.3809
2024-03-28 18:12:24,357 - config - INFO - Validation Loss: 0.4555
2024-03-28 18:12:24,357 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,376 - config - INFO - Epoch [567/2000], Train Loss: 0.3804
2024-03-28 18:12:24,380 - config - INFO - Validation Loss: 0.4587
2024-03-28 18:12:24,380 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,398 - config - INFO - Epoch [568/2000], Train Loss: 0.3801
2024-03-28 18:12:24,402 - config - INFO - Validation Loss: 0.4600
2024-03-28 18:12:24,402 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,421 - config - INFO - Epoch [569/2000], Train Loss: 0.3810
2024-03-28 18:12:24,425 - config - INFO - Validation Loss: 0.4626
2024-03-28 18:12:24,425 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:24,443 - config - INFO - Epoch [570/2000], Train Loss: 0.3803
2024-03-28 18:12:24,447 - config - INFO - Validation Loss: 0.4560
2024-03-28 18:12:24,447 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,466 - config - INFO - Epoch [571/2000], Train Loss: 0.3805
2024-03-28 18:12:24,470 - config - INFO - Validation Loss: 0.4547
2024-03-28 18:12:24,470 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,488 - config - INFO - Epoch [572/2000], Train Loss: 0.3802
2024-03-28 18:12:24,492 - config - INFO - Validation Loss: 0.4568
2024-03-28 18:12:24,493 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,511 - config - INFO - Epoch [573/2000], Train Loss: 0.3798
2024-03-28 18:12:24,515 - config - INFO - Validation Loss: 0.4560
2024-03-28 18:12:24,515 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,534 - config - INFO - Epoch [574/2000], Train Loss: 0.3797
2024-03-28 18:12:24,538 - config - INFO - Validation Loss: 0.4579
2024-03-28 18:12:24,538 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,556 - config - INFO - Epoch [575/2000], Train Loss: 0.3803
2024-03-28 18:12:24,560 - config - INFO - Validation Loss: 0.4570
2024-03-28 18:12:24,560 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,579 - config - INFO - Epoch [576/2000], Train Loss: 0.3799
2024-03-28 18:12:24,583 - config - INFO - Validation Loss: 0.4583
2024-03-28 18:12:24,583 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,604 - config - INFO - Epoch [577/2000], Train Loss: 0.3796
2024-03-28 18:12:24,609 - config - INFO - Validation Loss: 0.4571
2024-03-28 18:12:24,609 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,627 - config - INFO - Epoch [578/2000], Train Loss: 0.3796
2024-03-28 18:12:24,631 - config - INFO - Validation Loss: 0.4585
2024-03-28 18:12:24,631 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,650 - config - INFO - Epoch [579/2000], Train Loss: 0.3795
2024-03-28 18:12:24,654 - config - INFO - Validation Loss: 0.4567
2024-03-28 18:12:24,654 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,672 - config - INFO - Epoch [580/2000], Train Loss: 0.3799
2024-03-28 18:12:24,676 - config - INFO - Validation Loss: 0.4587
2024-03-28 18:12:24,676 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,695 - config - INFO - Epoch [581/2000], Train Loss: 0.3791
2024-03-28 18:12:24,699 - config - INFO - Validation Loss: 0.4582
2024-03-28 18:12:24,699 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,717 - config - INFO - Epoch [582/2000], Train Loss: 0.3790
2024-03-28 18:12:24,721 - config - INFO - Validation Loss: 0.4557
2024-03-28 18:12:24,722 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,740 - config - INFO - Epoch [583/2000], Train Loss: 0.3789
2024-03-28 18:12:24,744 - config - INFO - Validation Loss: 0.4571
2024-03-28 18:12:24,744 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,763 - config - INFO - Epoch [584/2000], Train Loss: 0.3785
2024-03-28 18:12:24,767 - config - INFO - Validation Loss: 0.4565
2024-03-28 18:12:24,767 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,785 - config - INFO - Epoch [585/2000], Train Loss: 0.3785
2024-03-28 18:12:24,789 - config - INFO - Validation Loss: 0.4554
2024-03-28 18:12:24,789 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,808 - config - INFO - Epoch [586/2000], Train Loss: 0.3783
2024-03-28 18:12:24,812 - config - INFO - Validation Loss: 0.4555
2024-03-28 18:12:24,812 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,831 - config - INFO - Epoch [587/2000], Train Loss: 0.3780
2024-03-28 18:12:24,834 - config - INFO - Validation Loss: 0.4562
2024-03-28 18:12:24,835 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,853 - config - INFO - Epoch [588/2000], Train Loss: 0.3782
2024-03-28 18:12:24,857 - config - INFO - Validation Loss: 0.4586
2024-03-28 18:12:24,857 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,876 - config - INFO - Epoch [589/2000], Train Loss: 0.3788
2024-03-28 18:12:24,880 - config - INFO - Validation Loss: 0.4567
2024-03-28 18:12:24,880 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,898 - config - INFO - Epoch [590/2000], Train Loss: 0.3785
2024-03-28 18:12:24,902 - config - INFO - Validation Loss: 0.4570
2024-03-28 18:12:24,902 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,921 - config - INFO - Epoch [591/2000], Train Loss: 0.3784
2024-03-28 18:12:24,925 - config - INFO - Validation Loss: 0.4543
2024-03-28 18:12:24,925 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,943 - config - INFO - Epoch [592/2000], Train Loss: 0.3783
2024-03-28 18:12:24,947 - config - INFO - Validation Loss: 0.4581
2024-03-28 18:12:24,947 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:24,966 - config - INFO - Epoch [593/2000], Train Loss: 0.3777
2024-03-28 18:12:24,970 - config - INFO - Validation Loss: 0.4564
2024-03-28 18:12:24,970 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:24,988 - config - INFO - Epoch [594/2000], Train Loss: 0.3774
2024-03-28 18:12:24,992 - config - INFO - Validation Loss: 0.4553
2024-03-28 18:12:24,993 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:25,011 - config - INFO - Epoch [595/2000], Train Loss: 0.3780
2024-03-28 18:12:25,015 - config - INFO - Validation Loss: 0.4549
2024-03-28 18:12:25,015 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:25,033 - config - INFO - Epoch [596/2000], Train Loss: 0.3783
2024-03-28 18:12:25,037 - config - INFO - Validation Loss: 0.4610
2024-03-28 18:12:25,038 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:25,056 - config - INFO - Epoch [597/2000], Train Loss: 0.3774
2024-03-28 18:12:25,060 - config - INFO - Validation Loss: 0.4598
2024-03-28 18:12:25,060 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:25,079 - config - INFO - Epoch [598/2000], Train Loss: 0.3772
2024-03-28 18:12:25,083 - config - INFO - Validation Loss: 0.4587
2024-03-28 18:12:25,083 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:25,101 - config - INFO - Epoch [599/2000], Train Loss: 0.3772
2024-03-28 18:12:25,105 - config - INFO - Validation Loss: 0.4588
2024-03-28 18:12:25,105 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:25,124 - config - INFO - Epoch [600/2000], Train Loss: 0.3773
2024-03-28 18:12:25,128 - config - INFO - Validation Loss: 0.4572
2024-03-28 18:12:25,128 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:25,146 - config - INFO - Epoch [601/2000], Train Loss: 0.3770
2024-03-28 18:12:25,150 - config - INFO - Validation Loss: 0.4549
2024-03-28 18:12:25,150 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:25,169 - config - INFO - Epoch [602/2000], Train Loss: 0.3766
2024-03-28 18:12:25,173 - config - INFO - Validation Loss: 0.4574
2024-03-28 18:12:25,173 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:25,191 - config - INFO - Epoch [603/2000], Train Loss: 0.3784
2024-03-28 18:12:25,195 - config - INFO - Validation Loss: 0.4620
2024-03-28 18:12:25,195 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:25,214 - config - INFO - Epoch [604/2000], Train Loss: 0.3762
2024-03-28 18:12:25,218 - config - INFO - Validation Loss: 0.4569
2024-03-28 18:12:25,218 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:25,237 - config - INFO - Epoch [605/2000], Train Loss: 0.3779
2024-03-28 18:12:25,240 - config - INFO - Validation Loss: 0.4539
2024-03-28 18:12:25,241 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:25,259 - config - INFO - Epoch [606/2000], Train Loss: 0.3768
2024-03-28 18:12:25,263 - config - INFO - Validation Loss: 0.4571
2024-03-28 18:12:25,263 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:25,282 - config - INFO - Epoch [607/2000], Train Loss: 0.3761
2024-03-28 18:12:25,286 - config - INFO - Validation Loss: 0.4592
2024-03-28 18:12:25,286 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:25,305 - config - INFO - Epoch [608/2000], Train Loss: 0.3761
2024-03-28 18:12:25,308 - config - INFO - Validation Loss: 0.4587
2024-03-28 18:12:25,309 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:25,327 - config - INFO - Epoch [609/2000], Train Loss: 0.3758
2024-03-28 18:12:25,331 - config - INFO - Validation Loss: 0.4594
2024-03-28 18:12:25,331 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:25,350 - config - INFO - Epoch [610/2000], Train Loss: 0.3761
2024-03-28 18:12:25,354 - config - INFO - Validation Loss: 0.4567
2024-03-28 18:12:25,354 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:25,372 - config - INFO - Epoch [611/2000], Train Loss: 0.3757
2024-03-28 18:12:25,376 - config - INFO - Validation Loss: 0.4584
2024-03-28 18:12:25,376 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:25,395 - config - INFO - Epoch [612/2000], Train Loss: 0.3762
2024-03-28 18:12:25,399 - config - INFO - Validation Loss: 0.4583
2024-03-28 18:12:25,399 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:25,417 - config - INFO - Epoch [613/2000], Train Loss: 0.3768
2024-03-28 18:12:25,421 - config - INFO - Validation Loss: 0.4542
2024-03-28 18:12:25,421 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:25,440 - config - INFO - Epoch [614/2000], Train Loss: 0.3757
2024-03-28 18:12:25,444 - config - INFO - Validation Loss: 0.4576
2024-03-28 18:12:25,444 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:25,462 - config - INFO - Epoch [615/2000], Train Loss: 0.3751
2024-03-28 18:12:25,466 - config - INFO - Validation Loss: 0.4613
2024-03-28 18:12:25,467 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:25,485 - config - INFO - Epoch [616/2000], Train Loss: 0.3755
2024-03-28 18:12:25,489 - config - INFO - Validation Loss: 0.4616
2024-03-28 18:12:25,489 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:25,508 - config - INFO - Epoch [617/2000], Train Loss: 0.3752
2024-03-28 18:12:25,512 - config - INFO - Validation Loss: 0.4598
2024-03-28 18:12:25,512 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:25,530 - config - INFO - Epoch [618/2000], Train Loss: 0.3749
2024-03-28 18:12:25,534 - config - INFO - Validation Loss: 0.4595
2024-03-28 18:12:25,534 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:25,553 - config - INFO - Epoch [619/2000], Train Loss: 0.3761
2024-03-28 18:12:25,557 - config - INFO - Validation Loss: 0.4577
2024-03-28 18:12:25,557 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:25,575 - config - INFO - Epoch [620/2000], Train Loss: 0.3749
2024-03-28 18:12:25,579 - config - INFO - Validation Loss: 0.4601
2024-03-28 18:12:25,579 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:25,598 - config - INFO - Epoch [621/2000], Train Loss: 0.3751
2024-03-28 18:12:25,602 - config - INFO - Validation Loss: 0.4571
2024-03-28 18:12:25,602 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:25,621 - config - INFO - Epoch [622/2000], Train Loss: 0.3746
2024-03-28 18:12:25,625 - config - INFO - Validation Loss: 0.4575
2024-03-28 18:12:25,625 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:25,643 - config - INFO - Epoch [623/2000], Train Loss: 0.3743
2024-03-28 18:12:25,647 - config - INFO - Validation Loss: 0.4562
2024-03-28 18:12:25,647 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:25,666 - config - INFO - Epoch [624/2000], Train Loss: 0.3746
2024-03-28 18:12:25,670 - config - INFO - Validation Loss: 0.4576
2024-03-28 18:12:25,670 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:25,688 - config - INFO - Epoch [625/2000], Train Loss: 0.3741
2024-03-28 18:12:25,692 - config - INFO - Validation Loss: 0.4556
2024-03-28 18:12:25,692 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:25,711 - config - INFO - Epoch [626/2000], Train Loss: 0.3745
2024-03-28 18:12:25,717 - config - INFO - Validation Loss: 0.4570
2024-03-28 18:12:25,717 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:25,735 - config - INFO - Epoch [627/2000], Train Loss: 0.3748
2024-03-28 18:12:25,739 - config - INFO - Validation Loss: 0.4535
2024-03-28 18:12:25,739 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:25,758 - config - INFO - Epoch [628/2000], Train Loss: 0.3755
2024-03-28 18:12:25,762 - config - INFO - Validation Loss: 0.4564
2024-03-28 18:12:25,762 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:25,780 - config - INFO - Epoch [629/2000], Train Loss: 0.3745
2024-03-28 18:12:25,784 - config - INFO - Validation Loss: 0.4564
2024-03-28 18:12:25,784 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:25,803 - config - INFO - Epoch [630/2000], Train Loss: 0.3739
2024-03-28 18:12:25,807 - config - INFO - Validation Loss: 0.4566
2024-03-28 18:12:25,807 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:25,826 - config - INFO - Epoch [631/2000], Train Loss: 0.3735
2024-03-28 18:12:25,830 - config - INFO - Validation Loss: 0.4548
2024-03-28 18:12:25,830 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:25,848 - config - INFO - Epoch [632/2000], Train Loss: 0.3752
2024-03-28 18:12:25,852 - config - INFO - Validation Loss: 0.4531
2024-03-28 18:12:25,853 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:25,871 - config - INFO - Epoch [633/2000], Train Loss: 0.3739
2024-03-28 18:12:25,875 - config - INFO - Validation Loss: 0.4562
2024-03-28 18:12:25,875 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:25,894 - config - INFO - Epoch [634/2000], Train Loss: 0.3730
2024-03-28 18:12:25,898 - config - INFO - Validation Loss: 0.4592
2024-03-28 18:12:25,898 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:25,916 - config - INFO - Epoch [635/2000], Train Loss: 0.3738
2024-03-28 18:12:25,920 - config - INFO - Validation Loss: 0.4588
2024-03-28 18:12:25,920 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:25,939 - config - INFO - Epoch [636/2000], Train Loss: 0.3731
2024-03-28 18:12:25,943 - config - INFO - Validation Loss: 0.4543
2024-03-28 18:12:25,943 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:25,961 - config - INFO - Epoch [637/2000], Train Loss: 0.3736
2024-03-28 18:12:25,965 - config - INFO - Validation Loss: 0.4538
2024-03-28 18:12:25,966 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:25,984 - config - INFO - Epoch [638/2000], Train Loss: 0.3733
2024-03-28 18:12:25,988 - config - INFO - Validation Loss: 0.4578
2024-03-28 18:12:25,988 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,007 - config - INFO - Epoch [639/2000], Train Loss: 0.3733
2024-03-28 18:12:26,010 - config - INFO - Validation Loss: 0.4572
2024-03-28 18:12:26,011 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:26,029 - config - INFO - Epoch [640/2000], Train Loss: 0.3736
2024-03-28 18:12:26,033 - config - INFO - Validation Loss: 0.4628
2024-03-28 18:12:26,033 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,052 - config - INFO - Epoch [641/2000], Train Loss: 0.3734
2024-03-28 18:12:26,056 - config - INFO - Validation Loss: 0.4606
2024-03-28 18:12:26,056 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,074 - config - INFO - Epoch [642/2000], Train Loss: 0.3728
2024-03-28 18:12:26,078 - config - INFO - Validation Loss: 0.4580
2024-03-28 18:12:26,078 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,097 - config - INFO - Epoch [643/2000], Train Loss: 0.3733
2024-03-28 18:12:26,101 - config - INFO - Validation Loss: 0.4545
2024-03-28 18:12:26,101 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:26,119 - config - INFO - Epoch [644/2000], Train Loss: 0.3725
2024-03-28 18:12:26,123 - config - INFO - Validation Loss: 0.4579
2024-03-28 18:12:26,123 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:26,144 - config - INFO - Epoch [645/2000], Train Loss: 0.3727
2024-03-28 18:12:26,148 - config - INFO - Validation Loss: 0.4577
2024-03-28 18:12:26,149 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:26,167 - config - INFO - Epoch [646/2000], Train Loss: 0.3723
2024-03-28 18:12:26,171 - config - INFO - Validation Loss: 0.4583
2024-03-28 18:12:26,172 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:26,190 - config - INFO - Epoch [647/2000], Train Loss: 0.3722
2024-03-28 18:12:26,194 - config - INFO - Validation Loss: 0.4595
2024-03-28 18:12:26,194 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,213 - config - INFO - Epoch [648/2000], Train Loss: 0.3722
2024-03-28 18:12:26,217 - config - INFO - Validation Loss: 0.4577
2024-03-28 18:12:26,217 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,236 - config - INFO - Epoch [649/2000], Train Loss: 0.3720
2024-03-28 18:12:26,240 - config - INFO - Validation Loss: 0.4590
2024-03-28 18:12:26,240 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,258 - config - INFO - Epoch [650/2000], Train Loss: 0.3721
2024-03-28 18:12:26,262 - config - INFO - Validation Loss: 0.4569
2024-03-28 18:12:26,262 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,281 - config - INFO - Epoch [651/2000], Train Loss: 0.3718
2024-03-28 18:12:26,285 - config - INFO - Validation Loss: 0.4558
2024-03-28 18:12:26,285 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:26,304 - config - INFO - Epoch [652/2000], Train Loss: 0.3720
2024-03-28 18:12:26,308 - config - INFO - Validation Loss: 0.4562
2024-03-28 18:12:26,308 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:26,326 - config - INFO - Epoch [653/2000], Train Loss: 0.3718
2024-03-28 18:12:26,330 - config - INFO - Validation Loss: 0.4564
2024-03-28 18:12:26,330 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,349 - config - INFO - Epoch [654/2000], Train Loss: 0.3717
2024-03-28 18:12:26,353 - config - INFO - Validation Loss: 0.4558
2024-03-28 18:12:26,353 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,372 - config - INFO - Epoch [655/2000], Train Loss: 0.3718
2024-03-28 18:12:26,375 - config - INFO - Validation Loss: 0.4578
2024-03-28 18:12:26,376 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,394 - config - INFO - Epoch [656/2000], Train Loss: 0.3716
2024-03-28 18:12:26,398 - config - INFO - Validation Loss: 0.4540
2024-03-28 18:12:26,398 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:26,417 - config - INFO - Epoch [657/2000], Train Loss: 0.3717
2024-03-28 18:12:26,421 - config - INFO - Validation Loss: 0.4539
2024-03-28 18:12:26,421 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:26,439 - config - INFO - Epoch [658/2000], Train Loss: 0.3711
2024-03-28 18:12:26,443 - config - INFO - Validation Loss: 0.4551
2024-03-28 18:12:26,443 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,462 - config - INFO - Epoch [659/2000], Train Loss: 0.3714
2024-03-28 18:12:26,466 - config - INFO - Validation Loss: 0.4574
2024-03-28 18:12:26,472 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,494 - config - INFO - Epoch [660/2000], Train Loss: 0.3708
2024-03-28 18:12:26,498 - config - INFO - Validation Loss: 0.4542
2024-03-28 18:12:26,499 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,520 - config - INFO - Epoch [661/2000], Train Loss: 0.3710
2024-03-28 18:12:26,524 - config - INFO - Validation Loss: 0.4548
2024-03-28 18:12:26,524 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,542 - config - INFO - Epoch [662/2000], Train Loss: 0.3709
2024-03-28 18:12:26,546 - config - INFO - Validation Loss: 0.4548
2024-03-28 18:12:26,547 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,565 - config - INFO - Epoch [663/2000], Train Loss: 0.3712
2024-03-28 18:12:26,569 - config - INFO - Validation Loss: 0.4557
2024-03-28 18:12:26,569 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,588 - config - INFO - Epoch [664/2000], Train Loss: 0.3709
2024-03-28 18:12:26,592 - config - INFO - Validation Loss: 0.4570
2024-03-28 18:12:26,592 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,610 - config - INFO - Epoch [665/2000], Train Loss: 0.3706
2024-03-28 18:12:26,614 - config - INFO - Validation Loss: 0.4566
2024-03-28 18:12:26,614 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,633 - config - INFO - Epoch [666/2000], Train Loss: 0.3703
2024-03-28 18:12:26,637 - config - INFO - Validation Loss: 0.4562
2024-03-28 18:12:26,637 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,655 - config - INFO - Epoch [667/2000], Train Loss: 0.3703
2024-03-28 18:12:26,659 - config - INFO - Validation Loss: 0.4559
2024-03-28 18:12:26,659 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:26,678 - config - INFO - Epoch [668/2000], Train Loss: 0.3705
2024-03-28 18:12:26,682 - config - INFO - Validation Loss: 0.4577
2024-03-28 18:12:26,682 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,700 - config - INFO - Epoch [669/2000], Train Loss: 0.3700
2024-03-28 18:12:26,704 - config - INFO - Validation Loss: 0.4598
2024-03-28 18:12:26,705 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,723 - config - INFO - Epoch [670/2000], Train Loss: 0.3702
2024-03-28 18:12:26,727 - config - INFO - Validation Loss: 0.4607
2024-03-28 18:12:26,727 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,746 - config - INFO - Epoch [671/2000], Train Loss: 0.3701
2024-03-28 18:12:26,750 - config - INFO - Validation Loss: 0.4565
2024-03-28 18:12:26,750 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,768 - config - INFO - Epoch [672/2000], Train Loss: 0.3699
2024-03-28 18:12:26,772 - config - INFO - Validation Loss: 0.4568
2024-03-28 18:12:26,773 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,791 - config - INFO - Epoch [673/2000], Train Loss: 0.3698
2024-03-28 18:12:26,795 - config - INFO - Validation Loss: 0.4583
2024-03-28 18:12:26,795 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,814 - config - INFO - Epoch [674/2000], Train Loss: 0.3699
2024-03-28 18:12:26,818 - config - INFO - Validation Loss: 0.4576
2024-03-28 18:12:26,818 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,837 - config - INFO - Epoch [675/2000], Train Loss: 0.3706
2024-03-28 18:12:26,841 - config - INFO - Validation Loss: 0.4596
2024-03-28 18:12:26,841 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,859 - config - INFO - Epoch [676/2000], Train Loss: 0.3705
2024-03-28 18:12:26,863 - config - INFO - Validation Loss: 0.4554
2024-03-28 18:12:26,863 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:26,882 - config - INFO - Epoch [677/2000], Train Loss: 0.3698
2024-03-28 18:12:26,886 - config - INFO - Validation Loss: 0.4547
2024-03-28 18:12:26,886 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:26,904 - config - INFO - Epoch [678/2000], Train Loss: 0.3694
2024-03-28 18:12:26,908 - config - INFO - Validation Loss: 0.4563
2024-03-28 18:12:26,908 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,927 - config - INFO - Epoch [679/2000], Train Loss: 0.3696
2024-03-28 18:12:26,931 - config - INFO - Validation Loss: 0.4594
2024-03-28 18:12:26,931 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,950 - config - INFO - Epoch [680/2000], Train Loss: 0.3693
2024-03-28 18:12:26,954 - config - INFO - Validation Loss: 0.4579
2024-03-28 18:12:26,954 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,972 - config - INFO - Epoch [681/2000], Train Loss: 0.3692
2024-03-28 18:12:26,976 - config - INFO - Validation Loss: 0.4554
2024-03-28 18:12:26,976 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:26,995 - config - INFO - Epoch [682/2000], Train Loss: 0.3697
2024-03-28 18:12:26,999 - config - INFO - Validation Loss: 0.4531
2024-03-28 18:12:26,999 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:27,017 - config - INFO - Epoch [683/2000], Train Loss: 0.3695
2024-03-28 18:12:27,021 - config - INFO - Validation Loss: 0.4563
2024-03-28 18:12:27,022 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,040 - config - INFO - Epoch [684/2000], Train Loss: 0.3688
2024-03-28 18:12:27,044 - config - INFO - Validation Loss: 0.4566
2024-03-28 18:12:27,044 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,063 - config - INFO - Epoch [685/2000], Train Loss: 0.3687
2024-03-28 18:12:27,067 - config - INFO - Validation Loss: 0.4577
2024-03-28 18:12:27,067 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,085 - config - INFO - Epoch [686/2000], Train Loss: 0.3690
2024-03-28 18:12:27,089 - config - INFO - Validation Loss: 0.4577
2024-03-28 18:12:27,089 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,108 - config - INFO - Epoch [687/2000], Train Loss: 0.3690
2024-03-28 18:12:27,112 - config - INFO - Validation Loss: 0.4553
2024-03-28 18:12:27,112 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,130 - config - INFO - Epoch [688/2000], Train Loss: 0.3684
2024-03-28 18:12:27,137 - config - INFO - Validation Loss: 0.4568
2024-03-28 18:12:27,137 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,156 - config - INFO - Epoch [689/2000], Train Loss: 0.3683
2024-03-28 18:12:27,160 - config - INFO - Validation Loss: 0.4565
2024-03-28 18:12:27,160 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,179 - config - INFO - Epoch [690/2000], Train Loss: 0.3688
2024-03-28 18:12:27,183 - config - INFO - Validation Loss: 0.4546
2024-03-28 18:12:27,183 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:27,201 - config - INFO - Epoch [691/2000], Train Loss: 0.3683
2024-03-28 18:12:27,205 - config - INFO - Validation Loss: 0.4555
2024-03-28 18:12:27,205 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,224 - config - INFO - Epoch [692/2000], Train Loss: 0.3683
2024-03-28 18:12:27,228 - config - INFO - Validation Loss: 0.4576
2024-03-28 18:12:27,228 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,247 - config - INFO - Epoch [693/2000], Train Loss: 0.3684
2024-03-28 18:12:27,251 - config - INFO - Validation Loss: 0.4547
2024-03-28 18:12:27,251 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:27,269 - config - INFO - Epoch [694/2000], Train Loss: 0.3684
2024-03-28 18:12:27,273 - config - INFO - Validation Loss: 0.4556
2024-03-28 18:12:27,273 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,292 - config - INFO - Epoch [695/2000], Train Loss: 0.3678
2024-03-28 18:12:27,296 - config - INFO - Validation Loss: 0.4564
2024-03-28 18:12:27,296 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,315 - config - INFO - Epoch [696/2000], Train Loss: 0.3680
2024-03-28 18:12:27,319 - config - INFO - Validation Loss: 0.4563
2024-03-28 18:12:27,319 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,337 - config - INFO - Epoch [697/2000], Train Loss: 0.3689
2024-03-28 18:12:27,341 - config - INFO - Validation Loss: 0.4621
2024-03-28 18:12:27,341 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,360 - config - INFO - Epoch [698/2000], Train Loss: 0.3684
2024-03-28 18:12:27,364 - config - INFO - Validation Loss: 0.4611
2024-03-28 18:12:27,364 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,383 - config - INFO - Epoch [699/2000], Train Loss: 0.3678
2024-03-28 18:12:27,387 - config - INFO - Validation Loss: 0.4603
2024-03-28 18:12:27,387 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,405 - config - INFO - Epoch [700/2000], Train Loss: 0.3679
2024-03-28 18:12:27,409 - config - INFO - Validation Loss: 0.4608
2024-03-28 18:12:27,409 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,428 - config - INFO - Epoch [701/2000], Train Loss: 0.3676
2024-03-28 18:12:27,432 - config - INFO - Validation Loss: 0.4588
2024-03-28 18:12:27,432 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,450 - config - INFO - Epoch [702/2000], Train Loss: 0.3674
2024-03-28 18:12:27,454 - config - INFO - Validation Loss: 0.4577
2024-03-28 18:12:27,455 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,473 - config - INFO - Epoch [703/2000], Train Loss: 0.3677
2024-03-28 18:12:27,477 - config - INFO - Validation Loss: 0.4593
2024-03-28 18:12:27,477 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,496 - config - INFO - Epoch [704/2000], Train Loss: 0.3701
2024-03-28 18:12:27,500 - config - INFO - Validation Loss: 0.4530
2024-03-28 18:12:27,500 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,518 - config - INFO - Epoch [705/2000], Train Loss: 0.3672
2024-03-28 18:12:27,522 - config - INFO - Validation Loss: 0.4564
2024-03-28 18:12:27,522 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,541 - config - INFO - Epoch [706/2000], Train Loss: 0.3665
2024-03-28 18:12:27,545 - config - INFO - Validation Loss: 0.4606
2024-03-28 18:12:27,545 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,563 - config - INFO - Epoch [707/2000], Train Loss: 0.3672
2024-03-28 18:12:27,567 - config - INFO - Validation Loss: 0.4614
2024-03-28 18:12:27,567 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,586 - config - INFO - Epoch [708/2000], Train Loss: 0.3668
2024-03-28 18:12:27,590 - config - INFO - Validation Loss: 0.4587
2024-03-28 18:12:27,590 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,609 - config - INFO - Epoch [709/2000], Train Loss: 0.3670
2024-03-28 18:12:27,612 - config - INFO - Validation Loss: 0.4568
2024-03-28 18:12:27,613 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,631 - config - INFO - Epoch [710/2000], Train Loss: 0.3669
2024-03-28 18:12:27,635 - config - INFO - Validation Loss: 0.4563
2024-03-28 18:12:27,635 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,654 - config - INFO - Epoch [711/2000], Train Loss: 0.3670
2024-03-28 18:12:27,658 - config - INFO - Validation Loss: 0.4590
2024-03-28 18:12:27,658 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,676 - config - INFO - Epoch [712/2000], Train Loss: 0.3666
2024-03-28 18:12:27,680 - config - INFO - Validation Loss: 0.4586
2024-03-28 18:12:27,680 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,699 - config - INFO - Epoch [713/2000], Train Loss: 0.3664
2024-03-28 18:12:27,703 - config - INFO - Validation Loss: 0.4581
2024-03-28 18:12:27,703 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,721 - config - INFO - Epoch [714/2000], Train Loss: 0.3673
2024-03-28 18:12:27,725 - config - INFO - Validation Loss: 0.4540
2024-03-28 18:12:27,726 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,744 - config - INFO - Epoch [715/2000], Train Loss: 0.3665
2024-03-28 18:12:27,748 - config - INFO - Validation Loss: 0.4537
2024-03-28 18:12:27,748 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,767 - config - INFO - Epoch [716/2000], Train Loss: 0.3665
2024-03-28 18:12:27,771 - config - INFO - Validation Loss: 0.4557
2024-03-28 18:12:27,771 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,789 - config - INFO - Epoch [717/2000], Train Loss: 0.3660
2024-03-28 18:12:27,793 - config - INFO - Validation Loss: 0.4540
2024-03-28 18:12:27,794 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,812 - config - INFO - Epoch [718/2000], Train Loss: 0.3658
2024-03-28 18:12:27,816 - config - INFO - Validation Loss: 0.4552
2024-03-28 18:12:27,816 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,835 - config - INFO - Epoch [719/2000], Train Loss: 0.3656
2024-03-28 18:12:27,839 - config - INFO - Validation Loss: 0.4553
2024-03-28 18:12:27,839 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,858 - config - INFO - Epoch [720/2000], Train Loss: 0.3659
2024-03-28 18:12:27,861 - config - INFO - Validation Loss: 0.4549
2024-03-28 18:12:27,862 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,880 - config - INFO - Epoch [721/2000], Train Loss: 0.3658
2024-03-28 18:12:27,884 - config - INFO - Validation Loss: 0.4576
2024-03-28 18:12:27,884 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,903 - config - INFO - Epoch [722/2000], Train Loss: 0.3658
2024-03-28 18:12:27,907 - config - INFO - Validation Loss: 0.4545
2024-03-28 18:12:27,907 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,925 - config - INFO - Epoch [723/2000], Train Loss: 0.3657
2024-03-28 18:12:27,929 - config - INFO - Validation Loss: 0.4564
2024-03-28 18:12:27,929 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,948 - config - INFO - Epoch [724/2000], Train Loss: 0.3653
2024-03-28 18:12:27,952 - config - INFO - Validation Loss: 0.4563
2024-03-28 18:12:27,952 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,970 - config - INFO - Epoch [725/2000], Train Loss: 0.3655
2024-03-28 18:12:27,974 - config - INFO - Validation Loss: 0.4546
2024-03-28 18:12:27,974 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:27,993 - config - INFO - Epoch [726/2000], Train Loss: 0.3651
2024-03-28 18:12:27,997 - config - INFO - Validation Loss: 0.4550
2024-03-28 18:12:27,997 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,016 - config - INFO - Epoch [727/2000], Train Loss: 0.3652
2024-03-28 18:12:28,020 - config - INFO - Validation Loss: 0.4554
2024-03-28 18:12:28,020 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,038 - config - INFO - Epoch [728/2000], Train Loss: 0.3651
2024-03-28 18:12:28,042 - config - INFO - Validation Loss: 0.4562
2024-03-28 18:12:28,042 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,061 - config - INFO - Epoch [729/2000], Train Loss: 0.3648
2024-03-28 18:12:28,065 - config - INFO - Validation Loss: 0.4556
2024-03-28 18:12:28,065 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,083 - config - INFO - Epoch [730/2000], Train Loss: 0.3651
2024-03-28 18:12:28,087 - config - INFO - Validation Loss: 0.4579
2024-03-28 18:12:28,088 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,106 - config - INFO - Epoch [731/2000], Train Loss: 0.3653
2024-03-28 18:12:28,110 - config - INFO - Validation Loss: 0.4548
2024-03-28 18:12:28,110 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,129 - config - INFO - Epoch [732/2000], Train Loss: 0.3652
2024-03-28 18:12:28,133 - config - INFO - Validation Loss: 0.4540
2024-03-28 18:12:28,133 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,151 - config - INFO - Epoch [733/2000], Train Loss: 0.3650
2024-03-28 18:12:28,155 - config - INFO - Validation Loss: 0.4571
2024-03-28 18:12:28,155 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,174 - config - INFO - Epoch [734/2000], Train Loss: 0.3645
2024-03-28 18:12:28,178 - config - INFO - Validation Loss: 0.4573
2024-03-28 18:12:28,178 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,196 - config - INFO - Epoch [735/2000], Train Loss: 0.3647
2024-03-28 18:12:28,200 - config - INFO - Validation Loss: 0.4556
2024-03-28 18:12:28,201 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,219 - config - INFO - Epoch [736/2000], Train Loss: 0.3645
2024-03-28 18:12:28,223 - config - INFO - Validation Loss: 0.4580
2024-03-28 18:12:28,223 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,242 - config - INFO - Epoch [737/2000], Train Loss: 0.3643
2024-03-28 18:12:28,246 - config - INFO - Validation Loss: 0.4564
2024-03-28 18:12:28,246 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,264 - config - INFO - Epoch [738/2000], Train Loss: 0.3646
2024-03-28 18:12:28,268 - config - INFO - Validation Loss: 0.4564
2024-03-28 18:12:28,269 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,287 - config - INFO - Epoch [739/2000], Train Loss: 0.3643
2024-03-28 18:12:28,291 - config - INFO - Validation Loss: 0.4572
2024-03-28 18:12:28,291 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,310 - config - INFO - Epoch [740/2000], Train Loss: 0.3640
2024-03-28 18:12:28,314 - config - INFO - Validation Loss: 0.4553
2024-03-28 18:12:28,314 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,332 - config - INFO - Epoch [741/2000], Train Loss: 0.3641
2024-03-28 18:12:28,336 - config - INFO - Validation Loss: 0.4553
2024-03-28 18:12:28,337 - config - INFO - Validation Acc: 0.8000
2024-03-28 18:12:28,355 - config - INFO - Epoch [742/2000], Train Loss: 0.3647
2024-03-28 18:12:28,359 - config - INFO - Validation Loss: 0.4555
2024-03-28 18:12:28,359 - config - INFO - Validation Acc: 0.8000
2024-03-28 18:12:28,378 - config - INFO - Epoch [743/2000], Train Loss: 0.3640
2024-03-28 18:12:28,382 - config - INFO - Validation Loss: 0.4577
2024-03-28 18:12:28,382 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,400 - config - INFO - Epoch [744/2000], Train Loss: 0.3641
2024-03-28 18:12:28,404 - config - INFO - Validation Loss: 0.4605
2024-03-28 18:12:28,404 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:28,423 - config - INFO - Epoch [745/2000], Train Loss: 0.3636
2024-03-28 18:12:28,427 - config - INFO - Validation Loss: 0.4583
2024-03-28 18:12:28,427 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,446 - config - INFO - Epoch [746/2000], Train Loss: 0.3636
2024-03-28 18:12:28,449 - config - INFO - Validation Loss: 0.4563
2024-03-28 18:12:28,450 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,468 - config - INFO - Epoch [747/2000], Train Loss: 0.3645
2024-03-28 18:12:28,472 - config - INFO - Validation Loss: 0.4545
2024-03-28 18:12:28,472 - config - INFO - Validation Acc: 0.8000
2024-03-28 18:12:28,491 - config - INFO - Epoch [748/2000], Train Loss: 0.3640
2024-03-28 18:12:28,495 - config - INFO - Validation Loss: 0.4625
2024-03-28 18:12:28,495 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:28,513 - config - INFO - Epoch [749/2000], Train Loss: 0.3640
2024-03-28 18:12:28,517 - config - INFO - Validation Loss: 0.4616
2024-03-28 18:12:28,517 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:28,536 - config - INFO - Epoch [750/2000], Train Loss: 0.3637
2024-03-28 18:12:28,540 - config - INFO - Validation Loss: 0.4564
2024-03-28 18:12:28,540 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,558 - config - INFO - Epoch [751/2000], Train Loss: 0.3630
2024-03-28 18:12:28,562 - config - INFO - Validation Loss: 0.4564
2024-03-28 18:12:28,563 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,581 - config - INFO - Epoch [752/2000], Train Loss: 0.3633
2024-03-28 18:12:28,585 - config - INFO - Validation Loss: 0.4551
2024-03-28 18:12:28,585 - config - INFO - Validation Acc: 0.8000
2024-03-28 18:12:28,604 - config - INFO - Epoch [753/2000], Train Loss: 0.3629
2024-03-28 18:12:28,608 - config - INFO - Validation Loss: 0.4561
2024-03-28 18:12:28,608 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,626 - config - INFO - Epoch [754/2000], Train Loss: 0.3630
2024-03-28 18:12:28,630 - config - INFO - Validation Loss: 0.4589
2024-03-28 18:12:28,631 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:28,649 - config - INFO - Epoch [755/2000], Train Loss: 0.3633
2024-03-28 18:12:28,653 - config - INFO - Validation Loss: 0.4589
2024-03-28 18:12:28,653 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:28,672 - config - INFO - Epoch [756/2000], Train Loss: 0.3635
2024-03-28 18:12:28,676 - config - INFO - Validation Loss: 0.4545
2024-03-28 18:12:28,676 - config - INFO - Validation Acc: 0.8000
2024-03-28 18:12:28,694 - config - INFO - Epoch [757/2000], Train Loss: 0.3628
2024-03-28 18:12:28,698 - config - INFO - Validation Loss: 0.4556
2024-03-28 18:12:28,698 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,717 - config - INFO - Epoch [758/2000], Train Loss: 0.3631
2024-03-28 18:12:28,721 - config - INFO - Validation Loss: 0.4571
2024-03-28 18:12:28,721 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,739 - config - INFO - Epoch [759/2000], Train Loss: 0.3628
2024-03-28 18:12:28,743 - config - INFO - Validation Loss: 0.4541
2024-03-28 18:12:28,744 - config - INFO - Validation Acc: 0.8000
2024-03-28 18:12:28,762 - config - INFO - Epoch [760/2000], Train Loss: 0.3632
2024-03-28 18:12:28,766 - config - INFO - Validation Loss: 0.4577
2024-03-28 18:12:28,766 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,785 - config - INFO - Epoch [761/2000], Train Loss: 0.3625
2024-03-28 18:12:28,789 - config - INFO - Validation Loss: 0.4577
2024-03-28 18:12:28,789 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,807 - config - INFO - Epoch [762/2000], Train Loss: 0.3624
2024-03-28 18:12:28,811 - config - INFO - Validation Loss: 0.4578
2024-03-28 18:12:28,811 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,830 - config - INFO - Epoch [763/2000], Train Loss: 0.3621
2024-03-28 18:12:28,834 - config - INFO - Validation Loss: 0.4538
2024-03-28 18:12:28,834 - config - INFO - Validation Acc: 0.8000
2024-03-28 18:12:28,853 - config - INFO - Epoch [764/2000], Train Loss: 0.3627
2024-03-28 18:12:28,857 - config - INFO - Validation Loss: 0.4528
2024-03-28 18:12:28,857 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,876 - config - INFO - Epoch [765/2000], Train Loss: 0.3625
2024-03-28 18:12:28,879 - config - INFO - Validation Loss: 0.4550
2024-03-28 18:12:28,880 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,898 - config - INFO - Epoch [766/2000], Train Loss: 0.3621
2024-03-28 18:12:28,902 - config - INFO - Validation Loss: 0.4550
2024-03-28 18:12:28,902 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:28,921 - config - INFO - Epoch [767/2000], Train Loss: 0.3622
2024-03-28 18:12:28,925 - config - INFO - Validation Loss: 0.4592
2024-03-28 18:12:28,925 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:28,943 - config - INFO - Epoch [768/2000], Train Loss: 0.3631
2024-03-28 18:12:28,947 - config - INFO - Validation Loss: 0.4604
2024-03-28 18:12:28,948 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:28,966 - config - INFO - Epoch [769/2000], Train Loss: 0.3633
2024-03-28 18:12:28,970 - config - INFO - Validation Loss: 0.4550
2024-03-28 18:12:28,970 - config - INFO - Validation Acc: 0.8000
2024-03-28 18:12:28,989 - config - INFO - Epoch [770/2000], Train Loss: 0.3622
2024-03-28 18:12:28,993 - config - INFO - Validation Loss: 0.4599
2024-03-28 18:12:28,993 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:29,011 - config - INFO - Epoch [771/2000], Train Loss: 0.3615
2024-03-28 18:12:29,015 - config - INFO - Validation Loss: 0.4565
2024-03-28 18:12:29,015 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,034 - config - INFO - Epoch [772/2000], Train Loss: 0.3618
2024-03-28 18:12:29,038 - config - INFO - Validation Loss: 0.4547
2024-03-28 18:12:29,038 - config - INFO - Validation Acc: 0.8000
2024-03-28 18:12:29,057 - config - INFO - Epoch [773/2000], Train Loss: 0.3616
2024-03-28 18:12:29,060 - config - INFO - Validation Loss: 0.4554
2024-03-28 18:12:29,061 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,079 - config - INFO - Epoch [774/2000], Train Loss: 0.3618
2024-03-28 18:12:29,083 - config - INFO - Validation Loss: 0.4567
2024-03-28 18:12:29,083 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,102 - config - INFO - Epoch [775/2000], Train Loss: 0.3621
2024-03-28 18:12:29,106 - config - INFO - Validation Loss: 0.4562
2024-03-28 18:12:29,106 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,125 - config - INFO - Epoch [776/2000], Train Loss: 0.3610
2024-03-28 18:12:29,129 - config - INFO - Validation Loss: 0.4548
2024-03-28 18:12:29,129 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,147 - config - INFO - Epoch [777/2000], Train Loss: 0.3610
2024-03-28 18:12:29,151 - config - INFO - Validation Loss: 0.4549
2024-03-28 18:12:29,151 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,170 - config - INFO - Epoch [778/2000], Train Loss: 0.3611
2024-03-28 18:12:29,174 - config - INFO - Validation Loss: 0.4556
2024-03-28 18:12:29,174 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,197 - config - INFO - Epoch [779/2000], Train Loss: 0.3613
2024-03-28 18:12:29,201 - config - INFO - Validation Loss: 0.4574
2024-03-28 18:12:29,201 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,220 - config - INFO - Epoch [780/2000], Train Loss: 0.3610
2024-03-28 18:12:29,224 - config - INFO - Validation Loss: 0.4582
2024-03-28 18:12:29,224 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,242 - config - INFO - Epoch [781/2000], Train Loss: 0.3613
2024-03-28 18:12:29,246 - config - INFO - Validation Loss: 0.4545
2024-03-28 18:12:29,247 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,265 - config - INFO - Epoch [782/2000], Train Loss: 0.3609
2024-03-28 18:12:29,269 - config - INFO - Validation Loss: 0.4567
2024-03-28 18:12:29,269 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,291 - config - INFO - Epoch [783/2000], Train Loss: 0.3610
2024-03-28 18:12:29,295 - config - INFO - Validation Loss: 0.4552
2024-03-28 18:12:29,295 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,314 - config - INFO - Epoch [784/2000], Train Loss: 0.3615
2024-03-28 18:12:29,318 - config - INFO - Validation Loss: 0.4574
2024-03-28 18:12:29,318 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:29,337 - config - INFO - Epoch [785/2000], Train Loss: 0.3611
2024-03-28 18:12:29,341 - config - INFO - Validation Loss: 0.4520
2024-03-28 18:12:29,341 - config - INFO - Validation Acc: 0.8000
2024-03-28 18:12:29,360 - config - INFO - Epoch [786/2000], Train Loss: 0.3611
2024-03-28 18:12:29,364 - config - INFO - Validation Loss: 0.4535
2024-03-28 18:12:29,364 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,382 - config - INFO - Epoch [787/2000], Train Loss: 0.3604
2024-03-28 18:12:29,386 - config - INFO - Validation Loss: 0.4540
2024-03-28 18:12:29,386 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,405 - config - INFO - Epoch [788/2000], Train Loss: 0.3605
2024-03-28 18:12:29,409 - config - INFO - Validation Loss: 0.4546
2024-03-28 18:12:29,409 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,427 - config - INFO - Epoch [789/2000], Train Loss: 0.3603
2024-03-28 18:12:29,431 - config - INFO - Validation Loss: 0.4562
2024-03-28 18:12:29,431 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:29,450 - config - INFO - Epoch [790/2000], Train Loss: 0.3602
2024-03-28 18:12:29,454 - config - INFO - Validation Loss: 0.4567
2024-03-28 18:12:29,454 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:29,473 - config - INFO - Epoch [791/2000], Train Loss: 0.3601
2024-03-28 18:12:29,476 - config - INFO - Validation Loss: 0.4589
2024-03-28 18:12:29,477 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:29,495 - config - INFO - Epoch [792/2000], Train Loss: 0.3607
2024-03-28 18:12:29,499 - config - INFO - Validation Loss: 0.4578
2024-03-28 18:12:29,499 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,518 - config - INFO - Epoch [793/2000], Train Loss: 0.3600
2024-03-28 18:12:29,522 - config - INFO - Validation Loss: 0.4603
2024-03-28 18:12:29,522 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:29,540 - config - INFO - Epoch [794/2000], Train Loss: 0.3605
2024-03-28 18:12:29,544 - config - INFO - Validation Loss: 0.4591
2024-03-28 18:12:29,544 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:29,563 - config - INFO - Epoch [795/2000], Train Loss: 0.3600
2024-03-28 18:12:29,567 - config - INFO - Validation Loss: 0.4611
2024-03-28 18:12:29,567 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:29,585 - config - INFO - Epoch [796/2000], Train Loss: 0.3599
2024-03-28 18:12:29,589 - config - INFO - Validation Loss: 0.4599
2024-03-28 18:12:29,589 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:29,608 - config - INFO - Epoch [797/2000], Train Loss: 0.3596
2024-03-28 18:12:29,612 - config - INFO - Validation Loss: 0.4601
2024-03-28 18:12:29,612 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:29,631 - config - INFO - Epoch [798/2000], Train Loss: 0.3606
2024-03-28 18:12:29,635 - config - INFO - Validation Loss: 0.4599
2024-03-28 18:12:29,635 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:29,653 - config - INFO - Epoch [799/2000], Train Loss: 0.3598
2024-03-28 18:12:29,657 - config - INFO - Validation Loss: 0.4556
2024-03-28 18:12:29,657 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,676 - config - INFO - Epoch [800/2000], Train Loss: 0.3599
2024-03-28 18:12:29,680 - config - INFO - Validation Loss: 0.4551
2024-03-28 18:12:29,680 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,698 - config - INFO - Epoch [801/2000], Train Loss: 0.3594
2024-03-28 18:12:29,702 - config - INFO - Validation Loss: 0.4550
2024-03-28 18:12:29,702 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,721 - config - INFO - Epoch [802/2000], Train Loss: 0.3594
2024-03-28 18:12:29,725 - config - INFO - Validation Loss: 0.4539
2024-03-28 18:12:29,725 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,744 - config - INFO - Epoch [803/2000], Train Loss: 0.3602
2024-03-28 18:12:29,748 - config - INFO - Validation Loss: 0.4565
2024-03-28 18:12:29,748 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,766 - config - INFO - Epoch [804/2000], Train Loss: 0.3593
2024-03-28 18:12:29,770 - config - INFO - Validation Loss: 0.4565
2024-03-28 18:12:29,771 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,789 - config - INFO - Epoch [805/2000], Train Loss: 0.3589
2024-03-28 18:12:29,793 - config - INFO - Validation Loss: 0.4556
2024-03-28 18:12:29,793 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,812 - config - INFO - Epoch [806/2000], Train Loss: 0.3590
2024-03-28 18:12:29,816 - config - INFO - Validation Loss: 0.4551
2024-03-28 18:12:29,816 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,834 - config - INFO - Epoch [807/2000], Train Loss: 0.3593
2024-03-28 18:12:29,838 - config - INFO - Validation Loss: 0.4571
2024-03-28 18:12:29,839 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,857 - config - INFO - Epoch [808/2000], Train Loss: 0.3599
2024-03-28 18:12:29,861 - config - INFO - Validation Loss: 0.4540
2024-03-28 18:12:29,861 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,880 - config - INFO - Epoch [809/2000], Train Loss: 0.3588
2024-03-28 18:12:29,884 - config - INFO - Validation Loss: 0.4566
2024-03-28 18:12:29,884 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,902 - config - INFO - Epoch [810/2000], Train Loss: 0.3597
2024-03-28 18:12:29,906 - config - INFO - Validation Loss: 0.4611
2024-03-28 18:12:29,906 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:29,925 - config - INFO - Epoch [811/2000], Train Loss: 0.3596
2024-03-28 18:12:29,929 - config - INFO - Validation Loss: 0.4575
2024-03-28 18:12:29,929 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,947 - config - INFO - Epoch [812/2000], Train Loss: 0.3591
2024-03-28 18:12:29,951 - config - INFO - Validation Loss: 0.4562
2024-03-28 18:12:29,951 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:29,970 - config - INFO - Epoch [813/2000], Train Loss: 0.3597
2024-03-28 18:12:29,974 - config - INFO - Validation Loss: 0.4588
2024-03-28 18:12:29,974 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:29,992 - config - INFO - Epoch [814/2000], Train Loss: 0.3586
2024-03-28 18:12:29,996 - config - INFO - Validation Loss: 0.4576
2024-03-28 18:12:29,996 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:30,015 - config - INFO - Epoch [815/2000], Train Loss: 0.3582
2024-03-28 18:12:30,019 - config - INFO - Validation Loss: 0.4575
2024-03-28 18:12:30,019 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:30,038 - config - INFO - Epoch [816/2000], Train Loss: 0.3585
2024-03-28 18:12:30,042 - config - INFO - Validation Loss: 0.4557
2024-03-28 18:12:30,042 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,060 - config - INFO - Epoch [817/2000], Train Loss: 0.3582
2024-03-28 18:12:30,064 - config - INFO - Validation Loss: 0.4547
2024-03-28 18:12:30,064 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,083 - config - INFO - Epoch [818/2000], Train Loss: 0.3582
2024-03-28 18:12:30,087 - config - INFO - Validation Loss: 0.4558
2024-03-28 18:12:30,087 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,105 - config - INFO - Epoch [819/2000], Train Loss: 0.3580
2024-03-28 18:12:30,109 - config - INFO - Validation Loss: 0.4568
2024-03-28 18:12:30,109 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,128 - config - INFO - Epoch [820/2000], Train Loss: 0.3581
2024-03-28 18:12:30,132 - config - INFO - Validation Loss: 0.4555
2024-03-28 18:12:30,132 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,150 - config - INFO - Epoch [821/2000], Train Loss: 0.3582
2024-03-28 18:12:30,154 - config - INFO - Validation Loss: 0.4567
2024-03-28 18:12:30,155 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,173 - config - INFO - Epoch [822/2000], Train Loss: 0.3577
2024-03-28 18:12:30,177 - config - INFO - Validation Loss: 0.4572
2024-03-28 18:12:30,177 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,196 - config - INFO - Epoch [823/2000], Train Loss: 0.3584
2024-03-28 18:12:30,200 - config - INFO - Validation Loss: 0.4601
2024-03-28 18:12:30,200 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:30,218 - config - INFO - Epoch [824/2000], Train Loss: 0.3579
2024-03-28 18:12:30,222 - config - INFO - Validation Loss: 0.4571
2024-03-28 18:12:30,222 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,241 - config - INFO - Epoch [825/2000], Train Loss: 0.3577
2024-03-28 18:12:30,245 - config - INFO - Validation Loss: 0.4564
2024-03-28 18:12:30,245 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,263 - config - INFO - Epoch [826/2000], Train Loss: 0.3581
2024-03-28 18:12:30,267 - config - INFO - Validation Loss: 0.4606
2024-03-28 18:12:30,268 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,286 - config - INFO - Epoch [827/2000], Train Loss: 0.3580
2024-03-28 18:12:30,290 - config - INFO - Validation Loss: 0.4602
2024-03-28 18:12:30,290 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,309 - config - INFO - Epoch [828/2000], Train Loss: 0.3574
2024-03-28 18:12:30,313 - config - INFO - Validation Loss: 0.4600
2024-03-28 18:12:30,313 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,332 - config - INFO - Epoch [829/2000], Train Loss: 0.3576
2024-03-28 18:12:30,335 - config - INFO - Validation Loss: 0.4596
2024-03-28 18:12:30,336 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,354 - config - INFO - Epoch [830/2000], Train Loss: 0.3575
2024-03-28 18:12:30,358 - config - INFO - Validation Loss: 0.4604
2024-03-28 18:12:30,358 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:30,377 - config - INFO - Epoch [831/2000], Train Loss: 0.3571
2024-03-28 18:12:30,381 - config - INFO - Validation Loss: 0.4577
2024-03-28 18:12:30,381 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,400 - config - INFO - Epoch [832/2000], Train Loss: 0.3576
2024-03-28 18:12:30,403 - config - INFO - Validation Loss: 0.4573
2024-03-28 18:12:30,404 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,422 - config - INFO - Epoch [833/2000], Train Loss: 0.3569
2024-03-28 18:12:30,426 - config - INFO - Validation Loss: 0.4594
2024-03-28 18:12:30,426 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:30,445 - config - INFO - Epoch [834/2000], Train Loss: 0.3574
2024-03-28 18:12:30,449 - config - INFO - Validation Loss: 0.4609
2024-03-28 18:12:30,449 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:30,467 - config - INFO - Epoch [835/2000], Train Loss: 0.3575
2024-03-28 18:12:30,471 - config - INFO - Validation Loss: 0.4611
2024-03-28 18:12:30,471 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:30,490 - config - INFO - Epoch [836/2000], Train Loss: 0.3573
2024-03-28 18:12:30,494 - config - INFO - Validation Loss: 0.4585
2024-03-28 18:12:30,494 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,512 - config - INFO - Epoch [837/2000], Train Loss: 0.3567
2024-03-28 18:12:30,516 - config - INFO - Validation Loss: 0.4598
2024-03-28 18:12:30,516 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:30,535 - config - INFO - Epoch [838/2000], Train Loss: 0.3572
2024-03-28 18:12:30,539 - config - INFO - Validation Loss: 0.4581
2024-03-28 18:12:30,539 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,557 - config - INFO - Epoch [839/2000], Train Loss: 0.3574
2024-03-28 18:12:30,561 - config - INFO - Validation Loss: 0.4624
2024-03-28 18:12:30,562 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:30,580 - config - INFO - Epoch [840/2000], Train Loss: 0.3575
2024-03-28 18:12:30,584 - config - INFO - Validation Loss: 0.4591
2024-03-28 18:12:30,584 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,603 - config - INFO - Epoch [841/2000], Train Loss: 0.3563
2024-03-28 18:12:30,607 - config - INFO - Validation Loss: 0.4593
2024-03-28 18:12:30,607 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,625 - config - INFO - Epoch [842/2000], Train Loss: 0.3573
2024-03-28 18:12:30,629 - config - INFO - Validation Loss: 0.4571
2024-03-28 18:12:30,629 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,648 - config - INFO - Epoch [843/2000], Train Loss: 0.3565
2024-03-28 18:12:30,652 - config - INFO - Validation Loss: 0.4602
2024-03-28 18:12:30,652 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:30,670 - config - INFO - Epoch [844/2000], Train Loss: 0.3565
2024-03-28 18:12:30,674 - config - INFO - Validation Loss: 0.4585
2024-03-28 18:12:30,674 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,693 - config - INFO - Epoch [845/2000], Train Loss: 0.3562
2024-03-28 18:12:30,697 - config - INFO - Validation Loss: 0.4609
2024-03-28 18:12:30,697 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:30,715 - config - INFO - Epoch [846/2000], Train Loss: 0.3564
2024-03-28 18:12:30,719 - config - INFO - Validation Loss: 0.4582
2024-03-28 18:12:30,720 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:30,738 - config - INFO - Epoch [847/2000], Train Loss: 0.3562
2024-03-28 18:12:30,742 - config - INFO - Validation Loss: 0.4576
2024-03-28 18:12:30,742 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:30,761 - config - INFO - Epoch [848/2000], Train Loss: 0.3562
2024-03-28 18:12:30,765 - config - INFO - Validation Loss: 0.4560
2024-03-28 18:12:30,765 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,783 - config - INFO - Epoch [849/2000], Train Loss: 0.3558
2024-03-28 18:12:30,787 - config - INFO - Validation Loss: 0.4570
2024-03-28 18:12:30,787 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:30,806 - config - INFO - Epoch [850/2000], Train Loss: 0.3564
2024-03-28 18:12:30,810 - config - INFO - Validation Loss: 0.4605
2024-03-28 18:12:30,810 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:30,828 - config - INFO - Epoch [851/2000], Train Loss: 0.3567
2024-03-28 18:12:30,832 - config - INFO - Validation Loss: 0.4562
2024-03-28 18:12:30,833 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,851 - config - INFO - Epoch [852/2000], Train Loss: 0.3564
2024-03-28 18:12:30,855 - config - INFO - Validation Loss: 0.4598
2024-03-28 18:12:30,855 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:30,874 - config - INFO - Epoch [853/2000], Train Loss: 0.3557
2024-03-28 18:12:30,878 - config - INFO - Validation Loss: 0.4581
2024-03-28 18:12:30,878 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:30,896 - config - INFO - Epoch [854/2000], Train Loss: 0.3553
2024-03-28 18:12:30,900 - config - INFO - Validation Loss: 0.4559
2024-03-28 18:12:30,901 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,919 - config - INFO - Epoch [855/2000], Train Loss: 0.3557
2024-03-28 18:12:30,923 - config - INFO - Validation Loss: 0.4555
2024-03-28 18:12:30,923 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,942 - config - INFO - Epoch [856/2000], Train Loss: 0.3557
2024-03-28 18:12:30,946 - config - INFO - Validation Loss: 0.4557
2024-03-28 18:12:30,946 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,964 - config - INFO - Epoch [857/2000], Train Loss: 0.3559
2024-03-28 18:12:30,968 - config - INFO - Validation Loss: 0.4542
2024-03-28 18:12:30,968 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:30,987 - config - INFO - Epoch [858/2000], Train Loss: 0.3556
2024-03-28 18:12:30,991 - config - INFO - Validation Loss: 0.4550
2024-03-28 18:12:30,991 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,009 - config - INFO - Epoch [859/2000], Train Loss: 0.3554
2024-03-28 18:12:31,013 - config - INFO - Validation Loss: 0.4601
2024-03-28 18:12:31,013 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:31,032 - config - INFO - Epoch [860/2000], Train Loss: 0.3552
2024-03-28 18:12:31,036 - config - INFO - Validation Loss: 0.4587
2024-03-28 18:12:31,036 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:31,054 - config - INFO - Epoch [861/2000], Train Loss: 0.3566
2024-03-28 18:12:31,058 - config - INFO - Validation Loss: 0.4558
2024-03-28 18:12:31,059 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,077 - config - INFO - Epoch [862/2000], Train Loss: 0.3552
2024-03-28 18:12:31,081 - config - INFO - Validation Loss: 0.4589
2024-03-28 18:12:31,081 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:31,100 - config - INFO - Epoch [863/2000], Train Loss: 0.3550
2024-03-28 18:12:31,103 - config - INFO - Validation Loss: 0.4606
2024-03-28 18:12:31,104 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:31,122 - config - INFO - Epoch [864/2000], Train Loss: 0.3554
2024-03-28 18:12:31,126 - config - INFO - Validation Loss: 0.4564
2024-03-28 18:12:31,126 - config - INFO - Validation Acc: 0.8000
2024-03-28 18:12:31,145 - config - INFO - Epoch [865/2000], Train Loss: 0.3546
2024-03-28 18:12:31,149 - config - INFO - Validation Loss: 0.4578
2024-03-28 18:12:31,149 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,167 - config - INFO - Epoch [866/2000], Train Loss: 0.3552
2024-03-28 18:12:31,171 - config - INFO - Validation Loss: 0.4598
2024-03-28 18:12:31,171 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:31,190 - config - INFO - Epoch [867/2000], Train Loss: 0.3552
2024-03-28 18:12:31,194 - config - INFO - Validation Loss: 0.4564
2024-03-28 18:12:31,194 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,212 - config - INFO - Epoch [868/2000], Train Loss: 0.3550
2024-03-28 18:12:31,216 - config - INFO - Validation Loss: 0.4556
2024-03-28 18:12:31,217 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,235 - config - INFO - Epoch [869/2000], Train Loss: 0.3544
2024-03-28 18:12:31,239 - config - INFO - Validation Loss: 0.4593
2024-03-28 18:12:31,239 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:31,258 - config - INFO - Epoch [870/2000], Train Loss: 0.3552
2024-03-28 18:12:31,262 - config - INFO - Validation Loss: 0.4591
2024-03-28 18:12:31,262 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:31,280 - config - INFO - Epoch [871/2000], Train Loss: 0.3549
2024-03-28 18:12:31,284 - config - INFO - Validation Loss: 0.4579
2024-03-28 18:12:31,285 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,303 - config - INFO - Epoch [872/2000], Train Loss: 0.3548
2024-03-28 18:12:31,307 - config - INFO - Validation Loss: 0.4564
2024-03-28 18:12:31,307 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,326 - config - INFO - Epoch [873/2000], Train Loss: 0.3545
2024-03-28 18:12:31,330 - config - INFO - Validation Loss: 0.4556
2024-03-28 18:12:31,330 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,348 - config - INFO - Epoch [874/2000], Train Loss: 0.3542
2024-03-28 18:12:31,352 - config - INFO - Validation Loss: 0.4563
2024-03-28 18:12:31,352 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,371 - config - INFO - Epoch [875/2000], Train Loss: 0.3546
2024-03-28 18:12:31,375 - config - INFO - Validation Loss: 0.4544
2024-03-28 18:12:31,375 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,394 - config - INFO - Epoch [876/2000], Train Loss: 0.3543
2024-03-28 18:12:31,398 - config - INFO - Validation Loss: 0.4546
2024-03-28 18:12:31,398 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,416 - config - INFO - Epoch [877/2000], Train Loss: 0.3545
2024-03-28 18:12:31,420 - config - INFO - Validation Loss: 0.4554
2024-03-28 18:12:31,420 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,439 - config - INFO - Epoch [878/2000], Train Loss: 0.3540
2024-03-28 18:12:31,443 - config - INFO - Validation Loss: 0.4586
2024-03-28 18:12:31,443 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,461 - config - INFO - Epoch [879/2000], Train Loss: 0.3542
2024-03-28 18:12:31,465 - config - INFO - Validation Loss: 0.4589
2024-03-28 18:12:31,466 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,498 - config - INFO - Epoch [880/2000], Train Loss: 0.3546
2024-03-28 18:12:31,502 - config - INFO - Validation Loss: 0.4588
2024-03-28 18:12:31,502 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,521 - config - INFO - Epoch [881/2000], Train Loss: 0.3546
2024-03-28 18:12:31,525 - config - INFO - Validation Loss: 0.4591
2024-03-28 18:12:31,525 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:31,544 - config - INFO - Epoch [882/2000], Train Loss: 0.3538
2024-03-28 18:12:31,548 - config - INFO - Validation Loss: 0.4559
2024-03-28 18:12:31,548 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,566 - config - INFO - Epoch [883/2000], Train Loss: 0.3538
2024-03-28 18:12:31,570 - config - INFO - Validation Loss: 0.4556
2024-03-28 18:12:31,570 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,589 - config - INFO - Epoch [884/2000], Train Loss: 0.3539
2024-03-28 18:12:31,593 - config - INFO - Validation Loss: 0.4550
2024-03-28 18:12:31,593 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,611 - config - INFO - Epoch [885/2000], Train Loss: 0.3541
2024-03-28 18:12:31,615 - config - INFO - Validation Loss: 0.4553
2024-03-28 18:12:31,615 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,634 - config - INFO - Epoch [886/2000], Train Loss: 0.3536
2024-03-28 18:12:31,638 - config - INFO - Validation Loss: 0.4575
2024-03-28 18:12:31,638 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,657 - config - INFO - Epoch [887/2000], Train Loss: 0.3541
2024-03-28 18:12:31,660 - config - INFO - Validation Loss: 0.4586
2024-03-28 18:12:31,661 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,679 - config - INFO - Epoch [888/2000], Train Loss: 0.3535
2024-03-28 18:12:31,683 - config - INFO - Validation Loss: 0.4541
2024-03-28 18:12:31,683 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,702 - config - INFO - Epoch [889/2000], Train Loss: 0.3534
2024-03-28 18:12:31,706 - config - INFO - Validation Loss: 0.4562
2024-03-28 18:12:31,706 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,724 - config - INFO - Epoch [890/2000], Train Loss: 0.3533
2024-03-28 18:12:31,728 - config - INFO - Validation Loss: 0.4590
2024-03-28 18:12:31,728 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:31,747 - config - INFO - Epoch [891/2000], Train Loss: 0.3536
2024-03-28 18:12:31,751 - config - INFO - Validation Loss: 0.4580
2024-03-28 18:12:31,751 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,769 - config - INFO - Epoch [892/2000], Train Loss: 0.3549
2024-03-28 18:12:31,773 - config - INFO - Validation Loss: 0.4648
2024-03-28 18:12:31,773 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:31,792 - config - INFO - Epoch [893/2000], Train Loss: 0.3537
2024-03-28 18:12:31,796 - config - INFO - Validation Loss: 0.4607
2024-03-28 18:12:31,796 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,815 - config - INFO - Epoch [894/2000], Train Loss: 0.3534
2024-03-28 18:12:31,819 - config - INFO - Validation Loss: 0.4596
2024-03-28 18:12:31,819 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,837 - config - INFO - Epoch [895/2000], Train Loss: 0.3532
2024-03-28 18:12:31,841 - config - INFO - Validation Loss: 0.4593
2024-03-28 18:12:31,841 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,860 - config - INFO - Epoch [896/2000], Train Loss: 0.3531
2024-03-28 18:12:31,864 - config - INFO - Validation Loss: 0.4584
2024-03-28 18:12:31,864 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,883 - config - INFO - Epoch [897/2000], Train Loss: 0.3533
2024-03-28 18:12:31,887 - config - INFO - Validation Loss: 0.4575
2024-03-28 18:12:31,887 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,905 - config - INFO - Epoch [898/2000], Train Loss: 0.3532
2024-03-28 18:12:31,909 - config - INFO - Validation Loss: 0.4602
2024-03-28 18:12:31,909 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:31,928 - config - INFO - Epoch [899/2000], Train Loss: 0.3531
2024-03-28 18:12:31,932 - config - INFO - Validation Loss: 0.4588
2024-03-28 18:12:31,932 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:31,950 - config - INFO - Epoch [900/2000], Train Loss: 0.3525
2024-03-28 18:12:31,954 - config - INFO - Validation Loss: 0.4548
2024-03-28 18:12:31,954 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,973 - config - INFO - Epoch [901/2000], Train Loss: 0.3527
2024-03-28 18:12:31,977 - config - INFO - Validation Loss: 0.4543
2024-03-28 18:12:31,977 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:31,996 - config - INFO - Epoch [902/2000], Train Loss: 0.3527
2024-03-28 18:12:32,000 - config - INFO - Validation Loss: 0.4549
2024-03-28 18:12:32,000 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:32,018 - config - INFO - Epoch [903/2000], Train Loss: 0.3525
2024-03-28 18:12:32,022 - config - INFO - Validation Loss: 0.4569
2024-03-28 18:12:32,022 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:32,041 - config - INFO - Epoch [904/2000], Train Loss: 0.3527
2024-03-28 18:12:32,045 - config - INFO - Validation Loss: 0.4600
2024-03-28 18:12:32,045 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,063 - config - INFO - Epoch [905/2000], Train Loss: 0.3526
2024-03-28 18:12:32,067 - config - INFO - Validation Loss: 0.4579
2024-03-28 18:12:32,067 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:32,086 - config - INFO - Epoch [906/2000], Train Loss: 0.3524
2024-03-28 18:12:32,090 - config - INFO - Validation Loss: 0.4579
2024-03-28 18:12:32,090 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:32,109 - config - INFO - Epoch [907/2000], Train Loss: 0.3525
2024-03-28 18:12:32,112 - config - INFO - Validation Loss: 0.4609
2024-03-28 18:12:32,113 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,131 - config - INFO - Epoch [908/2000], Train Loss: 0.3526
2024-03-28 18:12:32,135 - config - INFO - Validation Loss: 0.4612
2024-03-28 18:12:32,135 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,154 - config - INFO - Epoch [909/2000], Train Loss: 0.3520
2024-03-28 18:12:32,158 - config - INFO - Validation Loss: 0.4574
2024-03-28 18:12:32,158 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,176 - config - INFO - Epoch [910/2000], Train Loss: 0.3519
2024-03-28 18:12:32,180 - config - INFO - Validation Loss: 0.4581
2024-03-28 18:12:32,180 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,199 - config - INFO - Epoch [911/2000], Train Loss: 0.3523
2024-03-28 18:12:32,203 - config - INFO - Validation Loss: 0.4569
2024-03-28 18:12:32,203 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:32,221 - config - INFO - Epoch [912/2000], Train Loss: 0.3518
2024-03-28 18:12:32,225 - config - INFO - Validation Loss: 0.4579
2024-03-28 18:12:32,225 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,244 - config - INFO - Epoch [913/2000], Train Loss: 0.3515
2024-03-28 18:12:32,248 - config - INFO - Validation Loss: 0.4639
2024-03-28 18:12:32,248 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,266 - config - INFO - Epoch [914/2000], Train Loss: 0.3539
2024-03-28 18:12:32,270 - config - INFO - Validation Loss: 0.4657
2024-03-28 18:12:32,270 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,289 - config - INFO - Epoch [915/2000], Train Loss: 0.3519
2024-03-28 18:12:32,293 - config - INFO - Validation Loss: 0.4595
2024-03-28 18:12:32,293 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,312 - config - INFO - Epoch [916/2000], Train Loss: 0.3518
2024-03-28 18:12:32,316 - config - INFO - Validation Loss: 0.4563
2024-03-28 18:12:32,316 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:32,334 - config - INFO - Epoch [917/2000], Train Loss: 0.3523
2024-03-28 18:12:32,338 - config - INFO - Validation Loss: 0.4550
2024-03-28 18:12:32,338 - config - INFO - Validation Acc: 0.8000
2024-03-28 18:12:32,357 - config - INFO - Epoch [918/2000], Train Loss: 0.3521
2024-03-28 18:12:32,361 - config - INFO - Validation Loss: 0.4598
2024-03-28 18:12:32,361 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,379 - config - INFO - Epoch [919/2000], Train Loss: 0.3517
2024-03-28 18:12:32,383 - config - INFO - Validation Loss: 0.4618
2024-03-28 18:12:32,384 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,402 - config - INFO - Epoch [920/2000], Train Loss: 0.3516
2024-03-28 18:12:32,406 - config - INFO - Validation Loss: 0.4573
2024-03-28 18:12:32,406 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:32,425 - config - INFO - Epoch [921/2000], Train Loss: 0.3517
2024-03-28 18:12:32,429 - config - INFO - Validation Loss: 0.4568
2024-03-28 18:12:32,429 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:32,447 - config - INFO - Epoch [922/2000], Train Loss: 0.3513
2024-03-28 18:12:32,451 - config - INFO - Validation Loss: 0.4578
2024-03-28 18:12:32,451 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,470 - config - INFO - Epoch [923/2000], Train Loss: 0.3515
2024-03-28 18:12:32,474 - config - INFO - Validation Loss: 0.4602
2024-03-28 18:12:32,474 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,493 - config - INFO - Epoch [924/2000], Train Loss: 0.3511
2024-03-28 18:12:32,496 - config - INFO - Validation Loss: 0.4616
2024-03-28 18:12:32,497 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,515 - config - INFO - Epoch [925/2000], Train Loss: 0.3515
2024-03-28 18:12:32,519 - config - INFO - Validation Loss: 0.4635
2024-03-28 18:12:32,519 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,538 - config - INFO - Epoch [926/2000], Train Loss: 0.3513
2024-03-28 18:12:32,542 - config - INFO - Validation Loss: 0.4597
2024-03-28 18:12:32,542 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:32,560 - config - INFO - Epoch [927/2000], Train Loss: 0.3512
2024-03-28 18:12:32,564 - config - INFO - Validation Loss: 0.4600
2024-03-28 18:12:32,564 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:32,583 - config - INFO - Epoch [928/2000], Train Loss: 0.3511
2024-03-28 18:12:32,587 - config - INFO - Validation Loss: 0.4602
2024-03-28 18:12:32,587 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,605 - config - INFO - Epoch [929/2000], Train Loss: 0.3514
2024-03-28 18:12:32,609 - config - INFO - Validation Loss: 0.4589
2024-03-28 18:12:32,609 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:32,628 - config - INFO - Epoch [930/2000], Train Loss: 0.3509
2024-03-28 18:12:32,632 - config - INFO - Validation Loss: 0.4610
2024-03-28 18:12:32,632 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,650 - config - INFO - Epoch [931/2000], Train Loss: 0.3519
2024-03-28 18:12:32,654 - config - INFO - Validation Loss: 0.4634
2024-03-28 18:12:32,655 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,673 - config - INFO - Epoch [932/2000], Train Loss: 0.3508
2024-03-28 18:12:32,677 - config - INFO - Validation Loss: 0.4595
2024-03-28 18:12:32,677 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,696 - config - INFO - Epoch [933/2000], Train Loss: 0.3502
2024-03-28 18:12:32,700 - config - INFO - Validation Loss: 0.4567
2024-03-28 18:12:32,700 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:32,718 - config - INFO - Epoch [934/2000], Train Loss: 0.3507
2024-03-28 18:12:32,722 - config - INFO - Validation Loss: 0.4562
2024-03-28 18:12:32,722 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:32,741 - config - INFO - Epoch [935/2000], Train Loss: 0.3513
2024-03-28 18:12:32,745 - config - INFO - Validation Loss: 0.4612
2024-03-28 18:12:32,745 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,763 - config - INFO - Epoch [936/2000], Train Loss: 0.3504
2024-03-28 18:12:32,767 - config - INFO - Validation Loss: 0.4612
2024-03-28 18:12:32,767 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,786 - config - INFO - Epoch [937/2000], Train Loss: 0.3504
2024-03-28 18:12:32,790 - config - INFO - Validation Loss: 0.4605
2024-03-28 18:12:32,790 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,808 - config - INFO - Epoch [938/2000], Train Loss: 0.3514
2024-03-28 18:12:32,812 - config - INFO - Validation Loss: 0.4616
2024-03-28 18:12:32,813 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,831 - config - INFO - Epoch [939/2000], Train Loss: 0.3506
2024-03-28 18:12:32,835 - config - INFO - Validation Loss: 0.4570
2024-03-28 18:12:32,835 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:32,854 - config - INFO - Epoch [940/2000], Train Loss: 0.3503
2024-03-28 18:12:32,858 - config - INFO - Validation Loss: 0.4573
2024-03-28 18:12:32,858 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:32,876 - config - INFO - Epoch [941/2000], Train Loss: 0.3501
2024-03-28 18:12:32,880 - config - INFO - Validation Loss: 0.4587
2024-03-28 18:12:32,880 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,899 - config - INFO - Epoch [942/2000], Train Loss: 0.3503
2024-03-28 18:12:32,903 - config - INFO - Validation Loss: 0.4610
2024-03-28 18:12:32,903 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,922 - config - INFO - Epoch [943/2000], Train Loss: 0.3505
2024-03-28 18:12:32,926 - config - INFO - Validation Loss: 0.4641
2024-03-28 18:12:32,926 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,944 - config - INFO - Epoch [944/2000], Train Loss: 0.3506
2024-03-28 18:12:32,948 - config - INFO - Validation Loss: 0.4597
2024-03-28 18:12:32,948 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,967 - config - INFO - Epoch [945/2000], Train Loss: 0.3498
2024-03-28 18:12:32,971 - config - INFO - Validation Loss: 0.4575
2024-03-28 18:12:32,971 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:32,989 - config - INFO - Epoch [946/2000], Train Loss: 0.3502
2024-03-28 18:12:32,993 - config - INFO - Validation Loss: 0.4590
2024-03-28 18:12:32,994 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:33,012 - config - INFO - Epoch [947/2000], Train Loss: 0.3499
2024-03-28 18:12:33,016 - config - INFO - Validation Loss: 0.4600
2024-03-28 18:12:33,016 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:33,035 - config - INFO - Epoch [948/2000], Train Loss: 0.3498
2024-03-28 18:12:33,039 - config - INFO - Validation Loss: 0.4586
2024-03-28 18:12:33,039 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:33,057 - config - INFO - Epoch [949/2000], Train Loss: 0.3493
2024-03-28 18:12:33,061 - config - INFO - Validation Loss: 0.4561
2024-03-28 18:12:33,061 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,080 - config - INFO - Epoch [950/2000], Train Loss: 0.3497
2024-03-28 18:12:33,084 - config - INFO - Validation Loss: 0.4558
2024-03-28 18:12:33,084 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,102 - config - INFO - Epoch [951/2000], Train Loss: 0.3497
2024-03-28 18:12:33,106 - config - INFO - Validation Loss: 0.4582
2024-03-28 18:12:33,106 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:33,125 - config - INFO - Epoch [952/2000], Train Loss: 0.3494
2024-03-28 18:12:33,129 - config - INFO - Validation Loss: 0.4575
2024-03-28 18:12:33,129 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:33,147 - config - INFO - Epoch [953/2000], Train Loss: 0.3498
2024-03-28 18:12:33,151 - config - INFO - Validation Loss: 0.4584
2024-03-28 18:12:33,151 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:33,170 - config - INFO - Epoch [954/2000], Train Loss: 0.3492
2024-03-28 18:12:33,174 - config - INFO - Validation Loss: 0.4578
2024-03-28 18:12:33,174 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:33,192 - config - INFO - Epoch [955/2000], Train Loss: 0.3491
2024-03-28 18:12:33,196 - config - INFO - Validation Loss: 0.4565
2024-03-28 18:12:33,197 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,215 - config - INFO - Epoch [956/2000], Train Loss: 0.3495
2024-03-28 18:12:33,219 - config - INFO - Validation Loss: 0.4563
2024-03-28 18:12:33,219 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,238 - config - INFO - Epoch [957/2000], Train Loss: 0.3496
2024-03-28 18:12:33,241 - config - INFO - Validation Loss: 0.4593
2024-03-28 18:12:33,242 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:33,260 - config - INFO - Epoch [958/2000], Train Loss: 0.3491
2024-03-28 18:12:33,264 - config - INFO - Validation Loss: 0.4575
2024-03-28 18:12:33,264 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,283 - config - INFO - Epoch [959/2000], Train Loss: 0.3492
2024-03-28 18:12:33,287 - config - INFO - Validation Loss: 0.4553
2024-03-28 18:12:33,287 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,306 - config - INFO - Epoch [960/2000], Train Loss: 0.3491
2024-03-28 18:12:33,310 - config - INFO - Validation Loss: 0.4577
2024-03-28 18:12:33,311 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,329 - config - INFO - Epoch [961/2000], Train Loss: 0.3488
2024-03-28 18:12:33,333 - config - INFO - Validation Loss: 0.4582
2024-03-28 18:12:33,333 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,352 - config - INFO - Epoch [962/2000], Train Loss: 0.3489
2024-03-28 18:12:33,356 - config - INFO - Validation Loss: 0.4590
2024-03-28 18:12:33,356 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,374 - config - INFO - Epoch [963/2000], Train Loss: 0.3490
2024-03-28 18:12:33,378 - config - INFO - Validation Loss: 0.4567
2024-03-28 18:12:33,378 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,397 - config - INFO - Epoch [964/2000], Train Loss: 0.3499
2024-03-28 18:12:33,401 - config - INFO - Validation Loss: 0.4601
2024-03-28 18:12:33,401 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:33,420 - config - INFO - Epoch [965/2000], Train Loss: 0.3483
2024-03-28 18:12:33,424 - config - INFO - Validation Loss: 0.4579
2024-03-28 18:12:33,424 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,442 - config - INFO - Epoch [966/2000], Train Loss: 0.3492
2024-03-28 18:12:33,446 - config - INFO - Validation Loss: 0.4553
2024-03-28 18:12:33,446 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,465 - config - INFO - Epoch [967/2000], Train Loss: 0.3489
2024-03-28 18:12:33,469 - config - INFO - Validation Loss: 0.4562
2024-03-28 18:12:33,469 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,487 - config - INFO - Epoch [968/2000], Train Loss: 0.3482
2024-03-28 18:12:33,491 - config - INFO - Validation Loss: 0.4602
2024-03-28 18:12:33,491 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:33,510 - config - INFO - Epoch [969/2000], Train Loss: 0.3489
2024-03-28 18:12:33,514 - config - INFO - Validation Loss: 0.4610
2024-03-28 18:12:33,514 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:33,533 - config - INFO - Epoch [970/2000], Train Loss: 0.3480
2024-03-28 18:12:33,536 - config - INFO - Validation Loss: 0.4558
2024-03-28 18:12:33,537 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,555 - config - INFO - Epoch [971/2000], Train Loss: 0.3487
2024-03-28 18:12:33,559 - config - INFO - Validation Loss: 0.4548
2024-03-28 18:12:33,559 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,578 - config - INFO - Epoch [972/2000], Train Loss: 0.3495
2024-03-28 18:12:33,582 - config - INFO - Validation Loss: 0.4586
2024-03-28 18:12:33,582 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,600 - config - INFO - Epoch [973/2000], Train Loss: 0.3493
2024-03-28 18:12:33,604 - config - INFO - Validation Loss: 0.4563
2024-03-28 18:12:33,604 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,623 - config - INFO - Epoch [974/2000], Train Loss: 0.3484
2024-03-28 18:12:33,627 - config - INFO - Validation Loss: 0.4599
2024-03-28 18:12:33,627 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:33,645 - config - INFO - Epoch [975/2000], Train Loss: 0.3486
2024-03-28 18:12:33,649 - config - INFO - Validation Loss: 0.4590
2024-03-28 18:12:33,650 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,668 - config - INFO - Epoch [976/2000], Train Loss: 0.3483
2024-03-28 18:12:33,672 - config - INFO - Validation Loss: 0.4585
2024-03-28 18:12:33,672 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,691 - config - INFO - Epoch [977/2000], Train Loss: 0.3483
2024-03-28 18:12:33,695 - config - INFO - Validation Loss: 0.4571
2024-03-28 18:12:33,695 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,713 - config - INFO - Epoch [978/2000], Train Loss: 0.3483
2024-03-28 18:12:33,717 - config - INFO - Validation Loss: 0.4576
2024-03-28 18:12:33,717 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,736 - config - INFO - Epoch [979/2000], Train Loss: 0.3482
2024-03-28 18:12:33,740 - config - INFO - Validation Loss: 0.4576
2024-03-28 18:12:33,740 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,758 - config - INFO - Epoch [980/2000], Train Loss: 0.3476
2024-03-28 18:12:33,762 - config - INFO - Validation Loss: 0.4556
2024-03-28 18:12:33,763 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,781 - config - INFO - Epoch [981/2000], Train Loss: 0.3486
2024-03-28 18:12:33,785 - config - INFO - Validation Loss: 0.4562
2024-03-28 18:12:33,785 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,804 - config - INFO - Epoch [982/2000], Train Loss: 0.3481
2024-03-28 18:12:33,808 - config - INFO - Validation Loss: 0.4564
2024-03-28 18:12:33,808 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,826 - config - INFO - Epoch [983/2000], Train Loss: 0.3481
2024-03-28 18:12:33,830 - config - INFO - Validation Loss: 0.4596
2024-03-28 18:12:33,830 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,849 - config - INFO - Epoch [984/2000], Train Loss: 0.3476
2024-03-28 18:12:33,853 - config - INFO - Validation Loss: 0.4589
2024-03-28 18:12:33,853 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,871 - config - INFO - Epoch [985/2000], Train Loss: 0.3476
2024-03-28 18:12:33,875 - config - INFO - Validation Loss: 0.4576
2024-03-28 18:12:33,875 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,894 - config - INFO - Epoch [986/2000], Train Loss: 0.3483
2024-03-28 18:12:33,898 - config - INFO - Validation Loss: 0.4597
2024-03-28 18:12:33,898 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:33,917 - config - INFO - Epoch [987/2000], Train Loss: 0.3496
2024-03-28 18:12:33,921 - config - INFO - Validation Loss: 0.4569
2024-03-28 18:12:33,921 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:33,939 - config - INFO - Epoch [988/2000], Train Loss: 0.3472
2024-03-28 18:12:33,943 - config - INFO - Validation Loss: 0.4598
2024-03-28 18:12:33,943 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:33,962 - config - INFO - Epoch [989/2000], Train Loss: 0.3473
2024-03-28 18:12:33,966 - config - INFO - Validation Loss: 0.4613
2024-03-28 18:12:33,966 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:33,984 - config - INFO - Epoch [990/2000], Train Loss: 0.3475
2024-03-28 18:12:33,988 - config - INFO - Validation Loss: 0.4588
2024-03-28 18:12:33,988 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:34,007 - config - INFO - Epoch [991/2000], Train Loss: 0.3471
2024-03-28 18:12:34,011 - config - INFO - Validation Loss: 0.4578
2024-03-28 18:12:34,011 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,030 - config - INFO - Epoch [992/2000], Train Loss: 0.3476
2024-03-28 18:12:34,033 - config - INFO - Validation Loss: 0.4567
2024-03-28 18:12:34,034 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,052 - config - INFO - Epoch [993/2000], Train Loss: 0.3473
2024-03-28 18:12:34,056 - config - INFO - Validation Loss: 0.4598
2024-03-28 18:12:34,056 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:34,075 - config - INFO - Epoch [994/2000], Train Loss: 0.3471
2024-03-28 18:12:34,079 - config - INFO - Validation Loss: 0.4594
2024-03-28 18:12:34,079 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:34,097 - config - INFO - Epoch [995/2000], Train Loss: 0.3470
2024-03-28 18:12:34,101 - config - INFO - Validation Loss: 0.4593
2024-03-28 18:12:34,101 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:34,120 - config - INFO - Epoch [996/2000], Train Loss: 0.3470
2024-03-28 18:12:34,124 - config - INFO - Validation Loss: 0.4594
2024-03-28 18:12:34,124 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:34,142 - config - INFO - Epoch [997/2000], Train Loss: 0.3472
2024-03-28 18:12:34,146 - config - INFO - Validation Loss: 0.4575
2024-03-28 18:12:34,147 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,165 - config - INFO - Epoch [998/2000], Train Loss: 0.3470
2024-03-28 18:12:34,169 - config - INFO - Validation Loss: 0.4585
2024-03-28 18:12:34,169 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,188 - config - INFO - Epoch [999/2000], Train Loss: 0.3469
2024-03-28 18:12:34,192 - config - INFO - Validation Loss: 0.4582
2024-03-28 18:12:34,192 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,210 - config - INFO - Epoch [1000/2000], Train Loss: 0.3471
2024-03-28 18:12:34,214 - config - INFO - Validation Loss: 0.4592
2024-03-28 18:12:34,214 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,233 - config - INFO - Epoch [1001/2000], Train Loss: 0.3468
2024-03-28 18:12:34,237 - config - INFO - Validation Loss: 0.4606
2024-03-28 18:12:34,237 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:34,255 - config - INFO - Epoch [1002/2000], Train Loss: 0.3480
2024-03-28 18:12:34,259 - config - INFO - Validation Loss: 0.4631
2024-03-28 18:12:34,260 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:34,278 - config - INFO - Epoch [1003/2000], Train Loss: 0.3473
2024-03-28 18:12:34,282 - config - INFO - Validation Loss: 0.4593
2024-03-28 18:12:34,282 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,301 - config - INFO - Epoch [1004/2000], Train Loss: 0.3467
2024-03-28 18:12:34,305 - config - INFO - Validation Loss: 0.4594
2024-03-28 18:12:34,305 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,323 - config - INFO - Epoch [1005/2000], Train Loss: 0.3487
2024-03-28 18:12:34,327 - config - INFO - Validation Loss: 0.4572
2024-03-28 18:12:34,327 - config - INFO - Validation Acc: 0.8000
2024-03-28 18:12:34,346 - config - INFO - Epoch [1006/2000], Train Loss: 0.3475
2024-03-28 18:12:34,350 - config - INFO - Validation Loss: 0.4595
2024-03-28 18:12:34,350 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,369 - config - INFO - Epoch [1007/2000], Train Loss: 0.3464
2024-03-28 18:12:34,373 - config - INFO - Validation Loss: 0.4586
2024-03-28 18:12:34,373 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,391 - config - INFO - Epoch [1008/2000], Train Loss: 0.3467
2024-03-28 18:12:34,395 - config - INFO - Validation Loss: 0.4579
2024-03-28 18:12:34,395 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,414 - config - INFO - Epoch [1009/2000], Train Loss: 0.3464
2024-03-28 18:12:34,418 - config - INFO - Validation Loss: 0.4590
2024-03-28 18:12:34,418 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,437 - config - INFO - Epoch [1010/2000], Train Loss: 0.3473
2024-03-28 18:12:34,441 - config - INFO - Validation Loss: 0.4636
2024-03-28 18:12:34,441 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:34,459 - config - INFO - Epoch [1011/2000], Train Loss: 0.3461
2024-03-28 18:12:34,463 - config - INFO - Validation Loss: 0.4605
2024-03-28 18:12:34,464 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,482 - config - INFO - Epoch [1012/2000], Train Loss: 0.3459
2024-03-28 18:12:34,486 - config - INFO - Validation Loss: 0.4587
2024-03-28 18:12:34,486 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,505 - config - INFO - Epoch [1013/2000], Train Loss: 0.3461
2024-03-28 18:12:34,509 - config - INFO - Validation Loss: 0.4586
2024-03-28 18:12:34,509 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,527 - config - INFO - Epoch [1014/2000], Train Loss: 0.3465
2024-03-28 18:12:34,531 - config - INFO - Validation Loss: 0.4599
2024-03-28 18:12:34,531 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,550 - config - INFO - Epoch [1015/2000], Train Loss: 0.3468
2024-03-28 18:12:34,554 - config - INFO - Validation Loss: 0.4557
2024-03-28 18:12:34,554 - config - INFO - Validation Acc: 0.8000
2024-03-28 18:12:34,572 - config - INFO - Epoch [1016/2000], Train Loss: 0.3463
2024-03-28 18:12:34,576 - config - INFO - Validation Loss: 0.4589
2024-03-28 18:12:34,576 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,595 - config - INFO - Epoch [1017/2000], Train Loss: 0.3461
2024-03-28 18:12:34,599 - config - INFO - Validation Loss: 0.4622
2024-03-28 18:12:34,599 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,618 - config - INFO - Epoch [1018/2000], Train Loss: 0.3473
2024-03-28 18:12:34,621 - config - INFO - Validation Loss: 0.4674
2024-03-28 18:12:34,622 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:34,640 - config - INFO - Epoch [1019/2000], Train Loss: 0.3475
2024-03-28 18:12:34,644 - config - INFO - Validation Loss: 0.4586
2024-03-28 18:12:34,644 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,663 - config - INFO - Epoch [1020/2000], Train Loss: 0.3460
2024-03-28 18:12:34,667 - config - INFO - Validation Loss: 0.4593
2024-03-28 18:12:34,667 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,685 - config - INFO - Epoch [1021/2000], Train Loss: 0.3471
2024-03-28 18:12:34,689 - config - INFO - Validation Loss: 0.4618
2024-03-28 18:12:34,689 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:34,708 - config - INFO - Epoch [1022/2000], Train Loss: 0.3454
2024-03-28 18:12:34,712 - config - INFO - Validation Loss: 0.4591
2024-03-28 18:12:34,712 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,730 - config - INFO - Epoch [1023/2000], Train Loss: 0.3460
2024-03-28 18:12:34,734 - config - INFO - Validation Loss: 0.4567
2024-03-28 18:12:34,734 - config - INFO - Validation Acc: 0.8000
2024-03-28 18:12:34,753 - config - INFO - Epoch [1024/2000], Train Loss: 0.3460
2024-03-28 18:12:34,757 - config - INFO - Validation Loss: 0.4588
2024-03-28 18:12:34,757 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,775 - config - INFO - Epoch [1025/2000], Train Loss: 0.3456
2024-03-28 18:12:34,779 - config - INFO - Validation Loss: 0.4575
2024-03-28 18:12:34,779 - config - INFO - Validation Acc: 0.8000
2024-03-28 18:12:34,798 - config - INFO - Epoch [1026/2000], Train Loss: 0.3455
2024-03-28 18:12:34,802 - config - INFO - Validation Loss: 0.4603
2024-03-28 18:12:34,802 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,820 - config - INFO - Epoch [1027/2000], Train Loss: 0.3454
2024-03-28 18:12:34,824 - config - INFO - Validation Loss: 0.4635
2024-03-28 18:12:34,824 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:34,843 - config - INFO - Epoch [1028/2000], Train Loss: 0.3459
2024-03-28 18:12:34,847 - config - INFO - Validation Loss: 0.4630
2024-03-28 18:12:34,847 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:34,866 - config - INFO - Epoch [1029/2000], Train Loss: 0.3453
2024-03-28 18:12:34,869 - config - INFO - Validation Loss: 0.4631
2024-03-28 18:12:34,870 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:34,888 - config - INFO - Epoch [1030/2000], Train Loss: 0.3454
2024-03-28 18:12:34,892 - config - INFO - Validation Loss: 0.4611
2024-03-28 18:12:34,892 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,911 - config - INFO - Epoch [1031/2000], Train Loss: 0.3464
2024-03-28 18:12:34,915 - config - INFO - Validation Loss: 0.4634
2024-03-28 18:12:34,915 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:34,934 - config - INFO - Epoch [1032/2000], Train Loss: 0.3468
2024-03-28 18:12:34,937 - config - INFO - Validation Loss: 0.4562
2024-03-28 18:12:34,938 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,956 - config - INFO - Epoch [1033/2000], Train Loss: 0.3452
2024-03-28 18:12:34,960 - config - INFO - Validation Loss: 0.4580
2024-03-28 18:12:34,960 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:34,979 - config - INFO - Epoch [1034/2000], Train Loss: 0.3449
2024-03-28 18:12:34,982 - config - INFO - Validation Loss: 0.4599
2024-03-28 18:12:34,983 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,001 - config - INFO - Epoch [1035/2000], Train Loss: 0.3451
2024-03-28 18:12:35,005 - config - INFO - Validation Loss: 0.4617
2024-03-28 18:12:35,005 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:35,024 - config - INFO - Epoch [1036/2000], Train Loss: 0.3450
2024-03-28 18:12:35,028 - config - INFO - Validation Loss: 0.4615
2024-03-28 18:12:35,028 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,046 - config - INFO - Epoch [1037/2000], Train Loss: 0.3451
2024-03-28 18:12:35,050 - config - INFO - Validation Loss: 0.4611
2024-03-28 18:12:35,050 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,069 - config - INFO - Epoch [1038/2000], Train Loss: 0.3447
2024-03-28 18:12:35,073 - config - INFO - Validation Loss: 0.4608
2024-03-28 18:12:35,073 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,091 - config - INFO - Epoch [1039/2000], Train Loss: 0.3448
2024-03-28 18:12:35,095 - config - INFO - Validation Loss: 0.4591
2024-03-28 18:12:35,095 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,114 - config - INFO - Epoch [1040/2000], Train Loss: 0.3448
2024-03-28 18:12:35,118 - config - INFO - Validation Loss: 0.4580
2024-03-28 18:12:35,118 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,136 - config - INFO - Epoch [1041/2000], Train Loss: 0.3450
2024-03-28 18:12:35,140 - config - INFO - Validation Loss: 0.4578
2024-03-28 18:12:35,140 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,159 - config - INFO - Epoch [1042/2000], Train Loss: 0.3447
2024-03-28 18:12:35,163 - config - INFO - Validation Loss: 0.4589
2024-03-28 18:12:35,163 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,181 - config - INFO - Epoch [1043/2000], Train Loss: 0.3456
2024-03-28 18:12:35,185 - config - INFO - Validation Loss: 0.4616
2024-03-28 18:12:35,185 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,204 - config - INFO - Epoch [1044/2000], Train Loss: 0.3445
2024-03-28 18:12:35,208 - config - INFO - Validation Loss: 0.4621
2024-03-28 18:12:35,208 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,227 - config - INFO - Epoch [1045/2000], Train Loss: 0.3443
2024-03-28 18:12:35,231 - config - INFO - Validation Loss: 0.4597
2024-03-28 18:12:35,231 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,249 - config - INFO - Epoch [1046/2000], Train Loss: 0.3452
2024-03-28 18:12:35,253 - config - INFO - Validation Loss: 0.4595
2024-03-28 18:12:35,253 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,272 - config - INFO - Epoch [1047/2000], Train Loss: 0.3442
2024-03-28 18:12:35,276 - config - INFO - Validation Loss: 0.4621
2024-03-28 18:12:35,276 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,294 - config - INFO - Epoch [1048/2000], Train Loss: 0.3449
2024-03-28 18:12:35,298 - config - INFO - Validation Loss: 0.4612
2024-03-28 18:12:35,298 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,317 - config - INFO - Epoch [1049/2000], Train Loss: 0.3448
2024-03-28 18:12:35,321 - config - INFO - Validation Loss: 0.4652
2024-03-28 18:12:35,321 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:35,339 - config - INFO - Epoch [1050/2000], Train Loss: 0.3449
2024-03-28 18:12:35,343 - config - INFO - Validation Loss: 0.4633
2024-03-28 18:12:35,343 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,362 - config - INFO - Epoch [1051/2000], Train Loss: 0.3443
2024-03-28 18:12:35,366 - config - INFO - Validation Loss: 0.4619
2024-03-28 18:12:35,366 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,384 - config - INFO - Epoch [1052/2000], Train Loss: 0.3446
2024-03-28 18:12:35,388 - config - INFO - Validation Loss: 0.4604
2024-03-28 18:12:35,389 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,407 - config - INFO - Epoch [1053/2000], Train Loss: 0.3447
2024-03-28 18:12:35,411 - config - INFO - Validation Loss: 0.4629
2024-03-28 18:12:35,411 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,430 - config - INFO - Epoch [1054/2000], Train Loss: 0.3446
2024-03-28 18:12:35,434 - config - INFO - Validation Loss: 0.4619
2024-03-28 18:12:35,434 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,452 - config - INFO - Epoch [1055/2000], Train Loss: 0.3445
2024-03-28 18:12:35,456 - config - INFO - Validation Loss: 0.4581
2024-03-28 18:12:35,456 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,475 - config - INFO - Epoch [1056/2000], Train Loss: 0.3444
2024-03-28 18:12:35,479 - config - INFO - Validation Loss: 0.4606
2024-03-28 18:12:35,479 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,497 - config - INFO - Epoch [1057/2000], Train Loss: 0.3440
2024-03-28 18:12:35,501 - config - INFO - Validation Loss: 0.4568
2024-03-28 18:12:35,501 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,520 - config - INFO - Epoch [1058/2000], Train Loss: 0.3443
2024-03-28 18:12:35,524 - config - INFO - Validation Loss: 0.4571
2024-03-28 18:12:35,524 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,542 - config - INFO - Epoch [1059/2000], Train Loss: 0.3441
2024-03-28 18:12:35,546 - config - INFO - Validation Loss: 0.4594
2024-03-28 18:12:35,546 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,565 - config - INFO - Epoch [1060/2000], Train Loss: 0.3443
2024-03-28 18:12:35,569 - config - INFO - Validation Loss: 0.4597
2024-03-28 18:12:35,569 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,587 - config - INFO - Epoch [1061/2000], Train Loss: 0.3437
2024-03-28 18:12:35,591 - config - INFO - Validation Loss: 0.4584
2024-03-28 18:12:35,591 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,610 - config - INFO - Epoch [1062/2000], Train Loss: 0.3435
2024-03-28 18:12:35,614 - config - INFO - Validation Loss: 0.4594
2024-03-28 18:12:35,614 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,633 - config - INFO - Epoch [1063/2000], Train Loss: 0.3435
2024-03-28 18:12:35,636 - config - INFO - Validation Loss: 0.4598
2024-03-28 18:12:35,637 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,655 - config - INFO - Epoch [1064/2000], Train Loss: 0.3437
2024-03-28 18:12:35,659 - config - INFO - Validation Loss: 0.4601
2024-03-28 18:12:35,659 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,678 - config - INFO - Epoch [1065/2000], Train Loss: 0.3435
2024-03-28 18:12:35,682 - config - INFO - Validation Loss: 0.4605
2024-03-28 18:12:35,682 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,700 - config - INFO - Epoch [1066/2000], Train Loss: 0.3435
2024-03-28 18:12:35,704 - config - INFO - Validation Loss: 0.4609
2024-03-28 18:12:35,704 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,723 - config - INFO - Epoch [1067/2000], Train Loss: 0.3435
2024-03-28 18:12:35,727 - config - INFO - Validation Loss: 0.4610
2024-03-28 18:12:35,727 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,746 - config - INFO - Epoch [1068/2000], Train Loss: 0.3433
2024-03-28 18:12:35,749 - config - INFO - Validation Loss: 0.4615
2024-03-28 18:12:35,750 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,768 - config - INFO - Epoch [1069/2000], Train Loss: 0.3438
2024-03-28 18:12:35,772 - config - INFO - Validation Loss: 0.4613
2024-03-28 18:12:35,772 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,791 - config - INFO - Epoch [1070/2000], Train Loss: 0.3433
2024-03-28 18:12:35,794 - config - INFO - Validation Loss: 0.4603
2024-03-28 18:12:35,795 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,813 - config - INFO - Epoch [1071/2000], Train Loss: 0.3431
2024-03-28 18:12:35,817 - config - INFO - Validation Loss: 0.4609
2024-03-28 18:12:35,817 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,836 - config - INFO - Epoch [1072/2000], Train Loss: 0.3437
2024-03-28 18:12:35,840 - config - INFO - Validation Loss: 0.4618
2024-03-28 18:12:35,840 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:35,858 - config - INFO - Epoch [1073/2000], Train Loss: 0.3428
2024-03-28 18:12:35,862 - config - INFO - Validation Loss: 0.4587
2024-03-28 18:12:35,862 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,881 - config - INFO - Epoch [1074/2000], Train Loss: 0.3438
2024-03-28 18:12:35,885 - config - INFO - Validation Loss: 0.4567
2024-03-28 18:12:35,885 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,903 - config - INFO - Epoch [1075/2000], Train Loss: 0.3431
2024-03-28 18:12:35,907 - config - INFO - Validation Loss: 0.4593
2024-03-28 18:12:35,907 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:35,926 - config - INFO - Epoch [1076/2000], Train Loss: 0.3425
2024-03-28 18:12:35,930 - config - INFO - Validation Loss: 0.4648
2024-03-28 18:12:35,930 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:35,949 - config - INFO - Epoch [1077/2000], Train Loss: 0.3434
2024-03-28 18:12:35,953 - config - INFO - Validation Loss: 0.4686
2024-03-28 18:12:35,953 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:35,971 - config - INFO - Epoch [1078/2000], Train Loss: 0.3433
2024-03-28 18:12:35,975 - config - INFO - Validation Loss: 0.4633
2024-03-28 18:12:35,975 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:35,994 - config - INFO - Epoch [1079/2000], Train Loss: 0.3424
2024-03-28 18:12:35,998 - config - INFO - Validation Loss: 0.4590
2024-03-28 18:12:35,998 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,016 - config - INFO - Epoch [1080/2000], Train Loss: 0.3435
2024-03-28 18:12:36,020 - config - INFO - Validation Loss: 0.4570
2024-03-28 18:12:36,020 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,039 - config - INFO - Epoch [1081/2000], Train Loss: 0.3432
2024-03-28 18:12:36,043 - config - INFO - Validation Loss: 0.4602
2024-03-28 18:12:36,043 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,061 - config - INFO - Epoch [1082/2000], Train Loss: 0.3429
2024-03-28 18:12:36,065 - config - INFO - Validation Loss: 0.4589
2024-03-28 18:12:36,065 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,084 - config - INFO - Epoch [1083/2000], Train Loss: 0.3430
2024-03-28 18:12:36,088 - config - INFO - Validation Loss: 0.4608
2024-03-28 18:12:36,088 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:36,106 - config - INFO - Epoch [1084/2000], Train Loss: 0.3427
2024-03-28 18:12:36,110 - config - INFO - Validation Loss: 0.4595
2024-03-28 18:12:36,110 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,129 - config - INFO - Epoch [1085/2000], Train Loss: 0.3432
2024-03-28 18:12:36,133 - config - INFO - Validation Loss: 0.4577
2024-03-28 18:12:36,133 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,151 - config - INFO - Epoch [1086/2000], Train Loss: 0.3426
2024-03-28 18:12:36,155 - config - INFO - Validation Loss: 0.4597
2024-03-28 18:12:36,156 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,174 - config - INFO - Epoch [1087/2000], Train Loss: 0.3423
2024-03-28 18:12:36,178 - config - INFO - Validation Loss: 0.4602
2024-03-28 18:12:36,178 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,197 - config - INFO - Epoch [1088/2000], Train Loss: 0.3424
2024-03-28 18:12:36,200 - config - INFO - Validation Loss: 0.4602
2024-03-28 18:12:36,201 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,219 - config - INFO - Epoch [1089/2000], Train Loss: 0.3427
2024-03-28 18:12:36,223 - config - INFO - Validation Loss: 0.4600
2024-03-28 18:12:36,223 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,242 - config - INFO - Epoch [1090/2000], Train Loss: 0.3425
2024-03-28 18:12:36,246 - config - INFO - Validation Loss: 0.4630
2024-03-28 18:12:36,246 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,264 - config - INFO - Epoch [1091/2000], Train Loss: 0.3422
2024-03-28 18:12:36,268 - config - INFO - Validation Loss: 0.4639
2024-03-28 18:12:36,268 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:36,287 - config - INFO - Epoch [1092/2000], Train Loss: 0.3423
2024-03-28 18:12:36,291 - config - INFO - Validation Loss: 0.4608
2024-03-28 18:12:36,291 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,309 - config - INFO - Epoch [1093/2000], Train Loss: 0.3428
2024-03-28 18:12:36,313 - config - INFO - Validation Loss: 0.4582
2024-03-28 18:12:36,313 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,332 - config - INFO - Epoch [1094/2000], Train Loss: 0.3421
2024-03-28 18:12:36,336 - config - INFO - Validation Loss: 0.4604
2024-03-28 18:12:36,336 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,354 - config - INFO - Epoch [1095/2000], Train Loss: 0.3423
2024-03-28 18:12:36,358 - config - INFO - Validation Loss: 0.4653
2024-03-28 18:12:36,358 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:36,377 - config - INFO - Epoch [1096/2000], Train Loss: 0.3421
2024-03-28 18:12:36,381 - config - INFO - Validation Loss: 0.4622
2024-03-28 18:12:36,381 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,400 - config - INFO - Epoch [1097/2000], Train Loss: 0.3419
2024-03-28 18:12:36,403 - config - INFO - Validation Loss: 0.4626
2024-03-28 18:12:36,404 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,422 - config - INFO - Epoch [1098/2000], Train Loss: 0.3422
2024-03-28 18:12:36,426 - config - INFO - Validation Loss: 0.4611
2024-03-28 18:12:36,426 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,445 - config - INFO - Epoch [1099/2000], Train Loss: 0.3417
2024-03-28 18:12:36,449 - config - INFO - Validation Loss: 0.4623
2024-03-28 18:12:36,449 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,467 - config - INFO - Epoch [1100/2000], Train Loss: 0.3422
2024-03-28 18:12:36,471 - config - INFO - Validation Loss: 0.4648
2024-03-28 18:12:36,479 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:36,501 - config - INFO - Epoch [1101/2000], Train Loss: 0.3424
2024-03-28 18:12:36,505 - config - INFO - Validation Loss: 0.4641
2024-03-28 18:12:36,506 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:36,524 - config - INFO - Epoch [1102/2000], Train Loss: 0.3421
2024-03-28 18:12:36,528 - config - INFO - Validation Loss: 0.4606
2024-03-28 18:12:36,528 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,547 - config - INFO - Epoch [1103/2000], Train Loss: 0.3418
2024-03-28 18:12:36,550 - config - INFO - Validation Loss: 0.4617
2024-03-28 18:12:36,551 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,569 - config - INFO - Epoch [1104/2000], Train Loss: 0.3416
2024-03-28 18:12:36,573 - config - INFO - Validation Loss: 0.4653
2024-03-28 18:12:36,573 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:36,592 - config - INFO - Epoch [1105/2000], Train Loss: 0.3419
2024-03-28 18:12:36,596 - config - INFO - Validation Loss: 0.4645
2024-03-28 18:12:36,596 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:36,614 - config - INFO - Epoch [1106/2000], Train Loss: 0.3410
2024-03-28 18:12:36,618 - config - INFO - Validation Loss: 0.4602
2024-03-28 18:12:36,618 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,637 - config - INFO - Epoch [1107/2000], Train Loss: 0.3427
2024-03-28 18:12:36,641 - config - INFO - Validation Loss: 0.4581
2024-03-28 18:12:36,641 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,659 - config - INFO - Epoch [1108/2000], Train Loss: 0.3412
2024-03-28 18:12:36,663 - config - INFO - Validation Loss: 0.4629
2024-03-28 18:12:36,663 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:36,682 - config - INFO - Epoch [1109/2000], Train Loss: 0.3420
2024-03-28 18:12:36,686 - config - INFO - Validation Loss: 0.4683
2024-03-28 18:12:36,686 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:36,705 - config - INFO - Epoch [1110/2000], Train Loss: 0.3427
2024-03-28 18:12:36,709 - config - INFO - Validation Loss: 0.4646
2024-03-28 18:12:36,709 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:36,727 - config - INFO - Epoch [1111/2000], Train Loss: 0.3418
2024-03-28 18:12:36,731 - config - INFO - Validation Loss: 0.4637
2024-03-28 18:12:36,731 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:36,750 - config - INFO - Epoch [1112/2000], Train Loss: 0.3430
2024-03-28 18:12:36,754 - config - INFO - Validation Loss: 0.4587
2024-03-28 18:12:36,754 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,772 - config - INFO - Epoch [1113/2000], Train Loss: 0.3415
2024-03-28 18:12:36,776 - config - INFO - Validation Loss: 0.4615
2024-03-28 18:12:36,776 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,795 - config - INFO - Epoch [1114/2000], Train Loss: 0.3418
2024-03-28 18:12:36,799 - config - INFO - Validation Loss: 0.4607
2024-03-28 18:12:36,799 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,817 - config - INFO - Epoch [1115/2000], Train Loss: 0.3415
2024-03-28 18:12:36,821 - config - INFO - Validation Loss: 0.4622
2024-03-28 18:12:36,821 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,840 - config - INFO - Epoch [1116/2000], Train Loss: 0.3413
2024-03-28 18:12:36,844 - config - INFO - Validation Loss: 0.4611
2024-03-28 18:12:36,844 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,862 - config - INFO - Epoch [1117/2000], Train Loss: 0.3411
2024-03-28 18:12:36,866 - config - INFO - Validation Loss: 0.4611
2024-03-28 18:12:36,867 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,885 - config - INFO - Epoch [1118/2000], Train Loss: 0.3411
2024-03-28 18:12:36,889 - config - INFO - Validation Loss: 0.4625
2024-03-28 18:12:36,889 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,908 - config - INFO - Epoch [1119/2000], Train Loss: 0.3407
2024-03-28 18:12:36,912 - config - INFO - Validation Loss: 0.4609
2024-03-28 18:12:36,912 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,930 - config - INFO - Epoch [1120/2000], Train Loss: 0.3409
2024-03-28 18:12:36,934 - config - INFO - Validation Loss: 0.4605
2024-03-28 18:12:36,934 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:36,953 - config - INFO - Epoch [1121/2000], Train Loss: 0.3412
2024-03-28 18:12:36,957 - config - INFO - Validation Loss: 0.4635
2024-03-28 18:12:36,957 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:36,975 - config - INFO - Epoch [1122/2000], Train Loss: 0.3411
2024-03-28 18:12:36,979 - config - INFO - Validation Loss: 0.4627
2024-03-28 18:12:36,979 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:36,998 - config - INFO - Epoch [1123/2000], Train Loss: 0.3422
2024-03-28 18:12:37,002 - config - INFO - Validation Loss: 0.4647
2024-03-28 18:12:37,002 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:37,020 - config - INFO - Epoch [1124/2000], Train Loss: 0.3415
2024-03-28 18:12:37,024 - config - INFO - Validation Loss: 0.4571
2024-03-28 18:12:37,025 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,043 - config - INFO - Epoch [1125/2000], Train Loss: 0.3409
2024-03-28 18:12:37,047 - config - INFO - Validation Loss: 0.4576
2024-03-28 18:12:37,047 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,066 - config - INFO - Epoch [1126/2000], Train Loss: 0.3410
2024-03-28 18:12:37,069 - config - INFO - Validation Loss: 0.4606
2024-03-28 18:12:37,070 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,088 - config - INFO - Epoch [1127/2000], Train Loss: 0.3407
2024-03-28 18:12:37,092 - config - INFO - Validation Loss: 0.4607
2024-03-28 18:12:37,092 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,111 - config - INFO - Epoch [1128/2000], Train Loss: 0.3403
2024-03-28 18:12:37,115 - config - INFO - Validation Loss: 0.4576
2024-03-28 18:12:37,115 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,133 - config - INFO - Epoch [1129/2000], Train Loss: 0.3410
2024-03-28 18:12:37,137 - config - INFO - Validation Loss: 0.4568
2024-03-28 18:12:37,137 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,156 - config - INFO - Epoch [1130/2000], Train Loss: 0.3409
2024-03-28 18:12:37,159 - config - INFO - Validation Loss: 0.4608
2024-03-28 18:12:37,160 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,178 - config - INFO - Epoch [1131/2000], Train Loss: 0.3406
2024-03-28 18:12:37,182 - config - INFO - Validation Loss: 0.4633
2024-03-28 18:12:37,182 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:37,201 - config - INFO - Epoch [1132/2000], Train Loss: 0.3402
2024-03-28 18:12:37,205 - config - INFO - Validation Loss: 0.4647
2024-03-28 18:12:37,205 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:37,223 - config - INFO - Epoch [1133/2000], Train Loss: 0.3404
2024-03-28 18:12:37,227 - config - INFO - Validation Loss: 0.4643
2024-03-28 18:12:37,227 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:37,246 - config - INFO - Epoch [1134/2000], Train Loss: 0.3403
2024-03-28 18:12:37,250 - config - INFO - Validation Loss: 0.4648
2024-03-28 18:12:37,250 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:37,268 - config - INFO - Epoch [1135/2000], Train Loss: 0.3406
2024-03-28 18:12:37,272 - config - INFO - Validation Loss: 0.4658
2024-03-28 18:12:37,272 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:37,291 - config - INFO - Epoch [1136/2000], Train Loss: 0.3399
2024-03-28 18:12:37,295 - config - INFO - Validation Loss: 0.4632
2024-03-28 18:12:37,295 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,313 - config - INFO - Epoch [1137/2000], Train Loss: 0.3408
2024-03-28 18:12:37,317 - config - INFO - Validation Loss: 0.4618
2024-03-28 18:12:37,317 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,336 - config - INFO - Epoch [1138/2000], Train Loss: 0.3405
2024-03-28 18:12:37,340 - config - INFO - Validation Loss: 0.4603
2024-03-28 18:12:37,340 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,360 - config - INFO - Epoch [1139/2000], Train Loss: 0.3399
2024-03-28 18:12:37,364 - config - INFO - Validation Loss: 0.4643
2024-03-28 18:12:37,364 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:37,383 - config - INFO - Epoch [1140/2000], Train Loss: 0.3401
2024-03-28 18:12:37,387 - config - INFO - Validation Loss: 0.4663
2024-03-28 18:12:37,387 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:37,406 - config - INFO - Epoch [1141/2000], Train Loss: 0.3404
2024-03-28 18:12:37,410 - config - INFO - Validation Loss: 0.4662
2024-03-28 18:12:37,410 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:37,428 - config - INFO - Epoch [1142/2000], Train Loss: 0.3397
2024-03-28 18:12:37,432 - config - INFO - Validation Loss: 0.4611
2024-03-28 18:12:37,433 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,451 - config - INFO - Epoch [1143/2000], Train Loss: 0.3401
2024-03-28 18:12:37,455 - config - INFO - Validation Loss: 0.4593
2024-03-28 18:12:37,455 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,474 - config - INFO - Epoch [1144/2000], Train Loss: 0.3401
2024-03-28 18:12:37,478 - config - INFO - Validation Loss: 0.4575
2024-03-28 18:12:37,478 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,497 - config - INFO - Epoch [1145/2000], Train Loss: 0.3400
2024-03-28 18:12:37,500 - config - INFO - Validation Loss: 0.4584
2024-03-28 18:12:37,501 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,519 - config - INFO - Epoch [1146/2000], Train Loss: 0.3394
2024-03-28 18:12:37,523 - config - INFO - Validation Loss: 0.4601
2024-03-28 18:12:37,523 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,542 - config - INFO - Epoch [1147/2000], Train Loss: 0.3399
2024-03-28 18:12:37,546 - config - INFO - Validation Loss: 0.4622
2024-03-28 18:12:37,546 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:37,564 - config - INFO - Epoch [1148/2000], Train Loss: 0.3396
2024-03-28 18:12:37,568 - config - INFO - Validation Loss: 0.4612
2024-03-28 18:12:37,568 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,587 - config - INFO - Epoch [1149/2000], Train Loss: 0.3398
2024-03-28 18:12:37,591 - config - INFO - Validation Loss: 0.4632
2024-03-28 18:12:37,591 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,609 - config - INFO - Epoch [1150/2000], Train Loss: 0.3392
2024-03-28 18:12:37,613 - config - INFO - Validation Loss: 0.4617
2024-03-28 18:12:37,614 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,632 - config - INFO - Epoch [1151/2000], Train Loss: 0.3394
2024-03-28 18:12:37,636 - config - INFO - Validation Loss: 0.4600
2024-03-28 18:12:37,636 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,655 - config - INFO - Epoch [1152/2000], Train Loss: 0.3400
2024-03-28 18:12:37,659 - config - INFO - Validation Loss: 0.4593
2024-03-28 18:12:37,659 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,677 - config - INFO - Epoch [1153/2000], Train Loss: 0.3395
2024-03-28 18:12:37,681 - config - INFO - Validation Loss: 0.4613
2024-03-28 18:12:37,681 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:37,700 - config - INFO - Epoch [1154/2000], Train Loss: 0.3394
2024-03-28 18:12:37,704 - config - INFO - Validation Loss: 0.4626
2024-03-28 18:12:37,704 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,723 - config - INFO - Epoch [1155/2000], Train Loss: 0.3403
2024-03-28 18:12:37,727 - config - INFO - Validation Loss: 0.4581
2024-03-28 18:12:37,727 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,745 - config - INFO - Epoch [1156/2000], Train Loss: 0.3398
2024-03-28 18:12:37,749 - config - INFO - Validation Loss: 0.4626
2024-03-28 18:12:37,749 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,768 - config - INFO - Epoch [1157/2000], Train Loss: 0.3403
2024-03-28 18:12:37,772 - config - INFO - Validation Loss: 0.4644
2024-03-28 18:12:37,772 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:37,790 - config - INFO - Epoch [1158/2000], Train Loss: 0.3398
2024-03-28 18:12:37,794 - config - INFO - Validation Loss: 0.4624
2024-03-28 18:12:37,794 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,813 - config - INFO - Epoch [1159/2000], Train Loss: 0.3390
2024-03-28 18:12:37,817 - config - INFO - Validation Loss: 0.4611
2024-03-28 18:12:37,817 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,835 - config - INFO - Epoch [1160/2000], Train Loss: 0.3395
2024-03-28 18:12:37,839 - config - INFO - Validation Loss: 0.4618
2024-03-28 18:12:37,839 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,858 - config - INFO - Epoch [1161/2000], Train Loss: 0.3396
2024-03-28 18:12:37,862 - config - INFO - Validation Loss: 0.4611
2024-03-28 18:12:37,862 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,880 - config - INFO - Epoch [1162/2000], Train Loss: 0.3387
2024-03-28 18:12:37,884 - config - INFO - Validation Loss: 0.4621
2024-03-28 18:12:37,885 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,903 - config - INFO - Epoch [1163/2000], Train Loss: 0.3387
2024-03-28 18:12:37,907 - config - INFO - Validation Loss: 0.4622
2024-03-28 18:12:37,907 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,926 - config - INFO - Epoch [1164/2000], Train Loss: 0.3390
2024-03-28 18:12:37,930 - config - INFO - Validation Loss: 0.4633
2024-03-28 18:12:37,930 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,948 - config - INFO - Epoch [1165/2000], Train Loss: 0.3389
2024-03-28 18:12:37,952 - config - INFO - Validation Loss: 0.4609
2024-03-28 18:12:37,952 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:37,971 - config - INFO - Epoch [1166/2000], Train Loss: 0.3386
2024-03-28 18:12:37,975 - config - INFO - Validation Loss: 0.4654
2024-03-28 18:12:37,975 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:37,994 - config - INFO - Epoch [1167/2000], Train Loss: 0.3391
2024-03-28 18:12:37,998 - config - INFO - Validation Loss: 0.4659
2024-03-28 18:12:37,998 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:38,016 - config - INFO - Epoch [1168/2000], Train Loss: 0.3388
2024-03-28 18:12:38,020 - config - INFO - Validation Loss: 0.4656
2024-03-28 18:12:38,020 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:38,039 - config - INFO - Epoch [1169/2000], Train Loss: 0.3394
2024-03-28 18:12:38,043 - config - INFO - Validation Loss: 0.4660
2024-03-28 18:12:38,043 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:38,061 - config - INFO - Epoch [1170/2000], Train Loss: 0.3390
2024-03-28 18:12:38,065 - config - INFO - Validation Loss: 0.4635
2024-03-28 18:12:38,065 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:38,084 - config - INFO - Epoch [1171/2000], Train Loss: 0.3393
2024-03-28 18:12:38,088 - config - INFO - Validation Loss: 0.4608
2024-03-28 18:12:38,088 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:38,106 - config - INFO - Epoch [1172/2000], Train Loss: 0.3386
2024-03-28 18:12:38,110 - config - INFO - Validation Loss: 0.4662
2024-03-28 18:12:38,110 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:38,129 - config - INFO - Epoch [1173/2000], Train Loss: 0.3389
2024-03-28 18:12:38,133 - config - INFO - Validation Loss: 0.4653
2024-03-28 18:12:38,133 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:38,152 - config - INFO - Epoch [1174/2000], Train Loss: 0.3383
2024-03-28 18:12:38,155 - config - INFO - Validation Loss: 0.4620
2024-03-28 18:12:38,156 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:38,174 - config - INFO - Epoch [1175/2000], Train Loss: 0.3383
2024-03-28 18:12:38,178 - config - INFO - Validation Loss: 0.4595
2024-03-28 18:12:38,178 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:38,197 - config - INFO - Epoch [1176/2000], Train Loss: 0.3384
2024-03-28 18:12:38,200 - config - INFO - Validation Loss: 0.4596
2024-03-28 18:12:38,201 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:38,219 - config - INFO - Epoch [1177/2000], Train Loss: 0.3387
2024-03-28 18:12:38,223 - config - INFO - Validation Loss: 0.4625
2024-03-28 18:12:38,223 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:38,242 - config - INFO - Epoch [1178/2000], Train Loss: 0.3383
2024-03-28 18:12:38,246 - config - INFO - Validation Loss: 0.4604
2024-03-28 18:12:38,246 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:38,264 - config - INFO - Epoch [1179/2000], Train Loss: 0.3380
2024-03-28 18:12:38,268 - config - INFO - Validation Loss: 0.4606
2024-03-28 18:12:38,268 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:38,287 - config - INFO - Epoch [1180/2000], Train Loss: 0.3382
2024-03-28 18:12:38,291 - config - INFO - Validation Loss: 0.4624
2024-03-28 18:12:38,291 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:38,309 - config - INFO - Epoch [1181/2000], Train Loss: 0.3391
2024-03-28 18:12:38,313 - config - INFO - Validation Loss: 0.4621
2024-03-28 18:12:38,313 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:38,332 - config - INFO - Epoch [1182/2000], Train Loss: 0.3386
2024-03-28 18:12:38,336 - config - INFO - Validation Loss: 0.4601
2024-03-28 18:12:38,336 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:38,354 - config - INFO - Epoch [1183/2000], Train Loss: 0.3380
2024-03-28 18:12:38,358 - config - INFO - Validation Loss: 0.4618
2024-03-28 18:12:38,359 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:38,379 - config - INFO - Epoch [1184/2000], Train Loss: 0.3381
2024-03-28 18:12:38,383 - config - INFO - Validation Loss: 0.4627
2024-03-28 18:12:38,383 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:38,402 - config - INFO - Epoch [1185/2000], Train Loss: 0.3378
2024-03-28 18:12:38,406 - config - INFO - Validation Loss: 0.4629
2024-03-28 18:12:38,406 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:38,424 - config - INFO - Epoch [1186/2000], Train Loss: 0.3381
2024-03-28 18:12:38,428 - config - INFO - Validation Loss: 0.4607
2024-03-28 18:12:38,428 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:38,447 - config - INFO - Epoch [1187/2000], Train Loss: 0.3377
2024-03-28 18:12:38,451 - config - INFO - Validation Loss: 0.4636
2024-03-28 18:12:38,451 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:38,470 - config - INFO - Epoch [1188/2000], Train Loss: 0.3377
2024-03-28 18:12:38,474 - config - INFO - Validation Loss: 0.4634
2024-03-28 18:12:38,474 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:38,492 - config - INFO - Epoch [1189/2000], Train Loss: 0.3378
2024-03-28 18:12:38,496 - config - INFO - Validation Loss: 0.4648
2024-03-28 18:12:38,496 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:38,515 - config - INFO - Epoch [1190/2000], Train Loss: 0.3374
2024-03-28 18:12:38,519 - config - INFO - Validation Loss: 0.4628
2024-03-28 18:12:38,519 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:38,537 - config - INFO - Epoch [1191/2000], Train Loss: 0.3374
2024-03-28 18:12:38,541 - config - INFO - Validation Loss: 0.4604
2024-03-28 18:12:38,542 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:38,560 - config - INFO - Epoch [1192/2000], Train Loss: 0.3380
2024-03-28 18:12:38,564 - config - INFO - Validation Loss: 0.4592
2024-03-28 18:12:38,564 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:38,583 - config - INFO - Epoch [1193/2000], Train Loss: 0.3385
2024-03-28 18:12:38,586 - config - INFO - Validation Loss: 0.4635
2024-03-28 18:12:38,587 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:38,605 - config - INFO - Epoch [1194/2000], Train Loss: 0.3376
2024-03-28 18:12:38,609 - config - INFO - Validation Loss: 0.4623
2024-03-28 18:12:38,609 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:38,628 - config - INFO - Epoch [1195/2000], Train Loss: 0.3381
2024-03-28 18:12:38,632 - config - INFO - Validation Loss: 0.4596
2024-03-28 18:12:38,632 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:38,650 - config - INFO - Epoch [1196/2000], Train Loss: 0.3374
2024-03-28 18:12:38,654 - config - INFO - Validation Loss: 0.4621
2024-03-28 18:12:38,654 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:38,673 - config - INFO - Epoch [1197/2000], Train Loss: 0.3389
2024-03-28 18:12:38,677 - config - INFO - Validation Loss: 0.4661
2024-03-28 18:12:38,677 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:38,695 - config - INFO - Epoch [1198/2000], Train Loss: 0.3370
2024-03-28 18:12:38,699 - config - INFO - Validation Loss: 0.4625
2024-03-28 18:12:38,699 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:38,718 - config - INFO - Epoch [1199/2000], Train Loss: 0.3381
2024-03-28 18:12:38,722 - config - INFO - Validation Loss: 0.4599
2024-03-28 18:12:38,722 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:38,740 - config - INFO - Epoch [1200/2000], Train Loss: 0.3379
2024-03-28 18:12:38,744 - config - INFO - Validation Loss: 0.4625
2024-03-28 18:12:38,744 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:38,763 - config - INFO - Epoch [1201/2000], Train Loss: 0.3372
2024-03-28 18:12:38,767 - config - INFO - Validation Loss: 0.4651
2024-03-28 18:12:38,767 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:38,785 - config - INFO - Epoch [1202/2000], Train Loss: 0.3373
2024-03-28 18:12:38,789 - config - INFO - Validation Loss: 0.4628
2024-03-28 18:12:38,790 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:38,808 - config - INFO - Epoch [1203/2000], Train Loss: 0.3372
2024-03-28 18:12:38,812 - config - INFO - Validation Loss: 0.4623
2024-03-28 18:12:38,812 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:38,831 - config - INFO - Epoch [1204/2000], Train Loss: 0.3372
2024-03-28 18:12:38,835 - config - INFO - Validation Loss: 0.4617
2024-03-28 18:12:38,835 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:38,853 - config - INFO - Epoch [1205/2000], Train Loss: 0.3369
2024-03-28 18:12:38,857 - config - INFO - Validation Loss: 0.4614
2024-03-28 18:12:38,857 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:38,876 - config - INFO - Epoch [1206/2000], Train Loss: 0.3384
2024-03-28 18:12:38,880 - config - INFO - Validation Loss: 0.4591
2024-03-28 18:12:38,880 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:38,898 - config - INFO - Epoch [1207/2000], Train Loss: 0.3380
2024-03-28 18:12:38,902 - config - INFO - Validation Loss: 0.4625
2024-03-28 18:12:38,902 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:38,921 - config - INFO - Epoch [1208/2000], Train Loss: 0.3378
2024-03-28 18:12:38,925 - config - INFO - Validation Loss: 0.4585
2024-03-28 18:12:38,925 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:38,943 - config - INFO - Epoch [1209/2000], Train Loss: 0.3374
2024-03-28 18:12:38,947 - config - INFO - Validation Loss: 0.4605
2024-03-28 18:12:38,948 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:38,966 - config - INFO - Epoch [1210/2000], Train Loss: 0.3367
2024-03-28 18:12:38,970 - config - INFO - Validation Loss: 0.4618
2024-03-28 18:12:38,970 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:38,989 - config - INFO - Epoch [1211/2000], Train Loss: 0.3368
2024-03-28 18:12:38,993 - config - INFO - Validation Loss: 0.4652
2024-03-28 18:12:38,993 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,011 - config - INFO - Epoch [1212/2000], Train Loss: 0.3374
2024-03-28 18:12:39,015 - config - INFO - Validation Loss: 0.4678
2024-03-28 18:12:39,015 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,034 - config - INFO - Epoch [1213/2000], Train Loss: 0.3366
2024-03-28 18:12:39,038 - config - INFO - Validation Loss: 0.4636
2024-03-28 18:12:39,038 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,056 - config - INFO - Epoch [1214/2000], Train Loss: 0.3365
2024-03-28 18:12:39,060 - config - INFO - Validation Loss: 0.4630
2024-03-28 18:12:39,060 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,079 - config - INFO - Epoch [1215/2000], Train Loss: 0.3364
2024-03-28 18:12:39,083 - config - INFO - Validation Loss: 0.4620
2024-03-28 18:12:39,083 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,102 - config - INFO - Epoch [1216/2000], Train Loss: 0.3365
2024-03-28 18:12:39,105 - config - INFO - Validation Loss: 0.4622
2024-03-28 18:12:39,106 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,124 - config - INFO - Epoch [1217/2000], Train Loss: 0.3366
2024-03-28 18:12:39,128 - config - INFO - Validation Loss: 0.4629
2024-03-28 18:12:39,128 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,147 - config - INFO - Epoch [1218/2000], Train Loss: 0.3374
2024-03-28 18:12:39,151 - config - INFO - Validation Loss: 0.4663
2024-03-28 18:12:39,151 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,169 - config - INFO - Epoch [1219/2000], Train Loss: 0.3369
2024-03-28 18:12:39,173 - config - INFO - Validation Loss: 0.4633
2024-03-28 18:12:39,173 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,192 - config - INFO - Epoch [1220/2000], Train Loss: 0.3364
2024-03-28 18:12:39,196 - config - INFO - Validation Loss: 0.4629
2024-03-28 18:12:39,196 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:39,214 - config - INFO - Epoch [1221/2000], Train Loss: 0.3372
2024-03-28 18:12:39,218 - config - INFO - Validation Loss: 0.4665
2024-03-28 18:12:39,218 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,237 - config - INFO - Epoch [1222/2000], Train Loss: 0.3367
2024-03-28 18:12:39,241 - config - INFO - Validation Loss: 0.4635
2024-03-28 18:12:39,241 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,259 - config - INFO - Epoch [1223/2000], Train Loss: 0.3362
2024-03-28 18:12:39,263 - config - INFO - Validation Loss: 0.4646
2024-03-28 18:12:39,263 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,282 - config - INFO - Epoch [1224/2000], Train Loss: 0.3362
2024-03-28 18:12:39,286 - config - INFO - Validation Loss: 0.4637
2024-03-28 18:12:39,286 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:39,305 - config - INFO - Epoch [1225/2000], Train Loss: 0.3360
2024-03-28 18:12:39,308 - config - INFO - Validation Loss: 0.4635
2024-03-28 18:12:39,309 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,327 - config - INFO - Epoch [1226/2000], Train Loss: 0.3365
2024-03-28 18:12:39,331 - config - INFO - Validation Loss: 0.4661
2024-03-28 18:12:39,331 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,350 - config - INFO - Epoch [1227/2000], Train Loss: 0.3370
2024-03-28 18:12:39,354 - config - INFO - Validation Loss: 0.4689
2024-03-28 18:12:39,354 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,377 - config - INFO - Epoch [1228/2000], Train Loss: 0.3365
2024-03-28 18:12:39,381 - config - INFO - Validation Loss: 0.4648
2024-03-28 18:12:39,381 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,400 - config - INFO - Epoch [1229/2000], Train Loss: 0.3367
2024-03-28 18:12:39,404 - config - INFO - Validation Loss: 0.4663
2024-03-28 18:12:39,404 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,423 - config - INFO - Epoch [1230/2000], Train Loss: 0.3357
2024-03-28 18:12:39,427 - config - INFO - Validation Loss: 0.4618
2024-03-28 18:12:39,427 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,445 - config - INFO - Epoch [1231/2000], Train Loss: 0.3363
2024-03-28 18:12:39,449 - config - INFO - Validation Loss: 0.4614
2024-03-28 18:12:39,449 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,468 - config - INFO - Epoch [1232/2000], Train Loss: 0.3363
2024-03-28 18:12:39,472 - config - INFO - Validation Loss: 0.4621
2024-03-28 18:12:39,472 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,491 - config - INFO - Epoch [1233/2000], Train Loss: 0.3359
2024-03-28 18:12:39,494 - config - INFO - Validation Loss: 0.4620
2024-03-28 18:12:39,495 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,513 - config - INFO - Epoch [1234/2000], Train Loss: 0.3357
2024-03-28 18:12:39,517 - config - INFO - Validation Loss: 0.4612
2024-03-28 18:12:39,517 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,536 - config - INFO - Epoch [1235/2000], Train Loss: 0.3362
2024-03-28 18:12:39,540 - config - INFO - Validation Loss: 0.4591
2024-03-28 18:12:39,540 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,558 - config - INFO - Epoch [1236/2000], Train Loss: 0.3360
2024-03-28 18:12:39,562 - config - INFO - Validation Loss: 0.4603
2024-03-28 18:12:39,562 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,581 - config - INFO - Epoch [1237/2000], Train Loss: 0.3358
2024-03-28 18:12:39,585 - config - INFO - Validation Loss: 0.4612
2024-03-28 18:12:39,585 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,603 - config - INFO - Epoch [1238/2000], Train Loss: 0.3357
2024-03-28 18:12:39,607 - config - INFO - Validation Loss: 0.4628
2024-03-28 18:12:39,607 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,626 - config - INFO - Epoch [1239/2000], Train Loss: 0.3355
2024-03-28 18:12:39,630 - config - INFO - Validation Loss: 0.4630
2024-03-28 18:12:39,630 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,648 - config - INFO - Epoch [1240/2000], Train Loss: 0.3358
2024-03-28 18:12:39,652 - config - INFO - Validation Loss: 0.4626
2024-03-28 18:12:39,653 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,671 - config - INFO - Epoch [1241/2000], Train Loss: 0.3357
2024-03-28 18:12:39,675 - config - INFO - Validation Loss: 0.4651
2024-03-28 18:12:39,675 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,694 - config - INFO - Epoch [1242/2000], Train Loss: 0.3360
2024-03-28 18:12:39,698 - config - INFO - Validation Loss: 0.4678
2024-03-28 18:12:39,698 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,716 - config - INFO - Epoch [1243/2000], Train Loss: 0.3364
2024-03-28 18:12:39,720 - config - INFO - Validation Loss: 0.4631
2024-03-28 18:12:39,720 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,740 - config - INFO - Epoch [1244/2000], Train Loss: 0.3354
2024-03-28 18:12:39,744 - config - INFO - Validation Loss: 0.4645
2024-03-28 18:12:39,744 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,763 - config - INFO - Epoch [1245/2000], Train Loss: 0.3359
2024-03-28 18:12:39,767 - config - INFO - Validation Loss: 0.4649
2024-03-28 18:12:39,767 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,785 - config - INFO - Epoch [1246/2000], Train Loss: 0.3359
2024-03-28 18:12:39,789 - config - INFO - Validation Loss: 0.4695
2024-03-28 18:12:39,789 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,808 - config - INFO - Epoch [1247/2000], Train Loss: 0.3356
2024-03-28 18:12:39,812 - config - INFO - Validation Loss: 0.4637
2024-03-28 18:12:39,812 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:39,830 - config - INFO - Epoch [1248/2000], Train Loss: 0.3354
2024-03-28 18:12:39,834 - config - INFO - Validation Loss: 0.4648
2024-03-28 18:12:39,834 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:39,853 - config - INFO - Epoch [1249/2000], Train Loss: 0.3350
2024-03-28 18:12:39,857 - config - INFO - Validation Loss: 0.4653
2024-03-28 18:12:39,857 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:39,876 - config - INFO - Epoch [1250/2000], Train Loss: 0.3352
2024-03-28 18:12:39,879 - config - INFO - Validation Loss: 0.4661
2024-03-28 18:12:39,880 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,898 - config - INFO - Epoch [1251/2000], Train Loss: 0.3350
2024-03-28 18:12:39,902 - config - INFO - Validation Loss: 0.4655
2024-03-28 18:12:39,902 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:39,921 - config - INFO - Epoch [1252/2000], Train Loss: 0.3360
2024-03-28 18:12:39,925 - config - INFO - Validation Loss: 0.4622
2024-03-28 18:12:39,925 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:39,943 - config - INFO - Epoch [1253/2000], Train Loss: 0.3367
2024-03-28 18:12:39,947 - config - INFO - Validation Loss: 0.4688
2024-03-28 18:12:39,947 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:39,966 - config - INFO - Epoch [1254/2000], Train Loss: 0.3352
2024-03-28 18:12:39,970 - config - INFO - Validation Loss: 0.4662
2024-03-28 18:12:39,970 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:39,989 - config - INFO - Epoch [1255/2000], Train Loss: 0.3350
2024-03-28 18:12:39,992 - config - INFO - Validation Loss: 0.4663
2024-03-28 18:12:39,993 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,011 - config - INFO - Epoch [1256/2000], Train Loss: 0.3348
2024-03-28 18:12:40,015 - config - INFO - Validation Loss: 0.4656
2024-03-28 18:12:40,015 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,034 - config - INFO - Epoch [1257/2000], Train Loss: 0.3350
2024-03-28 18:12:40,038 - config - INFO - Validation Loss: 0.4660
2024-03-28 18:12:40,038 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,056 - config - INFO - Epoch [1258/2000], Train Loss: 0.3346
2024-03-28 18:12:40,060 - config - INFO - Validation Loss: 0.4645
2024-03-28 18:12:40,060 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,079 - config - INFO - Epoch [1259/2000], Train Loss: 0.3349
2024-03-28 18:12:40,083 - config - INFO - Validation Loss: 0.4651
2024-03-28 18:12:40,083 - config - INFO - Validation Acc: 0.8200
2024-03-28 18:12:40,101 - config - INFO - Epoch [1260/2000], Train Loss: 0.3347
2024-03-28 18:12:40,105 - config - INFO - Validation Loss: 0.4660
2024-03-28 18:12:40,105 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,124 - config - INFO - Epoch [1261/2000], Train Loss: 0.3351
2024-03-28 18:12:40,128 - config - INFO - Validation Loss: 0.4612
2024-03-28 18:12:40,128 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,146 - config - INFO - Epoch [1262/2000], Train Loss: 0.3346
2024-03-28 18:12:40,150 - config - INFO - Validation Loss: 0.4631
2024-03-28 18:12:40,151 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,169 - config - INFO - Epoch [1263/2000], Train Loss: 0.3344
2024-03-28 18:12:40,173 - config - INFO - Validation Loss: 0.4631
2024-03-28 18:12:40,173 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,192 - config - INFO - Epoch [1264/2000], Train Loss: 0.3346
2024-03-28 18:12:40,196 - config - INFO - Validation Loss: 0.4621
2024-03-28 18:12:40,196 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,214 - config - INFO - Epoch [1265/2000], Train Loss: 0.3343
2024-03-28 18:12:40,218 - config - INFO - Validation Loss: 0.4636
2024-03-28 18:12:40,218 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,237 - config - INFO - Epoch [1266/2000], Train Loss: 0.3358
2024-03-28 18:12:40,241 - config - INFO - Validation Loss: 0.4688
2024-03-28 18:12:40,241 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,259 - config - INFO - Epoch [1267/2000], Train Loss: 0.3351
2024-03-28 18:12:40,263 - config - INFO - Validation Loss: 0.4627
2024-03-28 18:12:40,263 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,282 - config - INFO - Epoch [1268/2000], Train Loss: 0.3358
2024-03-28 18:12:40,286 - config - INFO - Validation Loss: 0.4605
2024-03-28 18:12:40,286 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,304 - config - INFO - Epoch [1269/2000], Train Loss: 0.3342
2024-03-28 18:12:40,308 - config - INFO - Validation Loss: 0.4646
2024-03-28 18:12:40,308 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,327 - config - INFO - Epoch [1270/2000], Train Loss: 0.3349
2024-03-28 18:12:40,331 - config - INFO - Validation Loss: 0.4674
2024-03-28 18:12:40,331 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,349 - config - INFO - Epoch [1271/2000], Train Loss: 0.3346
2024-03-28 18:12:40,353 - config - INFO - Validation Loss: 0.4648
2024-03-28 18:12:40,353 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,372 - config - INFO - Epoch [1272/2000], Train Loss: 0.3341
2024-03-28 18:12:40,376 - config - INFO - Validation Loss: 0.4609
2024-03-28 18:12:40,376 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,395 - config - INFO - Epoch [1273/2000], Train Loss: 0.3344
2024-03-28 18:12:40,398 - config - INFO - Validation Loss: 0.4630
2024-03-28 18:12:40,399 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,417 - config - INFO - Epoch [1274/2000], Train Loss: 0.3347
2024-03-28 18:12:40,421 - config - INFO - Validation Loss: 0.4684
2024-03-28 18:12:40,421 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,440 - config - INFO - Epoch [1275/2000], Train Loss: 0.3346
2024-03-28 18:12:40,444 - config - INFO - Validation Loss: 0.4667
2024-03-28 18:12:40,444 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,462 - config - INFO - Epoch [1276/2000], Train Loss: 0.3343
2024-03-28 18:12:40,466 - config - INFO - Validation Loss: 0.4624
2024-03-28 18:12:40,466 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,485 - config - INFO - Epoch [1277/2000], Train Loss: 0.3344
2024-03-28 18:12:40,489 - config - INFO - Validation Loss: 0.4650
2024-03-28 18:12:40,489 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,508 - config - INFO - Epoch [1278/2000], Train Loss: 0.3339
2024-03-28 18:12:40,512 - config - INFO - Validation Loss: 0.4651
2024-03-28 18:12:40,512 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,530 - config - INFO - Epoch [1279/2000], Train Loss: 0.3340
2024-03-28 18:12:40,534 - config - INFO - Validation Loss: 0.4656
2024-03-28 18:12:40,534 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,553 - config - INFO - Epoch [1280/2000], Train Loss: 0.3339
2024-03-28 18:12:40,557 - config - INFO - Validation Loss: 0.4642
2024-03-28 18:12:40,557 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,575 - config - INFO - Epoch [1281/2000], Train Loss: 0.3337
2024-03-28 18:12:40,579 - config - INFO - Validation Loss: 0.4667
2024-03-28 18:12:40,579 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,598 - config - INFO - Epoch [1282/2000], Train Loss: 0.3339
2024-03-28 18:12:40,602 - config - INFO - Validation Loss: 0.4648
2024-03-28 18:12:40,602 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,625 - config - INFO - Epoch [1283/2000], Train Loss: 0.3335
2024-03-28 18:12:40,629 - config - INFO - Validation Loss: 0.4663
2024-03-28 18:12:40,629 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,648 - config - INFO - Epoch [1284/2000], Train Loss: 0.3341
2024-03-28 18:12:40,652 - config - INFO - Validation Loss: 0.4667
2024-03-28 18:12:40,652 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,670 - config - INFO - Epoch [1285/2000], Train Loss: 0.3338
2024-03-28 18:12:40,674 - config - INFO - Validation Loss: 0.4645
2024-03-28 18:12:40,675 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,693 - config - INFO - Epoch [1286/2000], Train Loss: 0.3340
2024-03-28 18:12:40,697 - config - INFO - Validation Loss: 0.4614
2024-03-28 18:12:40,697 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,715 - config - INFO - Epoch [1287/2000], Train Loss: 0.3337
2024-03-28 18:12:40,719 - config - INFO - Validation Loss: 0.4646
2024-03-28 18:12:40,720 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,738 - config - INFO - Epoch [1288/2000], Train Loss: 0.3336
2024-03-28 18:12:40,742 - config - INFO - Validation Loss: 0.4630
2024-03-28 18:12:40,742 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,761 - config - INFO - Epoch [1289/2000], Train Loss: 0.3335
2024-03-28 18:12:40,765 - config - INFO - Validation Loss: 0.4633
2024-03-28 18:12:40,765 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,783 - config - INFO - Epoch [1290/2000], Train Loss: 0.3333
2024-03-28 18:12:40,787 - config - INFO - Validation Loss: 0.4626
2024-03-28 18:12:40,787 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,806 - config - INFO - Epoch [1291/2000], Train Loss: 0.3334
2024-03-28 18:12:40,810 - config - INFO - Validation Loss: 0.4624
2024-03-28 18:12:40,810 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,828 - config - INFO - Epoch [1292/2000], Train Loss: 0.3334
2024-03-28 18:12:40,832 - config - INFO - Validation Loss: 0.4619
2024-03-28 18:12:40,832 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,851 - config - INFO - Epoch [1293/2000], Train Loss: 0.3335
2024-03-28 18:12:40,855 - config - INFO - Validation Loss: 0.4595
2024-03-28 18:12:40,855 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,874 - config - INFO - Epoch [1294/2000], Train Loss: 0.3333
2024-03-28 18:12:40,878 - config - INFO - Validation Loss: 0.4633
2024-03-28 18:12:40,878 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,896 - config - INFO - Epoch [1295/2000], Train Loss: 0.3333
2024-03-28 18:12:40,900 - config - INFO - Validation Loss: 0.4651
2024-03-28 18:12:40,900 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,919 - config - INFO - Epoch [1296/2000], Train Loss: 0.3332
2024-03-28 18:12:40,923 - config - INFO - Validation Loss: 0.4644
2024-03-28 18:12:40,923 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,941 - config - INFO - Epoch [1297/2000], Train Loss: 0.3334
2024-03-28 18:12:40,945 - config - INFO - Validation Loss: 0.4648
2024-03-28 18:12:40,945 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,964 - config - INFO - Epoch [1298/2000], Train Loss: 0.3333
2024-03-28 18:12:40,968 - config - INFO - Validation Loss: 0.4664
2024-03-28 18:12:40,968 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:40,987 - config - INFO - Epoch [1299/2000], Train Loss: 0.3334
2024-03-28 18:12:40,990 - config - INFO - Validation Loss: 0.4665
2024-03-28 18:12:40,991 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,009 - config - INFO - Epoch [1300/2000], Train Loss: 0.3333
2024-03-28 18:12:41,013 - config - INFO - Validation Loss: 0.4665
2024-03-28 18:12:41,013 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,032 - config - INFO - Epoch [1301/2000], Train Loss: 0.3334
2024-03-28 18:12:41,036 - config - INFO - Validation Loss: 0.4632
2024-03-28 18:12:41,036 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,054 - config - INFO - Epoch [1302/2000], Train Loss: 0.3337
2024-03-28 18:12:41,058 - config - INFO - Validation Loss: 0.4663
2024-03-28 18:12:41,058 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,077 - config - INFO - Epoch [1303/2000], Train Loss: 0.3328
2024-03-28 18:12:41,081 - config - INFO - Validation Loss: 0.4662
2024-03-28 18:12:41,081 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,099 - config - INFO - Epoch [1304/2000], Train Loss: 0.3332
2024-03-28 18:12:41,103 - config - INFO - Validation Loss: 0.4685
2024-03-28 18:12:41,103 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,122 - config - INFO - Epoch [1305/2000], Train Loss: 0.3329
2024-03-28 18:12:41,126 - config - INFO - Validation Loss: 0.4661
2024-03-28 18:12:41,126 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,144 - config - INFO - Epoch [1306/2000], Train Loss: 0.3335
2024-03-28 18:12:41,148 - config - INFO - Validation Loss: 0.4657
2024-03-28 18:12:41,149 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,167 - config - INFO - Epoch [1307/2000], Train Loss: 0.3332
2024-03-28 18:12:41,171 - config - INFO - Validation Loss: 0.4650
2024-03-28 18:12:41,171 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,190 - config - INFO - Epoch [1308/2000], Train Loss: 0.3327
2024-03-28 18:12:41,194 - config - INFO - Validation Loss: 0.4666
2024-03-28 18:12:41,194 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,212 - config - INFO - Epoch [1309/2000], Train Loss: 0.3328
2024-03-28 18:12:41,216 - config - INFO - Validation Loss: 0.4703
2024-03-28 18:12:41,217 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,235 - config - INFO - Epoch [1310/2000], Train Loss: 0.3332
2024-03-28 18:12:41,239 - config - INFO - Validation Loss: 0.4703
2024-03-28 18:12:41,239 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,258 - config - INFO - Epoch [1311/2000], Train Loss: 0.3327
2024-03-28 18:12:41,262 - config - INFO - Validation Loss: 0.4676
2024-03-28 18:12:41,262 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,280 - config - INFO - Epoch [1312/2000], Train Loss: 0.3332
2024-03-28 18:12:41,284 - config - INFO - Validation Loss: 0.4636
2024-03-28 18:12:41,284 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,303 - config - INFO - Epoch [1313/2000], Train Loss: 0.3330
2024-03-28 18:12:41,307 - config - INFO - Validation Loss: 0.4678
2024-03-28 18:12:41,307 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,326 - config - INFO - Epoch [1314/2000], Train Loss: 0.3326
2024-03-28 18:12:41,330 - config - INFO - Validation Loss: 0.4691
2024-03-28 18:12:41,330 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,348 - config - INFO - Epoch [1315/2000], Train Loss: 0.3330
2024-03-28 18:12:41,352 - config - INFO - Validation Loss: 0.4657
2024-03-28 18:12:41,352 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,371 - config - INFO - Epoch [1316/2000], Train Loss: 0.3324
2024-03-28 18:12:41,375 - config - INFO - Validation Loss: 0.4673
2024-03-28 18:12:41,375 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,393 - config - INFO - Epoch [1317/2000], Train Loss: 0.3328
2024-03-28 18:12:41,397 - config - INFO - Validation Loss: 0.4693
2024-03-28 18:12:41,398 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,416 - config - INFO - Epoch [1318/2000], Train Loss: 0.3324
2024-03-28 18:12:41,420 - config - INFO - Validation Loss: 0.4668
2024-03-28 18:12:41,420 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,439 - config - INFO - Epoch [1319/2000], Train Loss: 0.3324
2024-03-28 18:12:41,443 - config - INFO - Validation Loss: 0.4672
2024-03-28 18:12:41,443 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,461 - config - INFO - Epoch [1320/2000], Train Loss: 0.3328
2024-03-28 18:12:41,465 - config - INFO - Validation Loss: 0.4663
2024-03-28 18:12:41,466 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,484 - config - INFO - Epoch [1321/2000], Train Loss: 0.3320
2024-03-28 18:12:41,488 - config - INFO - Validation Loss: 0.4665
2024-03-28 18:12:41,494 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,517 - config - INFO - Epoch [1322/2000], Train Loss: 0.3323
2024-03-28 18:12:41,521 - config - INFO - Validation Loss: 0.4657
2024-03-28 18:12:41,522 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,540 - config - INFO - Epoch [1323/2000], Train Loss: 0.3323
2024-03-28 18:12:41,544 - config - INFO - Validation Loss: 0.4666
2024-03-28 18:12:41,544 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,563 - config - INFO - Epoch [1324/2000], Train Loss: 0.3320
2024-03-28 18:12:41,567 - config - INFO - Validation Loss: 0.4668
2024-03-28 18:12:41,567 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,585 - config - INFO - Epoch [1325/2000], Train Loss: 0.3319
2024-03-28 18:12:41,589 - config - INFO - Validation Loss: 0.4658
2024-03-28 18:12:41,590 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,608 - config - INFO - Epoch [1326/2000], Train Loss: 0.3322
2024-03-28 18:12:41,612 - config - INFO - Validation Loss: 0.4649
2024-03-28 18:12:41,612 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,631 - config - INFO - Epoch [1327/2000], Train Loss: 0.3326
2024-03-28 18:12:41,635 - config - INFO - Validation Loss: 0.4690
2024-03-28 18:12:41,635 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,653 - config - INFO - Epoch [1328/2000], Train Loss: 0.3318
2024-03-28 18:12:41,657 - config - INFO - Validation Loss: 0.4655
2024-03-28 18:12:41,657 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,676 - config - INFO - Epoch [1329/2000], Train Loss: 0.3320
2024-03-28 18:12:41,680 - config - INFO - Validation Loss: 0.4658
2024-03-28 18:12:41,680 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,698 - config - INFO - Epoch [1330/2000], Train Loss: 0.3320
2024-03-28 18:12:41,702 - config - INFO - Validation Loss: 0.4649
2024-03-28 18:12:41,702 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,721 - config - INFO - Epoch [1331/2000], Train Loss: 0.3322
2024-03-28 18:12:41,725 - config - INFO - Validation Loss: 0.4630
2024-03-28 18:12:41,725 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,744 - config - INFO - Epoch [1332/2000], Train Loss: 0.3326
2024-03-28 18:12:41,748 - config - INFO - Validation Loss: 0.4642
2024-03-28 18:12:41,748 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,766 - config - INFO - Epoch [1333/2000], Train Loss: 0.3336
2024-03-28 18:12:41,770 - config - INFO - Validation Loss: 0.4674
2024-03-28 18:12:41,770 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,789 - config - INFO - Epoch [1334/2000], Train Loss: 0.3335
2024-03-28 18:12:41,793 - config - INFO - Validation Loss: 0.4609
2024-03-28 18:12:41,793 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,811 - config - INFO - Epoch [1335/2000], Train Loss: 0.3324
2024-03-28 18:12:41,815 - config - INFO - Validation Loss: 0.4659
2024-03-28 18:12:41,815 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,834 - config - INFO - Epoch [1336/2000], Train Loss: 0.3318
2024-03-28 18:12:41,838 - config - INFO - Validation Loss: 0.4708
2024-03-28 18:12:41,838 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,857 - config - INFO - Epoch [1337/2000], Train Loss: 0.3316
2024-03-28 18:12:41,860 - config - INFO - Validation Loss: 0.4694
2024-03-28 18:12:41,861 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,879 - config - INFO - Epoch [1338/2000], Train Loss: 0.3313
2024-03-28 18:12:41,883 - config - INFO - Validation Loss: 0.4658
2024-03-28 18:12:41,883 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,902 - config - INFO - Epoch [1339/2000], Train Loss: 0.3321
2024-03-28 18:12:41,906 - config - INFO - Validation Loss: 0.4658
2024-03-28 18:12:41,906 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,924 - config - INFO - Epoch [1340/2000], Train Loss: 0.3315
2024-03-28 18:12:41,928 - config - INFO - Validation Loss: 0.4672
2024-03-28 18:12:41,929 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,947 - config - INFO - Epoch [1341/2000], Train Loss: 0.3316
2024-03-28 18:12:41,951 - config - INFO - Validation Loss: 0.4677
2024-03-28 18:12:41,951 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,970 - config - INFO - Epoch [1342/2000], Train Loss: 0.3319
2024-03-28 18:12:41,974 - config - INFO - Validation Loss: 0.4670
2024-03-28 18:12:41,974 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:41,992 - config - INFO - Epoch [1343/2000], Train Loss: 0.3310
2024-03-28 18:12:41,996 - config - INFO - Validation Loss: 0.4642
2024-03-28 18:12:41,997 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,015 - config - INFO - Epoch [1344/2000], Train Loss: 0.3315
2024-03-28 18:12:42,019 - config - INFO - Validation Loss: 0.4640
2024-03-28 18:12:42,019 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,038 - config - INFO - Epoch [1345/2000], Train Loss: 0.3318
2024-03-28 18:12:42,042 - config - INFO - Validation Loss: 0.4663
2024-03-28 18:12:42,042 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,060 - config - INFO - Epoch [1346/2000], Train Loss: 0.3316
2024-03-28 18:12:42,064 - config - INFO - Validation Loss: 0.4663
2024-03-28 18:12:42,064 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,083 - config - INFO - Epoch [1347/2000], Train Loss: 0.3312
2024-03-28 18:12:42,087 - config - INFO - Validation Loss: 0.4687
2024-03-28 18:12:42,087 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,106 - config - INFO - Epoch [1348/2000], Train Loss: 0.3314
2024-03-28 18:12:42,110 - config - INFO - Validation Loss: 0.4684
2024-03-28 18:12:42,110 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,128 - config - INFO - Epoch [1349/2000], Train Loss: 0.3313
2024-03-28 18:12:42,132 - config - INFO - Validation Loss: 0.4699
2024-03-28 18:12:42,132 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,151 - config - INFO - Epoch [1350/2000], Train Loss: 0.3315
2024-03-28 18:12:42,155 - config - INFO - Validation Loss: 0.4662
2024-03-28 18:12:42,155 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,173 - config - INFO - Epoch [1351/2000], Train Loss: 0.3316
2024-03-28 18:12:42,177 - config - INFO - Validation Loss: 0.4689
2024-03-28 18:12:42,178 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,196 - config - INFO - Epoch [1352/2000], Train Loss: 0.3317
2024-03-28 18:12:42,200 - config - INFO - Validation Loss: 0.4702
2024-03-28 18:12:42,200 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,219 - config - INFO - Epoch [1353/2000], Train Loss: 0.3310
2024-03-28 18:12:42,223 - config - INFO - Validation Loss: 0.4692
2024-03-28 18:12:42,223 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,241 - config - INFO - Epoch [1354/2000], Train Loss: 0.3305
2024-03-28 18:12:42,245 - config - INFO - Validation Loss: 0.4649
2024-03-28 18:12:42,245 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,264 - config - INFO - Epoch [1355/2000], Train Loss: 0.3311
2024-03-28 18:12:42,268 - config - INFO - Validation Loss: 0.4645
2024-03-28 18:12:42,268 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,287 - config - INFO - Epoch [1356/2000], Train Loss: 0.3310
2024-03-28 18:12:42,291 - config - INFO - Validation Loss: 0.4651
2024-03-28 18:12:42,291 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,309 - config - INFO - Epoch [1357/2000], Train Loss: 0.3307
2024-03-28 18:12:42,313 - config - INFO - Validation Loss: 0.4676
2024-03-28 18:12:42,313 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,334 - config - INFO - Epoch [1358/2000], Train Loss: 0.3308
2024-03-28 18:12:42,337 - config - INFO - Validation Loss: 0.4694
2024-03-28 18:12:42,338 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,356 - config - INFO - Epoch [1359/2000], Train Loss: 0.3307
2024-03-28 18:12:42,360 - config - INFO - Validation Loss: 0.4678
2024-03-28 18:12:42,360 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,379 - config - INFO - Epoch [1360/2000], Train Loss: 0.3305
2024-03-28 18:12:42,383 - config - INFO - Validation Loss: 0.4663
2024-03-28 18:12:42,383 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,401 - config - INFO - Epoch [1361/2000], Train Loss: 0.3306
2024-03-28 18:12:42,405 - config - INFO - Validation Loss: 0.4668
2024-03-28 18:12:42,406 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,424 - config - INFO - Epoch [1362/2000], Train Loss: 0.3308
2024-03-28 18:12:42,428 - config - INFO - Validation Loss: 0.4710
2024-03-28 18:12:42,428 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,447 - config - INFO - Epoch [1363/2000], Train Loss: 0.3318
2024-03-28 18:12:42,451 - config - INFO - Validation Loss: 0.4673
2024-03-28 18:12:42,451 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,469 - config - INFO - Epoch [1364/2000], Train Loss: 0.3307
2024-03-28 18:12:42,473 - config - INFO - Validation Loss: 0.4718
2024-03-28 18:12:42,474 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,492 - config - INFO - Epoch [1365/2000], Train Loss: 0.3315
2024-03-28 18:12:42,496 - config - INFO - Validation Loss: 0.4725
2024-03-28 18:12:42,496 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,515 - config - INFO - Epoch [1366/2000], Train Loss: 0.3310
2024-03-28 18:12:42,519 - config - INFO - Validation Loss: 0.4661
2024-03-28 18:12:42,519 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,537 - config - INFO - Epoch [1367/2000], Train Loss: 0.3310
2024-03-28 18:12:42,541 - config - INFO - Validation Loss: 0.4649
2024-03-28 18:12:42,542 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,560 - config - INFO - Epoch [1368/2000], Train Loss: 0.3308
2024-03-28 18:12:42,564 - config - INFO - Validation Loss: 0.4668
2024-03-28 18:12:42,564 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,583 - config - INFO - Epoch [1369/2000], Train Loss: 0.3306
2024-03-28 18:12:42,587 - config - INFO - Validation Loss: 0.4691
2024-03-28 18:12:42,587 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,605 - config - INFO - Epoch [1370/2000], Train Loss: 0.3304
2024-03-28 18:12:42,609 - config - INFO - Validation Loss: 0.4673
2024-03-28 18:12:42,609 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,628 - config - INFO - Epoch [1371/2000], Train Loss: 0.3306
2024-03-28 18:12:42,632 - config - INFO - Validation Loss: 0.4641
2024-03-28 18:12:42,632 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,651 - config - INFO - Epoch [1372/2000], Train Loss: 0.3315
2024-03-28 18:12:42,655 - config - INFO - Validation Loss: 0.4685
2024-03-28 18:12:42,655 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,673 - config - INFO - Epoch [1373/2000], Train Loss: 0.3310
2024-03-28 18:12:42,677 - config - INFO - Validation Loss: 0.4676
2024-03-28 18:12:42,677 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,696 - config - INFO - Epoch [1374/2000], Train Loss: 0.3303
2024-03-28 18:12:42,700 - config - INFO - Validation Loss: 0.4671
2024-03-28 18:12:42,700 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,718 - config - INFO - Epoch [1375/2000], Train Loss: 0.3300
2024-03-28 18:12:42,722 - config - INFO - Validation Loss: 0.4678
2024-03-28 18:12:42,722 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,741 - config - INFO - Epoch [1376/2000], Train Loss: 0.3302
2024-03-28 18:12:42,745 - config - INFO - Validation Loss: 0.4679
2024-03-28 18:12:42,745 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,764 - config - INFO - Epoch [1377/2000], Train Loss: 0.3303
2024-03-28 18:12:42,768 - config - INFO - Validation Loss: 0.4691
2024-03-28 18:12:42,768 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,786 - config - INFO - Epoch [1378/2000], Train Loss: 0.3303
2024-03-28 18:12:42,790 - config - INFO - Validation Loss: 0.4689
2024-03-28 18:12:42,790 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,809 - config - INFO - Epoch [1379/2000], Train Loss: 0.3305
2024-03-28 18:12:42,813 - config - INFO - Validation Loss: 0.4703
2024-03-28 18:12:42,813 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,831 - config - INFO - Epoch [1380/2000], Train Loss: 0.3299
2024-03-28 18:12:42,835 - config - INFO - Validation Loss: 0.4690
2024-03-28 18:12:42,836 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,854 - config - INFO - Epoch [1381/2000], Train Loss: 0.3298
2024-03-28 18:12:42,858 - config - INFO - Validation Loss: 0.4662
2024-03-28 18:12:42,858 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,877 - config - INFO - Epoch [1382/2000], Train Loss: 0.3301
2024-03-28 18:12:42,881 - config - INFO - Validation Loss: 0.4676
2024-03-28 18:12:42,881 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,899 - config - INFO - Epoch [1383/2000], Train Loss: 0.3301
2024-03-28 18:12:42,903 - config - INFO - Validation Loss: 0.4660
2024-03-28 18:12:42,903 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,922 - config - INFO - Epoch [1384/2000], Train Loss: 0.3299
2024-03-28 18:12:42,926 - config - INFO - Validation Loss: 0.4677
2024-03-28 18:12:42,926 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,945 - config - INFO - Epoch [1385/2000], Train Loss: 0.3300
2024-03-28 18:12:42,948 - config - INFO - Validation Loss: 0.4682
2024-03-28 18:12:42,949 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,967 - config - INFO - Epoch [1386/2000], Train Loss: 0.3300
2024-03-28 18:12:42,971 - config - INFO - Validation Loss: 0.4670
2024-03-28 18:12:42,971 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:42,990 - config - INFO - Epoch [1387/2000], Train Loss: 0.3298
2024-03-28 18:12:42,994 - config - INFO - Validation Loss: 0.4675
2024-03-28 18:12:42,994 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,012 - config - INFO - Epoch [1388/2000], Train Loss: 0.3297
2024-03-28 18:12:43,016 - config - INFO - Validation Loss: 0.4660
2024-03-28 18:12:43,017 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,035 - config - INFO - Epoch [1389/2000], Train Loss: 0.3302
2024-03-28 18:12:43,039 - config - INFO - Validation Loss: 0.4661
2024-03-28 18:12:43,039 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,058 - config - INFO - Epoch [1390/2000], Train Loss: 0.3297
2024-03-28 18:12:43,062 - config - INFO - Validation Loss: 0.4682
2024-03-28 18:12:43,062 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,080 - config - INFO - Epoch [1391/2000], Train Loss: 0.3298
2024-03-28 18:12:43,084 - config - INFO - Validation Loss: 0.4696
2024-03-28 18:12:43,085 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,103 - config - INFO - Epoch [1392/2000], Train Loss: 0.3294
2024-03-28 18:12:43,107 - config - INFO - Validation Loss: 0.4684
2024-03-28 18:12:43,107 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,126 - config - INFO - Epoch [1393/2000], Train Loss: 0.3295
2024-03-28 18:12:43,130 - config - INFO - Validation Loss: 0.4671
2024-03-28 18:12:43,130 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,148 - config - INFO - Epoch [1394/2000], Train Loss: 0.3297
2024-03-28 18:12:43,152 - config - INFO - Validation Loss: 0.4689
2024-03-28 18:12:43,152 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,171 - config - INFO - Epoch [1395/2000], Train Loss: 0.3293
2024-03-28 18:12:43,175 - config - INFO - Validation Loss: 0.4671
2024-03-28 18:12:43,175 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,194 - config - INFO - Epoch [1396/2000], Train Loss: 0.3293
2024-03-28 18:12:43,198 - config - INFO - Validation Loss: 0.4664
2024-03-28 18:12:43,198 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:43,216 - config - INFO - Epoch [1397/2000], Train Loss: 0.3295
2024-03-28 18:12:43,220 - config - INFO - Validation Loss: 0.4656
2024-03-28 18:12:43,220 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,239 - config - INFO - Epoch [1398/2000], Train Loss: 0.3296
2024-03-28 18:12:43,243 - config - INFO - Validation Loss: 0.4694
2024-03-28 18:12:43,243 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,261 - config - INFO - Epoch [1399/2000], Train Loss: 0.3292
2024-03-28 18:12:43,265 - config - INFO - Validation Loss: 0.4664
2024-03-28 18:12:43,266 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,284 - config - INFO - Epoch [1400/2000], Train Loss: 0.3296
2024-03-28 18:12:43,288 - config - INFO - Validation Loss: 0.4636
2024-03-28 18:12:43,288 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:43,307 - config - INFO - Epoch [1401/2000], Train Loss: 0.3296
2024-03-28 18:12:43,311 - config - INFO - Validation Loss: 0.4657
2024-03-28 18:12:43,311 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,329 - config - INFO - Epoch [1402/2000], Train Loss: 0.3287
2024-03-28 18:12:43,333 - config - INFO - Validation Loss: 0.4679
2024-03-28 18:12:43,333 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,352 - config - INFO - Epoch [1403/2000], Train Loss: 0.3303
2024-03-28 18:12:43,356 - config - INFO - Validation Loss: 0.4738
2024-03-28 18:12:43,356 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,375 - config - INFO - Epoch [1404/2000], Train Loss: 0.3297
2024-03-28 18:12:43,379 - config - INFO - Validation Loss: 0.4709
2024-03-28 18:12:43,379 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,397 - config - INFO - Epoch [1405/2000], Train Loss: 0.3303
2024-03-28 18:12:43,401 - config - INFO - Validation Loss: 0.4646
2024-03-28 18:12:43,401 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:43,420 - config - INFO - Epoch [1406/2000], Train Loss: 0.3299
2024-03-28 18:12:43,424 - config - INFO - Validation Loss: 0.4628
2024-03-28 18:12:43,424 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:43,442 - config - INFO - Epoch [1407/2000], Train Loss: 0.3292
2024-03-28 18:12:43,446 - config - INFO - Validation Loss: 0.4670
2024-03-28 18:12:43,447 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,465 - config - INFO - Epoch [1408/2000], Train Loss: 0.3287
2024-03-28 18:12:43,469 - config - INFO - Validation Loss: 0.4716
2024-03-28 18:12:43,469 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,488 - config - INFO - Epoch [1409/2000], Train Loss: 0.3292
2024-03-28 18:12:43,492 - config - INFO - Validation Loss: 0.4702
2024-03-28 18:12:43,492 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,510 - config - INFO - Epoch [1410/2000], Train Loss: 0.3289
2024-03-28 18:12:43,514 - config - INFO - Validation Loss: 0.4702
2024-03-28 18:12:43,515 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,533 - config - INFO - Epoch [1411/2000], Train Loss: 0.3294
2024-03-28 18:12:43,537 - config - INFO - Validation Loss: 0.4645
2024-03-28 18:12:43,537 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:43,556 - config - INFO - Epoch [1412/2000], Train Loss: 0.3292
2024-03-28 18:12:43,560 - config - INFO - Validation Loss: 0.4649
2024-03-28 18:12:43,560 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,578 - config - INFO - Epoch [1413/2000], Train Loss: 0.3290
2024-03-28 18:12:43,582 - config - INFO - Validation Loss: 0.4695
2024-03-28 18:12:43,582 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,601 - config - INFO - Epoch [1414/2000], Train Loss: 0.3289
2024-03-28 18:12:43,605 - config - INFO - Validation Loss: 0.4686
2024-03-28 18:12:43,605 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,624 - config - INFO - Epoch [1415/2000], Train Loss: 0.3294
2024-03-28 18:12:43,630 - config - INFO - Validation Loss: 0.4706
2024-03-28 18:12:43,631 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,649 - config - INFO - Epoch [1416/2000], Train Loss: 0.3287
2024-03-28 18:12:43,653 - config - INFO - Validation Loss: 0.4693
2024-03-28 18:12:43,653 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,671 - config - INFO - Epoch [1417/2000], Train Loss: 0.3297
2024-03-28 18:12:43,675 - config - INFO - Validation Loss: 0.4647
2024-03-28 18:12:43,676 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,694 - config - INFO - Epoch [1418/2000], Train Loss: 0.3288
2024-03-28 18:12:43,698 - config - INFO - Validation Loss: 0.4656
2024-03-28 18:12:43,698 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,717 - config - INFO - Epoch [1419/2000], Train Loss: 0.3287
2024-03-28 18:12:43,721 - config - INFO - Validation Loss: 0.4686
2024-03-28 18:12:43,721 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,740 - config - INFO - Epoch [1420/2000], Train Loss: 0.3285
2024-03-28 18:12:43,744 - config - INFO - Validation Loss: 0.4672
2024-03-28 18:12:43,744 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,762 - config - INFO - Epoch [1421/2000], Train Loss: 0.3285
2024-03-28 18:12:43,766 - config - INFO - Validation Loss: 0.4702
2024-03-28 18:12:43,766 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,785 - config - INFO - Epoch [1422/2000], Train Loss: 0.3282
2024-03-28 18:12:43,789 - config - INFO - Validation Loss: 0.4708
2024-03-28 18:12:43,789 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,807 - config - INFO - Epoch [1423/2000], Train Loss: 0.3290
2024-03-28 18:12:43,811 - config - INFO - Validation Loss: 0.4691
2024-03-28 18:12:43,812 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,830 - config - INFO - Epoch [1424/2000], Train Loss: 0.3282
2024-03-28 18:12:43,834 - config - INFO - Validation Loss: 0.4670
2024-03-28 18:12:43,834 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,853 - config - INFO - Epoch [1425/2000], Train Loss: 0.3281
2024-03-28 18:12:43,857 - config - INFO - Validation Loss: 0.4691
2024-03-28 18:12:43,857 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,875 - config - INFO - Epoch [1426/2000], Train Loss: 0.3282
2024-03-28 18:12:43,879 - config - INFO - Validation Loss: 0.4715
2024-03-28 18:12:43,879 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,898 - config - INFO - Epoch [1427/2000], Train Loss: 0.3283
2024-03-28 18:12:43,902 - config - INFO - Validation Loss: 0.4712
2024-03-28 18:12:43,902 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,920 - config - INFO - Epoch [1428/2000], Train Loss: 0.3289
2024-03-28 18:12:43,924 - config - INFO - Validation Loss: 0.4709
2024-03-28 18:12:43,924 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,943 - config - INFO - Epoch [1429/2000], Train Loss: 0.3293
2024-03-28 18:12:43,947 - config - INFO - Validation Loss: 0.4654
2024-03-28 18:12:43,947 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:43,966 - config - INFO - Epoch [1430/2000], Train Loss: 0.3285
2024-03-28 18:12:43,970 - config - INFO - Validation Loss: 0.4653
2024-03-28 18:12:43,970 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:43,988 - config - INFO - Epoch [1431/2000], Train Loss: 0.3280
2024-03-28 18:12:43,992 - config - INFO - Validation Loss: 0.4665
2024-03-28 18:12:43,992 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,011 - config - INFO - Epoch [1432/2000], Train Loss: 0.3281
2024-03-28 18:12:44,015 - config - INFO - Validation Loss: 0.4662
2024-03-28 18:12:44,015 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,034 - config - INFO - Epoch [1433/2000], Train Loss: 0.3282
2024-03-28 18:12:44,038 - config - INFO - Validation Loss: 0.4718
2024-03-28 18:12:44,038 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,056 - config - INFO - Epoch [1434/2000], Train Loss: 0.3286
2024-03-28 18:12:44,060 - config - INFO - Validation Loss: 0.4693
2024-03-28 18:12:44,060 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,079 - config - INFO - Epoch [1435/2000], Train Loss: 0.3277
2024-03-28 18:12:44,083 - config - INFO - Validation Loss: 0.4708
2024-03-28 18:12:44,083 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,101 - config - INFO - Epoch [1436/2000], Train Loss: 0.3285
2024-03-28 18:12:44,105 - config - INFO - Validation Loss: 0.4719
2024-03-28 18:12:44,106 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,124 - config - INFO - Epoch [1437/2000], Train Loss: 0.3280
2024-03-28 18:12:44,128 - config - INFO - Validation Loss: 0.4689
2024-03-28 18:12:44,128 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,147 - config - INFO - Epoch [1438/2000], Train Loss: 0.3279
2024-03-28 18:12:44,151 - config - INFO - Validation Loss: 0.4676
2024-03-28 18:12:44,151 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,169 - config - INFO - Epoch [1439/2000], Train Loss: 0.3282
2024-03-28 18:12:44,173 - config - INFO - Validation Loss: 0.4674
2024-03-28 18:12:44,173 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,192 - config - INFO - Epoch [1440/2000], Train Loss: 0.3277
2024-03-28 18:12:44,196 - config - INFO - Validation Loss: 0.4700
2024-03-28 18:12:44,196 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,214 - config - INFO - Epoch [1441/2000], Train Loss: 0.3276
2024-03-28 18:12:44,218 - config - INFO - Validation Loss: 0.4697
2024-03-28 18:12:44,219 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,237 - config - INFO - Epoch [1442/2000], Train Loss: 0.3275
2024-03-28 18:12:44,241 - config - INFO - Validation Loss: 0.4713
2024-03-28 18:12:44,241 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,260 - config - INFO - Epoch [1443/2000], Train Loss: 0.3277
2024-03-28 18:12:44,264 - config - INFO - Validation Loss: 0.4694
2024-03-28 18:12:44,264 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,282 - config - INFO - Epoch [1444/2000], Train Loss: 0.3285
2024-03-28 18:12:44,286 - config - INFO - Validation Loss: 0.4727
2024-03-28 18:12:44,286 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,305 - config - INFO - Epoch [1445/2000], Train Loss: 0.3281
2024-03-28 18:12:44,309 - config - INFO - Validation Loss: 0.4727
2024-03-28 18:12:44,309 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,328 - config - INFO - Epoch [1446/2000], Train Loss: 0.3283
2024-03-28 18:12:44,332 - config - INFO - Validation Loss: 0.4670
2024-03-28 18:12:44,332 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,350 - config - INFO - Epoch [1447/2000], Train Loss: 0.3279
2024-03-28 18:12:44,354 - config - INFO - Validation Loss: 0.4705
2024-03-28 18:12:44,354 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,373 - config - INFO - Epoch [1448/2000], Train Loss: 0.3281
2024-03-28 18:12:44,377 - config - INFO - Validation Loss: 0.4676
2024-03-28 18:12:44,377 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,395 - config - INFO - Epoch [1449/2000], Train Loss: 0.3272
2024-03-28 18:12:44,399 - config - INFO - Validation Loss: 0.4694
2024-03-28 18:12:44,400 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,418 - config - INFO - Epoch [1450/2000], Train Loss: 0.3274
2024-03-28 18:12:44,422 - config - INFO - Validation Loss: 0.4686
2024-03-28 18:12:44,422 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,441 - config - INFO - Epoch [1451/2000], Train Loss: 0.3276
2024-03-28 18:12:44,445 - config - INFO - Validation Loss: 0.4725
2024-03-28 18:12:44,445 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,463 - config - INFO - Epoch [1452/2000], Train Loss: 0.3275
2024-03-28 18:12:44,467 - config - INFO - Validation Loss: 0.4685
2024-03-28 18:12:44,468 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,486 - config - INFO - Epoch [1453/2000], Train Loss: 0.3283
2024-03-28 18:12:44,490 - config - INFO - Validation Loss: 0.4693
2024-03-28 18:12:44,490 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,509 - config - INFO - Epoch [1454/2000], Train Loss: 0.3274
2024-03-28 18:12:44,513 - config - INFO - Validation Loss: 0.4709
2024-03-28 18:12:44,513 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,531 - config - INFO - Epoch [1455/2000], Train Loss: 0.3273
2024-03-28 18:12:44,535 - config - INFO - Validation Loss: 0.4714
2024-03-28 18:12:44,535 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,554 - config - INFO - Epoch [1456/2000], Train Loss: 0.3272
2024-03-28 18:12:44,558 - config - INFO - Validation Loss: 0.4700
2024-03-28 18:12:44,558 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,577 - config - INFO - Epoch [1457/2000], Train Loss: 0.3274
2024-03-28 18:12:44,581 - config - INFO - Validation Loss: 0.4694
2024-03-28 18:12:44,581 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,599 - config - INFO - Epoch [1458/2000], Train Loss: 0.3273
2024-03-28 18:12:44,603 - config - INFO - Validation Loss: 0.4725
2024-03-28 18:12:44,604 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,622 - config - INFO - Epoch [1459/2000], Train Loss: 0.3272
2024-03-28 18:12:44,626 - config - INFO - Validation Loss: 0.4729
2024-03-28 18:12:44,626 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,645 - config - INFO - Epoch [1460/2000], Train Loss: 0.3273
2024-03-28 18:12:44,649 - config - INFO - Validation Loss: 0.4749
2024-03-28 18:12:44,649 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,667 - config - INFO - Epoch [1461/2000], Train Loss: 0.3269
2024-03-28 18:12:44,671 - config - INFO - Validation Loss: 0.4707
2024-03-28 18:12:44,671 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,690 - config - INFO - Epoch [1462/2000], Train Loss: 0.3274
2024-03-28 18:12:44,694 - config - INFO - Validation Loss: 0.4684
2024-03-28 18:12:44,694 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:44,712 - config - INFO - Epoch [1463/2000], Train Loss: 0.3265
2024-03-28 18:12:44,716 - config - INFO - Validation Loss: 0.4717
2024-03-28 18:12:44,717 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,735 - config - INFO - Epoch [1464/2000], Train Loss: 0.3272
2024-03-28 18:12:44,739 - config - INFO - Validation Loss: 0.4745
2024-03-28 18:12:44,739 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,758 - config - INFO - Epoch [1465/2000], Train Loss: 0.3271
2024-03-28 18:12:44,762 - config - INFO - Validation Loss: 0.4693
2024-03-28 18:12:44,762 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,780 - config - INFO - Epoch [1466/2000], Train Loss: 0.3267
2024-03-28 18:12:44,784 - config - INFO - Validation Loss: 0.4683
2024-03-28 18:12:44,784 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,803 - config - INFO - Epoch [1467/2000], Train Loss: 0.3267
2024-03-28 18:12:44,807 - config - INFO - Validation Loss: 0.4672
2024-03-28 18:12:44,807 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,825 - config - INFO - Epoch [1468/2000], Train Loss: 0.3283
2024-03-28 18:12:44,829 - config - INFO - Validation Loss: 0.4645
2024-03-28 18:12:44,830 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,848 - config - INFO - Epoch [1469/2000], Train Loss: 0.3283
2024-03-28 18:12:44,852 - config - INFO - Validation Loss: 0.4718
2024-03-28 18:12:44,852 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,871 - config - INFO - Epoch [1470/2000], Train Loss: 0.3273
2024-03-28 18:12:44,875 - config - INFO - Validation Loss: 0.4689
2024-03-28 18:12:44,875 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,893 - config - INFO - Epoch [1471/2000], Train Loss: 0.3271
2024-03-28 18:12:44,897 - config - INFO - Validation Loss: 0.4738
2024-03-28 18:12:44,897 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,916 - config - INFO - Epoch [1472/2000], Train Loss: 0.3270
2024-03-28 18:12:44,920 - config - INFO - Validation Loss: 0.4707
2024-03-28 18:12:44,920 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,939 - config - INFO - Epoch [1473/2000], Train Loss: 0.3269
2024-03-28 18:12:44,943 - config - INFO - Validation Loss: 0.4692
2024-03-28 18:12:44,943 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:44,961 - config - INFO - Epoch [1474/2000], Train Loss: 0.3276
2024-03-28 18:12:44,965 - config - INFO - Validation Loss: 0.4680
2024-03-28 18:12:44,965 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:44,984 - config - INFO - Epoch [1475/2000], Train Loss: 0.3263
2024-03-28 18:12:44,988 - config - INFO - Validation Loss: 0.4698
2024-03-28 18:12:44,988 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,006 - config - INFO - Epoch [1476/2000], Train Loss: 0.3264
2024-03-28 18:12:45,010 - config - INFO - Validation Loss: 0.4695
2024-03-28 18:12:45,011 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,029 - config - INFO - Epoch [1477/2000], Train Loss: 0.3272
2024-03-28 18:12:45,033 - config - INFO - Validation Loss: 0.4722
2024-03-28 18:12:45,033 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,052 - config - INFO - Epoch [1478/2000], Train Loss: 0.3264
2024-03-28 18:12:45,056 - config - INFO - Validation Loss: 0.4669
2024-03-28 18:12:45,056 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:45,074 - config - INFO - Epoch [1479/2000], Train Loss: 0.3272
2024-03-28 18:12:45,078 - config - INFO - Validation Loss: 0.4668
2024-03-28 18:12:45,078 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:45,097 - config - INFO - Epoch [1480/2000], Train Loss: 0.3267
2024-03-28 18:12:45,101 - config - INFO - Validation Loss: 0.4676
2024-03-28 18:12:45,101 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:45,119 - config - INFO - Epoch [1481/2000], Train Loss: 0.3263
2024-03-28 18:12:45,123 - config - INFO - Validation Loss: 0.4689
2024-03-28 18:12:45,123 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,142 - config - INFO - Epoch [1482/2000], Train Loss: 0.3265
2024-03-28 18:12:45,146 - config - INFO - Validation Loss: 0.4701
2024-03-28 18:12:45,146 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,164 - config - INFO - Epoch [1483/2000], Train Loss: 0.3275
2024-03-28 18:12:45,168 - config - INFO - Validation Loss: 0.4787
2024-03-28 18:12:45,169 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,187 - config - INFO - Epoch [1484/2000], Train Loss: 0.3278
2024-03-28 18:12:45,191 - config - INFO - Validation Loss: 0.4741
2024-03-28 18:12:45,191 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,210 - config - INFO - Epoch [1485/2000], Train Loss: 0.3265
2024-03-28 18:12:45,214 - config - INFO - Validation Loss: 0.4744
2024-03-28 18:12:45,214 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,232 - config - INFO - Epoch [1486/2000], Train Loss: 0.3264
2024-03-28 18:12:45,236 - config - INFO - Validation Loss: 0.4695
2024-03-28 18:12:45,236 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,255 - config - INFO - Epoch [1487/2000], Train Loss: 0.3264
2024-03-28 18:12:45,259 - config - INFO - Validation Loss: 0.4684
2024-03-28 18:12:45,259 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,278 - config - INFO - Epoch [1488/2000], Train Loss: 0.3261
2024-03-28 18:12:45,282 - config - INFO - Validation Loss: 0.4733
2024-03-28 18:12:45,282 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,300 - config - INFO - Epoch [1489/2000], Train Loss: 0.3258
2024-03-28 18:12:45,304 - config - INFO - Validation Loss: 0.4718
2024-03-28 18:12:45,304 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,323 - config - INFO - Epoch [1490/2000], Train Loss: 0.3259
2024-03-28 18:12:45,327 - config - INFO - Validation Loss: 0.4711
2024-03-28 18:12:45,327 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,346 - config - INFO - Epoch [1491/2000], Train Loss: 0.3260
2024-03-28 18:12:45,350 - config - INFO - Validation Loss: 0.4686
2024-03-28 18:12:45,350 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:45,368 - config - INFO - Epoch [1492/2000], Train Loss: 0.3258
2024-03-28 18:12:45,372 - config - INFO - Validation Loss: 0.4687
2024-03-28 18:12:45,372 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,391 - config - INFO - Epoch [1493/2000], Train Loss: 0.3260
2024-03-28 18:12:45,395 - config - INFO - Validation Loss: 0.4704
2024-03-28 18:12:45,395 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,413 - config - INFO - Epoch [1494/2000], Train Loss: 0.3258
2024-03-28 18:12:45,417 - config - INFO - Validation Loss: 0.4695
2024-03-28 18:12:45,417 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,436 - config - INFO - Epoch [1495/2000], Train Loss: 0.3258
2024-03-28 18:12:45,440 - config - INFO - Validation Loss: 0.4677
2024-03-28 18:12:45,440 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,459 - config - INFO - Epoch [1496/2000], Train Loss: 0.3256
2024-03-28 18:12:45,463 - config - INFO - Validation Loss: 0.4679
2024-03-28 18:12:45,463 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,481 - config - INFO - Epoch [1497/2000], Train Loss: 0.3260
2024-03-28 18:12:45,485 - config - INFO - Validation Loss: 0.4685
2024-03-28 18:12:45,485 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,504 - config - INFO - Epoch [1498/2000], Train Loss: 0.3255
2024-03-28 18:12:45,508 - config - INFO - Validation Loss: 0.4690
2024-03-28 18:12:45,508 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,526 - config - INFO - Epoch [1499/2000], Train Loss: 0.3260
2024-03-28 18:12:45,530 - config - INFO - Validation Loss: 0.4730
2024-03-28 18:12:45,531 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,549 - config - INFO - Epoch [1500/2000], Train Loss: 0.3271
2024-03-28 18:12:45,553 - config - INFO - Validation Loss: 0.4741
2024-03-28 18:12:45,553 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,572 - config - INFO - Epoch [1501/2000], Train Loss: 0.3268
2024-03-28 18:12:45,576 - config - INFO - Validation Loss: 0.4666
2024-03-28 18:12:45,576 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,595 - config - INFO - Epoch [1502/2000], Train Loss: 0.3257
2024-03-28 18:12:45,599 - config - INFO - Validation Loss: 0.4695
2024-03-28 18:12:45,599 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,617 - config - INFO - Epoch [1503/2000], Train Loss: 0.3254
2024-03-28 18:12:45,621 - config - INFO - Validation Loss: 0.4679
2024-03-28 18:12:45,622 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:45,643 - config - INFO - Epoch [1504/2000], Train Loss: 0.3253
2024-03-28 18:12:45,647 - config - INFO - Validation Loss: 0.4707
2024-03-28 18:12:45,647 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,666 - config - INFO - Epoch [1505/2000], Train Loss: 0.3258
2024-03-28 18:12:45,670 - config - INFO - Validation Loss: 0.4736
2024-03-28 18:12:45,670 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,689 - config - INFO - Epoch [1506/2000], Train Loss: 0.3253
2024-03-28 18:12:45,692 - config - INFO - Validation Loss: 0.4705
2024-03-28 18:12:45,693 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:45,711 - config - INFO - Epoch [1507/2000], Train Loss: 0.3253
2024-03-28 18:12:45,715 - config - INFO - Validation Loss: 0.4688
2024-03-28 18:12:45,715 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:45,734 - config - INFO - Epoch [1508/2000], Train Loss: 0.3252
2024-03-28 18:12:45,738 - config - INFO - Validation Loss: 0.4690
2024-03-28 18:12:45,738 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:45,756 - config - INFO - Epoch [1509/2000], Train Loss: 0.3257
2024-03-28 18:12:45,760 - config - INFO - Validation Loss: 0.4687
2024-03-28 18:12:45,761 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:45,779 - config - INFO - Epoch [1510/2000], Train Loss: 0.3257
2024-03-28 18:12:45,783 - config - INFO - Validation Loss: 0.4735
2024-03-28 18:12:45,783 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,802 - config - INFO - Epoch [1511/2000], Train Loss: 0.3262
2024-03-28 18:12:45,806 - config - INFO - Validation Loss: 0.4746
2024-03-28 18:12:45,806 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,824 - config - INFO - Epoch [1512/2000], Train Loss: 0.3250
2024-03-28 18:12:45,828 - config - INFO - Validation Loss: 0.4693
2024-03-28 18:12:45,828 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,847 - config - INFO - Epoch [1513/2000], Train Loss: 0.3251
2024-03-28 18:12:45,851 - config - INFO - Validation Loss: 0.4672
2024-03-28 18:12:45,851 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,870 - config - INFO - Epoch [1514/2000], Train Loss: 0.3255
2024-03-28 18:12:45,873 - config - INFO - Validation Loss: 0.4681
2024-03-28 18:12:45,874 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,892 - config - INFO - Epoch [1515/2000], Train Loss: 0.3263
2024-03-28 18:12:45,896 - config - INFO - Validation Loss: 0.4724
2024-03-28 18:12:45,896 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,915 - config - INFO - Epoch [1516/2000], Train Loss: 0.3249
2024-03-28 18:12:45,919 - config - INFO - Validation Loss: 0.4700
2024-03-28 18:12:45,919 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,937 - config - INFO - Epoch [1517/2000], Train Loss: 0.3251
2024-03-28 18:12:45,941 - config - INFO - Validation Loss: 0.4695
2024-03-28 18:12:45,941 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:45,960 - config - INFO - Epoch [1518/2000], Train Loss: 0.3252
2024-03-28 18:12:45,964 - config - INFO - Validation Loss: 0.4738
2024-03-28 18:12:45,964 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:45,983 - config - INFO - Epoch [1519/2000], Train Loss: 0.3252
2024-03-28 18:12:45,987 - config - INFO - Validation Loss: 0.4736
2024-03-28 18:12:45,987 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,005 - config - INFO - Epoch [1520/2000], Train Loss: 0.3253
2024-03-28 18:12:46,009 - config - INFO - Validation Loss: 0.4722
2024-03-28 18:12:46,009 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,028 - config - INFO - Epoch [1521/2000], Train Loss: 0.3253
2024-03-28 18:12:46,032 - config - INFO - Validation Loss: 0.4739
2024-03-28 18:12:46,032 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,050 - config - INFO - Epoch [1522/2000], Train Loss: 0.3249
2024-03-28 18:12:46,054 - config - INFO - Validation Loss: 0.4693
2024-03-28 18:12:46,055 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,073 - config - INFO - Epoch [1523/2000], Train Loss: 0.3251
2024-03-28 18:12:46,077 - config - INFO - Validation Loss: 0.4693
2024-03-28 18:12:46,077 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,096 - config - INFO - Epoch [1524/2000], Train Loss: 0.3245
2024-03-28 18:12:46,100 - config - INFO - Validation Loss: 0.4697
2024-03-28 18:12:46,100 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,118 - config - INFO - Epoch [1525/2000], Train Loss: 0.3245
2024-03-28 18:12:46,122 - config - INFO - Validation Loss: 0.4697
2024-03-28 18:12:46,122 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,141 - config - INFO - Epoch [1526/2000], Train Loss: 0.3254
2024-03-28 18:12:46,145 - config - INFO - Validation Loss: 0.4688
2024-03-28 18:12:46,145 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:46,164 - config - INFO - Epoch [1527/2000], Train Loss: 0.3246
2024-03-28 18:12:46,168 - config - INFO - Validation Loss: 0.4724
2024-03-28 18:12:46,168 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,186 - config - INFO - Epoch [1528/2000], Train Loss: 0.3247
2024-03-28 18:12:46,190 - config - INFO - Validation Loss: 0.4744
2024-03-28 18:12:46,190 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,209 - config - INFO - Epoch [1529/2000], Train Loss: 0.3247
2024-03-28 18:12:46,213 - config - INFO - Validation Loss: 0.4755
2024-03-28 18:12:46,213 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,231 - config - INFO - Epoch [1530/2000], Train Loss: 0.3251
2024-03-28 18:12:46,235 - config - INFO - Validation Loss: 0.4697
2024-03-28 18:12:46,236 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,254 - config - INFO - Epoch [1531/2000], Train Loss: 0.3249
2024-03-28 18:12:46,258 - config - INFO - Validation Loss: 0.4688
2024-03-28 18:12:46,258 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,277 - config - INFO - Epoch [1532/2000], Train Loss: 0.3244
2024-03-28 18:12:46,281 - config - INFO - Validation Loss: 0.4705
2024-03-28 18:12:46,281 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,299 - config - INFO - Epoch [1533/2000], Train Loss: 0.3255
2024-03-28 18:12:46,303 - config - INFO - Validation Loss: 0.4741
2024-03-28 18:12:46,303 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,322 - config - INFO - Epoch [1534/2000], Train Loss: 0.3249
2024-03-28 18:12:46,326 - config - INFO - Validation Loss: 0.4689
2024-03-28 18:12:46,326 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,345 - config - INFO - Epoch [1535/2000], Train Loss: 0.3249
2024-03-28 18:12:46,348 - config - INFO - Validation Loss: 0.4714
2024-03-28 18:12:46,349 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,367 - config - INFO - Epoch [1536/2000], Train Loss: 0.3243
2024-03-28 18:12:46,371 - config - INFO - Validation Loss: 0.4709
2024-03-28 18:12:46,371 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,390 - config - INFO - Epoch [1537/2000], Train Loss: 0.3242
2024-03-28 18:12:46,394 - config - INFO - Validation Loss: 0.4708
2024-03-28 18:12:46,394 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,412 - config - INFO - Epoch [1538/2000], Train Loss: 0.3247
2024-03-28 18:12:46,416 - config - INFO - Validation Loss: 0.4708
2024-03-28 18:12:46,416 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,435 - config - INFO - Epoch [1539/2000], Train Loss: 0.3243
2024-03-28 18:12:46,439 - config - INFO - Validation Loss: 0.4679
2024-03-28 18:12:46,439 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:46,457 - config - INFO - Epoch [1540/2000], Train Loss: 0.3250
2024-03-28 18:12:46,461 - config - INFO - Validation Loss: 0.4700
2024-03-28 18:12:46,462 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,480 - config - INFO - Epoch [1541/2000], Train Loss: 0.3241
2024-03-28 18:12:46,484 - config - INFO - Validation Loss: 0.4716
2024-03-28 18:12:46,484 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,503 - config - INFO - Epoch [1542/2000], Train Loss: 0.3251
2024-03-28 18:12:46,507 - config - INFO - Validation Loss: 0.4740
2024-03-28 18:12:46,513 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,536 - config - INFO - Epoch [1543/2000], Train Loss: 0.3240
2024-03-28 18:12:46,540 - config - INFO - Validation Loss: 0.4709
2024-03-28 18:12:46,541 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,559 - config - INFO - Epoch [1544/2000], Train Loss: 0.3246
2024-03-28 18:12:46,563 - config - INFO - Validation Loss: 0.4682
2024-03-28 18:12:46,563 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:46,582 - config - INFO - Epoch [1545/2000], Train Loss: 0.3241
2024-03-28 18:12:46,586 - config - INFO - Validation Loss: 0.4692
2024-03-28 18:12:46,586 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:46,604 - config - INFO - Epoch [1546/2000], Train Loss: 0.3238
2024-03-28 18:12:46,608 - config - INFO - Validation Loss: 0.4704
2024-03-28 18:12:46,609 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:46,627 - config - INFO - Epoch [1547/2000], Train Loss: 0.3244
2024-03-28 18:12:46,631 - config - INFO - Validation Loss: 0.4707
2024-03-28 18:12:46,631 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,650 - config - INFO - Epoch [1548/2000], Train Loss: 0.3251
2024-03-28 18:12:46,654 - config - INFO - Validation Loss: 0.4753
2024-03-28 18:12:46,654 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,672 - config - INFO - Epoch [1549/2000], Train Loss: 0.3250
2024-03-28 18:12:46,676 - config - INFO - Validation Loss: 0.4709
2024-03-28 18:12:46,676 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,695 - config - INFO - Epoch [1550/2000], Train Loss: 0.3239
2024-03-28 18:12:46,699 - config - INFO - Validation Loss: 0.4736
2024-03-28 18:12:46,699 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,717 - config - INFO - Epoch [1551/2000], Train Loss: 0.3240
2024-03-28 18:12:46,721 - config - INFO - Validation Loss: 0.4727
2024-03-28 18:12:46,722 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,740 - config - INFO - Epoch [1552/2000], Train Loss: 0.3236
2024-03-28 18:12:46,744 - config - INFO - Validation Loss: 0.4720
2024-03-28 18:12:46,744 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,763 - config - INFO - Epoch [1553/2000], Train Loss: 0.3239
2024-03-28 18:12:46,767 - config - INFO - Validation Loss: 0.4735
2024-03-28 18:12:46,767 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,785 - config - INFO - Epoch [1554/2000], Train Loss: 0.3238
2024-03-28 18:12:46,789 - config - INFO - Validation Loss: 0.4727
2024-03-28 18:12:46,789 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,808 - config - INFO - Epoch [1555/2000], Train Loss: 0.3239
2024-03-28 18:12:46,812 - config - INFO - Validation Loss: 0.4731
2024-03-28 18:12:46,812 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,830 - config - INFO - Epoch [1556/2000], Train Loss: 0.3235
2024-03-28 18:12:46,834 - config - INFO - Validation Loss: 0.4721
2024-03-28 18:12:46,835 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,853 - config - INFO - Epoch [1557/2000], Train Loss: 0.3235
2024-03-28 18:12:46,857 - config - INFO - Validation Loss: 0.4702
2024-03-28 18:12:46,857 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,876 - config - INFO - Epoch [1558/2000], Train Loss: 0.3238
2024-03-28 18:12:46,879 - config - INFO - Validation Loss: 0.4721
2024-03-28 18:12:46,880 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,898 - config - INFO - Epoch [1559/2000], Train Loss: 0.3241
2024-03-28 18:12:46,902 - config - INFO - Validation Loss: 0.4736
2024-03-28 18:12:46,902 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,921 - config - INFO - Epoch [1560/2000], Train Loss: 0.3239
2024-03-28 18:12:46,925 - config - INFO - Validation Loss: 0.4694
2024-03-28 18:12:46,925 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,943 - config - INFO - Epoch [1561/2000], Train Loss: 0.3238
2024-03-28 18:12:46,947 - config - INFO - Validation Loss: 0.4690
2024-03-28 18:12:46,947 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:46,966 - config - INFO - Epoch [1562/2000], Train Loss: 0.3241
2024-03-28 18:12:46,970 - config - INFO - Validation Loss: 0.4687
2024-03-28 18:12:46,970 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:46,989 - config - INFO - Epoch [1563/2000], Train Loss: 0.3235
2024-03-28 18:12:46,993 - config - INFO - Validation Loss: 0.4709
2024-03-28 18:12:46,993 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:47,011 - config - INFO - Epoch [1564/2000], Train Loss: 0.3235
2024-03-28 18:12:47,015 - config - INFO - Validation Loss: 0.4699
2024-03-28 18:12:47,015 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:47,034 - config - INFO - Epoch [1565/2000], Train Loss: 0.3237
2024-03-28 18:12:47,038 - config - INFO - Validation Loss: 0.4710
2024-03-28 18:12:47,038 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:47,056 - config - INFO - Epoch [1566/2000], Train Loss: 0.3239
2024-03-28 18:12:47,060 - config - INFO - Validation Loss: 0.4704
2024-03-28 18:12:47,061 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:47,079 - config - INFO - Epoch [1567/2000], Train Loss: 0.3238
2024-03-28 18:12:47,083 - config - INFO - Validation Loss: 0.4763
2024-03-28 18:12:47,083 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:47,102 - config - INFO - Epoch [1568/2000], Train Loss: 0.3237
2024-03-28 18:12:47,106 - config - INFO - Validation Loss: 0.4736
2024-03-28 18:12:47,106 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:47,124 - config - INFO - Epoch [1569/2000], Train Loss: 0.3235
2024-03-28 18:12:47,128 - config - INFO - Validation Loss: 0.4689
2024-03-28 18:12:47,128 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:47,147 - config - INFO - Epoch [1570/2000], Train Loss: 0.3234
2024-03-28 18:12:47,151 - config - INFO - Validation Loss: 0.4692
2024-03-28 18:12:47,151 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:47,169 - config - INFO - Epoch [1571/2000], Train Loss: 0.3231
2024-03-28 18:12:47,173 - config - INFO - Validation Loss: 0.4718
2024-03-28 18:12:47,173 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:47,192 - config - INFO - Epoch [1572/2000], Train Loss: 0.3231
2024-03-28 18:12:47,196 - config - INFO - Validation Loss: 0.4737
2024-03-28 18:12:47,196 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:47,215 - config - INFO - Epoch [1573/2000], Train Loss: 0.3237
2024-03-28 18:12:47,219 - config - INFO - Validation Loss: 0.4750
2024-03-28 18:12:47,219 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:47,237 - config - INFO - Epoch [1574/2000], Train Loss: 0.3235
2024-03-28 18:12:47,241 - config - INFO - Validation Loss: 0.4686
2024-03-28 18:12:47,241 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:47,260 - config - INFO - Epoch [1575/2000], Train Loss: 0.3233
2024-03-28 18:12:47,264 - config - INFO - Validation Loss: 0.4682
2024-03-28 18:12:47,264 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:47,282 - config - INFO - Epoch [1576/2000], Train Loss: 0.3230
2024-03-28 18:12:47,286 - config - INFO - Validation Loss: 0.4705
2024-03-28 18:12:47,287 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:47,305 - config - INFO - Epoch [1577/2000], Train Loss: 0.3230
2024-03-28 18:12:47,309 - config - INFO - Validation Loss: 0.4703
2024-03-28 18:12:47,309 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:47,328 - config - INFO - Epoch [1578/2000], Train Loss: 0.3235
2024-03-28 18:12:47,332 - config - INFO - Validation Loss: 0.4713
2024-03-28 18:12:47,332 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:47,350 - config - INFO - Epoch [1579/2000], Train Loss: 0.3226
2024-03-28 18:12:47,354 - config - INFO - Validation Loss: 0.4717
2024-03-28 18:12:47,354 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:47,373 - config - INFO - Epoch [1580/2000], Train Loss: 0.3230
2024-03-28 18:12:47,377 - config - INFO - Validation Loss: 0.4734
2024-03-28 18:12:47,377 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:47,395 - config - INFO - Epoch [1581/2000], Train Loss: 0.3229
2024-03-28 18:12:47,399 - config - INFO - Validation Loss: 0.4749
2024-03-28 18:12:47,399 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:47,418 - config - INFO - Epoch [1582/2000], Train Loss: 0.3228
2024-03-28 18:12:47,422 - config - INFO - Validation Loss: 0.4730
2024-03-28 18:12:47,422 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:47,441 - config - INFO - Epoch [1583/2000], Train Loss: 0.3228
2024-03-28 18:12:47,445 - config - INFO - Validation Loss: 0.4714
2024-03-28 18:12:47,445 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:47,463 - config - INFO - Epoch [1584/2000], Train Loss: 0.3229
2024-03-28 18:12:47,467 - config - INFO - Validation Loss: 0.4728
2024-03-28 18:12:47,467 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:47,486 - config - INFO - Epoch [1585/2000], Train Loss: 0.3228
2024-03-28 18:12:47,490 - config - INFO - Validation Loss: 0.4731
2024-03-28 18:12:47,490 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:47,508 - config - INFO - Epoch [1586/2000], Train Loss: 0.3232
2024-03-28 18:12:47,512 - config - INFO - Validation Loss: 0.4714
2024-03-28 18:12:47,513 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:47,531 - config - INFO - Epoch [1587/2000], Train Loss: 0.3224
2024-03-28 18:12:47,535 - config - INFO - Validation Loss: 0.4768
2024-03-28 18:12:47,535 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:47,554 - config - INFO - Epoch [1588/2000], Train Loss: 0.3234
2024-03-28 18:12:47,558 - config - INFO - Validation Loss: 0.4798
2024-03-28 18:12:47,558 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:47,577 - config - INFO - Epoch [1589/2000], Train Loss: 0.3229
2024-03-28 18:12:47,581 - config - INFO - Validation Loss: 0.4738
2024-03-28 18:12:47,581 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:47,599 - config - INFO - Epoch [1590/2000], Train Loss: 0.3221
2024-03-28 18:12:47,603 - config - INFO - Validation Loss: 0.4711
2024-03-28 18:12:47,604 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:47,622 - config - INFO - Epoch [1591/2000], Train Loss: 0.3227
2024-03-28 18:12:47,626 - config - INFO - Validation Loss: 0.4722
2024-03-28 18:12:47,626 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:47,645 - config - INFO - Epoch [1592/2000], Train Loss: 0.3225
2024-03-28 18:12:47,649 - config - INFO - Validation Loss: 0.4731
2024-03-28 18:12:47,649 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:47,667 - config - INFO - Epoch [1593/2000], Train Loss: 0.3226
2024-03-28 18:12:47,671 - config - INFO - Validation Loss: 0.4722
2024-03-28 18:12:47,672 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:47,690 - config - INFO - Epoch [1594/2000], Train Loss: 0.3233
2024-03-28 18:12:47,694 - config - INFO - Validation Loss: 0.4693
2024-03-28 18:12:47,694 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:47,713 - config - INFO - Epoch [1595/2000], Train Loss: 0.3240
2024-03-28 18:12:47,717 - config - INFO - Validation Loss: 0.4744
2024-03-28 18:12:47,717 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:47,736 - config - INFO - Epoch [1596/2000], Train Loss: 0.3224
2024-03-28 18:12:47,740 - config - INFO - Validation Loss: 0.4720
2024-03-28 18:12:47,740 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:47,758 - config - INFO - Epoch [1597/2000], Train Loss: 0.3223
2024-03-28 18:12:47,762 - config - INFO - Validation Loss: 0.4723
2024-03-28 18:12:47,763 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:47,781 - config - INFO - Epoch [1598/2000], Train Loss: 0.3224
2024-03-28 18:12:47,785 - config - INFO - Validation Loss: 0.4721
2024-03-28 18:12:47,785 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:47,804 - config - INFO - Epoch [1599/2000], Train Loss: 0.3224
2024-03-28 18:12:47,808 - config - INFO - Validation Loss: 0.4739
2024-03-28 18:12:47,808 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:47,826 - config - INFO - Epoch [1600/2000], Train Loss: 0.3222
2024-03-28 18:12:47,830 - config - INFO - Validation Loss: 0.4717
2024-03-28 18:12:47,831 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:47,849 - config - INFO - Epoch [1601/2000], Train Loss: 0.3223
2024-03-28 18:12:47,853 - config - INFO - Validation Loss: 0.4753
2024-03-28 18:12:47,853 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:47,872 - config - INFO - Epoch [1602/2000], Train Loss: 0.3222
2024-03-28 18:12:47,876 - config - INFO - Validation Loss: 0.4747
2024-03-28 18:12:47,876 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:47,894 - config - INFO - Epoch [1603/2000], Train Loss: 0.3223
2024-03-28 18:12:47,898 - config - INFO - Validation Loss: 0.4736
2024-03-28 18:12:47,899 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:47,917 - config - INFO - Epoch [1604/2000], Train Loss: 0.3223
2024-03-28 18:12:47,921 - config - INFO - Validation Loss: 0.4764
2024-03-28 18:12:47,921 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:47,940 - config - INFO - Epoch [1605/2000], Train Loss: 0.3220
2024-03-28 18:12:47,944 - config - INFO - Validation Loss: 0.4772
2024-03-28 18:12:47,944 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:47,963 - config - INFO - Epoch [1606/2000], Train Loss: 0.3220
2024-03-28 18:12:47,967 - config - INFO - Validation Loss: 0.4754
2024-03-28 18:12:47,967 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:47,985 - config - INFO - Epoch [1607/2000], Train Loss: 0.3223
2024-03-28 18:12:47,989 - config - INFO - Validation Loss: 0.4712
2024-03-28 18:12:47,989 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:48,008 - config - INFO - Epoch [1608/2000], Train Loss: 0.3222
2024-03-28 18:12:48,012 - config - INFO - Validation Loss: 0.4741
2024-03-28 18:12:48,012 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:48,031 - config - INFO - Epoch [1609/2000], Train Loss: 0.3219
2024-03-28 18:12:48,035 - config - INFO - Validation Loss: 0.4747
2024-03-28 18:12:48,035 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:48,053 - config - INFO - Epoch [1610/2000], Train Loss: 0.3221
2024-03-28 18:12:48,057 - config - INFO - Validation Loss: 0.4759
2024-03-28 18:12:48,057 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:48,076 - config - INFO - Epoch [1611/2000], Train Loss: 0.3220
2024-03-28 18:12:48,080 - config - INFO - Validation Loss: 0.4723
2024-03-28 18:12:48,080 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:48,099 - config - INFO - Epoch [1612/2000], Train Loss: 0.3217
2024-03-28 18:12:48,103 - config - INFO - Validation Loss: 0.4733
2024-03-28 18:12:48,103 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:48,121 - config - INFO - Epoch [1613/2000], Train Loss: 0.3220
2024-03-28 18:12:48,125 - config - INFO - Validation Loss: 0.4747
2024-03-28 18:12:48,126 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:48,144 - config - INFO - Epoch [1614/2000], Train Loss: 0.3219
2024-03-28 18:12:48,148 - config - INFO - Validation Loss: 0.4757
2024-03-28 18:12:48,148 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:48,167 - config - INFO - Epoch [1615/2000], Train Loss: 0.3218
2024-03-28 18:12:48,171 - config - INFO - Validation Loss: 0.4740
2024-03-28 18:12:48,171 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:48,190 - config - INFO - Epoch [1616/2000], Train Loss: 0.3216
2024-03-28 18:12:48,194 - config - INFO - Validation Loss: 0.4732
2024-03-28 18:12:48,194 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:48,215 - config - INFO - Epoch [1617/2000], Train Loss: 0.3216
2024-03-28 18:12:48,219 - config - INFO - Validation Loss: 0.4726
2024-03-28 18:12:48,220 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:48,238 - config - INFO - Epoch [1618/2000], Train Loss: 0.3217
2024-03-28 18:12:48,242 - config - INFO - Validation Loss: 0.4722
2024-03-28 18:12:48,242 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:48,261 - config - INFO - Epoch [1619/2000], Train Loss: 0.3218
2024-03-28 18:12:48,264 - config - INFO - Validation Loss: 0.4727
2024-03-28 18:12:48,265 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:48,283 - config - INFO - Epoch [1620/2000], Train Loss: 0.3218
2024-03-28 18:12:48,287 - config - INFO - Validation Loss: 0.4697
2024-03-28 18:12:48,287 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:48,306 - config - INFO - Epoch [1621/2000], Train Loss: 0.3217
2024-03-28 18:12:48,310 - config - INFO - Validation Loss: 0.4710
2024-03-28 18:12:48,310 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:48,328 - config - INFO - Epoch [1622/2000], Train Loss: 0.3223
2024-03-28 18:12:48,332 - config - INFO - Validation Loss: 0.4683
2024-03-28 18:12:48,333 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:48,351 - config - INFO - Epoch [1623/2000], Train Loss: 0.3218
2024-03-28 18:12:48,355 - config - INFO - Validation Loss: 0.4707
2024-03-28 18:12:48,355 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:48,374 - config - INFO - Epoch [1624/2000], Train Loss: 0.3219
2024-03-28 18:12:48,378 - config - INFO - Validation Loss: 0.4742
2024-03-28 18:12:48,378 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:48,396 - config - INFO - Epoch [1625/2000], Train Loss: 0.3222
2024-03-28 18:12:48,400 - config - INFO - Validation Loss: 0.4712
2024-03-28 18:12:48,400 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:48,419 - config - INFO - Epoch [1626/2000], Train Loss: 0.3213
2024-03-28 18:12:48,423 - config - INFO - Validation Loss: 0.4722
2024-03-28 18:12:48,423 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:48,441 - config - INFO - Epoch [1627/2000], Train Loss: 0.3222
2024-03-28 18:12:48,445 - config - INFO - Validation Loss: 0.4766
2024-03-28 18:12:48,445 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:48,464 - config - INFO - Epoch [1628/2000], Train Loss: 0.3212
2024-03-28 18:12:48,468 - config - INFO - Validation Loss: 0.4750
2024-03-28 18:12:48,468 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:48,486 - config - INFO - Epoch [1629/2000], Train Loss: 0.3216
2024-03-28 18:12:48,490 - config - INFO - Validation Loss: 0.4715
2024-03-28 18:12:48,490 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:48,509 - config - INFO - Epoch [1630/2000], Train Loss: 0.3216
2024-03-28 18:12:48,513 - config - INFO - Validation Loss: 0.4726
2024-03-28 18:12:48,513 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:48,531 - config - INFO - Epoch [1631/2000], Train Loss: 0.3212
2024-03-28 18:12:48,535 - config - INFO - Validation Loss: 0.4737
2024-03-28 18:12:48,535 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:48,554 - config - INFO - Epoch [1632/2000], Train Loss: 0.3220
2024-03-28 18:12:48,558 - config - INFO - Validation Loss: 0.4718
2024-03-28 18:12:48,558 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:48,576 - config - INFO - Epoch [1633/2000], Train Loss: 0.3212
2024-03-28 18:12:48,580 - config - INFO - Validation Loss: 0.4771
2024-03-28 18:12:48,580 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:48,599 - config - INFO - Epoch [1634/2000], Train Loss: 0.3220
2024-03-28 18:12:48,603 - config - INFO - Validation Loss: 0.4790
2024-03-28 18:12:48,603 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:48,622 - config - INFO - Epoch [1635/2000], Train Loss: 0.3222
2024-03-28 18:12:48,625 - config - INFO - Validation Loss: 0.4741
2024-03-28 18:12:48,626 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:48,644 - config - INFO - Epoch [1636/2000], Train Loss: 0.3216
2024-03-28 18:12:48,648 - config - INFO - Validation Loss: 0.4736
2024-03-28 18:12:48,648 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:48,667 - config - INFO - Epoch [1637/2000], Train Loss: 0.3212
2024-03-28 18:12:48,671 - config - INFO - Validation Loss: 0.4759
2024-03-28 18:12:48,671 - config - INFO - Validation Acc: 0.8600
2024-03-28 18:12:48,689 - config - INFO - Epoch [1638/2000], Train Loss: 0.3220
2024-03-28 18:12:48,693 - config - INFO - Validation Loss: 0.4820
2024-03-28 18:12:48,693 - config - INFO - Validation Acc: 0.8400
2024-03-28 18:12:48,693 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 18:13:24,647 - config - INFO - resume: None
2024-03-28 18:13:24,647 - config - INFO - device: cpu
2024-03-28 18:13:24,647 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-28 18:13:24,647 - config - INFO - learning_rate: 0.001
2024-03-28 18:13:24,647 - config - INFO - num_epochs: 2000
2024-03-28 18:13:24,647 - config - INFO - batch_size: 64
2024-03-28 18:13:24,648 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = None
        self.prev_val_loss = float('inf')
        self.tolerance = 0.03

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 18:13:24,661 - config - INFO - Dataset size: 891
2024-03-28 18:13:24,699 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.6 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()

    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 18:13:24,699 - config - INFO - Training start
2024-03-28 18:13:27,621 - config - INFO - Epoch [1/2000], Train Loss: 35.8785
2024-03-28 18:13:27,677 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:27,678 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:28,322 - config - INFO - Epoch [2/2000], Train Loss: 40.6367
2024-03-28 18:13:28,373 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:28,373 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:29,029 - config - INFO - Epoch [3/2000], Train Loss: 40.6367
2024-03-28 18:13:29,084 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:29,084 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:29,715 - config - INFO - Epoch [4/2000], Train Loss: 40.6367
2024-03-28 18:13:29,770 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:29,771 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:30,356 - config - INFO - Epoch [5/2000], Train Loss: 40.6367
2024-03-28 18:13:30,408 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:30,409 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:31,019 - config - INFO - Epoch [6/2000], Train Loss: 40.6367
2024-03-28 18:13:31,069 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:31,069 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:31,672 - config - INFO - Epoch [7/2000], Train Loss: 40.6367
2024-03-28 18:13:31,727 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:31,727 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:32,240 - config - INFO - Epoch [8/2000], Train Loss: 40.6367
2024-03-28 18:13:32,285 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:32,285 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:32,787 - config - INFO - Epoch [9/2000], Train Loss: 40.6367
2024-03-28 18:13:32,832 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:32,832 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:33,352 - config - INFO - Epoch [10/2000], Train Loss: 40.6367
2024-03-28 18:13:33,396 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:33,397 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:33,899 - config - INFO - Epoch [11/2000], Train Loss: 40.6367
2024-03-28 18:13:33,943 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:33,943 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:34,494 - config - INFO - Epoch [12/2000], Train Loss: 40.6367
2024-03-28 18:13:34,536 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:34,537 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:35,066 - config - INFO - Epoch [13/2000], Train Loss: 40.6367
2024-03-28 18:13:35,110 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:35,110 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:35,639 - config - INFO - Epoch [14/2000], Train Loss: 40.6367
2024-03-28 18:13:35,683 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:35,683 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:36,220 - config - INFO - Epoch [15/2000], Train Loss: 40.6367
2024-03-28 18:13:36,260 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:36,261 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:36,783 - config - INFO - Epoch [16/2000], Train Loss: 40.6367
2024-03-28 18:13:36,826 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:36,827 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:37,359 - config - INFO - Epoch [17/2000], Train Loss: 40.6367
2024-03-28 18:13:37,400 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:37,400 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:37,905 - config - INFO - Epoch [18/2000], Train Loss: 40.6367
2024-03-28 18:13:37,944 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:37,944 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:38,370 - config - INFO - Epoch [19/2000], Train Loss: 40.6367
2024-03-28 18:13:38,407 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:38,408 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:38,890 - config - INFO - Epoch [20/2000], Train Loss: 40.6367
2024-03-28 18:13:38,929 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:38,929 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:39,442 - config - INFO - Epoch [21/2000], Train Loss: 40.6367
2024-03-28 18:13:39,481 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:39,481 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:39,990 - config - INFO - Epoch [22/2000], Train Loss: 40.6367
2024-03-28 18:13:40,029 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:40,030 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:40,551 - config - INFO - Epoch [23/2000], Train Loss: 40.6367
2024-03-28 18:13:40,589 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:40,590 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:41,103 - config - INFO - Epoch [24/2000], Train Loss: 40.6367
2024-03-28 18:13:41,143 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:41,143 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:41,664 - config - INFO - Epoch [25/2000], Train Loss: 40.6367
2024-03-28 18:13:41,706 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:41,706 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:42,216 - config - INFO - Epoch [26/2000], Train Loss: 40.6367
2024-03-28 18:13:42,256 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:42,257 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:42,779 - config - INFO - Epoch [27/2000], Train Loss: 40.6367
2024-03-28 18:13:42,820 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:42,821 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:43,317 - config - INFO - Epoch [28/2000], Train Loss: 40.6367
2024-03-28 18:13:43,356 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:43,357 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:43,876 - config - INFO - Epoch [29/2000], Train Loss: 40.6367
2024-03-28 18:13:43,916 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:43,917 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:44,421 - config - INFO - Epoch [30/2000], Train Loss: 40.6367
2024-03-28 18:13:44,462 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:44,462 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:44,947 - config - INFO - Epoch [31/2000], Train Loss: 40.6367
2024-03-28 18:13:44,982 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:44,982 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:45,441 - config - INFO - Epoch [32/2000], Train Loss: 40.6367
2024-03-28 18:13:45,477 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:45,477 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:45,918 - config - INFO - Epoch [33/2000], Train Loss: 40.6367
2024-03-28 18:13:45,953 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:45,954 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:46,405 - config - INFO - Epoch [34/2000], Train Loss: 40.6367
2024-03-28 18:13:46,440 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:46,440 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:46,888 - config - INFO - Epoch [35/2000], Train Loss: 40.6367
2024-03-28 18:13:46,924 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:46,924 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:47,371 - config - INFO - Epoch [36/2000], Train Loss: 40.6367
2024-03-28 18:13:47,407 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:47,407 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:47,841 - config - INFO - Epoch [37/2000], Train Loss: 40.6367
2024-03-28 18:13:47,875 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:47,876 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:48,305 - config - INFO - Epoch [38/2000], Train Loss: 40.6367
2024-03-28 18:13:48,341 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:48,341 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:48,787 - config - INFO - Epoch [39/2000], Train Loss: 40.6367
2024-03-28 18:13:48,823 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:48,823 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:49,263 - config - INFO - Epoch [40/2000], Train Loss: 40.6367
2024-03-28 18:13:49,300 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:49,301 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:49,737 - config - INFO - Epoch [41/2000], Train Loss: 40.6367
2024-03-28 18:13:49,772 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:49,772 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:50,227 - config - INFO - Epoch [42/2000], Train Loss: 40.6367
2024-03-28 18:13:50,267 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:50,267 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:50,723 - config - INFO - Epoch [43/2000], Train Loss: 40.6367
2024-03-28 18:13:50,761 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:50,762 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:51,238 - config - INFO - Epoch [44/2000], Train Loss: 40.6367
2024-03-28 18:13:51,277 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:51,277 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:51,733 - config - INFO - Epoch [45/2000], Train Loss: 40.6367
2024-03-28 18:13:51,771 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:51,771 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:52,245 - config - INFO - Epoch [46/2000], Train Loss: 40.6367
2024-03-28 18:13:52,279 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:52,279 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:52,773 - config - INFO - Epoch [47/2000], Train Loss: 40.6367
2024-03-28 18:13:52,810 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:52,810 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:53,290 - config - INFO - Epoch [48/2000], Train Loss: 40.6367
2024-03-28 18:13:53,326 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:53,327 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:53,794 - config - INFO - Epoch [49/2000], Train Loss: 40.6367
2024-03-28 18:13:53,830 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:53,831 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:54,320 - config - INFO - Epoch [50/2000], Train Loss: 40.6367
2024-03-28 18:13:54,357 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:54,357 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:54,815 - config - INFO - Epoch [51/2000], Train Loss: 40.6367
2024-03-28 18:13:54,853 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:54,853 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:55,334 - config - INFO - Epoch [52/2000], Train Loss: 40.6367
2024-03-28 18:13:55,370 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:55,370 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:55,851 - config - INFO - Epoch [53/2000], Train Loss: 40.6367
2024-03-28 18:13:55,889 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:55,889 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:56,355 - config - INFO - Epoch [54/2000], Train Loss: 40.6367
2024-03-28 18:13:56,392 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:56,392 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:56,814 - config - INFO - Epoch [55/2000], Train Loss: 40.6367
2024-03-28 18:13:56,848 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:56,849 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:57,325 - config - INFO - Epoch [56/2000], Train Loss: 40.6367
2024-03-28 18:13:57,363 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:57,364 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:57,832 - config - INFO - Epoch [57/2000], Train Loss: 40.6367
2024-03-28 18:13:57,866 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:57,867 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:58,336 - config - INFO - Epoch [58/2000], Train Loss: 40.6367
2024-03-28 18:13:58,375 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:58,375 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:58,862 - config - INFO - Epoch [59/2000], Train Loss: 40.6367
2024-03-28 18:13:58,896 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:58,896 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:59,367 - config - INFO - Epoch [60/2000], Train Loss: 40.6367
2024-03-28 18:13:59,404 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:59,405 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:13:59,895 - config - INFO - Epoch [61/2000], Train Loss: 40.6367
2024-03-28 18:13:59,933 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:13:59,933 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:00,433 - config - INFO - Epoch [62/2000], Train Loss: 40.6367
2024-03-28 18:14:00,470 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:00,470 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:00,943 - config - INFO - Epoch [63/2000], Train Loss: 40.6367
2024-03-28 18:14:00,976 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:00,977 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:01,455 - config - INFO - Epoch [64/2000], Train Loss: 40.6367
2024-03-28 18:14:01,499 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:01,500 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:01,961 - config - INFO - Epoch [65/2000], Train Loss: 40.6367
2024-03-28 18:14:01,996 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:01,996 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:02,465 - config - INFO - Epoch [66/2000], Train Loss: 40.6367
2024-03-28 18:14:02,501 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:02,502 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:02,990 - config - INFO - Epoch [67/2000], Train Loss: 40.6367
2024-03-28 18:14:03,028 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:03,028 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:03,496 - config - INFO - Epoch [68/2000], Train Loss: 40.6367
2024-03-28 18:14:03,533 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:03,533 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:04,016 - config - INFO - Epoch [69/2000], Train Loss: 40.6367
2024-03-28 18:14:04,054 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:04,054 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:04,526 - config - INFO - Epoch [70/2000], Train Loss: 40.6367
2024-03-28 18:14:04,563 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:04,564 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:05,046 - config - INFO - Epoch [71/2000], Train Loss: 40.6367
2024-03-28 18:14:05,084 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:05,084 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:05,568 - config - INFO - Epoch [72/2000], Train Loss: 40.6367
2024-03-28 18:14:05,603 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:05,604 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:06,070 - config - INFO - Epoch [73/2000], Train Loss: 40.6367
2024-03-28 18:14:06,107 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:06,107 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:06,562 - config - INFO - Epoch [74/2000], Train Loss: 40.6367
2024-03-28 18:14:06,598 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:06,599 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:07,083 - config - INFO - Epoch [75/2000], Train Loss: 40.6367
2024-03-28 18:14:07,121 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:07,121 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:07,591 - config - INFO - Epoch [76/2000], Train Loss: 40.6367
2024-03-28 18:14:07,629 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:07,630 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:08,100 - config - INFO - Epoch [77/2000], Train Loss: 40.6367
2024-03-28 18:14:08,145 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:08,145 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:08,607 - config - INFO - Epoch [78/2000], Train Loss: 40.6367
2024-03-28 18:14:08,645 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:08,646 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:09,133 - config - INFO - Epoch [79/2000], Train Loss: 40.6367
2024-03-28 18:14:09,171 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:09,171 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:09,656 - config - INFO - Epoch [80/2000], Train Loss: 40.6367
2024-03-28 18:14:09,694 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:09,694 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:10,167 - config - INFO - Epoch [81/2000], Train Loss: 40.6367
2024-03-28 18:14:10,203 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:10,203 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:10,706 - config - INFO - Epoch [82/2000], Train Loss: 40.6367
2024-03-28 18:14:10,744 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:10,744 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:11,227 - config - INFO - Epoch [83/2000], Train Loss: 40.6367
2024-03-28 18:14:11,265 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:11,266 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:11,749 - config - INFO - Epoch [84/2000], Train Loss: 40.6367
2024-03-28 18:14:11,784 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:11,784 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:12,264 - config - INFO - Epoch [85/2000], Train Loss: 40.6367
2024-03-28 18:14:12,303 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:12,303 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:12,788 - config - INFO - Epoch [86/2000], Train Loss: 40.6367
2024-03-28 18:14:12,826 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:12,826 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:13,289 - config - INFO - Epoch [87/2000], Train Loss: 40.6367
2024-03-28 18:14:13,326 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:13,326 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:13,808 - config - INFO - Epoch [88/2000], Train Loss: 40.6367
2024-03-28 18:14:13,845 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:13,845 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:14,328 - config - INFO - Epoch [89/2000], Train Loss: 40.6367
2024-03-28 18:14:14,365 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:14,365 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:14,829 - config - INFO - Epoch [90/2000], Train Loss: 40.6367
2024-03-28 18:14:14,867 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:14,868 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:15,353 - config - INFO - Epoch [91/2000], Train Loss: 40.6367
2024-03-28 18:14:15,388 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:15,388 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:15,807 - config - INFO - Epoch [92/2000], Train Loss: 40.6367
2024-03-28 18:14:15,844 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:15,845 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:16,325 - config - INFO - Epoch [93/2000], Train Loss: 40.6367
2024-03-28 18:14:16,363 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:16,364 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:16,825 - config - INFO - Epoch [94/2000], Train Loss: 40.6367
2024-03-28 18:14:16,862 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:16,863 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:17,327 - config - INFO - Epoch [95/2000], Train Loss: 40.6367
2024-03-28 18:14:17,362 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:17,362 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:17,838 - config - INFO - Epoch [96/2000], Train Loss: 40.6367
2024-03-28 18:14:17,876 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:17,877 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:18,389 - config - INFO - Epoch [97/2000], Train Loss: 40.6367
2024-03-28 18:14:18,427 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:18,427 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:18,931 - config - INFO - Epoch [98/2000], Train Loss: 40.6367
2024-03-28 18:14:18,967 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:18,968 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:19,446 - config - INFO - Epoch [99/2000], Train Loss: 40.6367
2024-03-28 18:14:19,483 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:19,483 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:19,966 - config - INFO - Epoch [100/2000], Train Loss: 40.6367
2024-03-28 18:14:20,002 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:20,002 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:20,477 - config - INFO - Epoch [101/2000], Train Loss: 40.6367
2024-03-28 18:14:20,513 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:20,513 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:20,992 - config - INFO - Epoch [102/2000], Train Loss: 40.6367
2024-03-28 18:14:21,030 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:21,030 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:21,499 - config - INFO - Epoch [103/2000], Train Loss: 40.6367
2024-03-28 18:14:21,536 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:21,537 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:22,020 - config - INFO - Epoch [104/2000], Train Loss: 40.6367
2024-03-28 18:14:22,057 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:22,057 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:22,536 - config - INFO - Epoch [105/2000], Train Loss: 40.6367
2024-03-28 18:14:22,574 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:22,575 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:23,057 - config - INFO - Epoch [106/2000], Train Loss: 40.6367
2024-03-28 18:14:23,095 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:23,095 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:23,576 - config - INFO - Epoch [107/2000], Train Loss: 40.6367
2024-03-28 18:14:23,615 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:23,615 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:24,101 - config - INFO - Epoch [108/2000], Train Loss: 40.6367
2024-03-28 18:14:24,139 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:24,140 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:24,621 - config - INFO - Epoch [109/2000], Train Loss: 40.6367
2024-03-28 18:14:24,658 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:24,659 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:25,140 - config - INFO - Epoch [110/2000], Train Loss: 40.6367
2024-03-28 18:14:25,176 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:25,177 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:25,658 - config - INFO - Epoch [111/2000], Train Loss: 40.6367
2024-03-28 18:14:25,696 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:25,697 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:26,183 - config - INFO - Epoch [112/2000], Train Loss: 40.6367
2024-03-28 18:14:26,220 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:26,221 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:26,703 - config - INFO - Epoch [113/2000], Train Loss: 40.6367
2024-03-28 18:14:26,739 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:26,740 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:27,225 - config - INFO - Epoch [114/2000], Train Loss: 40.6367
2024-03-28 18:14:27,263 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:27,264 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:27,751 - config - INFO - Epoch [115/2000], Train Loss: 40.6367
2024-03-28 18:14:27,790 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:27,790 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:28,275 - config - INFO - Epoch [116/2000], Train Loss: 40.6367
2024-03-28 18:14:28,314 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:28,314 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:28,804 - config - INFO - Epoch [117/2000], Train Loss: 40.6367
2024-03-28 18:14:28,843 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:28,843 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:29,326 - config - INFO - Epoch [118/2000], Train Loss: 40.6367
2024-03-28 18:14:29,362 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:29,363 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:29,842 - config - INFO - Epoch [119/2000], Train Loss: 40.6367
2024-03-28 18:14:29,880 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:29,881 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:30,351 - config - INFO - Epoch [120/2000], Train Loss: 40.6367
2024-03-28 18:14:30,387 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:30,387 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:30,870 - config - INFO - Epoch [121/2000], Train Loss: 40.6367
2024-03-28 18:14:30,906 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:30,907 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:31,356 - config - INFO - Epoch [122/2000], Train Loss: 40.6367
2024-03-28 18:14:31,393 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:31,393 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:31,877 - config - INFO - Epoch [123/2000], Train Loss: 40.6367
2024-03-28 18:14:31,912 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:31,913 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:32,396 - config - INFO - Epoch [124/2000], Train Loss: 40.6367
2024-03-28 18:14:32,435 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:32,435 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:32,914 - config - INFO - Epoch [125/2000], Train Loss: 40.6367
2024-03-28 18:14:32,950 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:32,950 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:33,431 - config - INFO - Epoch [126/2000], Train Loss: 40.6367
2024-03-28 18:14:33,469 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:33,469 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:33,954 - config - INFO - Epoch [127/2000], Train Loss: 40.6367
2024-03-28 18:14:33,993 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:33,993 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:34,480 - config - INFO - Epoch [128/2000], Train Loss: 40.6367
2024-03-28 18:14:34,518 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:34,519 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:35,011 - config - INFO - Epoch [129/2000], Train Loss: 40.6367
2024-03-28 18:14:35,049 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:35,049 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:35,518 - config - INFO - Epoch [130/2000], Train Loss: 40.6367
2024-03-28 18:14:35,556 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:35,556 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:36,038 - config - INFO - Epoch [131/2000], Train Loss: 40.6367
2024-03-28 18:14:36,072 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:36,072 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:36,555 - config - INFO - Epoch [132/2000], Train Loss: 40.6367
2024-03-28 18:14:36,594 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:36,594 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:37,058 - config - INFO - Epoch [133/2000], Train Loss: 40.6367
2024-03-28 18:14:37,094 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:37,094 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:37,571 - config - INFO - Epoch [134/2000], Train Loss: 40.6367
2024-03-28 18:14:37,610 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:37,610 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:38,092 - config - INFO - Epoch [135/2000], Train Loss: 40.6367
2024-03-28 18:14:38,127 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:38,128 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:38,607 - config - INFO - Epoch [136/2000], Train Loss: 40.6367
2024-03-28 18:14:38,645 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:38,646 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:39,134 - config - INFO - Epoch [137/2000], Train Loss: 40.6367
2024-03-28 18:14:39,172 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:39,173 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:39,656 - config - INFO - Epoch [138/2000], Train Loss: 40.6367
2024-03-28 18:14:39,694 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:39,694 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:40,176 - config - INFO - Epoch [139/2000], Train Loss: 40.6367
2024-03-28 18:14:40,215 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:40,215 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:40,699 - config - INFO - Epoch [140/2000], Train Loss: 40.6367
2024-03-28 18:14:40,737 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:40,738 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:41,248 - config - INFO - Epoch [141/2000], Train Loss: 40.6367
2024-03-28 18:14:41,286 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:41,287 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:41,794 - config - INFO - Epoch [142/2000], Train Loss: 40.6367
2024-03-28 18:14:41,834 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:41,834 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:42,323 - config - INFO - Epoch [143/2000], Train Loss: 40.6367
2024-03-28 18:14:42,363 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:42,363 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:42,870 - config - INFO - Epoch [144/2000], Train Loss: 40.6367
2024-03-28 18:14:42,910 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:42,910 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:43,413 - config - INFO - Epoch [145/2000], Train Loss: 40.6367
2024-03-28 18:14:43,450 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:43,450 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:43,949 - config - INFO - Epoch [146/2000], Train Loss: 40.6367
2024-03-28 18:14:43,988 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:43,988 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:44,500 - config - INFO - Epoch [147/2000], Train Loss: 40.6367
2024-03-28 18:14:44,538 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:44,538 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:45,044 - config - INFO - Epoch [148/2000], Train Loss: 40.6367
2024-03-28 18:14:45,081 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:45,081 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:45,520 - config - INFO - Epoch [149/2000], Train Loss: 40.6367
2024-03-28 18:14:45,560 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:45,561 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:46,053 - config - INFO - Epoch [150/2000], Train Loss: 40.6367
2024-03-28 18:14:46,089 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:46,089 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:46,580 - config - INFO - Epoch [151/2000], Train Loss: 40.6367
2024-03-28 18:14:46,618 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:46,618 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:47,112 - config - INFO - Epoch [152/2000], Train Loss: 40.6367
2024-03-28 18:14:47,148 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:47,149 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:47,622 - config - INFO - Epoch [153/2000], Train Loss: 40.6367
2024-03-28 18:14:47,660 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:47,660 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:48,154 - config - INFO - Epoch [154/2000], Train Loss: 40.6367
2024-03-28 18:14:48,193 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:48,193 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:48,689 - config - INFO - Epoch [155/2000], Train Loss: 40.6367
2024-03-28 18:14:48,726 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:48,726 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:49,222 - config - INFO - Epoch [156/2000], Train Loss: 40.6367
2024-03-28 18:14:49,261 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:49,262 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:49,760 - config - INFO - Epoch [157/2000], Train Loss: 40.6367
2024-03-28 18:14:49,799 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:49,800 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:50,291 - config - INFO - Epoch [158/2000], Train Loss: 40.6367
2024-03-28 18:14:50,330 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:50,330 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:50,823 - config - INFO - Epoch [159/2000], Train Loss: 40.6367
2024-03-28 18:14:50,862 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:50,862 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:51,354 - config - INFO - Epoch [160/2000], Train Loss: 40.6367
2024-03-28 18:14:51,400 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:51,401 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:51,850 - config - INFO - Epoch [161/2000], Train Loss: 40.6367
2024-03-28 18:14:51,889 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:51,889 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:52,370 - config - INFO - Epoch [162/2000], Train Loss: 40.6367
2024-03-28 18:14:52,408 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:52,409 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:52,905 - config - INFO - Epoch [163/2000], Train Loss: 40.6367
2024-03-28 18:14:52,942 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:52,942 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:53,355 - config - INFO - Epoch [164/2000], Train Loss: 40.6367
2024-03-28 18:14:53,394 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:53,394 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:53,847 - config - INFO - Epoch [165/2000], Train Loss: 40.6367
2024-03-28 18:14:53,884 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:53,884 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:54,380 - config - INFO - Epoch [166/2000], Train Loss: 40.6367
2024-03-28 18:14:54,417 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:54,418 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:54,884 - config - INFO - Epoch [167/2000], Train Loss: 40.6367
2024-03-28 18:14:54,922 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:54,923 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:55,391 - config - INFO - Epoch [168/2000], Train Loss: 40.6367
2024-03-28 18:14:55,427 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:55,428 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:55,908 - config - INFO - Epoch [169/2000], Train Loss: 40.6367
2024-03-28 18:14:55,945 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:55,946 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:56,413 - config - INFO - Epoch [170/2000], Train Loss: 40.6367
2024-03-28 18:14:56,447 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:56,447 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:56,912 - config - INFO - Epoch [171/2000], Train Loss: 40.6367
2024-03-28 18:14:56,949 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:56,949 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:57,429 - config - INFO - Epoch [172/2000], Train Loss: 40.6367
2024-03-28 18:14:57,465 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:57,465 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:57,954 - config - INFO - Epoch [173/2000], Train Loss: 40.6367
2024-03-28 18:14:57,992 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:57,993 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:58,483 - config - INFO - Epoch [174/2000], Train Loss: 40.6367
2024-03-28 18:14:58,520 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:58,521 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:58,993 - config - INFO - Epoch [175/2000], Train Loss: 40.6367
2024-03-28 18:14:59,029 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:59,029 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:14:59,519 - config - INFO - Epoch [176/2000], Train Loss: 40.6367
2024-03-28 18:14:59,557 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:14:59,558 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:00,047 - config - INFO - Epoch [177/2000], Train Loss: 40.6367
2024-03-28 18:15:00,086 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:00,086 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:00,569 - config - INFO - Epoch [178/2000], Train Loss: 40.6367
2024-03-28 18:15:00,606 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:00,607 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:01,092 - config - INFO - Epoch [179/2000], Train Loss: 40.6367
2024-03-28 18:15:01,130 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:01,130 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:01,620 - config - INFO - Epoch [180/2000], Train Loss: 40.6367
2024-03-28 18:15:01,656 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:01,657 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:02,143 - config - INFO - Epoch [181/2000], Train Loss: 40.6367
2024-03-28 18:15:02,181 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:02,182 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:02,673 - config - INFO - Epoch [182/2000], Train Loss: 40.6367
2024-03-28 18:15:02,711 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:02,711 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:03,199 - config - INFO - Epoch [183/2000], Train Loss: 40.6367
2024-03-28 18:15:03,236 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:03,237 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:03,716 - config - INFO - Epoch [184/2000], Train Loss: 40.6367
2024-03-28 18:15:03,757 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:03,757 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:04,230 - config - INFO - Epoch [185/2000], Train Loss: 40.6367
2024-03-28 18:15:04,268 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:04,268 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:04,743 - config - INFO - Epoch [186/2000], Train Loss: 40.6367
2024-03-28 18:15:04,777 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:04,777 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:05,227 - config - INFO - Epoch [187/2000], Train Loss: 40.6367
2024-03-28 18:15:05,265 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:05,265 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:05,750 - config - INFO - Epoch [188/2000], Train Loss: 40.6367
2024-03-28 18:15:05,788 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:05,788 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:06,271 - config - INFO - Epoch [189/2000], Train Loss: 40.6367
2024-03-28 18:15:06,309 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:06,310 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:06,778 - config - INFO - Epoch [190/2000], Train Loss: 40.6367
2024-03-28 18:15:06,816 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:06,816 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:07,270 - config - INFO - Epoch [191/2000], Train Loss: 40.6367
2024-03-28 18:15:07,315 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:07,315 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:07,829 - config - INFO - Epoch [192/2000], Train Loss: 40.6367
2024-03-28 18:15:07,873 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:07,873 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:08,381 - config - INFO - Epoch [193/2000], Train Loss: 40.6367
2024-03-28 18:15:08,419 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:08,419 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:08,934 - config - INFO - Epoch [194/2000], Train Loss: 40.6367
2024-03-28 18:15:08,977 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:08,977 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:09,471 - config - INFO - Epoch [195/2000], Train Loss: 40.6367
2024-03-28 18:15:09,514 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:09,515 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:10,026 - config - INFO - Epoch [196/2000], Train Loss: 40.6367
2024-03-28 18:15:10,069 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:10,069 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:10,563 - config - INFO - Epoch [197/2000], Train Loss: 40.6367
2024-03-28 18:15:10,606 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:10,606 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:11,113 - config - INFO - Epoch [198/2000], Train Loss: 40.6367
2024-03-28 18:15:11,155 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:11,156 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:11,663 - config - INFO - Epoch [199/2000], Train Loss: 40.6367
2024-03-28 18:15:11,702 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:11,702 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:12,192 - config - INFO - Epoch [200/2000], Train Loss: 40.6367
2024-03-28 18:15:12,233 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:12,234 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:12,700 - config - INFO - Epoch [201/2000], Train Loss: 40.6367
2024-03-28 18:15:12,741 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:12,741 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:13,236 - config - INFO - Epoch [202/2000], Train Loss: 40.6367
2024-03-28 18:15:13,274 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:13,275 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:13,765 - config - INFO - Epoch [203/2000], Train Loss: 40.6367
2024-03-28 18:15:13,805 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:13,805 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:14,291 - config - INFO - Epoch [204/2000], Train Loss: 40.6367
2024-03-28 18:15:14,327 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:14,328 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:14,812 - config - INFO - Epoch [205/2000], Train Loss: 40.6367
2024-03-28 18:15:14,848 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:14,848 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:15,322 - config - INFO - Epoch [206/2000], Train Loss: 40.6367
2024-03-28 18:15:15,359 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:15,359 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:15,839 - config - INFO - Epoch [207/2000], Train Loss: 40.6367
2024-03-28 18:15:15,878 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:15,879 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:16,359 - config - INFO - Epoch [208/2000], Train Loss: 40.6367
2024-03-28 18:15:16,399 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:16,399 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:16,862 - config - INFO - Epoch [209/2000], Train Loss: 40.6367
2024-03-28 18:15:16,902 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:16,902 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:17,389 - config - INFO - Epoch [210/2000], Train Loss: 40.6367
2024-03-28 18:15:17,427 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:17,427 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:17,899 - config - INFO - Epoch [211/2000], Train Loss: 40.6367
2024-03-28 18:15:17,937 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:17,938 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:18,412 - config - INFO - Epoch [212/2000], Train Loss: 40.6367
2024-03-28 18:15:18,448 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:18,448 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:18,925 - config - INFO - Epoch [213/2000], Train Loss: 40.6367
2024-03-28 18:15:18,968 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:18,968 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:19,431 - config - INFO - Epoch [214/2000], Train Loss: 40.6367
2024-03-28 18:15:19,468 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:19,469 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:19,956 - config - INFO - Epoch [215/2000], Train Loss: 40.6367
2024-03-28 18:15:19,995 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:19,995 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:20,482 - config - INFO - Epoch [216/2000], Train Loss: 40.6367
2024-03-28 18:15:20,518 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:20,519 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:21,002 - config - INFO - Epoch [217/2000], Train Loss: 40.6367
2024-03-28 18:15:21,037 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:21,038 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:21,496 - config - INFO - Epoch [218/2000], Train Loss: 40.6367
2024-03-28 18:15:21,534 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:21,534 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:22,026 - config - INFO - Epoch [219/2000], Train Loss: 40.6367
2024-03-28 18:15:22,065 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:22,065 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:22,542 - config - INFO - Epoch [220/2000], Train Loss: 40.6367
2024-03-28 18:15:22,580 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:22,580 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:23,055 - config - INFO - Epoch [221/2000], Train Loss: 40.6367
2024-03-28 18:15:23,093 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:23,094 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:23,567 - config - INFO - Epoch [222/2000], Train Loss: 40.6367
2024-03-28 18:15:23,604 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:23,604 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:24,093 - config - INFO - Epoch [223/2000], Train Loss: 40.6367
2024-03-28 18:15:24,130 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:24,131 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:24,622 - config - INFO - Epoch [224/2000], Train Loss: 40.6367
2024-03-28 18:15:24,660 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:24,660 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:25,159 - config - INFO - Epoch [225/2000], Train Loss: 40.6367
2024-03-28 18:15:25,197 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:25,197 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:25,686 - config - INFO - Epoch [226/2000], Train Loss: 40.6367
2024-03-28 18:15:25,723 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:25,723 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:26,190 - config - INFO - Epoch [227/2000], Train Loss: 40.6367
2024-03-28 18:15:26,228 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:26,228 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:26,691 - config - INFO - Epoch [228/2000], Train Loss: 40.6367
2024-03-28 18:15:26,727 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:26,727 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:27,149 - config - INFO - Epoch [229/2000], Train Loss: 40.6367
2024-03-28 18:15:27,185 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:27,186 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:27,615 - config - INFO - Epoch [230/2000], Train Loss: 40.6367
2024-03-28 18:15:27,651 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:27,652 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:28,089 - config - INFO - Epoch [231/2000], Train Loss: 40.6367
2024-03-28 18:15:28,127 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:28,127 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:28,569 - config - INFO - Epoch [232/2000], Train Loss: 40.6367
2024-03-28 18:15:28,606 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:28,606 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:29,026 - config - INFO - Epoch [233/2000], Train Loss: 40.6367
2024-03-28 18:15:29,063 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:29,063 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:29,508 - config - INFO - Epoch [234/2000], Train Loss: 40.6367
2024-03-28 18:15:29,552 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:29,552 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:30,005 - config - INFO - Epoch [235/2000], Train Loss: 40.6367
2024-03-28 18:15:30,042 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:30,042 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:30,500 - config - INFO - Epoch [236/2000], Train Loss: 40.6367
2024-03-28 18:15:30,539 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:30,539 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:30,991 - config - INFO - Epoch [237/2000], Train Loss: 40.6367
2024-03-28 18:15:31,027 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:31,028 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:31,470 - config - INFO - Epoch [238/2000], Train Loss: 40.6367
2024-03-28 18:15:31,515 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:31,515 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:31,958 - config - INFO - Epoch [239/2000], Train Loss: 40.6367
2024-03-28 18:15:31,994 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:31,995 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:32,461 - config - INFO - Epoch [240/2000], Train Loss: 40.6367
2024-03-28 18:15:32,497 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:32,497 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:32,976 - config - INFO - Epoch [241/2000], Train Loss: 40.6367
2024-03-28 18:15:33,012 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:33,013 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:33,470 - config - INFO - Epoch [242/2000], Train Loss: 40.6367
2024-03-28 18:15:33,507 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:33,507 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:33,993 - config - INFO - Epoch [243/2000], Train Loss: 40.6367
2024-03-28 18:15:34,030 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:34,030 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:34,475 - config - INFO - Epoch [244/2000], Train Loss: 40.6367
2024-03-28 18:15:34,512 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:34,513 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:34,965 - config - INFO - Epoch [245/2000], Train Loss: 40.6367
2024-03-28 18:15:35,002 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:35,002 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:35,448 - config - INFO - Epoch [246/2000], Train Loss: 40.6367
2024-03-28 18:15:35,484 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:35,484 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:35,939 - config - INFO - Epoch [247/2000], Train Loss: 40.6367
2024-03-28 18:15:35,975 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:35,975 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:36,421 - config - INFO - Epoch [248/2000], Train Loss: 40.6367
2024-03-28 18:15:36,458 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:36,459 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:36,906 - config - INFO - Epoch [249/2000], Train Loss: 40.6367
2024-03-28 18:15:36,942 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:36,942 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:37,402 - config - INFO - Epoch [250/2000], Train Loss: 40.6367
2024-03-28 18:15:37,437 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:37,437 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:37,879 - config - INFO - Epoch [251/2000], Train Loss: 40.6367
2024-03-28 18:15:37,915 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:37,916 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:38,349 - config - INFO - Epoch [252/2000], Train Loss: 40.6367
2024-03-28 18:15:38,386 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:38,386 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:38,831 - config - INFO - Epoch [253/2000], Train Loss: 40.6367
2024-03-28 18:15:38,875 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:38,875 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:39,311 - config - INFO - Epoch [254/2000], Train Loss: 40.6367
2024-03-28 18:15:39,349 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:39,349 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:39,800 - config - INFO - Epoch [255/2000], Train Loss: 40.6367
2024-03-28 18:15:39,838 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:39,838 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:40,282 - config - INFO - Epoch [256/2000], Train Loss: 40.6367
2024-03-28 18:15:40,320 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:40,321 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:40,765 - config - INFO - Epoch [257/2000], Train Loss: 40.6367
2024-03-28 18:15:40,803 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:40,803 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:41,256 - config - INFO - Epoch [258/2000], Train Loss: 40.6367
2024-03-28 18:15:41,294 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:41,295 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:41,744 - config - INFO - Epoch [259/2000], Train Loss: 40.6367
2024-03-28 18:15:41,781 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:41,781 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:42,231 - config - INFO - Epoch [260/2000], Train Loss: 40.6367
2024-03-28 18:15:42,267 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:42,267 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:42,743 - config - INFO - Epoch [261/2000], Train Loss: 40.6367
2024-03-28 18:15:42,782 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:42,783 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:43,228 - config - INFO - Epoch [262/2000], Train Loss: 40.6367
2024-03-28 18:15:43,266 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:43,266 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:43,702 - config - INFO - Epoch [263/2000], Train Loss: 40.6367
2024-03-28 18:15:43,737 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:43,738 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:44,186 - config - INFO - Epoch [264/2000], Train Loss: 40.6367
2024-03-28 18:15:44,223 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:44,223 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:44,670 - config - INFO - Epoch [265/2000], Train Loss: 40.6367
2024-03-28 18:15:44,706 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:44,706 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:45,162 - config - INFO - Epoch [266/2000], Train Loss: 40.6367
2024-03-28 18:15:45,200 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:45,201 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:45,659 - config - INFO - Epoch [267/2000], Train Loss: 40.6367
2024-03-28 18:15:45,698 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:45,698 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:46,158 - config - INFO - Epoch [268/2000], Train Loss: 40.6367
2024-03-28 18:15:46,195 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:46,195 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:46,665 - config - INFO - Epoch [269/2000], Train Loss: 40.6367
2024-03-28 18:15:46,703 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:46,703 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:47,167 - config - INFO - Epoch [270/2000], Train Loss: 40.6367
2024-03-28 18:15:47,202 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:47,203 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:15:47,664 - config - INFO - Epoch [271/2000], Train Loss: 40.6367
2024-03-28 18:15:47,702 - config - INFO - Validation Loss: 35.9551
2024-03-28 18:15:47,703 - config - INFO - Validation Acc: 0.6600
2024-03-28 18:24:36,460 - config - INFO - resume: None
2024-03-28 18:24:36,460 - config - INFO - device: cpu
2024-03-28 18:24:36,460 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-28 18:24:36,460 - config - INFO - learning_rate: 0.1
2024-03-28 18:24:36,460 - config - INFO - num_epochs: 2000
2024-03-28 18:24:36,460 - config - INFO - batch_size: 64
2024-03-28 18:24:36,460 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = None
        self.prev_val_loss = float('inf')
        self.tolerance = 0.03

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 18:24:36,473 - config - INFO - Dataset size: 891
2024-03-28 18:24:36,514 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.6 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()

    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 18:24:36,514 - config - INFO - Training start
2024-03-28 18:24:39,493 - config - INFO - Epoch [1/2000], Train Loss: 33.4235
2024-03-28 18:24:39,533 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:39,534 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:40,054 - config - INFO - Epoch [2/2000], Train Loss: 37.2659
2024-03-28 18:24:40,092 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:40,092 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:40,627 - config - INFO - Epoch [3/2000], Train Loss: 37.2659
2024-03-28 18:24:40,666 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:40,666 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:41,144 - config - INFO - Epoch [4/2000], Train Loss: 37.2659
2024-03-28 18:24:41,182 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:41,182 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:41,718 - config - INFO - Epoch [5/2000], Train Loss: 37.2659
2024-03-28 18:24:41,759 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:41,760 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:42,267 - config - INFO - Epoch [6/2000], Train Loss: 37.2659
2024-03-28 18:24:42,305 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:42,305 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:42,739 - config - INFO - Epoch [7/2000], Train Loss: 37.2659
2024-03-28 18:24:42,778 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:42,778 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:43,258 - config - INFO - Epoch [8/2000], Train Loss: 37.2659
2024-03-28 18:24:43,296 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:43,297 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:43,772 - config - INFO - Epoch [9/2000], Train Loss: 37.2659
2024-03-28 18:24:43,822 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:43,822 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:44,348 - config - INFO - Epoch [10/2000], Train Loss: 37.2659
2024-03-28 18:24:44,387 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:44,387 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:44,875 - config - INFO - Epoch [11/2000], Train Loss: 37.2659
2024-03-28 18:24:44,911 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:44,912 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:45,374 - config - INFO - Epoch [12/2000], Train Loss: 37.2659
2024-03-28 18:24:45,421 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:45,422 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:45,867 - config - INFO - Epoch [13/2000], Train Loss: 37.2659
2024-03-28 18:24:45,905 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:45,905 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:46,380 - config - INFO - Epoch [14/2000], Train Loss: 37.2659
2024-03-28 18:24:46,417 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:46,417 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:46,890 - config - INFO - Epoch [15/2000], Train Loss: 37.2659
2024-03-28 18:24:46,927 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:46,928 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:47,432 - config - INFO - Epoch [16/2000], Train Loss: 37.2659
2024-03-28 18:24:47,468 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:47,468 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:47,914 - config - INFO - Epoch [17/2000], Train Loss: 37.2659
2024-03-28 18:24:47,962 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:47,963 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:48,415 - config - INFO - Epoch [18/2000], Train Loss: 37.2659
2024-03-28 18:24:48,459 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:48,459 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:48,891 - config - INFO - Epoch [19/2000], Train Loss: 37.2659
2024-03-28 18:24:48,928 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:48,928 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:49,382 - config - INFO - Epoch [20/2000], Train Loss: 37.2659
2024-03-28 18:24:49,419 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:49,420 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:49,874 - config - INFO - Epoch [21/2000], Train Loss: 37.2659
2024-03-28 18:24:49,911 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:49,911 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:50,384 - config - INFO - Epoch [22/2000], Train Loss: 37.2659
2024-03-28 18:24:50,421 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:50,421 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:50,899 - config - INFO - Epoch [23/2000], Train Loss: 37.2659
2024-03-28 18:24:50,950 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:50,951 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:51,383 - config - INFO - Epoch [24/2000], Train Loss: 37.2659
2024-03-28 18:24:51,419 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:51,419 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:51,826 - config - INFO - Epoch [25/2000], Train Loss: 37.2659
2024-03-28 18:24:51,862 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:51,862 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:52,332 - config - INFO - Epoch [26/2000], Train Loss: 37.2659
2024-03-28 18:24:52,368 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:52,368 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:52,766 - config - INFO - Epoch [27/2000], Train Loss: 37.2659
2024-03-28 18:24:52,802 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:52,802 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:53,259 - config - INFO - Epoch [28/2000], Train Loss: 37.2659
2024-03-28 18:24:53,295 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:53,295 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:53,717 - config - INFO - Epoch [29/2000], Train Loss: 37.2659
2024-03-28 18:24:53,753 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:53,753 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:54,232 - config - INFO - Epoch [30/2000], Train Loss: 37.2659
2024-03-28 18:24:54,275 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:54,275 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:54,737 - config - INFO - Epoch [31/2000], Train Loss: 37.2659
2024-03-28 18:24:54,775 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:54,775 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:55,245 - config - INFO - Epoch [32/2000], Train Loss: 37.2659
2024-03-28 18:24:55,283 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:55,283 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:55,710 - config - INFO - Epoch [33/2000], Train Loss: 37.2659
2024-03-28 18:24:55,747 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:55,747 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:56,152 - config - INFO - Epoch [34/2000], Train Loss: 37.2659
2024-03-28 18:24:56,188 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:56,188 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:56,599 - config - INFO - Epoch [35/2000], Train Loss: 37.2659
2024-03-28 18:24:56,634 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:56,635 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:57,048 - config - INFO - Epoch [36/2000], Train Loss: 37.2659
2024-03-28 18:24:57,085 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:57,085 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:57,534 - config - INFO - Epoch [37/2000], Train Loss: 37.2659
2024-03-28 18:24:57,568 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:57,568 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:57,973 - config - INFO - Epoch [38/2000], Train Loss: 37.2659
2024-03-28 18:24:58,015 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:58,015 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:58,526 - config - INFO - Epoch [39/2000], Train Loss: 37.2659
2024-03-28 18:24:58,567 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:58,567 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:59,085 - config - INFO - Epoch [40/2000], Train Loss: 37.2659
2024-03-28 18:24:59,127 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:59,127 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:24:59,579 - config - INFO - Epoch [41/2000], Train Loss: 37.2659
2024-03-28 18:24:59,625 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:24:59,626 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:00,146 - config - INFO - Epoch [42/2000], Train Loss: 37.2659
2024-03-28 18:25:00,186 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:00,187 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:00,649 - config - INFO - Epoch [43/2000], Train Loss: 37.2659
2024-03-28 18:25:00,689 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:00,689 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:01,156 - config - INFO - Epoch [44/2000], Train Loss: 37.2659
2024-03-28 18:25:01,196 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:01,197 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:01,702 - config - INFO - Epoch [45/2000], Train Loss: 37.2659
2024-03-28 18:25:01,740 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:01,740 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:02,160 - config - INFO - Epoch [46/2000], Train Loss: 37.2659
2024-03-28 18:25:02,199 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:02,200 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:02,721 - config - INFO - Epoch [47/2000], Train Loss: 37.2659
2024-03-28 18:25:02,759 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:02,760 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:03,216 - config - INFO - Epoch [48/2000], Train Loss: 37.2659
2024-03-28 18:25:03,261 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:03,262 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:03,709 - config - INFO - Epoch [49/2000], Train Loss: 37.2659
2024-03-28 18:25:03,747 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:03,747 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:04,250 - config - INFO - Epoch [50/2000], Train Loss: 37.2659
2024-03-28 18:25:04,289 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:04,289 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:04,790 - config - INFO - Epoch [51/2000], Train Loss: 37.2659
2024-03-28 18:25:04,828 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:04,828 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:05,311 - config - INFO - Epoch [52/2000], Train Loss: 37.2659
2024-03-28 18:25:05,350 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:05,350 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:05,829 - config - INFO - Epoch [53/2000], Train Loss: 37.2659
2024-03-28 18:25:05,873 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:05,873 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:06,331 - config - INFO - Epoch [54/2000], Train Loss: 37.2659
2024-03-28 18:25:06,370 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:06,370 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:06,825 - config - INFO - Epoch [55/2000], Train Loss: 37.2659
2024-03-28 18:25:06,863 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:06,863 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:07,321 - config - INFO - Epoch [56/2000], Train Loss: 37.2659
2024-03-28 18:25:07,360 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:07,360 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:07,838 - config - INFO - Epoch [57/2000], Train Loss: 37.2659
2024-03-28 18:25:07,877 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:07,877 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:08,339 - config - INFO - Epoch [58/2000], Train Loss: 37.2659
2024-03-28 18:25:08,378 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:08,378 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:08,881 - config - INFO - Epoch [59/2000], Train Loss: 37.2659
2024-03-28 18:25:08,919 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:08,920 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:09,370 - config - INFO - Epoch [60/2000], Train Loss: 37.2659
2024-03-28 18:25:09,408 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:09,408 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:09,847 - config - INFO - Epoch [61/2000], Train Loss: 37.2659
2024-03-28 18:25:09,884 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:09,884 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:10,336 - config - INFO - Epoch [62/2000], Train Loss: 37.2659
2024-03-28 18:25:10,372 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:10,373 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:10,833 - config - INFO - Epoch [63/2000], Train Loss: 37.2659
2024-03-28 18:25:10,878 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:10,879 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:11,299 - config - INFO - Epoch [64/2000], Train Loss: 37.2659
2024-03-28 18:25:11,343 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:11,343 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:11,776 - config - INFO - Epoch [65/2000], Train Loss: 37.2659
2024-03-28 18:25:11,814 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:11,814 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:12,289 - config - INFO - Epoch [66/2000], Train Loss: 37.2659
2024-03-28 18:25:12,325 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:12,326 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:12,753 - config - INFO - Epoch [67/2000], Train Loss: 37.2659
2024-03-28 18:25:12,790 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:12,791 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:13,253 - config - INFO - Epoch [68/2000], Train Loss: 37.2659
2024-03-28 18:25:13,289 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:13,289 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:13,719 - config - INFO - Epoch [69/2000], Train Loss: 37.2659
2024-03-28 18:25:13,756 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:13,756 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:14,243 - config - INFO - Epoch [70/2000], Train Loss: 37.2659
2024-03-28 18:25:14,287 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:14,287 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:14,723 - config - INFO - Epoch [71/2000], Train Loss: 37.2659
2024-03-28 18:25:14,761 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:14,761 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:15,194 - config - INFO - Epoch [72/2000], Train Loss: 37.2659
2024-03-28 18:25:15,229 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:15,230 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:15,648 - config - INFO - Epoch [73/2000], Train Loss: 37.2659
2024-03-28 18:25:15,684 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:15,684 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:16,079 - config - INFO - Epoch [74/2000], Train Loss: 37.2659
2024-03-28 18:25:16,115 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:16,115 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:16,530 - config - INFO - Epoch [75/2000], Train Loss: 37.2659
2024-03-28 18:25:16,566 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:16,566 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:17,015 - config - INFO - Epoch [76/2000], Train Loss: 37.2659
2024-03-28 18:25:17,050 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:17,051 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:17,504 - config - INFO - Epoch [77/2000], Train Loss: 37.2659
2024-03-28 18:25:17,541 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:17,541 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:17,964 - config - INFO - Epoch [78/2000], Train Loss: 37.2659
2024-03-28 18:25:18,000 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:18,000 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:18,444 - config - INFO - Epoch [79/2000], Train Loss: 37.2659
2024-03-28 18:25:18,486 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:18,487 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:18,848 - config - INFO - Epoch [80/2000], Train Loss: 37.2659
2024-03-28 18:25:18,888 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:18,889 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:19,259 - config - INFO - Epoch [81/2000], Train Loss: 37.2659
2024-03-28 18:25:19,306 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:19,307 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:19,691 - config - INFO - Epoch [82/2000], Train Loss: 37.2659
2024-03-28 18:25:19,731 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:19,731 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:20,113 - config - INFO - Epoch [83/2000], Train Loss: 37.2659
2024-03-28 18:25:20,155 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:20,155 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:20,516 - config - INFO - Epoch [84/2000], Train Loss: 37.2659
2024-03-28 18:25:20,556 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:20,557 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:20,931 - config - INFO - Epoch [85/2000], Train Loss: 37.2659
2024-03-28 18:25:20,965 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:20,966 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:21,338 - config - INFO - Epoch [86/2000], Train Loss: 37.2659
2024-03-28 18:25:21,376 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:21,376 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:21,760 - config - INFO - Epoch [87/2000], Train Loss: 37.2659
2024-03-28 18:25:21,795 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:21,795 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:22,157 - config - INFO - Epoch [88/2000], Train Loss: 37.2659
2024-03-28 18:25:22,198 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:22,198 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:22,571 - config - INFO - Epoch [89/2000], Train Loss: 37.2659
2024-03-28 18:25:22,611 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:22,612 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:22,971 - config - INFO - Epoch [90/2000], Train Loss: 37.2659
2024-03-28 18:25:23,012 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:23,012 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:23,427 - config - INFO - Epoch [91/2000], Train Loss: 37.2659
2024-03-28 18:25:23,467 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:23,467 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:23,866 - config - INFO - Epoch [92/2000], Train Loss: 37.2659
2024-03-28 18:25:23,904 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:23,904 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:24,264 - config - INFO - Epoch [93/2000], Train Loss: 37.2659
2024-03-28 18:25:24,305 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:24,306 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:24,667 - config - INFO - Epoch [94/2000], Train Loss: 37.2659
2024-03-28 18:25:24,705 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:24,706 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:25,060 - config - INFO - Epoch [95/2000], Train Loss: 37.2659
2024-03-28 18:25:25,095 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:25,095 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:25,467 - config - INFO - Epoch [96/2000], Train Loss: 37.2659
2024-03-28 18:25:25,506 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:25,506 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:25,859 - config - INFO - Epoch [97/2000], Train Loss: 37.2659
2024-03-28 18:25:25,894 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:25,895 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:26,253 - config - INFO - Epoch [98/2000], Train Loss: 37.2659
2024-03-28 18:25:26,294 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:26,294 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:26,665 - config - INFO - Epoch [99/2000], Train Loss: 37.2659
2024-03-28 18:25:26,707 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:26,707 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:27,065 - config - INFO - Epoch [100/2000], Train Loss: 37.2659
2024-03-28 18:25:27,103 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:27,104 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:27,481 - config - INFO - Epoch [101/2000], Train Loss: 37.2659
2024-03-28 18:25:27,517 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:27,517 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:27,899 - config - INFO - Epoch [102/2000], Train Loss: 37.2659
2024-03-28 18:25:27,937 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:27,938 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:28,315 - config - INFO - Epoch [103/2000], Train Loss: 37.2659
2024-03-28 18:25:28,362 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:28,362 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:28,721 - config - INFO - Epoch [104/2000], Train Loss: 37.2659
2024-03-28 18:25:28,762 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:28,762 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:29,128 - config - INFO - Epoch [105/2000], Train Loss: 37.2659
2024-03-28 18:25:29,167 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:29,167 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:29,569 - config - INFO - Epoch [106/2000], Train Loss: 37.2659
2024-03-28 18:25:29,610 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:29,611 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:29,978 - config - INFO - Epoch [107/2000], Train Loss: 37.2659
2024-03-28 18:25:30,017 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:30,017 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:30,392 - config - INFO - Epoch [108/2000], Train Loss: 37.2659
2024-03-28 18:25:30,429 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:30,429 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:30,811 - config - INFO - Epoch [109/2000], Train Loss: 37.2659
2024-03-28 18:25:30,853 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:30,853 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:31,209 - config - INFO - Epoch [110/2000], Train Loss: 37.2659
2024-03-28 18:25:31,246 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:31,246 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:31,619 - config - INFO - Epoch [111/2000], Train Loss: 37.2659
2024-03-28 18:25:31,660 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:31,661 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:32,041 - config - INFO - Epoch [112/2000], Train Loss: 37.2659
2024-03-28 18:25:32,088 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:32,088 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:32,439 - config - INFO - Epoch [113/2000], Train Loss: 37.2659
2024-03-28 18:25:32,479 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:32,479 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:32,832 - config - INFO - Epoch [114/2000], Train Loss: 37.2659
2024-03-28 18:25:32,873 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:32,873 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:33,230 - config - INFO - Epoch [115/2000], Train Loss: 37.2659
2024-03-28 18:25:33,268 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:33,269 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:33,651 - config - INFO - Epoch [116/2000], Train Loss: 37.2659
2024-03-28 18:25:33,693 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:33,693 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:34,091 - config - INFO - Epoch [117/2000], Train Loss: 37.2659
2024-03-28 18:25:34,128 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:34,129 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:34,534 - config - INFO - Epoch [118/2000], Train Loss: 37.2659
2024-03-28 18:25:34,569 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:34,569 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:34,967 - config - INFO - Epoch [119/2000], Train Loss: 37.2659
2024-03-28 18:25:35,007 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:35,008 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:35,376 - config - INFO - Epoch [120/2000], Train Loss: 37.2659
2024-03-28 18:25:35,417 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:35,418 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:35,787 - config - INFO - Epoch [121/2000], Train Loss: 37.2659
2024-03-28 18:25:35,825 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:35,825 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:36,217 - config - INFO - Epoch [122/2000], Train Loss: 37.2659
2024-03-28 18:25:36,252 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:36,253 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:36,648 - config - INFO - Epoch [123/2000], Train Loss: 37.2659
2024-03-28 18:25:36,685 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:36,685 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:37,079 - config - INFO - Epoch [124/2000], Train Loss: 37.2659
2024-03-28 18:25:37,118 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:37,119 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:37,538 - config - INFO - Epoch [125/2000], Train Loss: 37.2659
2024-03-28 18:25:37,575 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:37,576 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:37,958 - config - INFO - Epoch [126/2000], Train Loss: 37.2659
2024-03-28 18:25:37,999 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:37,999 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:38,391 - config - INFO - Epoch [127/2000], Train Loss: 37.2659
2024-03-28 18:25:38,430 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:38,430 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:38,833 - config - INFO - Epoch [128/2000], Train Loss: 37.2659
2024-03-28 18:25:38,874 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:38,875 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:39,288 - config - INFO - Epoch [129/2000], Train Loss: 37.2659
2024-03-28 18:25:39,330 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:39,330 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:39,770 - config - INFO - Epoch [130/2000], Train Loss: 37.2659
2024-03-28 18:25:39,811 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:39,812 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:40,215 - config - INFO - Epoch [131/2000], Train Loss: 37.2659
2024-03-28 18:25:40,254 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:40,254 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:40,621 - config - INFO - Epoch [132/2000], Train Loss: 37.2659
2024-03-28 18:25:40,662 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:40,662 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:41,042 - config - INFO - Epoch [133/2000], Train Loss: 37.2659
2024-03-28 18:25:41,082 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:41,082 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:41,476 - config - INFO - Epoch [134/2000], Train Loss: 37.2659
2024-03-28 18:25:41,522 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:41,522 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:41,928 - config - INFO - Epoch [135/2000], Train Loss: 37.2659
2024-03-28 18:25:41,972 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:41,972 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:42,357 - config - INFO - Epoch [136/2000], Train Loss: 37.2659
2024-03-28 18:25:42,398 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:42,398 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:42,831 - config - INFO - Epoch [137/2000], Train Loss: 37.2659
2024-03-28 18:25:42,872 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:42,872 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:43,242 - config - INFO - Epoch [138/2000], Train Loss: 37.2659
2024-03-28 18:25:43,276 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:43,276 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:43,668 - config - INFO - Epoch [139/2000], Train Loss: 37.2659
2024-03-28 18:25:43,705 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:43,706 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:44,120 - config - INFO - Epoch [140/2000], Train Loss: 37.2659
2024-03-28 18:25:44,158 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:44,158 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:44,559 - config - INFO - Epoch [141/2000], Train Loss: 37.2659
2024-03-28 18:25:44,599 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:44,599 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:44,968 - config - INFO - Epoch [142/2000], Train Loss: 37.2659
2024-03-28 18:25:45,006 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:45,006 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:45,380 - config - INFO - Epoch [143/2000], Train Loss: 37.2659
2024-03-28 18:25:45,420 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:45,420 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:45,796 - config - INFO - Epoch [144/2000], Train Loss: 37.2659
2024-03-28 18:25:45,833 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:45,833 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:46,201 - config - INFO - Epoch [145/2000], Train Loss: 37.2659
2024-03-28 18:25:46,241 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:46,241 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:46,632 - config - INFO - Epoch [146/2000], Train Loss: 37.2659
2024-03-28 18:25:46,672 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:46,672 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:47,058 - config - INFO - Epoch [147/2000], Train Loss: 37.2659
2024-03-28 18:25:47,096 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:47,096 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:47,468 - config - INFO - Epoch [148/2000], Train Loss: 37.2659
2024-03-28 18:25:47,515 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:47,515 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:47,901 - config - INFO - Epoch [149/2000], Train Loss: 37.2659
2024-03-28 18:25:47,941 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:47,942 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:48,331 - config - INFO - Epoch [150/2000], Train Loss: 37.2659
2024-03-28 18:25:48,371 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:48,372 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:48,750 - config - INFO - Epoch [151/2000], Train Loss: 37.2659
2024-03-28 18:25:48,790 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:48,790 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:49,167 - config - INFO - Epoch [152/2000], Train Loss: 37.2659
2024-03-28 18:25:49,206 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:49,206 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:49,590 - config - INFO - Epoch [153/2000], Train Loss: 37.2659
2024-03-28 18:25:49,637 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:49,637 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:50,003 - config - INFO - Epoch [154/2000], Train Loss: 37.2659
2024-03-28 18:25:50,043 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:50,043 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:50,506 - config - INFO - Epoch [155/2000], Train Loss: 37.2659
2024-03-28 18:25:50,542 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:50,543 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:50,980 - config - INFO - Epoch [156/2000], Train Loss: 37.2659
2024-03-28 18:25:51,016 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:51,016 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:51,501 - config - INFO - Epoch [157/2000], Train Loss: 37.2659
2024-03-28 18:25:51,544 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:51,545 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:51,940 - config - INFO - Epoch [158/2000], Train Loss: 37.2659
2024-03-28 18:25:51,977 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:51,978 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:52,456 - config - INFO - Epoch [159/2000], Train Loss: 37.2659
2024-03-28 18:25:52,492 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:52,492 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:52,918 - config - INFO - Epoch [160/2000], Train Loss: 37.2659
2024-03-28 18:25:52,954 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:52,954 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:53,391 - config - INFO - Epoch [161/2000], Train Loss: 37.2659
2024-03-28 18:25:53,428 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:53,429 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:53,885 - config - INFO - Epoch [162/2000], Train Loss: 37.2659
2024-03-28 18:25:53,922 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:53,922 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:54,349 - config - INFO - Epoch [163/2000], Train Loss: 37.2659
2024-03-28 18:25:54,385 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:54,385 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:54,793 - config - INFO - Epoch [164/2000], Train Loss: 37.2659
2024-03-28 18:25:54,829 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:54,829 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:55,250 - config - INFO - Epoch [165/2000], Train Loss: 37.2659
2024-03-28 18:25:55,286 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:55,286 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:55,707 - config - INFO - Epoch [166/2000], Train Loss: 37.2659
2024-03-28 18:25:55,743 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:55,743 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:56,148 - config - INFO - Epoch [167/2000], Train Loss: 37.2659
2024-03-28 18:25:56,183 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:56,184 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:56,670 - config - INFO - Epoch [168/2000], Train Loss: 37.2659
2024-03-28 18:25:56,706 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:56,706 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:57,167 - config - INFO - Epoch [169/2000], Train Loss: 37.2659
2024-03-28 18:25:57,202 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:57,202 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:57,634 - config - INFO - Epoch [170/2000], Train Loss: 37.2659
2024-03-28 18:25:57,669 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:57,670 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:58,100 - config - INFO - Epoch [171/2000], Train Loss: 37.2659
2024-03-28 18:25:58,137 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:58,137 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:58,580 - config - INFO - Epoch [172/2000], Train Loss: 37.2659
2024-03-28 18:25:58,615 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:58,615 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:59,072 - config - INFO - Epoch [173/2000], Train Loss: 37.2659
2024-03-28 18:25:59,106 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:59,107 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:25:59,539 - config - INFO - Epoch [174/2000], Train Loss: 37.2659
2024-03-28 18:25:59,581 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:25:59,581 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:00,025 - config - INFO - Epoch [175/2000], Train Loss: 37.2659
2024-03-28 18:26:00,059 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:00,059 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:00,463 - config - INFO - Epoch [176/2000], Train Loss: 37.2659
2024-03-28 18:26:00,504 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:00,505 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:00,938 - config - INFO - Epoch [177/2000], Train Loss: 37.2659
2024-03-28 18:26:00,972 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:00,973 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:01,414 - config - INFO - Epoch [178/2000], Train Loss: 37.2659
2024-03-28 18:26:01,449 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:01,450 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:01,877 - config - INFO - Epoch [179/2000], Train Loss: 37.2659
2024-03-28 18:26:01,911 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:01,911 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:02,346 - config - INFO - Epoch [180/2000], Train Loss: 37.2659
2024-03-28 18:26:02,387 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:02,388 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:02,815 - config - INFO - Epoch [181/2000], Train Loss: 37.2659
2024-03-28 18:26:02,849 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:02,849 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:03,322 - config - INFO - Epoch [182/2000], Train Loss: 37.2659
2024-03-28 18:26:03,357 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:03,357 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:03,795 - config - INFO - Epoch [183/2000], Train Loss: 37.2659
2024-03-28 18:26:03,829 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:03,830 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:04,298 - config - INFO - Epoch [184/2000], Train Loss: 37.2659
2024-03-28 18:26:04,341 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:04,341 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:04,815 - config - INFO - Epoch [185/2000], Train Loss: 37.2659
2024-03-28 18:26:04,852 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:04,853 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:05,303 - config - INFO - Epoch [186/2000], Train Loss: 37.2659
2024-03-28 18:26:05,339 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:05,339 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:05,788 - config - INFO - Epoch [187/2000], Train Loss: 37.2659
2024-03-28 18:26:05,824 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:05,824 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:06,250 - config - INFO - Epoch [188/2000], Train Loss: 37.2659
2024-03-28 18:26:06,286 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:06,287 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:06,743 - config - INFO - Epoch [189/2000], Train Loss: 37.2659
2024-03-28 18:26:06,779 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:06,780 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:07,259 - config - INFO - Epoch [190/2000], Train Loss: 37.2659
2024-03-28 18:26:07,296 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:07,297 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:07,729 - config - INFO - Epoch [191/2000], Train Loss: 37.2659
2024-03-28 18:26:07,764 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:07,765 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:08,184 - config - INFO - Epoch [192/2000], Train Loss: 37.2659
2024-03-28 18:26:08,220 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:08,220 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:08,677 - config - INFO - Epoch [193/2000], Train Loss: 37.2659
2024-03-28 18:26:08,712 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:08,712 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:09,161 - config - INFO - Epoch [194/2000], Train Loss: 37.2659
2024-03-28 18:26:09,196 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:09,196 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:09,606 - config - INFO - Epoch [195/2000], Train Loss: 37.2659
2024-03-28 18:26:09,648 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:09,649 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:10,099 - config - INFO - Epoch [196/2000], Train Loss: 37.2659
2024-03-28 18:26:10,134 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:10,134 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:10,568 - config - INFO - Epoch [197/2000], Train Loss: 37.2659
2024-03-28 18:26:10,602 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:10,603 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:11,034 - config - INFO - Epoch [198/2000], Train Loss: 37.2659
2024-03-28 18:26:11,069 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:11,069 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:11,459 - config - INFO - Epoch [199/2000], Train Loss: 37.2659
2024-03-28 18:26:11,505 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:11,506 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:11,933 - config - INFO - Epoch [200/2000], Train Loss: 37.2659
2024-03-28 18:26:11,968 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:11,968 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:12,376 - config - INFO - Epoch [201/2000], Train Loss: 37.2659
2024-03-28 18:26:12,411 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:12,411 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:12,818 - config - INFO - Epoch [202/2000], Train Loss: 37.2659
2024-03-28 18:26:12,854 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:12,854 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:13,275 - config - INFO - Epoch [203/2000], Train Loss: 37.2659
2024-03-28 18:26:13,317 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:13,317 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:13,709 - config - INFO - Epoch [204/2000], Train Loss: 37.2659
2024-03-28 18:26:13,744 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:13,745 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:14,151 - config - INFO - Epoch [205/2000], Train Loss: 37.2659
2024-03-28 18:26:14,186 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:14,186 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:14,579 - config - INFO - Epoch [206/2000], Train Loss: 37.2659
2024-03-28 18:26:14,614 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:14,614 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:15,006 - config - INFO - Epoch [207/2000], Train Loss: 37.2659
2024-03-28 18:26:15,052 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:15,052 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:15,518 - config - INFO - Epoch [208/2000], Train Loss: 37.2659
2024-03-28 18:26:15,553 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:15,553 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:15,972 - config - INFO - Epoch [209/2000], Train Loss: 37.2659
2024-03-28 18:26:16,007 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:16,008 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:16,407 - config - INFO - Epoch [210/2000], Train Loss: 37.2659
2024-03-28 18:26:16,442 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:16,443 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:16,878 - config - INFO - Epoch [211/2000], Train Loss: 37.2659
2024-03-28 18:26:16,913 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:16,913 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:17,344 - config - INFO - Epoch [212/2000], Train Loss: 37.2659
2024-03-28 18:26:17,379 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:17,379 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:17,863 - config - INFO - Epoch [213/2000], Train Loss: 37.2659
2024-03-28 18:26:17,897 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:17,898 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:18,325 - config - INFO - Epoch [214/2000], Train Loss: 37.2659
2024-03-28 18:26:18,360 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:18,360 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:18,811 - config - INFO - Epoch [215/2000], Train Loss: 37.2659
2024-03-28 18:26:18,846 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:18,846 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:19,261 - config - INFO - Epoch [216/2000], Train Loss: 37.2659
2024-03-28 18:26:19,297 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:19,298 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:19,729 - config - INFO - Epoch [217/2000], Train Loss: 37.2659
2024-03-28 18:26:19,764 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:19,764 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:20,161 - config - INFO - Epoch [218/2000], Train Loss: 37.2659
2024-03-28 18:26:20,196 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:20,197 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:20,623 - config - INFO - Epoch [219/2000], Train Loss: 37.2659
2024-03-28 18:26:20,658 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:20,658 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:21,099 - config - INFO - Epoch [220/2000], Train Loss: 37.2659
2024-03-28 18:26:21,135 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:21,135 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:21,566 - config - INFO - Epoch [221/2000], Train Loss: 37.2659
2024-03-28 18:26:21,602 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:21,602 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:22,059 - config - INFO - Epoch [222/2000], Train Loss: 37.2659
2024-03-28 18:26:22,095 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:22,095 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:22,552 - config - INFO - Epoch [223/2000], Train Loss: 37.2659
2024-03-28 18:26:22,587 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:22,587 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:23,014 - config - INFO - Epoch [224/2000], Train Loss: 37.2659
2024-03-28 18:26:23,049 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:23,049 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:23,510 - config - INFO - Epoch [225/2000], Train Loss: 37.2659
2024-03-28 18:26:23,552 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:23,552 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:23,955 - config - INFO - Epoch [226/2000], Train Loss: 37.2659
2024-03-28 18:26:23,990 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:23,991 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:24,405 - config - INFO - Epoch [227/2000], Train Loss: 37.2659
2024-03-28 18:26:24,439 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:24,440 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:24,852 - config - INFO - Epoch [228/2000], Train Loss: 37.2659
2024-03-28 18:26:24,889 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:24,889 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:25,327 - config - INFO - Epoch [229/2000], Train Loss: 37.2659
2024-03-28 18:26:25,361 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:25,362 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:25,851 - config - INFO - Epoch [230/2000], Train Loss: 37.2659
2024-03-28 18:26:25,889 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:25,889 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:26,402 - config - INFO - Epoch [231/2000], Train Loss: 37.2659
2024-03-28 18:26:26,447 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:26,447 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:26,913 - config - INFO - Epoch [232/2000], Train Loss: 37.2659
2024-03-28 18:26:26,951 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:26,951 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:27,439 - config - INFO - Epoch [233/2000], Train Loss: 37.2659
2024-03-28 18:26:27,483 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:27,483 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:27,962 - config - INFO - Epoch [234/2000], Train Loss: 37.2659
2024-03-28 18:26:27,999 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:28,000 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:28,455 - config - INFO - Epoch [235/2000], Train Loss: 37.2659
2024-03-28 18:26:28,493 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:28,493 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:28,937 - config - INFO - Epoch [236/2000], Train Loss: 37.2659
2024-03-28 18:26:28,974 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:28,974 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:29,424 - config - INFO - Epoch [237/2000], Train Loss: 37.2659
2024-03-28 18:26:29,463 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:29,463 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:29,908 - config - INFO - Epoch [238/2000], Train Loss: 37.2659
2024-03-28 18:26:29,946 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:29,946 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:30,379 - config - INFO - Epoch [239/2000], Train Loss: 37.2659
2024-03-28 18:26:30,424 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:30,425 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:30,874 - config - INFO - Epoch [240/2000], Train Loss: 37.2659
2024-03-28 18:26:30,912 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:30,912 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:31,369 - config - INFO - Epoch [241/2000], Train Loss: 37.2659
2024-03-28 18:26:31,407 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:31,408 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:31,859 - config - INFO - Epoch [242/2000], Train Loss: 37.2659
2024-03-28 18:26:31,897 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:31,897 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:32,401 - config - INFO - Epoch [243/2000], Train Loss: 37.2659
2024-03-28 18:26:32,439 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:32,439 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:32,900 - config - INFO - Epoch [244/2000], Train Loss: 37.2659
2024-03-28 18:26:32,937 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:32,938 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:33,362 - config - INFO - Epoch [245/2000], Train Loss: 37.2659
2024-03-28 18:26:33,400 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:33,400 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:33,874 - config - INFO - Epoch [246/2000], Train Loss: 37.2659
2024-03-28 18:26:33,911 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:33,911 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:34,368 - config - INFO - Epoch [247/2000], Train Loss: 37.2659
2024-03-28 18:26:34,406 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:34,406 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:34,845 - config - INFO - Epoch [248/2000], Train Loss: 37.2659
2024-03-28 18:26:34,883 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:34,883 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:35,308 - config - INFO - Epoch [249/2000], Train Loss: 37.2659
2024-03-28 18:26:35,346 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:35,346 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:35,843 - config - INFO - Epoch [250/2000], Train Loss: 37.2659
2024-03-28 18:26:35,880 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:35,880 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:36,335 - config - INFO - Epoch [251/2000], Train Loss: 37.2659
2024-03-28 18:26:36,373 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:36,373 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:36,835 - config - INFO - Epoch [252/2000], Train Loss: 37.2659
2024-03-28 18:26:36,871 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:36,871 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:37,346 - config - INFO - Epoch [253/2000], Train Loss: 37.2659
2024-03-28 18:26:37,383 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:37,383 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:37,868 - config - INFO - Epoch [254/2000], Train Loss: 37.2659
2024-03-28 18:26:37,905 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:37,905 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:38,314 - config - INFO - Epoch [255/2000], Train Loss: 37.2659
2024-03-28 18:26:38,351 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:38,351 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:38,773 - config - INFO - Epoch [256/2000], Train Loss: 37.2659
2024-03-28 18:26:38,810 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:38,810 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:39,245 - config - INFO - Epoch [257/2000], Train Loss: 37.2659
2024-03-28 18:26:39,282 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:39,282 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:39,728 - config - INFO - Epoch [258/2000], Train Loss: 37.2659
2024-03-28 18:26:39,764 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:39,765 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:40,191 - config - INFO - Epoch [259/2000], Train Loss: 37.2659
2024-03-28 18:26:40,229 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:40,229 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:40,647 - config - INFO - Epoch [260/2000], Train Loss: 37.2659
2024-03-28 18:26:40,699 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:40,700 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:41,129 - config - INFO - Epoch [261/2000], Train Loss: 37.2659
2024-03-28 18:26:41,166 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:41,166 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:41,648 - config - INFO - Epoch [262/2000], Train Loss: 37.2659
2024-03-28 18:26:41,684 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:41,684 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:42,170 - config - INFO - Epoch [263/2000], Train Loss: 37.2659
2024-03-28 18:26:42,207 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:42,207 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:42,663 - config - INFO - Epoch [264/2000], Train Loss: 37.2659
2024-03-28 18:26:42,711 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:42,711 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:43,165 - config - INFO - Epoch [265/2000], Train Loss: 37.2659
2024-03-28 18:26:43,202 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:43,202 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:43,673 - config - INFO - Epoch [266/2000], Train Loss: 37.2659
2024-03-28 18:26:43,709 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:43,709 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:44,160 - config - INFO - Epoch [267/2000], Train Loss: 37.2659
2024-03-28 18:26:44,197 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:44,198 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:44,682 - config - INFO - Epoch [268/2000], Train Loss: 37.2659
2024-03-28 18:26:44,718 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:44,718 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:45,160 - config - INFO - Epoch [269/2000], Train Loss: 37.2659
2024-03-28 18:26:45,203 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:45,203 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:45,680 - config - INFO - Epoch [270/2000], Train Loss: 37.2659
2024-03-28 18:26:45,719 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:45,719 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:46,233 - config - INFO - Epoch [271/2000], Train Loss: 37.2659
2024-03-28 18:26:46,270 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:46,270 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:46,755 - config - INFO - Epoch [272/2000], Train Loss: 37.2659
2024-03-28 18:26:46,791 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:46,791 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:47,216 - config - INFO - Epoch [273/2000], Train Loss: 37.2659
2024-03-28 18:26:47,253 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:47,253 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:47,675 - config - INFO - Epoch [274/2000], Train Loss: 37.2659
2024-03-28 18:26:47,711 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:47,712 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:48,143 - config - INFO - Epoch [275/2000], Train Loss: 37.2659
2024-03-28 18:26:48,180 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:48,180 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:48,621 - config - INFO - Epoch [276/2000], Train Loss: 37.2659
2024-03-28 18:26:48,658 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:48,659 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:49,102 - config - INFO - Epoch [277/2000], Train Loss: 37.2659
2024-03-28 18:26:49,139 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:49,139 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:49,588 - config - INFO - Epoch [278/2000], Train Loss: 37.2659
2024-03-28 18:26:49,625 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:49,625 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:50,035 - config - INFO - Epoch [279/2000], Train Loss: 37.2659
2024-03-28 18:26:50,081 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:50,081 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:50,514 - config - INFO - Epoch [280/2000], Train Loss: 37.2659
2024-03-28 18:26:50,551 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:50,551 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:50,995 - config - INFO - Epoch [281/2000], Train Loss: 37.2659
2024-03-28 18:26:51,032 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:51,032 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:51,504 - config - INFO - Epoch [282/2000], Train Loss: 37.2659
2024-03-28 18:26:51,541 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:51,541 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:52,041 - config - INFO - Epoch [283/2000], Train Loss: 37.2659
2024-03-28 18:26:52,078 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:52,078 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:52,510 - config - INFO - Epoch [284/2000], Train Loss: 37.2659
2024-03-28 18:26:52,546 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:52,547 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:52,990 - config - INFO - Epoch [285/2000], Train Loss: 37.2659
2024-03-28 18:26:53,027 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:53,027 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:53,440 - config - INFO - Epoch [286/2000], Train Loss: 37.2659
2024-03-28 18:26:53,477 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:53,477 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:53,913 - config - INFO - Epoch [287/2000], Train Loss: 37.2659
2024-03-28 18:26:53,950 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:53,950 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:54,367 - config - INFO - Epoch [288/2000], Train Loss: 37.2659
2024-03-28 18:26:54,403 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:54,404 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:54,846 - config - INFO - Epoch [289/2000], Train Loss: 37.2659
2024-03-28 18:26:54,883 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:54,883 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:55,339 - config - INFO - Epoch [290/2000], Train Loss: 37.2659
2024-03-28 18:26:55,375 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:55,375 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:55,841 - config - INFO - Epoch [291/2000], Train Loss: 37.2659
2024-03-28 18:26:55,878 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:55,878 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:56,338 - config - INFO - Epoch [292/2000], Train Loss: 37.2659
2024-03-28 18:26:56,375 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:56,375 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:56,801 - config - INFO - Epoch [293/2000], Train Loss: 37.2659
2024-03-28 18:26:56,838 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:56,839 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:57,288 - config - INFO - Epoch [294/2000], Train Loss: 37.2659
2024-03-28 18:26:57,338 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:57,338 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:57,797 - config - INFO - Epoch [295/2000], Train Loss: 37.2659
2024-03-28 18:26:57,833 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:57,834 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:58,293 - config - INFO - Epoch [296/2000], Train Loss: 37.2659
2024-03-28 18:26:58,330 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:58,331 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:58,764 - config - INFO - Epoch [297/2000], Train Loss: 37.2659
2024-03-28 18:26:58,801 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:58,801 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:59,211 - config - INFO - Epoch [298/2000], Train Loss: 37.2659
2024-03-28 18:26:59,247 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:59,248 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:26:59,723 - config - INFO - Epoch [299/2000], Train Loss: 37.2659
2024-03-28 18:26:59,760 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:26:59,760 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:00,180 - config - INFO - Epoch [300/2000], Train Loss: 37.2659
2024-03-28 18:27:00,229 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:00,229 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:00,716 - config - INFO - Epoch [301/2000], Train Loss: 37.2659
2024-03-28 18:27:00,752 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:00,753 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:01,210 - config - INFO - Epoch [302/2000], Train Loss: 37.2659
2024-03-28 18:27:01,246 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:01,246 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:01,717 - config - INFO - Epoch [303/2000], Train Loss: 37.2659
2024-03-28 18:27:01,754 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:01,754 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:02,195 - config - INFO - Epoch [304/2000], Train Loss: 37.2659
2024-03-28 18:27:02,237 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:02,237 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:02,712 - config - INFO - Epoch [305/2000], Train Loss: 37.2659
2024-03-28 18:27:02,749 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:02,749 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:03,127 - config - INFO - Epoch [306/2000], Train Loss: 37.2659
2024-03-28 18:27:03,168 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:03,169 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:03,520 - config - INFO - Epoch [307/2000], Train Loss: 37.2659
2024-03-28 18:27:03,560 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:03,561 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:03,949 - config - INFO - Epoch [308/2000], Train Loss: 37.2659
2024-03-28 18:27:03,989 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:03,990 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:04,348 - config - INFO - Epoch [309/2000], Train Loss: 37.2659
2024-03-28 18:27:04,384 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:04,384 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:04,744 - config - INFO - Epoch [310/2000], Train Loss: 37.2659
2024-03-28 18:27:04,786 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:04,786 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:05,190 - config - INFO - Epoch [311/2000], Train Loss: 37.2659
2024-03-28 18:27:05,237 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:05,237 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:05,598 - config - INFO - Epoch [312/2000], Train Loss: 37.2659
2024-03-28 18:27:05,643 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:05,643 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:05,996 - config - INFO - Epoch [313/2000], Train Loss: 37.2659
2024-03-28 18:27:06,036 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:06,036 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:06,463 - config - INFO - Epoch [314/2000], Train Loss: 37.2659
2024-03-28 18:27:06,503 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:06,504 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:06,853 - config - INFO - Epoch [315/2000], Train Loss: 37.2659
2024-03-28 18:27:06,894 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:06,894 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:07,259 - config - INFO - Epoch [316/2000], Train Loss: 37.2659
2024-03-28 18:27:07,297 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:07,297 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:07,655 - config - INFO - Epoch [317/2000], Train Loss: 37.2659
2024-03-28 18:27:07,689 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:07,690 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:08,063 - config - INFO - Epoch [318/2000], Train Loss: 37.2659
2024-03-28 18:27:08,099 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:08,100 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:08,485 - config - INFO - Epoch [319/2000], Train Loss: 37.2659
2024-03-28 18:27:08,525 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:08,525 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:08,897 - config - INFO - Epoch [320/2000], Train Loss: 37.2659
2024-03-28 18:27:08,938 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:08,938 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:09,282 - config - INFO - Epoch [321/2000], Train Loss: 37.2659
2024-03-28 18:27:09,326 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:09,326 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:09,669 - config - INFO - Epoch [322/2000], Train Loss: 37.2659
2024-03-28 18:27:09,709 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:09,709 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:10,060 - config - INFO - Epoch [323/2000], Train Loss: 37.2659
2024-03-28 18:27:10,106 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:10,107 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:10,476 - config - INFO - Epoch [324/2000], Train Loss: 37.2659
2024-03-28 18:27:10,512 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:10,513 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:10,882 - config - INFO - Epoch [325/2000], Train Loss: 37.2659
2024-03-28 18:27:10,923 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:10,923 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:11,312 - config - INFO - Epoch [326/2000], Train Loss: 37.2659
2024-03-28 18:27:11,358 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:11,359 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:11,716 - config - INFO - Epoch [327/2000], Train Loss: 37.2659
2024-03-28 18:27:11,760 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:11,760 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:12,160 - config - INFO - Epoch [328/2000], Train Loss: 37.2659
2024-03-28 18:27:12,195 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:12,196 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:12,604 - config - INFO - Epoch [329/2000], Train Loss: 37.2659
2024-03-28 18:27:12,640 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:12,641 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:13,077 - config - INFO - Epoch [330/2000], Train Loss: 37.2659
2024-03-28 18:27:13,118 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:13,118 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:13,510 - config - INFO - Epoch [331/2000], Train Loss: 37.2659
2024-03-28 18:27:13,546 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:13,546 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:13,978 - config - INFO - Epoch [332/2000], Train Loss: 37.2659
2024-03-28 18:27:14,016 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:14,016 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:14,425 - config - INFO - Epoch [333/2000], Train Loss: 37.2659
2024-03-28 18:27:14,461 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:14,461 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:14,876 - config - INFO - Epoch [334/2000], Train Loss: 37.2659
2024-03-28 18:27:14,917 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:14,918 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:15,314 - config - INFO - Epoch [335/2000], Train Loss: 37.2659
2024-03-28 18:27:15,350 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:15,350 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:15,730 - config - INFO - Epoch [336/2000], Train Loss: 37.2659
2024-03-28 18:27:15,769 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:15,769 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:16,180 - config - INFO - Epoch [337/2000], Train Loss: 37.2659
2024-03-28 18:27:16,218 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:16,218 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:16,578 - config - INFO - Epoch [338/2000], Train Loss: 37.2659
2024-03-28 18:27:16,613 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:16,614 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:16,974 - config - INFO - Epoch [339/2000], Train Loss: 37.2659
2024-03-28 18:27:17,009 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:17,009 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:17,395 - config - INFO - Epoch [340/2000], Train Loss: 37.2659
2024-03-28 18:27:17,434 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:17,434 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:17,832 - config - INFO - Epoch [341/2000], Train Loss: 37.2659
2024-03-28 18:27:17,878 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:17,879 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:18,292 - config - INFO - Epoch [342/2000], Train Loss: 37.2659
2024-03-28 18:27:18,332 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:18,332 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:18,704 - config - INFO - Epoch [343/2000], Train Loss: 37.2659
2024-03-28 18:27:18,740 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:18,740 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:19,110 - config - INFO - Epoch [344/2000], Train Loss: 37.2659
2024-03-28 18:27:19,149 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:19,149 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:19,561 - config - INFO - Epoch [345/2000], Train Loss: 37.2659
2024-03-28 18:27:19,595 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:19,596 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:20,058 - config - INFO - Epoch [346/2000], Train Loss: 37.2659
2024-03-28 18:27:20,095 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:20,096 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:20,555 - config - INFO - Epoch [347/2000], Train Loss: 37.2659
2024-03-28 18:27:20,599 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:20,599 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:21,061 - config - INFO - Epoch [348/2000], Train Loss: 37.2659
2024-03-28 18:27:21,099 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:21,099 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:21,581 - config - INFO - Epoch [349/2000], Train Loss: 37.2659
2024-03-28 18:27:21,618 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:21,618 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:22,041 - config - INFO - Epoch [350/2000], Train Loss: 37.2659
2024-03-28 18:27:22,078 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:22,079 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:22,490 - config - INFO - Epoch [351/2000], Train Loss: 37.2659
2024-03-28 18:27:22,530 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:22,530 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:22,991 - config - INFO - Epoch [352/2000], Train Loss: 37.2659
2024-03-28 18:27:23,028 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:23,029 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:23,425 - config - INFO - Epoch [353/2000], Train Loss: 37.2659
2024-03-28 18:27:23,462 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:23,462 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:23,899 - config - INFO - Epoch [354/2000], Train Loss: 37.2659
2024-03-28 18:27:23,933 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:23,933 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:24,369 - config - INFO - Epoch [355/2000], Train Loss: 37.2659
2024-03-28 18:27:24,408 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:24,408 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:24,834 - config - INFO - Epoch [356/2000], Train Loss: 37.2659
2024-03-28 18:27:24,882 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:24,882 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:25,269 - config - INFO - Epoch [357/2000], Train Loss: 37.2659
2024-03-28 18:27:25,306 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:25,306 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:25,667 - config - INFO - Epoch [358/2000], Train Loss: 37.2659
2024-03-28 18:27:25,704 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:25,704 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:26,099 - config - INFO - Epoch [359/2000], Train Loss: 37.2659
2024-03-28 18:27:26,162 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:26,162 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:26,538 - config - INFO - Epoch [360/2000], Train Loss: 37.2659
2024-03-28 18:27:26,582 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:26,583 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:26,905 - config - INFO - Epoch [361/2000], Train Loss: 37.2659
2024-03-28 18:27:26,941 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:26,941 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:27,267 - config - INFO - Epoch [362/2000], Train Loss: 37.2659
2024-03-28 18:27:27,303 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:27,303 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:27,646 - config - INFO - Epoch [363/2000], Train Loss: 37.2659
2024-03-28 18:27:27,684 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:27,684 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:28,080 - config - INFO - Epoch [364/2000], Train Loss: 37.2659
2024-03-28 18:27:28,119 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:28,119 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:28,476 - config - INFO - Epoch [365/2000], Train Loss: 37.2659
2024-03-28 18:27:28,514 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:28,514 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:28,915 - config - INFO - Epoch [366/2000], Train Loss: 37.2659
2024-03-28 18:27:28,952 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:28,952 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:29,408 - config - INFO - Epoch [367/2000], Train Loss: 37.2659
2024-03-28 18:27:29,444 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:29,444 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:29,869 - config - INFO - Epoch [368/2000], Train Loss: 37.2659
2024-03-28 18:27:29,905 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:29,906 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:30,331 - config - INFO - Epoch [369/2000], Train Loss: 37.2659
2024-03-28 18:27:30,367 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:30,367 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:30,750 - config - INFO - Epoch [370/2000], Train Loss: 37.2659
2024-03-28 18:27:30,786 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:30,786 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:31,203 - config - INFO - Epoch [371/2000], Train Loss: 37.2659
2024-03-28 18:27:31,239 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:31,239 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:31,639 - config - INFO - Epoch [372/2000], Train Loss: 37.2659
2024-03-28 18:27:31,675 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:31,675 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:32,078 - config - INFO - Epoch [373/2000], Train Loss: 37.2659
2024-03-28 18:27:32,122 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:32,122 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:32,538 - config - INFO - Epoch [374/2000], Train Loss: 37.2659
2024-03-28 18:27:32,574 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:32,575 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:33,013 - config - INFO - Epoch [375/2000], Train Loss: 37.2659
2024-03-28 18:27:33,048 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:33,049 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:33,467 - config - INFO - Epoch [376/2000], Train Loss: 37.2659
2024-03-28 18:27:33,504 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:33,504 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:33,913 - config - INFO - Epoch [377/2000], Train Loss: 37.2659
2024-03-28 18:27:33,955 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:33,955 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:34,370 - config - INFO - Epoch [378/2000], Train Loss: 37.2659
2024-03-28 18:27:34,407 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:34,407 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:34,747 - config - INFO - Epoch [379/2000], Train Loss: 37.2659
2024-03-28 18:27:34,787 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:34,787 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:35,167 - config - INFO - Epoch [380/2000], Train Loss: 37.2659
2024-03-28 18:27:35,206 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:35,207 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:35,586 - config - INFO - Epoch [381/2000], Train Loss: 37.2659
2024-03-28 18:27:35,623 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:35,623 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:36,007 - config - INFO - Epoch [382/2000], Train Loss: 37.2659
2024-03-28 18:27:36,044 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:36,044 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:36,456 - config - INFO - Epoch [383/2000], Train Loss: 37.2659
2024-03-28 18:27:36,500 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:36,500 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:36,900 - config - INFO - Epoch [384/2000], Train Loss: 37.2659
2024-03-28 18:27:36,944 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:36,944 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:37,313 - config - INFO - Epoch [385/2000], Train Loss: 37.2659
2024-03-28 18:27:37,354 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:37,354 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:37,725 - config - INFO - Epoch [386/2000], Train Loss: 37.2659
2024-03-28 18:27:37,761 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:37,762 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:38,158 - config - INFO - Epoch [387/2000], Train Loss: 37.2659
2024-03-28 18:27:38,211 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:38,211 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:38,642 - config - INFO - Epoch [388/2000], Train Loss: 37.2659
2024-03-28 18:27:38,692 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:38,692 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:39,122 - config - INFO - Epoch [389/2000], Train Loss: 37.2659
2024-03-28 18:27:39,159 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:39,160 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:39,561 - config - INFO - Epoch [390/2000], Train Loss: 37.2659
2024-03-28 18:27:39,598 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:39,598 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:40,004 - config - INFO - Epoch [391/2000], Train Loss: 37.2659
2024-03-28 18:27:40,042 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:40,042 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:40,414 - config - INFO - Epoch [392/2000], Train Loss: 37.2659
2024-03-28 18:27:40,452 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:40,453 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:40,871 - config - INFO - Epoch [393/2000], Train Loss: 37.2659
2024-03-28 18:27:40,906 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:40,906 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:41,336 - config - INFO - Epoch [394/2000], Train Loss: 37.2659
2024-03-28 18:27:41,376 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:41,376 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:41,776 - config - INFO - Epoch [395/2000], Train Loss: 37.2659
2024-03-28 18:27:41,828 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:41,828 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:42,189 - config - INFO - Epoch [396/2000], Train Loss: 37.2659
2024-03-28 18:27:42,226 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:42,227 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:42,629 - config - INFO - Epoch [397/2000], Train Loss: 37.2659
2024-03-28 18:27:42,672 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:42,672 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:43,032 - config - INFO - Epoch [398/2000], Train Loss: 37.2659
2024-03-28 18:27:43,068 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:43,068 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:43,426 - config - INFO - Epoch [399/2000], Train Loss: 37.2659
2024-03-28 18:27:43,463 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:43,463 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:43,899 - config - INFO - Epoch [400/2000], Train Loss: 37.2659
2024-03-28 18:27:43,936 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:43,936 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:44,352 - config - INFO - Epoch [401/2000], Train Loss: 37.2659
2024-03-28 18:27:44,388 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:44,388 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:44,786 - config - INFO - Epoch [402/2000], Train Loss: 37.2659
2024-03-28 18:27:44,823 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:44,823 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:45,234 - config - INFO - Epoch [403/2000], Train Loss: 37.2659
2024-03-28 18:27:45,271 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:45,271 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:45,693 - config - INFO - Epoch [404/2000], Train Loss: 37.2659
2024-03-28 18:27:45,730 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:45,730 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:46,129 - config - INFO - Epoch [405/2000], Train Loss: 37.2659
2024-03-28 18:27:46,166 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:46,166 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:46,564 - config - INFO - Epoch [406/2000], Train Loss: 37.2659
2024-03-28 18:27:46,601 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:46,602 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:47,009 - config - INFO - Epoch [407/2000], Train Loss: 37.2659
2024-03-28 18:27:47,046 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:47,046 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:47,455 - config - INFO - Epoch [408/2000], Train Loss: 37.2659
2024-03-28 18:27:47,491 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:47,491 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:47,909 - config - INFO - Epoch [409/2000], Train Loss: 37.2659
2024-03-28 18:27:47,946 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:47,946 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:48,362 - config - INFO - Epoch [410/2000], Train Loss: 37.2659
2024-03-28 18:27:48,405 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:48,405 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:48,818 - config - INFO - Epoch [411/2000], Train Loss: 37.2659
2024-03-28 18:27:48,854 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:48,855 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:49,230 - config - INFO - Epoch [412/2000], Train Loss: 37.2659
2024-03-28 18:27:49,266 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:49,267 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:49,685 - config - INFO - Epoch [413/2000], Train Loss: 37.2659
2024-03-28 18:27:49,721 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:49,721 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:50,126 - config - INFO - Epoch [414/2000], Train Loss: 37.2659
2024-03-28 18:27:50,162 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:50,163 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:50,553 - config - INFO - Epoch [415/2000], Train Loss: 37.2659
2024-03-28 18:27:50,589 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:50,590 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:50,987 - config - INFO - Epoch [416/2000], Train Loss: 37.2659
2024-03-28 18:27:51,022 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:51,022 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:51,388 - config - INFO - Epoch [417/2000], Train Loss: 37.2659
2024-03-28 18:27:51,435 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:51,435 - config - INFO - Validation Acc: 0.5400
2024-03-28 18:27:51,812 - config - INFO - Epoch [418/2000], Train Loss: 37.2659
2024-03-28 18:27:51,852 - config - INFO - Validation Loss: 39.3258
2024-03-28 18:27:51,853 - config - INFO - Validation Acc: 0.5400
2024-03-29 10:14:04,481 - config - INFO - resume: None
2024-03-29 10:14:04,481 - config - INFO - device: cpu
2024-03-29 10:14:04,481 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-29 10:14:04,481 - config - INFO - learning_rate: 0.001
2024-03-29 10:14:04,481 - config - INFO - num_epochs: 260
2024-03-29 10:14:04,481 - config - INFO - batch_size: 64
2024-03-29 10:14:04,481 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.3

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-29 10:14:04,503 - config - INFO - Dataset size: 891
2024-03-29 10:14:04,524 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 12800)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(12800, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-29 10:14:04,524 - config - INFO - Training start
2024-03-29 10:14:06,819 - config - INFO - Epoch [1/260], Train Loss: 0.6631
2024-03-29 10:14:06,825 - config - INFO - Validation Loss: 0.6481
2024-03-29 10:14:06,825 - config - INFO - Validation Acc: 0.6600
2024-03-29 10:14:06,863 - config - INFO - Epoch [2/260], Train Loss: 0.6194
2024-03-29 10:14:06,868 - config - INFO - Validation Loss: 0.6080
2024-03-29 10:14:06,868 - config - INFO - Validation Acc: 0.6800
2024-03-29 10:14:06,906 - config - INFO - Epoch [3/260], Train Loss: 0.5742
2024-03-29 10:14:06,911 - config - INFO - Validation Loss: 0.5624
2024-03-29 10:14:06,911 - config - INFO - Validation Acc: 0.7200
2024-03-29 10:14:06,948 - config - INFO - Epoch [4/260], Train Loss: 0.5272
2024-03-29 10:14:06,954 - config - INFO - Validation Loss: 0.5194
2024-03-29 10:14:06,954 - config - INFO - Validation Acc: 0.7200
2024-03-29 10:14:06,989 - config - INFO - Epoch [5/260], Train Loss: 0.4883
2024-03-29 10:14:06,994 - config - INFO - Validation Loss: 0.4860
2024-03-29 10:14:06,994 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:07,030 - config - INFO - Epoch [6/260], Train Loss: 0.4632
2024-03-29 10:14:07,035 - config - INFO - Validation Loss: 0.4660
2024-03-29 10:14:07,035 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:07,068 - config - INFO - Epoch [7/260], Train Loss: 0.4491
2024-03-29 10:14:07,073 - config - INFO - Validation Loss: 0.4514
2024-03-29 10:14:07,074 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:07,108 - config - INFO - Epoch [8/260], Train Loss: 0.4380
2024-03-29 10:14:07,113 - config - INFO - Validation Loss: 0.4458
2024-03-29 10:14:07,113 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:07,147 - config - INFO - Epoch [9/260], Train Loss: 0.4310
2024-03-29 10:14:07,152 - config - INFO - Validation Loss: 0.4444
2024-03-29 10:14:07,152 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:07,186 - config - INFO - Epoch [10/260], Train Loss: 0.4245
2024-03-29 10:14:07,191 - config - INFO - Validation Loss: 0.4420
2024-03-29 10:14:07,191 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:07,245 - config - INFO - Epoch [11/260], Train Loss: 0.4193
2024-03-29 10:14:07,250 - config - INFO - Validation Loss: 0.4431
2024-03-29 10:14:07,250 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:07,285 - config - INFO - Epoch [12/260], Train Loss: 0.4139
2024-03-29 10:14:07,290 - config - INFO - Validation Loss: 0.4448
2024-03-29 10:14:07,290 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:07,324 - config - INFO - Epoch [13/260], Train Loss: 0.4103
2024-03-29 10:14:07,329 - config - INFO - Validation Loss: 0.4495
2024-03-29 10:14:07,329 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:07,363 - config - INFO - Epoch [14/260], Train Loss: 0.4077
2024-03-29 10:14:07,368 - config - INFO - Validation Loss: 0.4470
2024-03-29 10:14:07,368 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:07,402 - config - INFO - Epoch [15/260], Train Loss: 0.4043
2024-03-29 10:14:07,407 - config - INFO - Validation Loss: 0.4431
2024-03-29 10:14:07,407 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:07,437 - config - INFO - Epoch [16/260], Train Loss: 0.4013
2024-03-29 10:14:07,441 - config - INFO - Validation Loss: 0.4495
2024-03-29 10:14:07,441 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:07,470 - config - INFO - Epoch [17/260], Train Loss: 0.3991
2024-03-29 10:14:07,474 - config - INFO - Validation Loss: 0.4490
2024-03-29 10:14:07,474 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:07,504 - config - INFO - Epoch [18/260], Train Loss: 0.3982
2024-03-29 10:14:07,508 - config - INFO - Validation Loss: 0.4470
2024-03-29 10:14:07,508 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:07,537 - config - INFO - Epoch [19/260], Train Loss: 0.3951
2024-03-29 10:14:07,541 - config - INFO - Validation Loss: 0.4512
2024-03-29 10:14:07,541 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:07,571 - config - INFO - Epoch [20/260], Train Loss: 0.3929
2024-03-29 10:14:07,575 - config - INFO - Validation Loss: 0.4496
2024-03-29 10:14:07,575 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:07,603 - config - INFO - Epoch [21/260], Train Loss: 0.3939
2024-03-29 10:14:07,607 - config - INFO - Validation Loss: 0.4458
2024-03-29 10:14:07,608 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:07,636 - config - INFO - Epoch [22/260], Train Loss: 0.3939
2024-03-29 10:14:07,640 - config - INFO - Validation Loss: 0.4502
2024-03-29 10:14:07,640 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:07,669 - config - INFO - Epoch [23/260], Train Loss: 0.3897
2024-03-29 10:14:07,673 - config - INFO - Validation Loss: 0.4566
2024-03-29 10:14:07,673 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:07,702 - config - INFO - Epoch [24/260], Train Loss: 0.3867
2024-03-29 10:14:07,706 - config - INFO - Validation Loss: 0.4555
2024-03-29 10:14:07,706 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:07,736 - config - INFO - Epoch [25/260], Train Loss: 0.3883
2024-03-29 10:14:07,740 - config - INFO - Validation Loss: 0.4584
2024-03-29 10:14:07,740 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:07,769 - config - INFO - Epoch [26/260], Train Loss: 0.3862
2024-03-29 10:14:07,773 - config - INFO - Validation Loss: 0.4646
2024-03-29 10:14:07,773 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:07,801 - config - INFO - Epoch [27/260], Train Loss: 0.3861
2024-03-29 10:14:07,805 - config - INFO - Validation Loss: 0.4588
2024-03-29 10:14:07,805 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:07,834 - config - INFO - Epoch [28/260], Train Loss: 0.3835
2024-03-29 10:14:07,838 - config - INFO - Validation Loss: 0.4577
2024-03-29 10:14:07,838 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:07,867 - config - INFO - Epoch [29/260], Train Loss: 0.3820
2024-03-29 10:14:07,871 - config - INFO - Validation Loss: 0.4585
2024-03-29 10:14:07,871 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:07,899 - config - INFO - Epoch [30/260], Train Loss: 0.3820
2024-03-29 10:14:07,903 - config - INFO - Validation Loss: 0.4628
2024-03-29 10:14:07,903 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:07,932 - config - INFO - Epoch [31/260], Train Loss: 0.3820
2024-03-29 10:14:07,936 - config - INFO - Validation Loss: 0.4643
2024-03-29 10:14:07,936 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:07,965 - config - INFO - Epoch [32/260], Train Loss: 0.3826
2024-03-29 10:14:07,969 - config - INFO - Validation Loss: 0.4605
2024-03-29 10:14:07,969 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:07,997 - config - INFO - Epoch [33/260], Train Loss: 0.3794
2024-03-29 10:14:08,001 - config - INFO - Validation Loss: 0.4622
2024-03-29 10:14:08,001 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,029 - config - INFO - Epoch [34/260], Train Loss: 0.3802
2024-03-29 10:14:08,033 - config - INFO - Validation Loss: 0.4628
2024-03-29 10:14:08,034 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,062 - config - INFO - Epoch [35/260], Train Loss: 0.3806
2024-03-29 10:14:08,066 - config - INFO - Validation Loss: 0.4605
2024-03-29 10:14:08,066 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,094 - config - INFO - Epoch [36/260], Train Loss: 0.3785
2024-03-29 10:14:08,098 - config - INFO - Validation Loss: 0.4674
2024-03-29 10:14:08,098 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,126 - config - INFO - Epoch [37/260], Train Loss: 0.3776
2024-03-29 10:14:08,130 - config - INFO - Validation Loss: 0.4617
2024-03-29 10:14:08,130 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,158 - config - INFO - Epoch [38/260], Train Loss: 0.3772
2024-03-29 10:14:08,162 - config - INFO - Validation Loss: 0.4646
2024-03-29 10:14:08,162 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,190 - config - INFO - Epoch [39/260], Train Loss: 0.3773
2024-03-29 10:14:08,194 - config - INFO - Validation Loss: 0.4657
2024-03-29 10:14:08,194 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,222 - config - INFO - Epoch [40/260], Train Loss: 0.3757
2024-03-29 10:14:08,226 - config - INFO - Validation Loss: 0.4664
2024-03-29 10:14:08,226 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,262 - config - INFO - Epoch [41/260], Train Loss: 0.3755
2024-03-29 10:14:08,267 - config - INFO - Validation Loss: 0.4690
2024-03-29 10:14:08,267 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,295 - config - INFO - Epoch [42/260], Train Loss: 0.3751
2024-03-29 10:14:08,299 - config - INFO - Validation Loss: 0.4668
2024-03-29 10:14:08,299 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,327 - config - INFO - Epoch [43/260], Train Loss: 0.3732
2024-03-29 10:14:08,331 - config - INFO - Validation Loss: 0.4658
2024-03-29 10:14:08,331 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,359 - config - INFO - Epoch [44/260], Train Loss: 0.3746
2024-03-29 10:14:08,363 - config - INFO - Validation Loss: 0.4643
2024-03-29 10:14:08,363 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:08,392 - config - INFO - Epoch [45/260], Train Loss: 0.3723
2024-03-29 10:14:08,396 - config - INFO - Validation Loss: 0.4696
2024-03-29 10:14:08,396 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,425 - config - INFO - Epoch [46/260], Train Loss: 0.3718
2024-03-29 10:14:08,429 - config - INFO - Validation Loss: 0.4725
2024-03-29 10:14:08,429 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,457 - config - INFO - Epoch [47/260], Train Loss: 0.3712
2024-03-29 10:14:08,461 - config - INFO - Validation Loss: 0.4709
2024-03-29 10:14:08,462 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,489 - config - INFO - Epoch [48/260], Train Loss: 0.3716
2024-03-29 10:14:08,493 - config - INFO - Validation Loss: 0.4679
2024-03-29 10:14:08,493 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,521 - config - INFO - Epoch [49/260], Train Loss: 0.3703
2024-03-29 10:14:08,525 - config - INFO - Validation Loss: 0.4670
2024-03-29 10:14:08,525 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,553 - config - INFO - Epoch [50/260], Train Loss: 0.3712
2024-03-29 10:14:08,557 - config - INFO - Validation Loss: 0.4639
2024-03-29 10:14:08,558 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,586 - config - INFO - Epoch [51/260], Train Loss: 0.3706
2024-03-29 10:14:08,590 - config - INFO - Validation Loss: 0.4682
2024-03-29 10:14:08,590 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:08,619 - config - INFO - Epoch [52/260], Train Loss: 0.3700
2024-03-29 10:14:08,623 - config - INFO - Validation Loss: 0.4668
2024-03-29 10:14:08,623 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,651 - config - INFO - Epoch [53/260], Train Loss: 0.3699
2024-03-29 10:14:08,655 - config - INFO - Validation Loss: 0.4680
2024-03-29 10:14:08,655 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,683 - config - INFO - Epoch [54/260], Train Loss: 0.3707
2024-03-29 10:14:08,687 - config - INFO - Validation Loss: 0.4687
2024-03-29 10:14:08,687 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,715 - config - INFO - Epoch [55/260], Train Loss: 0.3691
2024-03-29 10:14:08,719 - config - INFO - Validation Loss: 0.4662
2024-03-29 10:14:08,720 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:08,762 - config - INFO - Epoch [56/260], Train Loss: 0.3680
2024-03-29 10:14:08,766 - config - INFO - Validation Loss: 0.4674
2024-03-29 10:14:08,767 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,794 - config - INFO - Epoch [57/260], Train Loss: 0.3686
2024-03-29 10:14:08,798 - config - INFO - Validation Loss: 0.4680
2024-03-29 10:14:08,798 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,826 - config - INFO - Epoch [58/260], Train Loss: 0.3678
2024-03-29 10:14:08,830 - config - INFO - Validation Loss: 0.4695
2024-03-29 10:14:08,830 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,858 - config - INFO - Epoch [59/260], Train Loss: 0.3679
2024-03-29 10:14:08,862 - config - INFO - Validation Loss: 0.4653
2024-03-29 10:14:08,862 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,889 - config - INFO - Epoch [60/260], Train Loss: 0.3663
2024-03-29 10:14:08,893 - config - INFO - Validation Loss: 0.4639
2024-03-29 10:14:08,893 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,921 - config - INFO - Epoch [61/260], Train Loss: 0.3667
2024-03-29 10:14:08,925 - config - INFO - Validation Loss: 0.4671
2024-03-29 10:14:08,925 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:08,953 - config - INFO - Epoch [62/260], Train Loss: 0.3653
2024-03-29 10:14:08,957 - config - INFO - Validation Loss: 0.4753
2024-03-29 10:14:08,957 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:08,985 - config - INFO - Epoch [63/260], Train Loss: 0.3683
2024-03-29 10:14:08,989 - config - INFO - Validation Loss: 0.4795
2024-03-29 10:14:08,989 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,017 - config - INFO - Epoch [64/260], Train Loss: 0.3657
2024-03-29 10:14:09,021 - config - INFO - Validation Loss: 0.4703
2024-03-29 10:14:09,022 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,049 - config - INFO - Epoch [65/260], Train Loss: 0.3649
2024-03-29 10:14:09,053 - config - INFO - Validation Loss: 0.4728
2024-03-29 10:14:09,053 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,081 - config - INFO - Epoch [66/260], Train Loss: 0.3644
2024-03-29 10:14:09,085 - config - INFO - Validation Loss: 0.4781
2024-03-29 10:14:09,085 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,114 - config - INFO - Epoch [67/260], Train Loss: 0.3655
2024-03-29 10:14:09,118 - config - INFO - Validation Loss: 0.4718
2024-03-29 10:14:09,118 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,146 - config - INFO - Epoch [68/260], Train Loss: 0.3630
2024-03-29 10:14:09,150 - config - INFO - Validation Loss: 0.4741
2024-03-29 10:14:09,150 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,178 - config - INFO - Epoch [69/260], Train Loss: 0.3649
2024-03-29 10:14:09,182 - config - INFO - Validation Loss: 0.4688
2024-03-29 10:14:09,182 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,210 - config - INFO - Epoch [70/260], Train Loss: 0.3647
2024-03-29 10:14:09,214 - config - INFO - Validation Loss: 0.4677
2024-03-29 10:14:09,214 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,242 - config - INFO - Epoch [71/260], Train Loss: 0.3633
2024-03-29 10:14:09,245 - config - INFO - Validation Loss: 0.4677
2024-03-29 10:14:09,246 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,273 - config - INFO - Epoch [72/260], Train Loss: 0.3623
2024-03-29 10:14:09,277 - config - INFO - Validation Loss: 0.4685
2024-03-29 10:14:09,277 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,305 - config - INFO - Epoch [73/260], Train Loss: 0.3625
2024-03-29 10:14:09,309 - config - INFO - Validation Loss: 0.4697
2024-03-29 10:14:09,309 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,337 - config - INFO - Epoch [74/260], Train Loss: 0.3623
2024-03-29 10:14:09,341 - config - INFO - Validation Loss: 0.4763
2024-03-29 10:14:09,341 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,368 - config - INFO - Epoch [75/260], Train Loss: 0.3628
2024-03-29 10:14:09,372 - config - INFO - Validation Loss: 0.4734
2024-03-29 10:14:09,372 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,400 - config - INFO - Epoch [76/260], Train Loss: 0.3626
2024-03-29 10:14:09,404 - config - INFO - Validation Loss: 0.4758
2024-03-29 10:14:09,404 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,432 - config - INFO - Epoch [77/260], Train Loss: 0.3614
2024-03-29 10:14:09,436 - config - INFO - Validation Loss: 0.4766
2024-03-29 10:14:09,436 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,464 - config - INFO - Epoch [78/260], Train Loss: 0.3624
2024-03-29 10:14:09,468 - config - INFO - Validation Loss: 0.4722
2024-03-29 10:14:09,468 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,496 - config - INFO - Epoch [79/260], Train Loss: 0.3670
2024-03-29 10:14:09,500 - config - INFO - Validation Loss: 0.4807
2024-03-29 10:14:09,506 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,538 - config - INFO - Epoch [80/260], Train Loss: 0.3657
2024-03-29 10:14:09,542 - config - INFO - Validation Loss: 0.4753
2024-03-29 10:14:09,542 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,569 - config - INFO - Epoch [81/260], Train Loss: 0.3617
2024-03-29 10:14:09,573 - config - INFO - Validation Loss: 0.4774
2024-03-29 10:14:09,573 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:09,601 - config - INFO - Epoch [82/260], Train Loss: 0.3606
2024-03-29 10:14:09,605 - config - INFO - Validation Loss: 0.4774
2024-03-29 10:14:09,605 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,633 - config - INFO - Epoch [83/260], Train Loss: 0.3612
2024-03-29 10:14:09,637 - config - INFO - Validation Loss: 0.4793
2024-03-29 10:14:09,637 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,664 - config - INFO - Epoch [84/260], Train Loss: 0.3613
2024-03-29 10:14:09,668 - config - INFO - Validation Loss: 0.4792
2024-03-29 10:14:09,668 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,696 - config - INFO - Epoch [85/260], Train Loss: 0.3593
2024-03-29 10:14:09,700 - config - INFO - Validation Loss: 0.4820
2024-03-29 10:14:09,700 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,728 - config - INFO - Epoch [86/260], Train Loss: 0.3590
2024-03-29 10:14:09,732 - config - INFO - Validation Loss: 0.4825
2024-03-29 10:14:09,732 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,760 - config - INFO - Epoch [87/260], Train Loss: 0.3571
2024-03-29 10:14:09,763 - config - INFO - Validation Loss: 0.4803
2024-03-29 10:14:09,764 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,791 - config - INFO - Epoch [88/260], Train Loss: 0.3586
2024-03-29 10:14:09,795 - config - INFO - Validation Loss: 0.4807
2024-03-29 10:14:09,795 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,823 - config - INFO - Epoch [89/260], Train Loss: 0.3587
2024-03-29 10:14:09,826 - config - INFO - Validation Loss: 0.4823
2024-03-29 10:14:09,827 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,854 - config - INFO - Epoch [90/260], Train Loss: 0.3582
2024-03-29 10:14:09,858 - config - INFO - Validation Loss: 0.4773
2024-03-29 10:14:09,858 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,885 - config - INFO - Epoch [91/260], Train Loss: 0.3626
2024-03-29 10:14:09,889 - config - INFO - Validation Loss: 0.4860
2024-03-29 10:14:09,890 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,917 - config - INFO - Epoch [92/260], Train Loss: 0.3597
2024-03-29 10:14:09,921 - config - INFO - Validation Loss: 0.4773
2024-03-29 10:14:09,921 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:09,949 - config - INFO - Epoch [93/260], Train Loss: 0.3562
2024-03-29 10:14:09,953 - config - INFO - Validation Loss: 0.4828
2024-03-29 10:14:09,953 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:09,980 - config - INFO - Epoch [94/260], Train Loss: 0.3565
2024-03-29 10:14:09,984 - config - INFO - Validation Loss: 0.4839
2024-03-29 10:14:09,984 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:10,012 - config - INFO - Epoch [95/260], Train Loss: 0.3601
2024-03-29 10:14:10,016 - config - INFO - Validation Loss: 0.4845
2024-03-29 10:14:10,016 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:10,045 - config - INFO - Epoch [96/260], Train Loss: 0.3637
2024-03-29 10:14:10,049 - config - INFO - Validation Loss: 0.4686
2024-03-29 10:14:10,049 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:10,077 - config - INFO - Epoch [97/260], Train Loss: 0.3639
2024-03-29 10:14:10,081 - config - INFO - Validation Loss: 0.4725
2024-03-29 10:14:10,081 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:10,111 - config - INFO - Epoch [98/260], Train Loss: 0.3596
2024-03-29 10:14:10,115 - config - INFO - Validation Loss: 0.4684
2024-03-29 10:14:10,115 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:10,143 - config - INFO - Epoch [99/260], Train Loss: 0.3551
2024-03-29 10:14:10,147 - config - INFO - Validation Loss: 0.4799
2024-03-29 10:14:10,147 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:10,175 - config - INFO - Epoch [100/260], Train Loss: 0.3542
2024-03-29 10:14:10,179 - config - INFO - Validation Loss: 0.4883
2024-03-29 10:14:10,179 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:10,207 - config - INFO - Epoch [101/260], Train Loss: 0.3555
2024-03-29 10:14:10,211 - config - INFO - Validation Loss: 0.4906
2024-03-29 10:14:10,211 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:10,238 - config - INFO - Epoch [102/260], Train Loss: 0.3531
2024-03-29 10:14:10,242 - config - INFO - Validation Loss: 0.4875
2024-03-29 10:14:10,243 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:10,270 - config - INFO - Epoch [103/260], Train Loss: 0.3533
2024-03-29 10:14:10,274 - config - INFO - Validation Loss: 0.4843
2024-03-29 10:14:10,274 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:10,301 - config - INFO - Epoch [104/260], Train Loss: 0.3519
2024-03-29 10:14:10,305 - config - INFO - Validation Loss: 0.4851
2024-03-29 10:14:10,306 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:10,333 - config - INFO - Epoch [105/260], Train Loss: 0.3534
2024-03-29 10:14:10,337 - config - INFO - Validation Loss: 0.4866
2024-03-29 10:14:10,337 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:10,364 - config - INFO - Epoch [106/260], Train Loss: 0.3526
2024-03-29 10:14:10,368 - config - INFO - Validation Loss: 0.4861
2024-03-29 10:14:10,369 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:10,401 - config - INFO - Epoch [107/260], Train Loss: 0.3536
2024-03-29 10:14:10,405 - config - INFO - Validation Loss: 0.4879
2024-03-29 10:14:10,405 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:10,432 - config - INFO - Epoch [108/260], Train Loss: 0.3525
2024-03-29 10:14:10,436 - config - INFO - Validation Loss: 0.4899
2024-03-29 10:14:10,436 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:10,464 - config - INFO - Epoch [109/260], Train Loss: 0.3543
2024-03-29 10:14:10,468 - config - INFO - Validation Loss: 0.4905
2024-03-29 10:14:10,468 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:10,496 - config - INFO - Epoch [110/260], Train Loss: 0.3550
2024-03-29 10:14:10,500 - config - INFO - Validation Loss: 0.4831
2024-03-29 10:14:10,500 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:10,529 - config - INFO - Epoch [111/260], Train Loss: 0.3521
2024-03-29 10:14:10,533 - config - INFO - Validation Loss: 0.4837
2024-03-29 10:14:10,533 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:10,561 - config - INFO - Epoch [112/260], Train Loss: 0.3529
2024-03-29 10:14:10,565 - config - INFO - Validation Loss: 0.4845
2024-03-29 10:14:10,565 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:10,593 - config - INFO - Epoch [113/260], Train Loss: 0.3513
2024-03-29 10:14:10,597 - config - INFO - Validation Loss: 0.4870
2024-03-29 10:14:10,597 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:10,625 - config - INFO - Epoch [114/260], Train Loss: 0.3489
2024-03-29 10:14:10,629 - config - INFO - Validation Loss: 0.4865
2024-03-29 10:14:10,630 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:10,657 - config - INFO - Epoch [115/260], Train Loss: 0.3489
2024-03-29 10:14:10,661 - config - INFO - Validation Loss: 0.4895
2024-03-29 10:14:10,661 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:10,688 - config - INFO - Epoch [116/260], Train Loss: 0.3486
2024-03-29 10:14:10,692 - config - INFO - Validation Loss: 0.4924
2024-03-29 10:14:10,692 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:10,720 - config - INFO - Epoch [117/260], Train Loss: 0.3479
2024-03-29 10:14:10,724 - config - INFO - Validation Loss: 0.4925
2024-03-29 10:14:10,724 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:10,753 - config - INFO - Epoch [118/260], Train Loss: 0.3482
2024-03-29 10:14:10,758 - config - INFO - Validation Loss: 0.4907
2024-03-29 10:14:10,758 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:10,785 - config - INFO - Epoch [119/260], Train Loss: 0.3483
2024-03-29 10:14:10,789 - config - INFO - Validation Loss: 0.4866
2024-03-29 10:14:10,790 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:10,817 - config - INFO - Epoch [120/260], Train Loss: 0.3474
2024-03-29 10:14:10,821 - config - INFO - Validation Loss: 0.4910
2024-03-29 10:14:10,821 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:10,852 - config - INFO - Epoch [121/260], Train Loss: 0.3488
2024-03-29 10:14:10,856 - config - INFO - Validation Loss: 0.4929
2024-03-29 10:14:10,856 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:10,883 - config - INFO - Epoch [122/260], Train Loss: 0.3502
2024-03-29 10:14:10,887 - config - INFO - Validation Loss: 0.4967
2024-03-29 10:14:10,887 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:10,914 - config - INFO - Epoch [123/260], Train Loss: 0.3484
2024-03-29 10:14:10,918 - config - INFO - Validation Loss: 0.4913
2024-03-29 10:14:10,918 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:10,946 - config - INFO - Epoch [124/260], Train Loss: 0.3481
2024-03-29 10:14:10,950 - config - INFO - Validation Loss: 0.4933
2024-03-29 10:14:10,950 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:10,978 - config - INFO - Epoch [125/260], Train Loss: 0.3464
2024-03-29 10:14:10,982 - config - INFO - Validation Loss: 0.4940
2024-03-29 10:14:10,982 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:11,009 - config - INFO - Epoch [126/260], Train Loss: 0.3486
2024-03-29 10:14:11,013 - config - INFO - Validation Loss: 0.4967
2024-03-29 10:14:11,014 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:11,042 - config - INFO - Epoch [127/260], Train Loss: 0.3507
2024-03-29 10:14:11,046 - config - INFO - Validation Loss: 0.5032
2024-03-29 10:14:11,046 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:11,074 - config - INFO - Epoch [128/260], Train Loss: 0.3484
2024-03-29 10:14:11,078 - config - INFO - Validation Loss: 0.4925
2024-03-29 10:14:11,078 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:11,105 - config - INFO - Epoch [129/260], Train Loss: 0.3463
2024-03-29 10:14:11,109 - config - INFO - Validation Loss: 0.4937
2024-03-29 10:14:11,109 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:11,136 - config - INFO - Epoch [130/260], Train Loss: 0.3440
2024-03-29 10:14:11,140 - config - INFO - Validation Loss: 0.4963
2024-03-29 10:14:11,140 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:11,168 - config - INFO - Epoch [131/260], Train Loss: 0.3455
2024-03-29 10:14:11,172 - config - INFO - Validation Loss: 0.4978
2024-03-29 10:14:11,172 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:11,200 - config - INFO - Epoch [132/260], Train Loss: 0.3499
2024-03-29 10:14:11,204 - config - INFO - Validation Loss: 0.5021
2024-03-29 10:14:11,204 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:11,231 - config - INFO - Epoch [133/260], Train Loss: 0.3468
2024-03-29 10:14:11,235 - config - INFO - Validation Loss: 0.5093
2024-03-29 10:14:11,235 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:11,263 - config - INFO - Epoch [134/260], Train Loss: 0.3453
2024-03-29 10:14:11,267 - config - INFO - Validation Loss: 0.5056
2024-03-29 10:14:11,267 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:11,294 - config - INFO - Epoch [135/260], Train Loss: 0.3457
2024-03-29 10:14:11,298 - config - INFO - Validation Loss: 0.5021
2024-03-29 10:14:11,298 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:11,325 - config - INFO - Epoch [136/260], Train Loss: 0.3444
2024-03-29 10:14:11,329 - config - INFO - Validation Loss: 0.4985
2024-03-29 10:14:11,330 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:11,357 - config - INFO - Epoch [137/260], Train Loss: 0.3428
2024-03-29 10:14:11,361 - config - INFO - Validation Loss: 0.4997
2024-03-29 10:14:11,361 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:11,388 - config - INFO - Epoch [138/260], Train Loss: 0.3480
2024-03-29 10:14:11,392 - config - INFO - Validation Loss: 0.5019
2024-03-29 10:14:11,392 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:11,420 - config - INFO - Epoch [139/260], Train Loss: 0.3449
2024-03-29 10:14:11,424 - config - INFO - Validation Loss: 0.5030
2024-03-29 10:14:11,424 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:11,452 - config - INFO - Epoch [140/260], Train Loss: 0.3399
2024-03-29 10:14:11,456 - config - INFO - Validation Loss: 0.4914
2024-03-29 10:14:11,456 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:11,487 - config - INFO - Epoch [141/260], Train Loss: 0.3476
2024-03-29 10:14:11,491 - config - INFO - Validation Loss: 0.4988
2024-03-29 10:14:11,491 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:11,518 - config - INFO - Epoch [142/260], Train Loss: 0.3424
2024-03-29 10:14:11,522 - config - INFO - Validation Loss: 0.5052
2024-03-29 10:14:11,522 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:11,551 - config - INFO - Epoch [143/260], Train Loss: 0.3399
2024-03-29 10:14:11,555 - config - INFO - Validation Loss: 0.5071
2024-03-29 10:14:11,555 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:11,583 - config - INFO - Epoch [144/260], Train Loss: 0.3401
2024-03-29 10:14:11,587 - config - INFO - Validation Loss: 0.5044
2024-03-29 10:14:11,587 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:11,614 - config - INFO - Epoch [145/260], Train Loss: 0.3412
2024-03-29 10:14:11,618 - config - INFO - Validation Loss: 0.5045
2024-03-29 10:14:11,619 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:11,646 - config - INFO - Epoch [146/260], Train Loss: 0.3400
2024-03-29 10:14:11,650 - config - INFO - Validation Loss: 0.5029
2024-03-29 10:14:11,650 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:11,678 - config - INFO - Epoch [147/260], Train Loss: 0.3389
2024-03-29 10:14:11,682 - config - INFO - Validation Loss: 0.5051
2024-03-29 10:14:11,682 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:11,709 - config - INFO - Epoch [148/260], Train Loss: 0.3392
2024-03-29 10:14:11,713 - config - INFO - Validation Loss: 0.5040
2024-03-29 10:14:11,714 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:11,741 - config - INFO - Epoch [149/260], Train Loss: 0.3400
2024-03-29 10:14:11,745 - config - INFO - Validation Loss: 0.5048
2024-03-29 10:14:11,746 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:11,776 - config - INFO - Epoch [150/260], Train Loss: 0.3402
2024-03-29 10:14:11,780 - config - INFO - Validation Loss: 0.5059
2024-03-29 10:14:11,780 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:11,807 - config - INFO - Epoch [151/260], Train Loss: 0.3374
2024-03-29 10:14:11,811 - config - INFO - Validation Loss: 0.5028
2024-03-29 10:14:11,811 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:11,838 - config - INFO - Epoch [152/260], Train Loss: 0.3378
2024-03-29 10:14:11,842 - config - INFO - Validation Loss: 0.5038
2024-03-29 10:14:11,842 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:11,870 - config - INFO - Epoch [153/260], Train Loss: 0.3370
2024-03-29 10:14:11,874 - config - INFO - Validation Loss: 0.5070
2024-03-29 10:14:11,874 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:11,902 - config - INFO - Epoch [154/260], Train Loss: 0.3432
2024-03-29 10:14:11,906 - config - INFO - Validation Loss: 0.5079
2024-03-29 10:14:11,906 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:11,934 - config - INFO - Epoch [155/260], Train Loss: 0.3369
2024-03-29 10:14:11,938 - config - INFO - Validation Loss: 0.5070
2024-03-29 10:14:11,938 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:11,968 - config - INFO - Epoch [156/260], Train Loss: 0.3388
2024-03-29 10:14:11,972 - config - INFO - Validation Loss: 0.5085
2024-03-29 10:14:11,972 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:12,000 - config - INFO - Epoch [157/260], Train Loss: 0.3446
2024-03-29 10:14:12,004 - config - INFO - Validation Loss: 0.5081
2024-03-29 10:14:12,004 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:12,031 - config - INFO - Epoch [158/260], Train Loss: 0.3370
2024-03-29 10:14:12,035 - config - INFO - Validation Loss: 0.5127
2024-03-29 10:14:12,035 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:12,069 - config - INFO - Epoch [159/260], Train Loss: 0.3393
2024-03-29 10:14:12,075 - config - INFO - Validation Loss: 0.5073
2024-03-29 10:14:12,076 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:12,106 - config - INFO - Epoch [160/260], Train Loss: 0.3407
2024-03-29 10:14:12,110 - config - INFO - Validation Loss: 0.5036
2024-03-29 10:14:12,110 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:12,144 - config - INFO - Epoch [161/260], Train Loss: 0.3378
2024-03-29 10:14:12,148 - config - INFO - Validation Loss: 0.5042
2024-03-29 10:14:12,148 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:12,175 - config - INFO - Epoch [162/260], Train Loss: 0.3371
2024-03-29 10:14:12,179 - config - INFO - Validation Loss: 0.5067
2024-03-29 10:14:12,179 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:12,207 - config - INFO - Epoch [163/260], Train Loss: 0.3372
2024-03-29 10:14:12,211 - config - INFO - Validation Loss: 0.4981
2024-03-29 10:14:12,211 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:12,238 - config - INFO - Epoch [164/260], Train Loss: 0.3379
2024-03-29 10:14:12,242 - config - INFO - Validation Loss: 0.5037
2024-03-29 10:14:12,242 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:12,269 - config - INFO - Epoch [165/260], Train Loss: 0.3382
2024-03-29 10:14:12,273 - config - INFO - Validation Loss: 0.5061
2024-03-29 10:14:12,274 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:12,301 - config - INFO - Epoch [166/260], Train Loss: 0.3390
2024-03-29 10:14:12,305 - config - INFO - Validation Loss: 0.5102
2024-03-29 10:14:12,305 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:12,332 - config - INFO - Epoch [167/260], Train Loss: 0.3349
2024-03-29 10:14:12,336 - config - INFO - Validation Loss: 0.5063
2024-03-29 10:14:12,336 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:12,363 - config - INFO - Epoch [168/260], Train Loss: 0.3359
2024-03-29 10:14:12,367 - config - INFO - Validation Loss: 0.5103
2024-03-29 10:14:12,368 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:12,401 - config - INFO - Epoch [169/260], Train Loss: 0.3333
2024-03-29 10:14:12,405 - config - INFO - Validation Loss: 0.5126
2024-03-29 10:14:12,406 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:12,433 - config - INFO - Epoch [170/260], Train Loss: 0.3344
2024-03-29 10:14:12,437 - config - INFO - Validation Loss: 0.5115
2024-03-29 10:14:12,437 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:12,464 - config - INFO - Epoch [171/260], Train Loss: 0.3326
2024-03-29 10:14:12,468 - config - INFO - Validation Loss: 0.5086
2024-03-29 10:14:12,468 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:12,496 - config - INFO - Epoch [172/260], Train Loss: 0.3333
2024-03-29 10:14:12,500 - config - INFO - Validation Loss: 0.5083
2024-03-29 10:14:12,500 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:12,527 - config - INFO - Epoch [173/260], Train Loss: 0.3317
2024-03-29 10:14:12,531 - config - INFO - Validation Loss: 0.5014
2024-03-29 10:14:12,532 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:12,559 - config - INFO - Epoch [174/260], Train Loss: 0.3366
2024-03-29 10:14:12,563 - config - INFO - Validation Loss: 0.5036
2024-03-29 10:14:12,563 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:12,591 - config - INFO - Epoch [175/260], Train Loss: 0.3336
2024-03-29 10:14:12,595 - config - INFO - Validation Loss: 0.5181
2024-03-29 10:14:12,596 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:12,623 - config - INFO - Epoch [176/260], Train Loss: 0.3342
2024-03-29 10:14:12,627 - config - INFO - Validation Loss: 0.5185
2024-03-29 10:14:12,627 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:12,655 - config - INFO - Epoch [177/260], Train Loss: 0.3311
2024-03-29 10:14:12,659 - config - INFO - Validation Loss: 0.5159
2024-03-29 10:14:12,659 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:12,686 - config - INFO - Epoch [178/260], Train Loss: 0.3329
2024-03-29 10:14:12,690 - config - INFO - Validation Loss: 0.5068
2024-03-29 10:14:12,690 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:12,718 - config - INFO - Epoch [179/260], Train Loss: 0.3329
2024-03-29 10:14:12,722 - config - INFO - Validation Loss: 0.5141
2024-03-29 10:14:12,722 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:12,758 - config - INFO - Epoch [180/260], Train Loss: 0.3317
2024-03-29 10:14:12,762 - config - INFO - Validation Loss: 0.5124
2024-03-29 10:14:12,763 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:12,790 - config - INFO - Epoch [181/260], Train Loss: 0.3315
2024-03-29 10:14:12,794 - config - INFO - Validation Loss: 0.5098
2024-03-29 10:14:12,794 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:12,821 - config - INFO - Epoch [182/260], Train Loss: 0.3292
2024-03-29 10:14:12,825 - config - INFO - Validation Loss: 0.5134
2024-03-29 10:14:12,825 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:12,853 - config - INFO - Epoch [183/260], Train Loss: 0.3294
2024-03-29 10:14:12,857 - config - INFO - Validation Loss: 0.5106
2024-03-29 10:14:12,857 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:12,884 - config - INFO - Epoch [184/260], Train Loss: 0.3374
2024-03-29 10:14:12,888 - config - INFO - Validation Loss: 0.5155
2024-03-29 10:14:12,888 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:12,917 - config - INFO - Epoch [185/260], Train Loss: 0.3304
2024-03-29 10:14:12,924 - config - INFO - Validation Loss: 0.5156
2024-03-29 10:14:12,924 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:12,952 - config - INFO - Epoch [186/260], Train Loss: 0.3293
2024-03-29 10:14:12,956 - config - INFO - Validation Loss: 0.5116
2024-03-29 10:14:12,956 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:12,983 - config - INFO - Epoch [187/260], Train Loss: 0.3290
2024-03-29 10:14:12,987 - config - INFO - Validation Loss: 0.5050
2024-03-29 10:14:12,987 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:14:13,014 - config - INFO - Epoch [188/260], Train Loss: 0.3295
2024-03-29 10:14:13,018 - config - INFO - Validation Loss: 0.5070
2024-03-29 10:14:13,019 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:13,046 - config - INFO - Epoch [189/260], Train Loss: 0.3281
2024-03-29 10:14:13,050 - config - INFO - Validation Loss: 0.5117
2024-03-29 10:14:13,050 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:13,077 - config - INFO - Epoch [190/260], Train Loss: 0.3289
2024-03-29 10:14:13,081 - config - INFO - Validation Loss: 0.5167
2024-03-29 10:14:13,081 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:13,113 - config - INFO - Epoch [191/260], Train Loss: 0.3270
2024-03-29 10:14:13,119 - config - INFO - Validation Loss: 0.5173
2024-03-29 10:14:13,119 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:13,147 - config - INFO - Epoch [192/260], Train Loss: 0.3267
2024-03-29 10:14:13,150 - config - INFO - Validation Loss: 0.5135
2024-03-29 10:14:13,151 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:13,178 - config - INFO - Epoch [193/260], Train Loss: 0.3310
2024-03-29 10:14:13,182 - config - INFO - Validation Loss: 0.5204
2024-03-29 10:14:13,182 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:13,210 - config - INFO - Epoch [194/260], Train Loss: 0.3275
2024-03-29 10:14:13,214 - config - INFO - Validation Loss: 0.5178
2024-03-29 10:14:13,214 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:13,248 - config - INFO - Epoch [195/260], Train Loss: 0.3268
2024-03-29 10:14:13,251 - config - INFO - Validation Loss: 0.5149
2024-03-29 10:14:13,252 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:13,279 - config - INFO - Epoch [196/260], Train Loss: 0.3296
2024-03-29 10:14:13,283 - config - INFO - Validation Loss: 0.5096
2024-03-29 10:14:13,283 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:13,315 - config - INFO - Epoch [197/260], Train Loss: 0.3258
2024-03-29 10:14:13,319 - config - INFO - Validation Loss: 0.5075
2024-03-29 10:14:13,320 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:14:13,347 - config - INFO - Epoch [198/260], Train Loss: 0.3256
2024-03-29 10:14:13,351 - config - INFO - Validation Loss: 0.5162
2024-03-29 10:14:13,351 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:14:13,379 - config - INFO - Epoch [199/260], Train Loss: 0.3256
2024-03-29 10:14:13,383 - config - INFO - Validation Loss: 0.5164
2024-03-29 10:14:13,383 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:14:13,410 - config - INFO - Epoch [200/260], Train Loss: 0.3270
2024-03-29 10:14:13,414 - config - INFO - Validation Loss: 0.5252
2024-03-29 10:14:13,414 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:13,441 - config - INFO - Epoch [201/260], Train Loss: 0.3270
2024-03-29 10:14:13,445 - config - INFO - Validation Loss: 0.5263
2024-03-29 10:14:13,446 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:13,477 - config - INFO - Epoch [202/260], Train Loss: 0.3244
2024-03-29 10:14:13,482 - config - INFO - Validation Loss: 0.5316
2024-03-29 10:14:13,482 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:13,509 - config - INFO - Epoch [203/260], Train Loss: 0.3243
2024-03-29 10:14:13,513 - config - INFO - Validation Loss: 0.5200
2024-03-29 10:14:13,513 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:13,540 - config - INFO - Epoch [204/260], Train Loss: 0.3244
2024-03-29 10:14:13,544 - config - INFO - Validation Loss: 0.5214
2024-03-29 10:14:13,545 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:13,572 - config - INFO - Epoch [205/260], Train Loss: 0.3250
2024-03-29 10:14:13,576 - config - INFO - Validation Loss: 0.5190
2024-03-29 10:14:13,576 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:13,603 - config - INFO - Epoch [206/260], Train Loss: 0.3268
2024-03-29 10:14:13,607 - config - INFO - Validation Loss: 0.5165
2024-03-29 10:14:13,608 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:13,635 - config - INFO - Epoch [207/260], Train Loss: 0.3237
2024-03-29 10:14:13,639 - config - INFO - Validation Loss: 0.5218
2024-03-29 10:14:13,639 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:13,667 - config - INFO - Epoch [208/260], Train Loss: 0.3245
2024-03-29 10:14:13,671 - config - INFO - Validation Loss: 0.5297
2024-03-29 10:14:13,671 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:13,698 - config - INFO - Epoch [209/260], Train Loss: 0.3356
2024-03-29 10:14:13,702 - config - INFO - Validation Loss: 0.5285
2024-03-29 10:14:13,703 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:13,730 - config - INFO - Epoch [210/260], Train Loss: 0.3282
2024-03-29 10:14:13,734 - config - INFO - Validation Loss: 0.5296
2024-03-29 10:14:13,734 - config - INFO - Validation Acc: 0.7400
2024-03-29 10:14:13,762 - config - INFO - Epoch [211/260], Train Loss: 0.3253
2024-03-29 10:14:13,766 - config - INFO - Validation Loss: 0.5283
2024-03-29 10:14:13,766 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:13,794 - config - INFO - Epoch [212/260], Train Loss: 0.3250
2024-03-29 10:14:13,798 - config - INFO - Validation Loss: 0.5210
2024-03-29 10:14:13,798 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:13,825 - config - INFO - Epoch [213/260], Train Loss: 0.3223
2024-03-29 10:14:13,829 - config - INFO - Validation Loss: 0.5329
2024-03-29 10:14:13,829 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:14:13,856 - config - INFO - Epoch [214/260], Train Loss: 0.3266
2024-03-29 10:14:13,860 - config - INFO - Validation Loss: 0.5253
2024-03-29 10:14:13,861 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:14:13,888 - config - INFO - Epoch [215/260], Train Loss: 0.3203
2024-03-29 10:14:13,892 - config - INFO - Validation Loss: 0.5179
2024-03-29 10:14:13,892 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:14:13,919 - config - INFO - Epoch [216/260], Train Loss: 0.3216
2024-03-29 10:14:13,923 - config - INFO - Validation Loss: 0.5231
2024-03-29 10:14:13,924 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:14:13,951 - config - INFO - Epoch [217/260], Train Loss: 0.3198
2024-03-29 10:14:13,955 - config - INFO - Validation Loss: 0.5220
2024-03-29 10:14:13,955 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:14:13,982 - config - INFO - Epoch [218/260], Train Loss: 0.3204
2024-03-29 10:14:13,986 - config - INFO - Validation Loss: 0.5232
2024-03-29 10:14:13,987 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:14:14,014 - config - INFO - Epoch [219/260], Train Loss: 0.3184
2024-03-29 10:14:14,018 - config - INFO - Validation Loss: 0.5229
2024-03-29 10:14:14,018 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:14:14,045 - config - INFO - Epoch [220/260], Train Loss: 0.3202
2024-03-29 10:14:14,050 - config - INFO - Validation Loss: 0.5164
2024-03-29 10:14:14,050 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:14:14,082 - config - INFO - Epoch [221/260], Train Loss: 0.3206
2024-03-29 10:14:14,086 - config - INFO - Validation Loss: 0.5160
2024-03-29 10:14:14,086 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:14,113 - config - INFO - Epoch [222/260], Train Loss: 0.3203
2024-03-29 10:14:14,117 - config - INFO - Validation Loss: 0.5161
2024-03-29 10:14:14,117 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:14,145 - config - INFO - Epoch [223/260], Train Loss: 0.3219
2024-03-29 10:14:14,149 - config - INFO - Validation Loss: 0.5244
2024-03-29 10:14:14,149 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:14,182 - config - INFO - Epoch [224/260], Train Loss: 0.3233
2024-03-29 10:14:14,186 - config - INFO - Validation Loss: 0.5260
2024-03-29 10:14:14,186 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:14,215 - config - INFO - Epoch [225/260], Train Loss: 0.3244
2024-03-29 10:14:14,219 - config - INFO - Validation Loss: 0.5155
2024-03-29 10:14:14,219 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:14:14,247 - config - INFO - Epoch [226/260], Train Loss: 0.3225
2024-03-29 10:14:14,251 - config - INFO - Validation Loss: 0.5230
2024-03-29 10:14:14,251 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:14,278 - config - INFO - Epoch [227/260], Train Loss: 0.3187
2024-03-29 10:14:14,282 - config - INFO - Validation Loss: 0.5263
2024-03-29 10:14:14,282 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:14,310 - config - INFO - Epoch [228/260], Train Loss: 0.3191
2024-03-29 10:14:14,314 - config - INFO - Validation Loss: 0.5280
2024-03-29 10:14:14,314 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:14:14,341 - config - INFO - Epoch [229/260], Train Loss: 0.3197
2024-03-29 10:14:14,345 - config - INFO - Validation Loss: 0.5302
2024-03-29 10:14:14,345 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:14:14,374 - config - INFO - Epoch [230/260], Train Loss: 0.3234
2024-03-29 10:14:14,378 - config - INFO - Validation Loss: 0.5356
2024-03-29 10:14:14,378 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:14,405 - config - INFO - Epoch [231/260], Train Loss: 0.3196
2024-03-29 10:14:14,409 - config - INFO - Validation Loss: 0.5389
2024-03-29 10:14:14,410 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:14:14,442 - config - INFO - Epoch [232/260], Train Loss: 0.3155
2024-03-29 10:14:14,446 - config - INFO - Validation Loss: 0.5412
2024-03-29 10:14:14,446 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:14:14,473 - config - INFO - Epoch [233/260], Train Loss: 0.3237
2024-03-29 10:14:14,477 - config - INFO - Validation Loss: 0.5517
2024-03-29 10:14:14,477 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:14,504 - config - INFO - Epoch [234/260], Train Loss: 0.3181
2024-03-29 10:14:14,508 - config - INFO - Validation Loss: 0.5450
2024-03-29 10:14:14,515 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:14,545 - config - INFO - Epoch [235/260], Train Loss: 0.3173
2024-03-29 10:14:14,549 - config - INFO - Validation Loss: 0.5319
2024-03-29 10:14:14,549 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:14:14,577 - config - INFO - Epoch [236/260], Train Loss: 0.3155
2024-03-29 10:14:14,581 - config - INFO - Validation Loss: 0.5292
2024-03-29 10:14:14,581 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:14,615 - config - INFO - Epoch [237/260], Train Loss: 0.3150
2024-03-29 10:14:14,621 - config - INFO - Validation Loss: 0.5330
2024-03-29 10:14:14,622 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:14:14,649 - config - INFO - Epoch [238/260], Train Loss: 0.3165
2024-03-29 10:14:14,653 - config - INFO - Validation Loss: 0.5412
2024-03-29 10:14:14,653 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:14,682 - config - INFO - Epoch [239/260], Train Loss: 0.3148
2024-03-29 10:14:14,689 - config - INFO - Validation Loss: 0.5418
2024-03-29 10:14:14,689 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:14,718 - config - INFO - Epoch [240/260], Train Loss: 0.3137
2024-03-29 10:14:14,722 - config - INFO - Validation Loss: 0.5511
2024-03-29 10:14:14,723 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:14,750 - config - INFO - Epoch [241/260], Train Loss: 0.3190
2024-03-29 10:14:14,754 - config - INFO - Validation Loss: 0.5567
2024-03-29 10:14:14,754 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:14,782 - config - INFO - Epoch [242/260], Train Loss: 0.3147
2024-03-29 10:14:14,786 - config - INFO - Validation Loss: 0.5423
2024-03-29 10:14:14,786 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:14,813 - config - INFO - Epoch [243/260], Train Loss: 0.3153
2024-03-29 10:14:14,817 - config - INFO - Validation Loss: 0.5395
2024-03-29 10:14:14,817 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:14,844 - config - INFO - Epoch [244/260], Train Loss: 0.3191
2024-03-29 10:14:14,848 - config - INFO - Validation Loss: 0.5447
2024-03-29 10:14:14,849 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:14:14,879 - config - INFO - Epoch [245/260], Train Loss: 0.3140
2024-03-29 10:14:14,883 - config - INFO - Validation Loss: 0.5382
2024-03-29 10:14:14,883 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:14,911 - config - INFO - Epoch [246/260], Train Loss: 0.3128
2024-03-29 10:14:14,915 - config - INFO - Validation Loss: 0.5468
2024-03-29 10:14:14,915 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:14,942 - config - INFO - Epoch [247/260], Train Loss: 0.3130
2024-03-29 10:14:14,946 - config - INFO - Validation Loss: 0.5415
2024-03-29 10:14:14,946 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:14:14,974 - config - INFO - Epoch [248/260], Train Loss: 0.3135
2024-03-29 10:14:14,978 - config - INFO - Validation Loss: 0.5515
2024-03-29 10:14:14,978 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:15,005 - config - INFO - Epoch [249/260], Train Loss: 0.3148
2024-03-29 10:14:15,009 - config - INFO - Validation Loss: 0.5596
2024-03-29 10:14:15,010 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:15,037 - config - INFO - Epoch [250/260], Train Loss: 0.3157
2024-03-29 10:14:15,041 - config - INFO - Validation Loss: 0.5384
2024-03-29 10:14:15,041 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:15,069 - config - INFO - Epoch [251/260], Train Loss: 0.3127
2024-03-29 10:14:15,073 - config - INFO - Validation Loss: 0.5302
2024-03-29 10:14:15,073 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:15,100 - config - INFO - Epoch [252/260], Train Loss: 0.3148
2024-03-29 10:14:15,104 - config - INFO - Validation Loss: 0.5241
2024-03-29 10:14:15,104 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:15,131 - config - INFO - Epoch [253/260], Train Loss: 0.3128
2024-03-29 10:14:15,135 - config - INFO - Validation Loss: 0.5347
2024-03-29 10:14:15,136 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:15,163 - config - INFO - Epoch [254/260], Train Loss: 0.3115
2024-03-29 10:14:15,167 - config - INFO - Validation Loss: 0.5277
2024-03-29 10:14:15,167 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:15,195 - config - INFO - Epoch [255/260], Train Loss: 0.3109
2024-03-29 10:14:15,199 - config - INFO - Validation Loss: 0.5440
2024-03-29 10:14:15,199 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:15,226 - config - INFO - Epoch [256/260], Train Loss: 0.3118
2024-03-29 10:14:15,231 - config - INFO - Validation Loss: 0.5484
2024-03-29 10:14:15,231 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:15,258 - config - INFO - Epoch [257/260], Train Loss: 0.3100
2024-03-29 10:14:15,262 - config - INFO - Validation Loss: 0.5471
2024-03-29 10:14:15,262 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:14:15,290 - config - INFO - Epoch [258/260], Train Loss: 0.3117
2024-03-29 10:14:15,294 - config - INFO - Validation Loss: 0.5447
2024-03-29 10:14:15,294 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:15,321 - config - INFO - Epoch [259/260], Train Loss: 0.3122
2024-03-29 10:14:15,325 - config - INFO - Validation Loss: 0.5413
2024-03-29 10:14:15,325 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:14:15,352 - config - INFO - Epoch [260/260], Train Loss: 0.3095
2024-03-29 10:14:15,356 - config - INFO - Validation Loss: 0.5347
2024-03-29 10:14:15,356 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:46,921 - config - INFO - resume: None
2024-03-29 10:14:46,921 - config - INFO - device: cpu
2024-03-29 10:14:46,921 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-29 10:14:46,921 - config - INFO - learning_rate: 0.001
2024-03-29 10:14:46,921 - config - INFO - num_epochs: 260
2024-03-29 10:14:46,921 - config - INFO - batch_size: 64
2024-03-29 10:14:46,921 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.3

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-29 10:14:46,943 - config - INFO - Dataset size: 891
2024-03-29 10:14:46,964 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 52800)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(52800, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-29 10:14:46,964 - config - INFO - Training start
2024-03-29 10:14:49,273 - config - INFO - Epoch [1/260], Train Loss: 0.6674
2024-03-29 10:14:49,283 - config - INFO - Validation Loss: 0.6612
2024-03-29 10:14:49,284 - config - INFO - Validation Acc: 0.5400
2024-03-29 10:14:49,330 - config - INFO - Epoch [2/260], Train Loss: 0.6269
2024-03-29 10:14:49,338 - config - INFO - Validation Loss: 0.6381
2024-03-29 10:14:49,338 - config - INFO - Validation Acc: 0.5800
2024-03-29 10:14:49,379 - config - INFO - Epoch [3/260], Train Loss: 0.5882
2024-03-29 10:14:49,383 - config - INFO - Validation Loss: 0.6127
2024-03-29 10:14:49,383 - config - INFO - Validation Acc: 0.5800
2024-03-29 10:14:49,425 - config - INFO - Epoch [4/260], Train Loss: 0.5407
2024-03-29 10:14:49,430 - config - INFO - Validation Loss: 0.5841
2024-03-29 10:14:49,430 - config - INFO - Validation Acc: 0.7400
2024-03-29 10:14:49,470 - config - INFO - Epoch [5/260], Train Loss: 0.4906
2024-03-29 10:14:49,475 - config - INFO - Validation Loss: 0.5653
2024-03-29 10:14:49,476 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:49,514 - config - INFO - Epoch [6/260], Train Loss: 0.4541
2024-03-29 10:14:49,519 - config - INFO - Validation Loss: 0.5536
2024-03-29 10:14:49,519 - config - INFO - Validation Acc: 0.7400
2024-03-29 10:14:49,559 - config - INFO - Epoch [7/260], Train Loss: 0.4307
2024-03-29 10:14:49,564 - config - INFO - Validation Loss: 0.5582
2024-03-29 10:14:49,564 - config - INFO - Validation Acc: 0.7000
2024-03-29 10:14:49,605 - config - INFO - Epoch [8/260], Train Loss: 0.4152
2024-03-29 10:14:49,610 - config - INFO - Validation Loss: 0.5609
2024-03-29 10:14:49,610 - config - INFO - Validation Acc: 0.7200
2024-03-29 10:14:49,650 - config - INFO - Epoch [9/260], Train Loss: 0.4072
2024-03-29 10:14:49,655 - config - INFO - Validation Loss: 0.5659
2024-03-29 10:14:49,655 - config - INFO - Validation Acc: 0.7200
2024-03-29 10:14:49,688 - config - INFO - Epoch [10/260], Train Loss: 0.4018
2024-03-29 10:14:49,693 - config - INFO - Validation Loss: 0.5631
2024-03-29 10:14:49,693 - config - INFO - Validation Acc: 0.7200
2024-03-29 10:14:49,725 - config - INFO - Epoch [11/260], Train Loss: 0.3974
2024-03-29 10:14:49,730 - config - INFO - Validation Loss: 0.5538
2024-03-29 10:14:49,731 - config - INFO - Validation Acc: 0.7200
2024-03-29 10:14:49,763 - config - INFO - Epoch [12/260], Train Loss: 0.3940
2024-03-29 10:14:49,768 - config - INFO - Validation Loss: 0.5470
2024-03-29 10:14:49,768 - config - INFO - Validation Acc: 0.7400
2024-03-29 10:14:49,800 - config - INFO - Epoch [13/260], Train Loss: 0.3911
2024-03-29 10:14:49,805 - config - INFO - Validation Loss: 0.5414
2024-03-29 10:14:49,806 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:49,838 - config - INFO - Epoch [14/260], Train Loss: 0.3862
2024-03-29 10:14:49,843 - config - INFO - Validation Loss: 0.5511
2024-03-29 10:14:49,843 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:49,876 - config - INFO - Epoch [15/260], Train Loss: 0.3855
2024-03-29 10:14:49,881 - config - INFO - Validation Loss: 0.5458
2024-03-29 10:14:49,881 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:49,913 - config - INFO - Epoch [16/260], Train Loss: 0.3836
2024-03-29 10:14:49,918 - config - INFO - Validation Loss: 0.5502
2024-03-29 10:14:49,918 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:49,951 - config - INFO - Epoch [17/260], Train Loss: 0.3801
2024-03-29 10:14:49,956 - config - INFO - Validation Loss: 0.5448
2024-03-29 10:14:49,956 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:49,989 - config - INFO - Epoch [18/260], Train Loss: 0.3780
2024-03-29 10:14:49,994 - config - INFO - Validation Loss: 0.5390
2024-03-29 10:14:49,994 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,026 - config - INFO - Epoch [19/260], Train Loss: 0.3753
2024-03-29 10:14:50,031 - config - INFO - Validation Loss: 0.5329
2024-03-29 10:14:50,031 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,064 - config - INFO - Epoch [20/260], Train Loss: 0.3749
2024-03-29 10:14:50,068 - config - INFO - Validation Loss: 0.5263
2024-03-29 10:14:50,069 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,102 - config - INFO - Epoch [21/260], Train Loss: 0.3723
2024-03-29 10:14:50,123 - config - INFO - Validation Loss: 0.5300
2024-03-29 10:14:50,123 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,156 - config - INFO - Epoch [22/260], Train Loss: 0.3712
2024-03-29 10:14:50,161 - config - INFO - Validation Loss: 0.5343
2024-03-29 10:14:50,161 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,194 - config - INFO - Epoch [23/260], Train Loss: 0.3689
2024-03-29 10:14:50,199 - config - INFO - Validation Loss: 0.5356
2024-03-29 10:14:50,199 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,231 - config - INFO - Epoch [24/260], Train Loss: 0.3670
2024-03-29 10:14:50,236 - config - INFO - Validation Loss: 0.5394
2024-03-29 10:14:50,237 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,269 - config - INFO - Epoch [25/260], Train Loss: 0.3652
2024-03-29 10:14:50,274 - config - INFO - Validation Loss: 0.5311
2024-03-29 10:14:50,274 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,306 - config - INFO - Epoch [26/260], Train Loss: 0.3649
2024-03-29 10:14:50,311 - config - INFO - Validation Loss: 0.5350
2024-03-29 10:14:50,311 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,344 - config - INFO - Epoch [27/260], Train Loss: 0.3635
2024-03-29 10:14:50,349 - config - INFO - Validation Loss: 0.5277
2024-03-29 10:14:50,349 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,381 - config - INFO - Epoch [28/260], Train Loss: 0.3618
2024-03-29 10:14:50,386 - config - INFO - Validation Loss: 0.5309
2024-03-29 10:14:50,386 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,419 - config - INFO - Epoch [29/260], Train Loss: 0.3606
2024-03-29 10:14:50,424 - config - INFO - Validation Loss: 0.5343
2024-03-29 10:14:50,424 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,457 - config - INFO - Epoch [30/260], Train Loss: 0.3596
2024-03-29 10:14:50,462 - config - INFO - Validation Loss: 0.5386
2024-03-29 10:14:50,462 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,495 - config - INFO - Epoch [31/260], Train Loss: 0.3593
2024-03-29 10:14:50,500 - config - INFO - Validation Loss: 0.5373
2024-03-29 10:14:50,500 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,532 - config - INFO - Epoch [32/260], Train Loss: 0.3573
2024-03-29 10:14:50,537 - config - INFO - Validation Loss: 0.5317
2024-03-29 10:14:50,538 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,570 - config - INFO - Epoch [33/260], Train Loss: 0.3575
2024-03-29 10:14:50,575 - config - INFO - Validation Loss: 0.5290
2024-03-29 10:14:50,575 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,608 - config - INFO - Epoch [34/260], Train Loss: 0.3576
2024-03-29 10:14:50,613 - config - INFO - Validation Loss: 0.5408
2024-03-29 10:14:50,614 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,651 - config - INFO - Epoch [35/260], Train Loss: 0.3558
2024-03-29 10:14:50,654 - config - INFO - Validation Loss: 0.5364
2024-03-29 10:14:50,655 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,680 - config - INFO - Epoch [36/260], Train Loss: 0.3553
2024-03-29 10:14:50,683 - config - INFO - Validation Loss: 0.5374
2024-03-29 10:14:50,683 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,708 - config - INFO - Epoch [37/260], Train Loss: 0.3530
2024-03-29 10:14:50,712 - config - INFO - Validation Loss: 0.5364
2024-03-29 10:14:50,712 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,736 - config - INFO - Epoch [38/260], Train Loss: 0.3535
2024-03-29 10:14:50,740 - config - INFO - Validation Loss: 0.5385
2024-03-29 10:14:50,740 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,765 - config - INFO - Epoch [39/260], Train Loss: 0.3539
2024-03-29 10:14:50,769 - config - INFO - Validation Loss: 0.5355
2024-03-29 10:14:50,769 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,794 - config - INFO - Epoch [40/260], Train Loss: 0.3525
2024-03-29 10:14:50,798 - config - INFO - Validation Loss: 0.5306
2024-03-29 10:14:50,798 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,822 - config - INFO - Epoch [41/260], Train Loss: 0.3519
2024-03-29 10:14:50,826 - config - INFO - Validation Loss: 0.5362
2024-03-29 10:14:50,826 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,851 - config - INFO - Epoch [42/260], Train Loss: 0.3507
2024-03-29 10:14:50,855 - config - INFO - Validation Loss: 0.5325
2024-03-29 10:14:50,855 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,879 - config - INFO - Epoch [43/260], Train Loss: 0.3510
2024-03-29 10:14:50,884 - config - INFO - Validation Loss: 0.5405
2024-03-29 10:14:50,884 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,912 - config - INFO - Epoch [44/260], Train Loss: 0.3508
2024-03-29 10:14:50,917 - config - INFO - Validation Loss: 0.5339
2024-03-29 10:14:50,917 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,946 - config - INFO - Epoch [45/260], Train Loss: 0.3496
2024-03-29 10:14:50,950 - config - INFO - Validation Loss: 0.5309
2024-03-29 10:14:50,950 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:50,978 - config - INFO - Epoch [46/260], Train Loss: 0.3504
2024-03-29 10:14:50,982 - config - INFO - Validation Loss: 0.5302
2024-03-29 10:14:50,983 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:51,011 - config - INFO - Epoch [47/260], Train Loss: 0.3486
2024-03-29 10:14:51,015 - config - INFO - Validation Loss: 0.5404
2024-03-29 10:14:51,016 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:51,044 - config - INFO - Epoch [48/260], Train Loss: 0.3486
2024-03-29 10:14:51,048 - config - INFO - Validation Loss: 0.5410
2024-03-29 10:14:51,049 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:51,077 - config - INFO - Epoch [49/260], Train Loss: 0.3464
2024-03-29 10:14:51,081 - config - INFO - Validation Loss: 0.5359
2024-03-29 10:14:51,081 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:51,110 - config - INFO - Epoch [50/260], Train Loss: 0.3478
2024-03-29 10:14:51,114 - config - INFO - Validation Loss: 0.5360
2024-03-29 10:14:51,115 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:51,143 - config - INFO - Epoch [51/260], Train Loss: 0.3457
2024-03-29 10:14:51,153 - config - INFO - Validation Loss: 0.5291
2024-03-29 10:14:51,154 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:51,184 - config - INFO - Epoch [52/260], Train Loss: 0.3450
2024-03-29 10:14:51,189 - config - INFO - Validation Loss: 0.5331
2024-03-29 10:14:51,189 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:51,217 - config - INFO - Epoch [53/260], Train Loss: 0.3437
2024-03-29 10:14:51,221 - config - INFO - Validation Loss: 0.5409
2024-03-29 10:14:51,221 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:51,250 - config - INFO - Epoch [54/260], Train Loss: 0.3458
2024-03-29 10:14:51,254 - config - INFO - Validation Loss: 0.5415
2024-03-29 10:14:51,254 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:51,283 - config - INFO - Epoch [55/260], Train Loss: 0.3444
2024-03-29 10:14:51,287 - config - INFO - Validation Loss: 0.5450
2024-03-29 10:14:51,287 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:51,315 - config - INFO - Epoch [56/260], Train Loss: 0.3455
2024-03-29 10:14:51,319 - config - INFO - Validation Loss: 0.5457
2024-03-29 10:14:51,320 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:51,348 - config - INFO - Epoch [57/260], Train Loss: 0.3462
2024-03-29 10:14:51,352 - config - INFO - Validation Loss: 0.5342
2024-03-29 10:14:51,353 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:51,381 - config - INFO - Epoch [58/260], Train Loss: 0.3428
2024-03-29 10:14:51,385 - config - INFO - Validation Loss: 0.5263
2024-03-29 10:14:51,385 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:51,414 - config - INFO - Epoch [59/260], Train Loss: 0.3412
2024-03-29 10:14:51,418 - config - INFO - Validation Loss: 0.5322
2024-03-29 10:14:51,418 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:51,447 - config - INFO - Epoch [60/260], Train Loss: 0.3409
2024-03-29 10:14:51,451 - config - INFO - Validation Loss: 0.5399
2024-03-29 10:14:51,451 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:51,480 - config - INFO - Epoch [61/260], Train Loss: 0.3422
2024-03-29 10:14:51,484 - config - INFO - Validation Loss: 0.5401
2024-03-29 10:14:51,484 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:51,513 - config - INFO - Epoch [62/260], Train Loss: 0.3404
2024-03-29 10:14:51,517 - config - INFO - Validation Loss: 0.5350
2024-03-29 10:14:51,517 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:51,546 - config - INFO - Epoch [63/260], Train Loss: 0.3387
2024-03-29 10:14:51,550 - config - INFO - Validation Loss: 0.5382
2024-03-29 10:14:51,550 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:51,579 - config - INFO - Epoch [64/260], Train Loss: 0.3395
2024-03-29 10:14:51,583 - config - INFO - Validation Loss: 0.5467
2024-03-29 10:14:51,583 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:51,612 - config - INFO - Epoch [65/260], Train Loss: 0.3406
2024-03-29 10:14:51,616 - config - INFO - Validation Loss: 0.5426
2024-03-29 10:14:51,616 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:51,644 - config - INFO - Epoch [66/260], Train Loss: 0.3414
2024-03-29 10:14:51,649 - config - INFO - Validation Loss: 0.5401
2024-03-29 10:14:51,649 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:51,678 - config - INFO - Epoch [67/260], Train Loss: 0.3392
2024-03-29 10:14:51,682 - config - INFO - Validation Loss: 0.5297
2024-03-29 10:14:51,683 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:51,711 - config - INFO - Epoch [68/260], Train Loss: 0.3382
2024-03-29 10:14:51,716 - config - INFO - Validation Loss: 0.5329
2024-03-29 10:14:51,716 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:51,745 - config - INFO - Epoch [69/260], Train Loss: 0.3377
2024-03-29 10:14:51,749 - config - INFO - Validation Loss: 0.5355
2024-03-29 10:14:51,749 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:51,778 - config - INFO - Epoch [70/260], Train Loss: 0.3370
2024-03-29 10:14:51,782 - config - INFO - Validation Loss: 0.5410
2024-03-29 10:14:51,782 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:51,811 - config - INFO - Epoch [71/260], Train Loss: 0.3388
2024-03-29 10:14:51,815 - config - INFO - Validation Loss: 0.5539
2024-03-29 10:14:51,815 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:51,843 - config - INFO - Epoch [72/260], Train Loss: 0.3359
2024-03-29 10:14:51,847 - config - INFO - Validation Loss: 0.5412
2024-03-29 10:14:51,848 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:51,876 - config - INFO - Epoch [73/260], Train Loss: 0.3346
2024-03-29 10:14:51,880 - config - INFO - Validation Loss: 0.5360
2024-03-29 10:14:51,880 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:51,909 - config - INFO - Epoch [74/260], Train Loss: 0.3349
2024-03-29 10:14:51,913 - config - INFO - Validation Loss: 0.5386
2024-03-29 10:14:51,913 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:51,941 - config - INFO - Epoch [75/260], Train Loss: 0.3351
2024-03-29 10:14:51,945 - config - INFO - Validation Loss: 0.5326
2024-03-29 10:14:51,946 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:51,974 - config - INFO - Epoch [76/260], Train Loss: 0.3336
2024-03-29 10:14:51,978 - config - INFO - Validation Loss: 0.5374
2024-03-29 10:14:51,979 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:52,007 - config - INFO - Epoch [77/260], Train Loss: 0.3339
2024-03-29 10:14:52,011 - config - INFO - Validation Loss: 0.5355
2024-03-29 10:14:52,011 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:52,040 - config - INFO - Epoch [78/260], Train Loss: 0.3327
2024-03-29 10:14:52,044 - config - INFO - Validation Loss: 0.5352
2024-03-29 10:14:52,044 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:52,072 - config - INFO - Epoch [79/260], Train Loss: 0.3323
2024-03-29 10:14:52,077 - config - INFO - Validation Loss: 0.5398
2024-03-29 10:14:52,077 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:52,105 - config - INFO - Epoch [80/260], Train Loss: 0.3331
2024-03-29 10:14:52,110 - config - INFO - Validation Loss: 0.5402
2024-03-29 10:14:52,110 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:52,138 - config - INFO - Epoch [81/260], Train Loss: 0.3318
2024-03-29 10:14:52,142 - config - INFO - Validation Loss: 0.5290
2024-03-29 10:14:52,143 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:52,188 - config - INFO - Epoch [82/260], Train Loss: 0.3311
2024-03-29 10:14:52,192 - config - INFO - Validation Loss: 0.5321
2024-03-29 10:14:52,193 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:52,221 - config - INFO - Epoch [83/260], Train Loss: 0.3302
2024-03-29 10:14:52,225 - config - INFO - Validation Loss: 0.5440
2024-03-29 10:14:52,225 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:52,253 - config - INFO - Epoch [84/260], Train Loss: 0.3326
2024-03-29 10:14:52,258 - config - INFO - Validation Loss: 0.5366
2024-03-29 10:14:52,258 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:52,290 - config - INFO - Epoch [85/260], Train Loss: 0.3313
2024-03-29 10:14:52,295 - config - INFO - Validation Loss: 0.5465
2024-03-29 10:14:52,295 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:52,328 - config - INFO - Epoch [86/260], Train Loss: 0.3296
2024-03-29 10:14:52,332 - config - INFO - Validation Loss: 0.5428
2024-03-29 10:14:52,333 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:52,365 - config - INFO - Epoch [87/260], Train Loss: 0.3284
2024-03-29 10:14:52,370 - config - INFO - Validation Loss: 0.5273
2024-03-29 10:14:52,370 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:52,402 - config - INFO - Epoch [88/260], Train Loss: 0.3285
2024-03-29 10:14:52,407 - config - INFO - Validation Loss: 0.5309
2024-03-29 10:14:52,407 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:52,439 - config - INFO - Epoch [89/260], Train Loss: 0.3293
2024-03-29 10:14:52,444 - config - INFO - Validation Loss: 0.5305
2024-03-29 10:14:52,444 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:52,476 - config - INFO - Epoch [90/260], Train Loss: 0.3272
2024-03-29 10:14:52,481 - config - INFO - Validation Loss: 0.5431
2024-03-29 10:14:52,481 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:52,513 - config - INFO - Epoch [91/260], Train Loss: 0.3288
2024-03-29 10:14:52,518 - config - INFO - Validation Loss: 0.5385
2024-03-29 10:14:52,518 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:52,551 - config - INFO - Epoch [92/260], Train Loss: 0.3277
2024-03-29 10:14:52,556 - config - INFO - Validation Loss: 0.5391
2024-03-29 10:14:52,556 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:52,588 - config - INFO - Epoch [93/260], Train Loss: 0.3302
2024-03-29 10:14:52,593 - config - INFO - Validation Loss: 0.5430
2024-03-29 10:14:52,593 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:52,625 - config - INFO - Epoch [94/260], Train Loss: 0.3238
2024-03-29 10:14:52,630 - config - INFO - Validation Loss: 0.5316
2024-03-29 10:14:52,630 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:52,662 - config - INFO - Epoch [95/260], Train Loss: 0.3317
2024-03-29 10:14:52,667 - config - INFO - Validation Loss: 0.5276
2024-03-29 10:14:52,667 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:52,700 - config - INFO - Epoch [96/260], Train Loss: 0.3270
2024-03-29 10:14:52,704 - config - INFO - Validation Loss: 0.5321
2024-03-29 10:14:52,705 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:52,738 - config - INFO - Epoch [97/260], Train Loss: 0.3252
2024-03-29 10:14:52,743 - config - INFO - Validation Loss: 0.5232
2024-03-29 10:14:52,743 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:52,775 - config - INFO - Epoch [98/260], Train Loss: 0.3239
2024-03-29 10:14:52,780 - config - INFO - Validation Loss: 0.5359
2024-03-29 10:14:52,780 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:52,812 - config - INFO - Epoch [99/260], Train Loss: 0.3258
2024-03-29 10:14:52,817 - config - INFO - Validation Loss: 0.5430
2024-03-29 10:14:52,817 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:52,849 - config - INFO - Epoch [100/260], Train Loss: 0.3237
2024-03-29 10:14:52,854 - config - INFO - Validation Loss: 0.5401
2024-03-29 10:14:52,854 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:52,886 - config - INFO - Epoch [101/260], Train Loss: 0.3222
2024-03-29 10:14:52,891 - config - INFO - Validation Loss: 0.5438
2024-03-29 10:14:52,891 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:52,923 - config - INFO - Epoch [102/260], Train Loss: 0.3215
2024-03-29 10:14:52,928 - config - INFO - Validation Loss: 0.5447
2024-03-29 10:14:52,928 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:52,960 - config - INFO - Epoch [103/260], Train Loss: 0.3220
2024-03-29 10:14:52,965 - config - INFO - Validation Loss: 0.5432
2024-03-29 10:14:52,965 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:52,997 - config - INFO - Epoch [104/260], Train Loss: 0.3211
2024-03-29 10:14:53,002 - config - INFO - Validation Loss: 0.5389
2024-03-29 10:14:53,002 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:53,035 - config - INFO - Epoch [105/260], Train Loss: 0.3238
2024-03-29 10:14:53,040 - config - INFO - Validation Loss: 0.5428
2024-03-29 10:14:53,040 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:53,072 - config - INFO - Epoch [106/260], Train Loss: 0.3197
2024-03-29 10:14:53,077 - config - INFO - Validation Loss: 0.5353
2024-03-29 10:14:53,077 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:53,109 - config - INFO - Epoch [107/260], Train Loss: 0.3196
2024-03-29 10:14:53,114 - config - INFO - Validation Loss: 0.5351
2024-03-29 10:14:53,114 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:53,147 - config - INFO - Epoch [108/260], Train Loss: 0.3202
2024-03-29 10:14:53,152 - config - INFO - Validation Loss: 0.5382
2024-03-29 10:14:53,153 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:53,195 - config - INFO - Epoch [109/260], Train Loss: 0.3203
2024-03-29 10:14:53,199 - config - INFO - Validation Loss: 0.5355
2024-03-29 10:14:53,200 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:53,237 - config - INFO - Epoch [110/260], Train Loss: 0.3208
2024-03-29 10:14:53,241 - config - INFO - Validation Loss: 0.5406
2024-03-29 10:14:53,241 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:53,270 - config - INFO - Epoch [111/260], Train Loss: 0.3169
2024-03-29 10:14:53,275 - config - INFO - Validation Loss: 0.5358
2024-03-29 10:14:53,275 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:53,304 - config - INFO - Epoch [112/260], Train Loss: 0.3169
2024-03-29 10:14:53,308 - config - INFO - Validation Loss: 0.5374
2024-03-29 10:14:53,308 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:53,337 - config - INFO - Epoch [113/260], Train Loss: 0.3167
2024-03-29 10:14:53,341 - config - INFO - Validation Loss: 0.5423
2024-03-29 10:14:53,341 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:53,370 - config - INFO - Epoch [114/260], Train Loss: 0.3165
2024-03-29 10:14:53,374 - config - INFO - Validation Loss: 0.5455
2024-03-29 10:14:53,374 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:53,403 - config - INFO - Epoch [115/260], Train Loss: 0.3147
2024-03-29 10:14:53,407 - config - INFO - Validation Loss: 0.5384
2024-03-29 10:14:53,407 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:53,436 - config - INFO - Epoch [116/260], Train Loss: 0.3151
2024-03-29 10:14:53,440 - config - INFO - Validation Loss: 0.5438
2024-03-29 10:14:53,440 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:53,469 - config - INFO - Epoch [117/260], Train Loss: 0.3143
2024-03-29 10:14:53,473 - config - INFO - Validation Loss: 0.5470
2024-03-29 10:14:53,473 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:53,501 - config - INFO - Epoch [118/260], Train Loss: 0.3135
2024-03-29 10:14:53,506 - config - INFO - Validation Loss: 0.5473
2024-03-29 10:14:53,506 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:53,534 - config - INFO - Epoch [119/260], Train Loss: 0.3162
2024-03-29 10:14:53,538 - config - INFO - Validation Loss: 0.5477
2024-03-29 10:14:53,539 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:53,567 - config - INFO - Epoch [120/260], Train Loss: 0.3159
2024-03-29 10:14:53,572 - config - INFO - Validation Loss: 0.5347
2024-03-29 10:14:53,572 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:53,600 - config - INFO - Epoch [121/260], Train Loss: 0.3158
2024-03-29 10:14:53,604 - config - INFO - Validation Loss: 0.5345
2024-03-29 10:14:53,605 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:53,636 - config - INFO - Epoch [122/260], Train Loss: 0.3133
2024-03-29 10:14:53,642 - config - INFO - Validation Loss: 0.5429
2024-03-29 10:14:53,642 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:53,672 - config - INFO - Epoch [123/260], Train Loss: 0.3115
2024-03-29 10:14:53,676 - config - INFO - Validation Loss: 0.5520
2024-03-29 10:14:53,676 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:53,704 - config - INFO - Epoch [124/260], Train Loss: 0.3118
2024-03-29 10:14:53,709 - config - INFO - Validation Loss: 0.5583
2024-03-29 10:14:53,709 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:53,738 - config - INFO - Epoch [125/260], Train Loss: 0.3121
2024-03-29 10:14:53,742 - config - INFO - Validation Loss: 0.5509
2024-03-29 10:14:53,742 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:53,771 - config - INFO - Epoch [126/260], Train Loss: 0.3120
2024-03-29 10:14:53,775 - config - INFO - Validation Loss: 0.5549
2024-03-29 10:14:53,775 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:53,804 - config - INFO - Epoch [127/260], Train Loss: 0.3184
2024-03-29 10:14:53,809 - config - INFO - Validation Loss: 0.5715
2024-03-29 10:14:53,809 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:53,837 - config - INFO - Epoch [128/260], Train Loss: 0.3113
2024-03-29 10:14:53,841 - config - INFO - Validation Loss: 0.5438
2024-03-29 10:14:53,842 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:53,870 - config - INFO - Epoch [129/260], Train Loss: 0.3141
2024-03-29 10:14:53,874 - config - INFO - Validation Loss: 0.5532
2024-03-29 10:14:53,874 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:53,902 - config - INFO - Epoch [130/260], Train Loss: 0.3098
2024-03-29 10:14:53,907 - config - INFO - Validation Loss: 0.5521
2024-03-29 10:14:53,907 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:53,935 - config - INFO - Epoch [131/260], Train Loss: 0.3096
2024-03-29 10:14:53,939 - config - INFO - Validation Loss: 0.5455
2024-03-29 10:14:53,940 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:53,968 - config - INFO - Epoch [132/260], Train Loss: 0.3090
2024-03-29 10:14:53,972 - config - INFO - Validation Loss: 0.5497
2024-03-29 10:14:53,972 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,001 - config - INFO - Epoch [133/260], Train Loss: 0.3087
2024-03-29 10:14:54,005 - config - INFO - Validation Loss: 0.5497
2024-03-29 10:14:54,005 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,033 - config - INFO - Epoch [134/260], Train Loss: 0.3097
2024-03-29 10:14:54,038 - config - INFO - Validation Loss: 0.5524
2024-03-29 10:14:54,038 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,066 - config - INFO - Epoch [135/260], Train Loss: 0.3079
2024-03-29 10:14:54,071 - config - INFO - Validation Loss: 0.5543
2024-03-29 10:14:54,071 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,099 - config - INFO - Epoch [136/260], Train Loss: 0.3076
2024-03-29 10:14:54,103 - config - INFO - Validation Loss: 0.5575
2024-03-29 10:14:54,103 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,132 - config - INFO - Epoch [137/260], Train Loss: 0.3089
2024-03-29 10:14:54,138 - config - INFO - Validation Loss: 0.5424
2024-03-29 10:14:54,138 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,167 - config - INFO - Epoch [138/260], Train Loss: 0.3059
2024-03-29 10:14:54,172 - config - INFO - Validation Loss: 0.5554
2024-03-29 10:14:54,172 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,204 - config - INFO - Epoch [139/260], Train Loss: 0.3078
2024-03-29 10:14:54,208 - config - INFO - Validation Loss: 0.5607
2024-03-29 10:14:54,209 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,237 - config - INFO - Epoch [140/260], Train Loss: 0.3054
2024-03-29 10:14:54,241 - config - INFO - Validation Loss: 0.5478
2024-03-29 10:14:54,241 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,270 - config - INFO - Epoch [141/260], Train Loss: 0.3057
2024-03-29 10:14:54,274 - config - INFO - Validation Loss: 0.5521
2024-03-29 10:14:54,274 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:54,303 - config - INFO - Epoch [142/260], Train Loss: 0.3065
2024-03-29 10:14:54,307 - config - INFO - Validation Loss: 0.5456
2024-03-29 10:14:54,313 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:54,347 - config - INFO - Epoch [143/260], Train Loss: 0.3065
2024-03-29 10:14:54,351 - config - INFO - Validation Loss: 0.5556
2024-03-29 10:14:54,351 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,380 - config - INFO - Epoch [144/260], Train Loss: 0.3049
2024-03-29 10:14:54,385 - config - INFO - Validation Loss: 0.5529
2024-03-29 10:14:54,385 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,414 - config - INFO - Epoch [145/260], Train Loss: 0.3060
2024-03-29 10:14:54,418 - config - INFO - Validation Loss: 0.5582
2024-03-29 10:14:54,418 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,447 - config - INFO - Epoch [146/260], Train Loss: 0.3031
2024-03-29 10:14:54,452 - config - INFO - Validation Loss: 0.5529
2024-03-29 10:14:54,452 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,481 - config - INFO - Epoch [147/260], Train Loss: 0.3047
2024-03-29 10:14:54,485 - config - INFO - Validation Loss: 0.5444
2024-03-29 10:14:54,485 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,514 - config - INFO - Epoch [148/260], Train Loss: 0.3051
2024-03-29 10:14:54,519 - config - INFO - Validation Loss: 0.5443
2024-03-29 10:14:54,519 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,548 - config - INFO - Epoch [149/260], Train Loss: 0.3063
2024-03-29 10:14:54,552 - config - INFO - Validation Loss: 0.5583
2024-03-29 10:14:54,553 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:54,582 - config - INFO - Epoch [150/260], Train Loss: 0.3058
2024-03-29 10:14:54,587 - config - INFO - Validation Loss: 0.5583
2024-03-29 10:14:54,587 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,616 - config - INFO - Epoch [151/260], Train Loss: 0.3024
2024-03-29 10:14:54,620 - config - INFO - Validation Loss: 0.5547
2024-03-29 10:14:54,620 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,649 - config - INFO - Epoch [152/260], Train Loss: 0.3027
2024-03-29 10:14:54,653 - config - INFO - Validation Loss: 0.5556
2024-03-29 10:14:54,654 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,683 - config - INFO - Epoch [153/260], Train Loss: 0.3078
2024-03-29 10:14:54,688 - config - INFO - Validation Loss: 0.5583
2024-03-29 10:14:54,688 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,717 - config - INFO - Epoch [154/260], Train Loss: 0.3062
2024-03-29 10:14:54,721 - config - INFO - Validation Loss: 0.5451
2024-03-29 10:14:54,722 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:54,751 - config - INFO - Epoch [155/260], Train Loss: 0.3049
2024-03-29 10:14:54,755 - config - INFO - Validation Loss: 0.5604
2024-03-29 10:14:54,755 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,785 - config - INFO - Epoch [156/260], Train Loss: 0.3007
2024-03-29 10:14:54,789 - config - INFO - Validation Loss: 0.5471
2024-03-29 10:14:54,789 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,817 - config - INFO - Epoch [157/260], Train Loss: 0.2992
2024-03-29 10:14:54,822 - config - INFO - Validation Loss: 0.5568
2024-03-29 10:14:54,822 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,851 - config - INFO - Epoch [158/260], Train Loss: 0.3024
2024-03-29 10:14:54,855 - config - INFO - Validation Loss: 0.5421
2024-03-29 10:14:54,855 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,883 - config - INFO - Epoch [159/260], Train Loss: 0.3006
2024-03-29 10:14:54,888 - config - INFO - Validation Loss: 0.5575
2024-03-29 10:14:54,888 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,916 - config - INFO - Epoch [160/260], Train Loss: 0.2980
2024-03-29 10:14:54,920 - config - INFO - Validation Loss: 0.5516
2024-03-29 10:14:54,921 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,949 - config - INFO - Epoch [161/260], Train Loss: 0.2991
2024-03-29 10:14:54,953 - config - INFO - Validation Loss: 0.5499
2024-03-29 10:14:54,953 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:54,981 - config - INFO - Epoch [162/260], Train Loss: 0.2984
2024-03-29 10:14:54,985 - config - INFO - Validation Loss: 0.5568
2024-03-29 10:14:54,986 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,014 - config - INFO - Epoch [163/260], Train Loss: 0.2984
2024-03-29 10:14:55,018 - config - INFO - Validation Loss: 0.5635
2024-03-29 10:14:55,018 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,047 - config - INFO - Epoch [164/260], Train Loss: 0.3015
2024-03-29 10:14:55,051 - config - INFO - Validation Loss: 0.5553
2024-03-29 10:14:55,051 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,080 - config - INFO - Epoch [165/260], Train Loss: 0.2980
2024-03-29 10:14:55,084 - config - INFO - Validation Loss: 0.5791
2024-03-29 10:14:55,084 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,113 - config - INFO - Epoch [166/260], Train Loss: 0.2962
2024-03-29 10:14:55,117 - config - INFO - Validation Loss: 0.5581
2024-03-29 10:14:55,117 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,147 - config - INFO - Epoch [167/260], Train Loss: 0.2978
2024-03-29 10:14:55,151 - config - INFO - Validation Loss: 0.5667
2024-03-29 10:14:55,151 - config - INFO - Validation Acc: 0.7400
2024-03-29 10:14:55,179 - config - INFO - Epoch [168/260], Train Loss: 0.2953
2024-03-29 10:14:55,183 - config - INFO - Validation Loss: 0.5617
2024-03-29 10:14:55,184 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,222 - config - INFO - Epoch [169/260], Train Loss: 0.2984
2024-03-29 10:14:55,227 - config - INFO - Validation Loss: 0.5602
2024-03-29 10:14:55,228 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,256 - config - INFO - Epoch [170/260], Train Loss: 0.2976
2024-03-29 10:14:55,260 - config - INFO - Validation Loss: 0.5644
2024-03-29 10:14:55,260 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,289 - config - INFO - Epoch [171/260], Train Loss: 0.2957
2024-03-29 10:14:55,294 - config - INFO - Validation Loss: 0.5643
2024-03-29 10:14:55,294 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,322 - config - INFO - Epoch [172/260], Train Loss: 0.2940
2024-03-29 10:14:55,326 - config - INFO - Validation Loss: 0.5678
2024-03-29 10:14:55,326 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,354 - config - INFO - Epoch [173/260], Train Loss: 0.2962
2024-03-29 10:14:55,358 - config - INFO - Validation Loss: 0.5510
2024-03-29 10:14:55,359 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,387 - config - INFO - Epoch [174/260], Train Loss: 0.2975
2024-03-29 10:14:55,391 - config - INFO - Validation Loss: 0.5664
2024-03-29 10:14:55,391 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,419 - config - INFO - Epoch [175/260], Train Loss: 0.3152
2024-03-29 10:14:55,423 - config - INFO - Validation Loss: 0.5976
2024-03-29 10:14:55,423 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:55,451 - config - INFO - Epoch [176/260], Train Loss: 0.3006
2024-03-29 10:14:55,455 - config - INFO - Validation Loss: 0.5586
2024-03-29 10:14:55,455 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:55,483 - config - INFO - Epoch [177/260], Train Loss: 0.2947
2024-03-29 10:14:55,488 - config - INFO - Validation Loss: 0.5725
2024-03-29 10:14:55,488 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,516 - config - INFO - Epoch [178/260], Train Loss: 0.2943
2024-03-29 10:14:55,520 - config - INFO - Validation Loss: 0.5751
2024-03-29 10:14:55,521 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:55,549 - config - INFO - Epoch [179/260], Train Loss: 0.2936
2024-03-29 10:14:55,553 - config - INFO - Validation Loss: 0.5603
2024-03-29 10:14:55,553 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,581 - config - INFO - Epoch [180/260], Train Loss: 0.2898
2024-03-29 10:14:55,585 - config - INFO - Validation Loss: 0.5738
2024-03-29 10:14:55,585 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,613 - config - INFO - Epoch [181/260], Train Loss: 0.2911
2024-03-29 10:14:55,617 - config - INFO - Validation Loss: 0.5723
2024-03-29 10:14:55,618 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,646 - config - INFO - Epoch [182/260], Train Loss: 0.2917
2024-03-29 10:14:55,650 - config - INFO - Validation Loss: 0.5560
2024-03-29 10:14:55,650 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,678 - config - INFO - Epoch [183/260], Train Loss: 0.2923
2024-03-29 10:14:55,682 - config - INFO - Validation Loss: 0.5584
2024-03-29 10:14:55,682 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,710 - config - INFO - Epoch [184/260], Train Loss: 0.2910
2024-03-29 10:14:55,714 - config - INFO - Validation Loss: 0.5632
2024-03-29 10:14:55,714 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,743 - config - INFO - Epoch [185/260], Train Loss: 0.2889
2024-03-29 10:14:55,747 - config - INFO - Validation Loss: 0.5749
2024-03-29 10:14:55,747 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,776 - config - INFO - Epoch [186/260], Train Loss: 0.2881
2024-03-29 10:14:55,780 - config - INFO - Validation Loss: 0.5721
2024-03-29 10:14:55,780 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,808 - config - INFO - Epoch [187/260], Train Loss: 0.2873
2024-03-29 10:14:55,812 - config - INFO - Validation Loss: 0.5766
2024-03-29 10:14:55,812 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,840 - config - INFO - Epoch [188/260], Train Loss: 0.2913
2024-03-29 10:14:55,844 - config - INFO - Validation Loss: 0.5669
2024-03-29 10:14:55,844 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,872 - config - INFO - Epoch [189/260], Train Loss: 0.2880
2024-03-29 10:14:55,876 - config - INFO - Validation Loss: 0.5670
2024-03-29 10:14:55,876 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,905 - config - INFO - Epoch [190/260], Train Loss: 0.2889
2024-03-29 10:14:55,910 - config - INFO - Validation Loss: 0.5716
2024-03-29 10:14:55,910 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,938 - config - INFO - Epoch [191/260], Train Loss: 0.2883
2024-03-29 10:14:55,942 - config - INFO - Validation Loss: 0.5723
2024-03-29 10:14:55,942 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:55,970 - config - INFO - Epoch [192/260], Train Loss: 0.2869
2024-03-29 10:14:55,975 - config - INFO - Validation Loss: 0.5684
2024-03-29 10:14:55,975 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,003 - config - INFO - Epoch [193/260], Train Loss: 0.2875
2024-03-29 10:14:56,007 - config - INFO - Validation Loss: 0.5721
2024-03-29 10:14:56,007 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,035 - config - INFO - Epoch [194/260], Train Loss: 0.2861
2024-03-29 10:14:56,039 - config - INFO - Validation Loss: 0.5750
2024-03-29 10:14:56,039 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,068 - config - INFO - Epoch [195/260], Train Loss: 0.2909
2024-03-29 10:14:56,072 - config - INFO - Validation Loss: 0.5785
2024-03-29 10:14:56,072 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,100 - config - INFO - Epoch [196/260], Train Loss: 0.2858
2024-03-29 10:14:56,104 - config - INFO - Validation Loss: 0.5700
2024-03-29 10:14:56,104 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,133 - config - INFO - Epoch [197/260], Train Loss: 0.2863
2024-03-29 10:14:56,137 - config - INFO - Validation Loss: 0.5670
2024-03-29 10:14:56,137 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,165 - config - INFO - Epoch [198/260], Train Loss: 0.2853
2024-03-29 10:14:56,169 - config - INFO - Validation Loss: 0.5728
2024-03-29 10:14:56,169 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,198 - config - INFO - Epoch [199/260], Train Loss: 0.2875
2024-03-29 10:14:56,202 - config - INFO - Validation Loss: 0.5606
2024-03-29 10:14:56,202 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,230 - config - INFO - Epoch [200/260], Train Loss: 0.2829
2024-03-29 10:14:56,234 - config - INFO - Validation Loss: 0.5739
2024-03-29 10:14:56,234 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,262 - config - INFO - Epoch [201/260], Train Loss: 0.2858
2024-03-29 10:14:56,266 - config - INFO - Validation Loss: 0.5758
2024-03-29 10:14:56,266 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,294 - config - INFO - Epoch [202/260], Train Loss: 0.2858
2024-03-29 10:14:56,299 - config - INFO - Validation Loss: 0.5750
2024-03-29 10:14:56,299 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,333 - config - INFO - Epoch [203/260], Train Loss: 0.2820
2024-03-29 10:14:56,338 - config - INFO - Validation Loss: 0.5715
2024-03-29 10:14:56,338 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,366 - config - INFO - Epoch [204/260], Train Loss: 0.2833
2024-03-29 10:14:56,370 - config - INFO - Validation Loss: 0.5732
2024-03-29 10:14:56,370 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,403 - config - INFO - Epoch [205/260], Train Loss: 0.2812
2024-03-29 10:14:56,407 - config - INFO - Validation Loss: 0.5736
2024-03-29 10:14:56,408 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,436 - config - INFO - Epoch [206/260], Train Loss: 0.2825
2024-03-29 10:14:56,440 - config - INFO - Validation Loss: 0.5731
2024-03-29 10:14:56,440 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,474 - config - INFO - Epoch [207/260], Train Loss: 0.2819
2024-03-29 10:14:56,478 - config - INFO - Validation Loss: 0.5760
2024-03-29 10:14:56,479 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,515 - config - INFO - Epoch [208/260], Train Loss: 0.2803
2024-03-29 10:14:56,519 - config - INFO - Validation Loss: 0.5814
2024-03-29 10:14:56,519 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,547 - config - INFO - Epoch [209/260], Train Loss: 0.2794
2024-03-29 10:14:56,552 - config - INFO - Validation Loss: 0.5767
2024-03-29 10:14:56,552 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,583 - config - INFO - Epoch [210/260], Train Loss: 0.2821
2024-03-29 10:14:56,587 - config - INFO - Validation Loss: 0.5797
2024-03-29 10:14:56,587 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,616 - config - INFO - Epoch [211/260], Train Loss: 0.2806
2024-03-29 10:14:56,620 - config - INFO - Validation Loss: 0.5716
2024-03-29 10:14:56,620 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,648 - config - INFO - Epoch [212/260], Train Loss: 0.2833
2024-03-29 10:14:56,652 - config - INFO - Validation Loss: 0.5814
2024-03-29 10:14:56,652 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,680 - config - INFO - Epoch [213/260], Train Loss: 0.2800
2024-03-29 10:14:56,685 - config - INFO - Validation Loss: 0.5771
2024-03-29 10:14:56,685 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,713 - config - INFO - Epoch [214/260], Train Loss: 0.2796
2024-03-29 10:14:56,717 - config - INFO - Validation Loss: 0.5834
2024-03-29 10:14:56,717 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,745 - config - INFO - Epoch [215/260], Train Loss: 0.2802
2024-03-29 10:14:56,749 - config - INFO - Validation Loss: 0.5837
2024-03-29 10:14:56,750 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,778 - config - INFO - Epoch [216/260], Train Loss: 0.2774
2024-03-29 10:14:56,782 - config - INFO - Validation Loss: 0.5778
2024-03-29 10:14:56,782 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,813 - config - INFO - Epoch [217/260], Train Loss: 0.2778
2024-03-29 10:14:56,817 - config - INFO - Validation Loss: 0.5831
2024-03-29 10:14:56,817 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,845 - config - INFO - Epoch [218/260], Train Loss: 0.2849
2024-03-29 10:14:56,850 - config - INFO - Validation Loss: 0.5807
2024-03-29 10:14:56,850 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:56,878 - config - INFO - Epoch [219/260], Train Loss: 0.2764
2024-03-29 10:14:56,882 - config - INFO - Validation Loss: 0.5890
2024-03-29 10:14:56,882 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,910 - config - INFO - Epoch [220/260], Train Loss: 0.2818
2024-03-29 10:14:56,914 - config - INFO - Validation Loss: 0.5723
2024-03-29 10:14:56,914 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,946 - config - INFO - Epoch [221/260], Train Loss: 0.2797
2024-03-29 10:14:56,950 - config - INFO - Validation Loss: 0.5925
2024-03-29 10:14:56,950 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:56,978 - config - INFO - Epoch [222/260], Train Loss: 0.2765
2024-03-29 10:14:56,982 - config - INFO - Validation Loss: 0.5797
2024-03-29 10:14:56,982 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:57,013 - config - INFO - Epoch [223/260], Train Loss: 0.2774
2024-03-29 10:14:57,017 - config - INFO - Validation Loss: 0.5760
2024-03-29 10:14:57,018 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:57,051 - config - INFO - Epoch [224/260], Train Loss: 0.2764
2024-03-29 10:14:57,058 - config - INFO - Validation Loss: 0.5758
2024-03-29 10:14:57,058 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:57,091 - config - INFO - Epoch [225/260], Train Loss: 0.2749
2024-03-29 10:14:57,096 - config - INFO - Validation Loss: 0.5788
2024-03-29 10:14:57,096 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:57,132 - config - INFO - Epoch [226/260], Train Loss: 0.2745
2024-03-29 10:14:57,137 - config - INFO - Validation Loss: 0.5811
2024-03-29 10:14:57,137 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:57,165 - config - INFO - Epoch [227/260], Train Loss: 0.2779
2024-03-29 10:14:57,169 - config - INFO - Validation Loss: 0.5863
2024-03-29 10:14:57,169 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:57,207 - config - INFO - Epoch [228/260], Train Loss: 0.2767
2024-03-29 10:14:57,211 - config - INFO - Validation Loss: 0.5802
2024-03-29 10:14:57,211 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:57,239 - config - INFO - Epoch [229/260], Train Loss: 0.2769
2024-03-29 10:14:57,243 - config - INFO - Validation Loss: 0.5837
2024-03-29 10:14:57,243 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:57,271 - config - INFO - Epoch [230/260], Train Loss: 0.2784
2024-03-29 10:14:57,275 - config - INFO - Validation Loss: 0.5774
2024-03-29 10:14:57,275 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:57,310 - config - INFO - Epoch [231/260], Train Loss: 0.2737
2024-03-29 10:14:57,314 - config - INFO - Validation Loss: 0.5798
2024-03-29 10:14:57,314 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:57,349 - config - INFO - Epoch [232/260], Train Loss: 0.2756
2024-03-29 10:14:57,353 - config - INFO - Validation Loss: 0.5755
2024-03-29 10:14:57,353 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:57,382 - config - INFO - Epoch [233/260], Train Loss: 0.2750
2024-03-29 10:14:57,386 - config - INFO - Validation Loss: 0.5907
2024-03-29 10:14:57,386 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:57,415 - config - INFO - Epoch [234/260], Train Loss: 0.2760
2024-03-29 10:14:57,419 - config - INFO - Validation Loss: 0.5921
2024-03-29 10:14:57,420 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:57,454 - config - INFO - Epoch [235/260], Train Loss: 0.2728
2024-03-29 10:14:57,459 - config - INFO - Validation Loss: 0.5850
2024-03-29 10:14:57,459 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:57,490 - config - INFO - Epoch [236/260], Train Loss: 0.2738
2024-03-29 10:14:57,495 - config - INFO - Validation Loss: 0.5803
2024-03-29 10:14:57,495 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:57,526 - config - INFO - Epoch [237/260], Train Loss: 0.2720
2024-03-29 10:14:57,530 - config - INFO - Validation Loss: 0.5782
2024-03-29 10:14:57,530 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:57,558 - config - INFO - Epoch [238/260], Train Loss: 0.2708
2024-03-29 10:14:57,563 - config - INFO - Validation Loss: 0.5750
2024-03-29 10:14:57,563 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:57,594 - config - INFO - Epoch [239/260], Train Loss: 0.2728
2024-03-29 10:14:57,598 - config - INFO - Validation Loss: 0.5789
2024-03-29 10:14:57,598 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:57,644 - config - INFO - Epoch [240/260], Train Loss: 0.2717
2024-03-29 10:14:57,649 - config - INFO - Validation Loss: 0.5764
2024-03-29 10:14:57,649 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:57,678 - config - INFO - Epoch [241/260], Train Loss: 0.2720
2024-03-29 10:14:57,682 - config - INFO - Validation Loss: 0.5911
2024-03-29 10:14:57,682 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:57,710 - config - INFO - Epoch [242/260], Train Loss: 0.2741
2024-03-29 10:14:57,715 - config - INFO - Validation Loss: 0.5888
2024-03-29 10:14:57,715 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:57,749 - config - INFO - Epoch [243/260], Train Loss: 0.2682
2024-03-29 10:14:57,755 - config - INFO - Validation Loss: 0.5756
2024-03-29 10:14:57,755 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:57,783 - config - INFO - Epoch [244/260], Train Loss: 0.2699
2024-03-29 10:14:57,787 - config - INFO - Validation Loss: 0.5863
2024-03-29 10:14:57,787 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:57,815 - config - INFO - Epoch [245/260], Train Loss: 0.2695
2024-03-29 10:14:57,819 - config - INFO - Validation Loss: 0.5812
2024-03-29 10:14:57,819 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:57,847 - config - INFO - Epoch [246/260], Train Loss: 0.2703
2024-03-29 10:14:57,851 - config - INFO - Validation Loss: 0.5979
2024-03-29 10:14:57,851 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:57,879 - config - INFO - Epoch [247/260], Train Loss: 0.2692
2024-03-29 10:14:57,883 - config - INFO - Validation Loss: 0.5876
2024-03-29 10:14:57,883 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:57,911 - config - INFO - Epoch [248/260], Train Loss: 0.2692
2024-03-29 10:14:57,915 - config - INFO - Validation Loss: 0.5941
2024-03-29 10:14:57,915 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:57,943 - config - INFO - Epoch [249/260], Train Loss: 0.2694
2024-03-29 10:14:57,947 - config - INFO - Validation Loss: 0.5906
2024-03-29 10:14:57,948 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:57,982 - config - INFO - Epoch [250/260], Train Loss: 0.2675
2024-03-29 10:14:57,986 - config - INFO - Validation Loss: 0.5983
2024-03-29 10:14:57,986 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:58,019 - config - INFO - Epoch [251/260], Train Loss: 0.2758
2024-03-29 10:14:58,023 - config - INFO - Validation Loss: 0.6056
2024-03-29 10:14:58,023 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:58,051 - config - INFO - Epoch [252/260], Train Loss: 0.2675
2024-03-29 10:14:58,055 - config - INFO - Validation Loss: 0.5893
2024-03-29 10:14:58,055 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:58,088 - config - INFO - Epoch [253/260], Train Loss: 0.2688
2024-03-29 10:14:58,092 - config - INFO - Validation Loss: 0.6043
2024-03-29 10:14:58,092 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:58,124 - config - INFO - Epoch [254/260], Train Loss: 0.2737
2024-03-29 10:14:58,130 - config - INFO - Validation Loss: 0.5972
2024-03-29 10:14:58,130 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:58,158 - config - INFO - Epoch [255/260], Train Loss: 0.2674
2024-03-29 10:14:58,162 - config - INFO - Validation Loss: 0.5962
2024-03-29 10:14:58,162 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:14:58,191 - config - INFO - Epoch [256/260], Train Loss: 0.2668
2024-03-29 10:14:58,198 - config - INFO - Validation Loss: 0.5935
2024-03-29 10:14:58,198 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:58,230 - config - INFO - Epoch [257/260], Train Loss: 0.2692
2024-03-29 10:14:58,235 - config - INFO - Validation Loss: 0.5980
2024-03-29 10:14:58,235 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:58,263 - config - INFO - Epoch [258/260], Train Loss: 0.2664
2024-03-29 10:14:58,267 - config - INFO - Validation Loss: 0.5892
2024-03-29 10:14:58,267 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:14:58,295 - config - INFO - Epoch [259/260], Train Loss: 0.2693
2024-03-29 10:14:58,300 - config - INFO - Validation Loss: 0.6045
2024-03-29 10:14:58,300 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:14:58,332 - config - INFO - Epoch [260/260], Train Loss: 0.2674
2024-03-29 10:14:58,336 - config - INFO - Validation Loss: 0.6112
2024-03-29 10:14:58,336 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:31,550 - config - INFO - resume: None
2024-03-29 10:15:31,550 - config - INFO - device: cpu
2024-03-29 10:15:31,550 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-29 10:15:31,550 - config - INFO - learning_rate: 0.001
2024-03-29 10:15:31,550 - config - INFO - num_epochs: 260
2024-03-29 10:15:31,550 - config - INFO - batch_size: 64
2024-03-29 10:15:31,550 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.3

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-29 10:15:31,571 - config - INFO - Dataset size: 891
2024-03-29 10:15:31,595 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 92800)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(92800, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-29 10:15:31,595 - config - INFO - Training start
2024-03-29 10:15:33,965 - config - INFO - Epoch [1/260], Train Loss: 0.6609
2024-03-29 10:15:33,971 - config - INFO - Validation Loss: 0.6374
2024-03-29 10:15:33,976 - config - INFO - Validation Acc: 0.6800
2024-03-29 10:15:34,016 - config - INFO - Epoch [2/260], Train Loss: 0.5986
2024-03-29 10:15:34,020 - config - INFO - Validation Loss: 0.5945
2024-03-29 10:15:34,020 - config - INFO - Validation Acc: 0.7200
2024-03-29 10:15:34,049 - config - INFO - Epoch [3/260], Train Loss: 0.5461
2024-03-29 10:15:34,053 - config - INFO - Validation Loss: 0.5544
2024-03-29 10:15:34,053 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:15:34,084 - config - INFO - Epoch [4/260], Train Loss: 0.5007
2024-03-29 10:15:34,088 - config - INFO - Validation Loss: 0.5223
2024-03-29 10:15:34,088 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:34,117 - config - INFO - Epoch [5/260], Train Loss: 0.4702
2024-03-29 10:15:34,121 - config - INFO - Validation Loss: 0.4991
2024-03-29 10:15:34,121 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:34,150 - config - INFO - Epoch [6/260], Train Loss: 0.4493
2024-03-29 10:15:34,154 - config - INFO - Validation Loss: 0.4834
2024-03-29 10:15:34,155 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:34,184 - config - INFO - Epoch [7/260], Train Loss: 0.4392
2024-03-29 10:15:34,188 - config - INFO - Validation Loss: 0.4716
2024-03-29 10:15:34,188 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:34,219 - config - INFO - Epoch [8/260], Train Loss: 0.4327
2024-03-29 10:15:34,223 - config - INFO - Validation Loss: 0.4677
2024-03-29 10:15:34,223 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:34,252 - config - INFO - Epoch [9/260], Train Loss: 0.4253
2024-03-29 10:15:34,255 - config - INFO - Validation Loss: 0.4614
2024-03-29 10:15:34,256 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:34,282 - config - INFO - Epoch [10/260], Train Loss: 0.4207
2024-03-29 10:15:34,287 - config - INFO - Validation Loss: 0.4559
2024-03-29 10:15:34,287 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:34,316 - config - INFO - Epoch [11/260], Train Loss: 0.4192
2024-03-29 10:15:34,321 - config - INFO - Validation Loss: 0.4530
2024-03-29 10:15:34,321 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:34,350 - config - INFO - Epoch [12/260], Train Loss: 0.4138
2024-03-29 10:15:34,355 - config - INFO - Validation Loss: 0.4524
2024-03-29 10:15:34,355 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:34,385 - config - INFO - Epoch [13/260], Train Loss: 0.4101
2024-03-29 10:15:34,389 - config - INFO - Validation Loss: 0.4469
2024-03-29 10:15:34,389 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:34,419 - config - INFO - Epoch [14/260], Train Loss: 0.4080
2024-03-29 10:15:34,424 - config - INFO - Validation Loss: 0.4452
2024-03-29 10:15:34,424 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:34,454 - config - INFO - Epoch [15/260], Train Loss: 0.4059
2024-03-29 10:15:34,458 - config - INFO - Validation Loss: 0.4477
2024-03-29 10:15:34,458 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:34,491 - config - INFO - Epoch [16/260], Train Loss: 0.4060
2024-03-29 10:15:34,495 - config - INFO - Validation Loss: 0.4453
2024-03-29 10:15:34,496 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:34,525 - config - INFO - Epoch [17/260], Train Loss: 0.4019
2024-03-29 10:15:34,530 - config - INFO - Validation Loss: 0.4371
2024-03-29 10:15:34,530 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:34,560 - config - INFO - Epoch [18/260], Train Loss: 0.3999
2024-03-29 10:15:34,564 - config - INFO - Validation Loss: 0.4373
2024-03-29 10:15:34,564 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:34,594 - config - INFO - Epoch [19/260], Train Loss: 0.3976
2024-03-29 10:15:34,598 - config - INFO - Validation Loss: 0.4358
2024-03-29 10:15:34,599 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:34,628 - config - INFO - Epoch [20/260], Train Loss: 0.3964
2024-03-29 10:15:34,632 - config - INFO - Validation Loss: 0.4337
2024-03-29 10:15:34,633 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:34,662 - config - INFO - Epoch [21/260], Train Loss: 0.3951
2024-03-29 10:15:34,667 - config - INFO - Validation Loss: 0.4382
2024-03-29 10:15:34,667 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:34,697 - config - INFO - Epoch [22/260], Train Loss: 0.3943
2024-03-29 10:15:34,717 - config - INFO - Validation Loss: 0.4347
2024-03-29 10:15:34,717 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:34,748 - config - INFO - Epoch [23/260], Train Loss: 0.3921
2024-03-29 10:15:34,753 - config - INFO - Validation Loss: 0.4312
2024-03-29 10:15:34,753 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:34,782 - config - INFO - Epoch [24/260], Train Loss: 0.3921
2024-03-29 10:15:34,786 - config - INFO - Validation Loss: 0.4305
2024-03-29 10:15:34,786 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:34,816 - config - INFO - Epoch [25/260], Train Loss: 0.3896
2024-03-29 10:15:34,820 - config - INFO - Validation Loss: 0.4349
2024-03-29 10:15:34,820 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:34,850 - config - INFO - Epoch [26/260], Train Loss: 0.3887
2024-03-29 10:15:34,855 - config - INFO - Validation Loss: 0.4330
2024-03-29 10:15:34,855 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:34,885 - config - INFO - Epoch [27/260], Train Loss: 0.3880
2024-03-29 10:15:34,889 - config - INFO - Validation Loss: 0.4309
2024-03-29 10:15:34,889 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:34,918 - config - INFO - Epoch [28/260], Train Loss: 0.3863
2024-03-29 10:15:34,923 - config - INFO - Validation Loss: 0.4306
2024-03-29 10:15:34,923 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:34,952 - config - INFO - Epoch [29/260], Train Loss: 0.3849
2024-03-29 10:15:34,957 - config - INFO - Validation Loss: 0.4308
2024-03-29 10:15:34,957 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:34,986 - config - INFO - Epoch [30/260], Train Loss: 0.3843
2024-03-29 10:15:34,990 - config - INFO - Validation Loss: 0.4305
2024-03-29 10:15:34,990 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:35,020 - config - INFO - Epoch [31/260], Train Loss: 0.3838
2024-03-29 10:15:35,024 - config - INFO - Validation Loss: 0.4287
2024-03-29 10:15:35,024 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:35,054 - config - INFO - Epoch [32/260], Train Loss: 0.3825
2024-03-29 10:15:35,058 - config - INFO - Validation Loss: 0.4293
2024-03-29 10:15:35,058 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:35,087 - config - INFO - Epoch [33/260], Train Loss: 0.3812
2024-03-29 10:15:35,092 - config - INFO - Validation Loss: 0.4301
2024-03-29 10:15:35,092 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:35,122 - config - INFO - Epoch [34/260], Train Loss: 0.3798
2024-03-29 10:15:35,126 - config - INFO - Validation Loss: 0.4316
2024-03-29 10:15:35,126 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:35,156 - config - INFO - Epoch [35/260], Train Loss: 0.3791
2024-03-29 10:15:35,160 - config - INFO - Validation Loss: 0.4309
2024-03-29 10:15:35,160 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:35,190 - config - INFO - Epoch [36/260], Train Loss: 0.3784
2024-03-29 10:15:35,194 - config - INFO - Validation Loss: 0.4276
2024-03-29 10:15:35,194 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:35,226 - config - INFO - Epoch [37/260], Train Loss: 0.3780
2024-03-29 10:15:35,230 - config - INFO - Validation Loss: 0.4279
2024-03-29 10:15:35,230 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:35,261 - config - INFO - Epoch [38/260], Train Loss: 0.3771
2024-03-29 10:15:35,266 - config - INFO - Validation Loss: 0.4304
2024-03-29 10:15:35,266 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:35,301 - config - INFO - Epoch [39/260], Train Loss: 0.3772
2024-03-29 10:15:35,306 - config - INFO - Validation Loss: 0.4311
2024-03-29 10:15:35,306 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:35,338 - config - INFO - Epoch [40/260], Train Loss: 0.3759
2024-03-29 10:15:35,343 - config - INFO - Validation Loss: 0.4316
2024-03-29 10:15:35,343 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:35,374 - config - INFO - Epoch [41/260], Train Loss: 0.3780
2024-03-29 10:15:35,378 - config - INFO - Validation Loss: 0.4270
2024-03-29 10:15:35,378 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:35,408 - config - INFO - Epoch [42/260], Train Loss: 0.3751
2024-03-29 10:15:35,412 - config - INFO - Validation Loss: 0.4291
2024-03-29 10:15:35,412 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:35,442 - config - INFO - Epoch [43/260], Train Loss: 0.3736
2024-03-29 10:15:35,447 - config - INFO - Validation Loss: 0.4290
2024-03-29 10:15:35,447 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:35,479 - config - INFO - Epoch [44/260], Train Loss: 0.3731
2024-03-29 10:15:35,483 - config - INFO - Validation Loss: 0.4290
2024-03-29 10:15:35,483 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:35,513 - config - INFO - Epoch [45/260], Train Loss: 0.3721
2024-03-29 10:15:35,517 - config - INFO - Validation Loss: 0.4301
2024-03-29 10:15:35,517 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:35,546 - config - INFO - Epoch [46/260], Train Loss: 0.3709
2024-03-29 10:15:35,551 - config - INFO - Validation Loss: 0.4275
2024-03-29 10:15:35,551 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:35,580 - config - INFO - Epoch [47/260], Train Loss: 0.3693
2024-03-29 10:15:35,585 - config - INFO - Validation Loss: 0.4290
2024-03-29 10:15:35,585 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:35,614 - config - INFO - Epoch [48/260], Train Loss: 0.3744
2024-03-29 10:15:35,619 - config - INFO - Validation Loss: 0.4349
2024-03-29 10:15:35,619 - config - INFO - Validation Acc: 0.8600
2024-03-29 10:15:35,649 - config - INFO - Epoch [49/260], Train Loss: 0.3697
2024-03-29 10:15:35,654 - config - INFO - Validation Loss: 0.4283
2024-03-29 10:15:35,654 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:35,685 - config - INFO - Epoch [50/260], Train Loss: 0.3685
2024-03-29 10:15:35,689 - config - INFO - Validation Loss: 0.4305
2024-03-29 10:15:35,689 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:35,727 - config - INFO - Epoch [51/260], Train Loss: 0.3672
2024-03-29 10:15:35,732 - config - INFO - Validation Loss: 0.4286
2024-03-29 10:15:35,732 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:35,762 - config - INFO - Epoch [52/260], Train Loss: 0.3671
2024-03-29 10:15:35,766 - config - INFO - Validation Loss: 0.4295
2024-03-29 10:15:35,766 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:35,796 - config - INFO - Epoch [53/260], Train Loss: 0.3680
2024-03-29 10:15:35,800 - config - INFO - Validation Loss: 0.4308
2024-03-29 10:15:35,801 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:35,830 - config - INFO - Epoch [54/260], Train Loss: 0.3681
2024-03-29 10:15:35,834 - config - INFO - Validation Loss: 0.4308
2024-03-29 10:15:35,834 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:35,865 - config - INFO - Epoch [55/260], Train Loss: 0.3660
2024-03-29 10:15:35,869 - config - INFO - Validation Loss: 0.4350
2024-03-29 10:15:35,870 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:35,899 - config - INFO - Epoch [56/260], Train Loss: 0.3644
2024-03-29 10:15:35,904 - config - INFO - Validation Loss: 0.4334
2024-03-29 10:15:35,904 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:35,934 - config - INFO - Epoch [57/260], Train Loss: 0.3652
2024-03-29 10:15:35,938 - config - INFO - Validation Loss: 0.4363
2024-03-29 10:15:35,938 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:35,967 - config - INFO - Epoch [58/260], Train Loss: 0.3651
2024-03-29 10:15:35,972 - config - INFO - Validation Loss: 0.4348
2024-03-29 10:15:35,972 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:36,001 - config - INFO - Epoch [59/260], Train Loss: 0.3637
2024-03-29 10:15:36,005 - config - INFO - Validation Loss: 0.4314
2024-03-29 10:15:36,005 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:36,034 - config - INFO - Epoch [60/260], Train Loss: 0.3617
2024-03-29 10:15:36,039 - config - INFO - Validation Loss: 0.4307
2024-03-29 10:15:36,039 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:36,070 - config - INFO - Epoch [61/260], Train Loss: 0.3630
2024-03-29 10:15:36,074 - config - INFO - Validation Loss: 0.4314
2024-03-29 10:15:36,075 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:36,104 - config - INFO - Epoch [62/260], Train Loss: 0.3608
2024-03-29 10:15:36,108 - config - INFO - Validation Loss: 0.4276
2024-03-29 10:15:36,108 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:36,137 - config - INFO - Epoch [63/260], Train Loss: 0.3619
2024-03-29 10:15:36,141 - config - INFO - Validation Loss: 0.4278
2024-03-29 10:15:36,142 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:36,171 - config - INFO - Epoch [64/260], Train Loss: 0.3593
2024-03-29 10:15:36,175 - config - INFO - Validation Loss: 0.4335
2024-03-29 10:15:36,175 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:36,205 - config - INFO - Epoch [65/260], Train Loss: 0.3609
2024-03-29 10:15:36,223 - config - INFO - Validation Loss: 0.4341
2024-03-29 10:15:36,224 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:36,251 - config - INFO - Epoch [66/260], Train Loss: 0.3597
2024-03-29 10:15:36,254 - config - INFO - Validation Loss: 0.4289
2024-03-29 10:15:36,254 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:36,279 - config - INFO - Epoch [67/260], Train Loss: 0.3603
2024-03-29 10:15:36,282 - config - INFO - Validation Loss: 0.4339
2024-03-29 10:15:36,282 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:36,308 - config - INFO - Epoch [68/260], Train Loss: 0.3571
2024-03-29 10:15:36,311 - config - INFO - Validation Loss: 0.4340
2024-03-29 10:15:36,312 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:36,338 - config - INFO - Epoch [69/260], Train Loss: 0.3577
2024-03-29 10:15:36,342 - config - INFO - Validation Loss: 0.4340
2024-03-29 10:15:36,342 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:36,368 - config - INFO - Epoch [70/260], Train Loss: 0.3556
2024-03-29 10:15:36,372 - config - INFO - Validation Loss: 0.4338
2024-03-29 10:15:36,372 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:36,398 - config - INFO - Epoch [71/260], Train Loss: 0.3548
2024-03-29 10:15:36,402 - config - INFO - Validation Loss: 0.4343
2024-03-29 10:15:36,402 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:36,427 - config - INFO - Epoch [72/260], Train Loss: 0.3574
2024-03-29 10:15:36,431 - config - INFO - Validation Loss: 0.4371
2024-03-29 10:15:36,431 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:36,455 - config - INFO - Epoch [73/260], Train Loss: 0.3546
2024-03-29 10:15:36,459 - config - INFO - Validation Loss: 0.4310
2024-03-29 10:15:36,459 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:36,484 - config - INFO - Epoch [74/260], Train Loss: 0.3548
2024-03-29 10:15:36,487 - config - INFO - Validation Loss: 0.4298
2024-03-29 10:15:36,488 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:36,512 - config - INFO - Epoch [75/260], Train Loss: 0.3544
2024-03-29 10:15:36,516 - config - INFO - Validation Loss: 0.4381
2024-03-29 10:15:36,516 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:36,540 - config - INFO - Epoch [76/260], Train Loss: 0.3532
2024-03-29 10:15:36,544 - config - INFO - Validation Loss: 0.4314
2024-03-29 10:15:36,544 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:36,568 - config - INFO - Epoch [77/260], Train Loss: 0.3523
2024-03-29 10:15:36,572 - config - INFO - Validation Loss: 0.4357
2024-03-29 10:15:36,572 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:36,597 - config - INFO - Epoch [78/260], Train Loss: 0.3520
2024-03-29 10:15:36,600 - config - INFO - Validation Loss: 0.4309
2024-03-29 10:15:36,600 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:36,625 - config - INFO - Epoch [79/260], Train Loss: 0.3525
2024-03-29 10:15:36,629 - config - INFO - Validation Loss: 0.4321
2024-03-29 10:15:36,629 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:36,653 - config - INFO - Epoch [80/260], Train Loss: 0.3513
2024-03-29 10:15:36,657 - config - INFO - Validation Loss: 0.4281
2024-03-29 10:15:36,657 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:36,682 - config - INFO - Epoch [81/260], Train Loss: 0.3482
2024-03-29 10:15:36,685 - config - INFO - Validation Loss: 0.4319
2024-03-29 10:15:36,685 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:36,710 - config - INFO - Epoch [82/260], Train Loss: 0.3502
2024-03-29 10:15:36,713 - config - INFO - Validation Loss: 0.4321
2024-03-29 10:15:36,714 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:36,738 - config - INFO - Epoch [83/260], Train Loss: 0.3488
2024-03-29 10:15:36,742 - config - INFO - Validation Loss: 0.4350
2024-03-29 10:15:36,742 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:36,767 - config - INFO - Epoch [84/260], Train Loss: 0.3496
2024-03-29 10:15:36,770 - config - INFO - Validation Loss: 0.4341
2024-03-29 10:15:36,770 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:36,795 - config - INFO - Epoch [85/260], Train Loss: 0.3491
2024-03-29 10:15:36,798 - config - INFO - Validation Loss: 0.4323
2024-03-29 10:15:36,799 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:36,823 - config - INFO - Epoch [86/260], Train Loss: 0.3480
2024-03-29 10:15:36,827 - config - INFO - Validation Loss: 0.4331
2024-03-29 10:15:36,827 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:36,851 - config - INFO - Epoch [87/260], Train Loss: 0.3483
2024-03-29 10:15:36,855 - config - INFO - Validation Loss: 0.4383
2024-03-29 10:15:36,855 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:36,880 - config - INFO - Epoch [88/260], Train Loss: 0.3477
2024-03-29 10:15:36,883 - config - INFO - Validation Loss: 0.4405
2024-03-29 10:15:36,883 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:36,908 - config - INFO - Epoch [89/260], Train Loss: 0.3465
2024-03-29 10:15:36,912 - config - INFO - Validation Loss: 0.4375
2024-03-29 10:15:36,912 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:36,936 - config - INFO - Epoch [90/260], Train Loss: 0.3438
2024-03-29 10:15:36,940 - config - INFO - Validation Loss: 0.4335
2024-03-29 10:15:36,940 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:36,964 - config - INFO - Epoch [91/260], Train Loss: 0.3445
2024-03-29 10:15:36,968 - config - INFO - Validation Loss: 0.4350
2024-03-29 10:15:36,968 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:36,993 - config - INFO - Epoch [92/260], Train Loss: 0.3464
2024-03-29 10:15:36,996 - config - INFO - Validation Loss: 0.4340
2024-03-29 10:15:36,996 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:37,021 - config - INFO - Epoch [93/260], Train Loss: 0.3485
2024-03-29 10:15:37,025 - config - INFO - Validation Loss: 0.4396
2024-03-29 10:15:37,025 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,049 - config - INFO - Epoch [94/260], Train Loss: 0.3436
2024-03-29 10:15:37,053 - config - INFO - Validation Loss: 0.4308
2024-03-29 10:15:37,053 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,078 - config - INFO - Epoch [95/260], Train Loss: 0.3423
2024-03-29 10:15:37,081 - config - INFO - Validation Loss: 0.4305
2024-03-29 10:15:37,081 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,106 - config - INFO - Epoch [96/260], Train Loss: 0.3432
2024-03-29 10:15:37,109 - config - INFO - Validation Loss: 0.4309
2024-03-29 10:15:37,110 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,134 - config - INFO - Epoch [97/260], Train Loss: 0.3441
2024-03-29 10:15:37,138 - config - INFO - Validation Loss: 0.4300
2024-03-29 10:15:37,138 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,162 - config - INFO - Epoch [98/260], Train Loss: 0.3429
2024-03-29 10:15:37,166 - config - INFO - Validation Loss: 0.4343
2024-03-29 10:15:37,166 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:37,190 - config - INFO - Epoch [99/260], Train Loss: 0.3434
2024-03-29 10:15:37,194 - config - INFO - Validation Loss: 0.4376
2024-03-29 10:15:37,194 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,219 - config - INFO - Epoch [100/260], Train Loss: 0.3403
2024-03-29 10:15:37,222 - config - INFO - Validation Loss: 0.4322
2024-03-29 10:15:37,223 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,247 - config - INFO - Epoch [101/260], Train Loss: 0.3414
2024-03-29 10:15:37,251 - config - INFO - Validation Loss: 0.4328
2024-03-29 10:15:37,251 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:37,275 - config - INFO - Epoch [102/260], Train Loss: 0.3389
2024-03-29 10:15:37,279 - config - INFO - Validation Loss: 0.4313
2024-03-29 10:15:37,279 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,305 - config - INFO - Epoch [103/260], Train Loss: 0.3411
2024-03-29 10:15:37,308 - config - INFO - Validation Loss: 0.4308
2024-03-29 10:15:37,308 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,333 - config - INFO - Epoch [104/260], Train Loss: 0.3385
2024-03-29 10:15:37,336 - config - INFO - Validation Loss: 0.4336
2024-03-29 10:15:37,336 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,361 - config - INFO - Epoch [105/260], Train Loss: 0.3402
2024-03-29 10:15:37,364 - config - INFO - Validation Loss: 0.4406
2024-03-29 10:15:37,365 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,389 - config - INFO - Epoch [106/260], Train Loss: 0.3374
2024-03-29 10:15:37,393 - config - INFO - Validation Loss: 0.4362
2024-03-29 10:15:37,393 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,417 - config - INFO - Epoch [107/260], Train Loss: 0.3371
2024-03-29 10:15:37,421 - config - INFO - Validation Loss: 0.4372
2024-03-29 10:15:37,421 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,445 - config - INFO - Epoch [108/260], Train Loss: 0.3374
2024-03-29 10:15:37,449 - config - INFO - Validation Loss: 0.4415
2024-03-29 10:15:37,449 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:37,474 - config - INFO - Epoch [109/260], Train Loss: 0.3391
2024-03-29 10:15:37,477 - config - INFO - Validation Loss: 0.4393
2024-03-29 10:15:37,477 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,502 - config - INFO - Epoch [110/260], Train Loss: 0.3361
2024-03-29 10:15:37,506 - config - INFO - Validation Loss: 0.4382
2024-03-29 10:15:37,506 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,530 - config - INFO - Epoch [111/260], Train Loss: 0.3352
2024-03-29 10:15:37,534 - config - INFO - Validation Loss: 0.4383
2024-03-29 10:15:37,534 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,559 - config - INFO - Epoch [112/260], Train Loss: 0.3353
2024-03-29 10:15:37,562 - config - INFO - Validation Loss: 0.4361
2024-03-29 10:15:37,562 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,587 - config - INFO - Epoch [113/260], Train Loss: 0.3375
2024-03-29 10:15:37,590 - config - INFO - Validation Loss: 0.4487
2024-03-29 10:15:37,590 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,615 - config - INFO - Epoch [114/260], Train Loss: 0.3380
2024-03-29 10:15:37,618 - config - INFO - Validation Loss: 0.4400
2024-03-29 10:15:37,618 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,643 - config - INFO - Epoch [115/260], Train Loss: 0.3360
2024-03-29 10:15:37,646 - config - INFO - Validation Loss: 0.4423
2024-03-29 10:15:37,647 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:37,671 - config - INFO - Epoch [116/260], Train Loss: 0.3324
2024-03-29 10:15:37,675 - config - INFO - Validation Loss: 0.4381
2024-03-29 10:15:37,675 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,699 - config - INFO - Epoch [117/260], Train Loss: 0.3336
2024-03-29 10:15:37,703 - config - INFO - Validation Loss: 0.4357
2024-03-29 10:15:37,703 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,728 - config - INFO - Epoch [118/260], Train Loss: 0.3376
2024-03-29 10:15:37,732 - config - INFO - Validation Loss: 0.4459
2024-03-29 10:15:37,732 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:37,756 - config - INFO - Epoch [119/260], Train Loss: 0.3330
2024-03-29 10:15:37,760 - config - INFO - Validation Loss: 0.4375
2024-03-29 10:15:37,760 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,785 - config - INFO - Epoch [120/260], Train Loss: 0.3326
2024-03-29 10:15:37,788 - config - INFO - Validation Loss: 0.4399
2024-03-29 10:15:37,788 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,813 - config - INFO - Epoch [121/260], Train Loss: 0.3308
2024-03-29 10:15:37,816 - config - INFO - Validation Loss: 0.4409
2024-03-29 10:15:37,817 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,841 - config - INFO - Epoch [122/260], Train Loss: 0.3312
2024-03-29 10:15:37,845 - config - INFO - Validation Loss: 0.4434
2024-03-29 10:15:37,845 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,869 - config - INFO - Epoch [123/260], Train Loss: 0.3322
2024-03-29 10:15:37,873 - config - INFO - Validation Loss: 0.4341
2024-03-29 10:15:37,873 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,898 - config - INFO - Epoch [124/260], Train Loss: 0.3334
2024-03-29 10:15:37,901 - config - INFO - Validation Loss: 0.4365
2024-03-29 10:15:37,901 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,926 - config - INFO - Epoch [125/260], Train Loss: 0.3308
2024-03-29 10:15:37,929 - config - INFO - Validation Loss: 0.4390
2024-03-29 10:15:37,929 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:37,954 - config - INFO - Epoch [126/260], Train Loss: 0.3303
2024-03-29 10:15:37,957 - config - INFO - Validation Loss: 0.4403
2024-03-29 10:15:37,958 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:37,982 - config - INFO - Epoch [127/260], Train Loss: 0.3286
2024-03-29 10:15:37,986 - config - INFO - Validation Loss: 0.4408
2024-03-29 10:15:37,986 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,010 - config - INFO - Epoch [128/260], Train Loss: 0.3283
2024-03-29 10:15:38,014 - config - INFO - Validation Loss: 0.4406
2024-03-29 10:15:38,014 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,038 - config - INFO - Epoch [129/260], Train Loss: 0.3277
2024-03-29 10:15:38,042 - config - INFO - Validation Loss: 0.4420
2024-03-29 10:15:38,042 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,066 - config - INFO - Epoch [130/260], Train Loss: 0.3274
2024-03-29 10:15:38,070 - config - INFO - Validation Loss: 0.4398
2024-03-29 10:15:38,070 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,095 - config - INFO - Epoch [131/260], Train Loss: 0.3269
2024-03-29 10:15:38,098 - config - INFO - Validation Loss: 0.4388
2024-03-29 10:15:38,098 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,123 - config - INFO - Epoch [132/260], Train Loss: 0.3269
2024-03-29 10:15:38,127 - config - INFO - Validation Loss: 0.4415
2024-03-29 10:15:38,127 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,151 - config - INFO - Epoch [133/260], Train Loss: 0.3267
2024-03-29 10:15:38,155 - config - INFO - Validation Loss: 0.4417
2024-03-29 10:15:38,155 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,180 - config - INFO - Epoch [134/260], Train Loss: 0.3256
2024-03-29 10:15:38,183 - config - INFO - Validation Loss: 0.4389
2024-03-29 10:15:38,184 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,208 - config - INFO - Epoch [135/260], Train Loss: 0.3296
2024-03-29 10:15:38,212 - config - INFO - Validation Loss: 0.4402
2024-03-29 10:15:38,212 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,237 - config - INFO - Epoch [136/260], Train Loss: 0.3273
2024-03-29 10:15:38,240 - config - INFO - Validation Loss: 0.4466
2024-03-29 10:15:38,240 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,265 - config - INFO - Epoch [137/260], Train Loss: 0.3258
2024-03-29 10:15:38,269 - config - INFO - Validation Loss: 0.4448
2024-03-29 10:15:38,269 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:15:38,294 - config - INFO - Epoch [138/260], Train Loss: 0.3238
2024-03-29 10:15:38,297 - config - INFO - Validation Loss: 0.4463
2024-03-29 10:15:38,297 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:38,332 - config - INFO - Epoch [139/260], Train Loss: 0.3245
2024-03-29 10:15:38,337 - config - INFO - Validation Loss: 0.4448
2024-03-29 10:15:38,337 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,362 - config - INFO - Epoch [140/260], Train Loss: 0.3238
2024-03-29 10:15:38,365 - config - INFO - Validation Loss: 0.4438
2024-03-29 10:15:38,365 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,390 - config - INFO - Epoch [141/260], Train Loss: 0.3249
2024-03-29 10:15:38,394 - config - INFO - Validation Loss: 0.4445
2024-03-29 10:15:38,394 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,418 - config - INFO - Epoch [142/260], Train Loss: 0.3272
2024-03-29 10:15:38,422 - config - INFO - Validation Loss: 0.4582
2024-03-29 10:15:38,422 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:15:38,447 - config - INFO - Epoch [143/260], Train Loss: 0.3320
2024-03-29 10:15:38,450 - config - INFO - Validation Loss: 0.4503
2024-03-29 10:15:38,451 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,475 - config - INFO - Epoch [144/260], Train Loss: 0.3284
2024-03-29 10:15:38,479 - config - INFO - Validation Loss: 0.4383
2024-03-29 10:15:38,479 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:38,504 - config - INFO - Epoch [145/260], Train Loss: 0.3272
2024-03-29 10:15:38,508 - config - INFO - Validation Loss: 0.4491
2024-03-29 10:15:38,508 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:38,533 - config - INFO - Epoch [146/260], Train Loss: 0.3248
2024-03-29 10:15:38,536 - config - INFO - Validation Loss: 0.4463
2024-03-29 10:15:38,536 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,561 - config - INFO - Epoch [147/260], Train Loss: 0.3232
2024-03-29 10:15:38,565 - config - INFO - Validation Loss: 0.4444
2024-03-29 10:15:38,565 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,589 - config - INFO - Epoch [148/260], Train Loss: 0.3233
2024-03-29 10:15:38,593 - config - INFO - Validation Loss: 0.4439
2024-03-29 10:15:38,593 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,618 - config - INFO - Epoch [149/260], Train Loss: 0.3209
2024-03-29 10:15:38,621 - config - INFO - Validation Loss: 0.4495
2024-03-29 10:15:38,621 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,647 - config - INFO - Epoch [150/260], Train Loss: 0.3211
2024-03-29 10:15:38,650 - config - INFO - Validation Loss: 0.4460
2024-03-29 10:15:38,650 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,675 - config - INFO - Epoch [151/260], Train Loss: 0.3253
2024-03-29 10:15:38,678 - config - INFO - Validation Loss: 0.4410
2024-03-29 10:15:38,679 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,711 - config - INFO - Epoch [152/260], Train Loss: 0.3237
2024-03-29 10:15:38,715 - config - INFO - Validation Loss: 0.4494
2024-03-29 10:15:38,716 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:38,740 - config - INFO - Epoch [153/260], Train Loss: 0.3210
2024-03-29 10:15:38,744 - config - INFO - Validation Loss: 0.4459
2024-03-29 10:15:38,744 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:38,768 - config - INFO - Epoch [154/260], Train Loss: 0.3206
2024-03-29 10:15:38,772 - config - INFO - Validation Loss: 0.4454
2024-03-29 10:15:38,772 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,797 - config - INFO - Epoch [155/260], Train Loss: 0.3208
2024-03-29 10:15:38,800 - config - INFO - Validation Loss: 0.4454
2024-03-29 10:15:38,800 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,825 - config - INFO - Epoch [156/260], Train Loss: 0.3202
2024-03-29 10:15:38,828 - config - INFO - Validation Loss: 0.4463
2024-03-29 10:15:38,829 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,853 - config - INFO - Epoch [157/260], Train Loss: 0.3196
2024-03-29 10:15:38,857 - config - INFO - Validation Loss: 0.4451
2024-03-29 10:15:38,857 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,882 - config - INFO - Epoch [158/260], Train Loss: 0.3178
2024-03-29 10:15:38,889 - config - INFO - Validation Loss: 0.4454
2024-03-29 10:15:38,889 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:38,916 - config - INFO - Epoch [159/260], Train Loss: 0.3189
2024-03-29 10:15:38,920 - config - INFO - Validation Loss: 0.4468
2024-03-29 10:15:38,921 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,949 - config - INFO - Epoch [160/260], Train Loss: 0.3185
2024-03-29 10:15:38,955 - config - INFO - Validation Loss: 0.4501
2024-03-29 10:15:38,955 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:38,989 - config - INFO - Epoch [161/260], Train Loss: 0.3208
2024-03-29 10:15:38,993 - config - INFO - Validation Loss: 0.4460
2024-03-29 10:15:38,999 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:39,032 - config - INFO - Epoch [162/260], Train Loss: 0.3212
2024-03-29 10:15:39,036 - config - INFO - Validation Loss: 0.4483
2024-03-29 10:15:39,036 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:39,064 - config - INFO - Epoch [163/260], Train Loss: 0.3196
2024-03-29 10:15:39,069 - config - INFO - Validation Loss: 0.4457
2024-03-29 10:15:39,069 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:39,097 - config - INFO - Epoch [164/260], Train Loss: 0.3187
2024-03-29 10:15:39,101 - config - INFO - Validation Loss: 0.4578
2024-03-29 10:15:39,101 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:39,134 - config - INFO - Epoch [165/260], Train Loss: 0.3202
2024-03-29 10:15:39,138 - config - INFO - Validation Loss: 0.4456
2024-03-29 10:15:39,138 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:39,167 - config - INFO - Epoch [166/260], Train Loss: 0.3174
2024-03-29 10:15:39,171 - config - INFO - Validation Loss: 0.4539
2024-03-29 10:15:39,171 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:39,199 - config - INFO - Epoch [167/260], Train Loss: 0.3165
2024-03-29 10:15:39,203 - config - INFO - Validation Loss: 0.4476
2024-03-29 10:15:39,204 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:39,232 - config - INFO - Epoch [168/260], Train Loss: 0.3173
2024-03-29 10:15:39,236 - config - INFO - Validation Loss: 0.4504
2024-03-29 10:15:39,236 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:39,271 - config - INFO - Epoch [169/260], Train Loss: 0.3152
2024-03-29 10:15:39,276 - config - INFO - Validation Loss: 0.4586
2024-03-29 10:15:39,276 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:39,304 - config - INFO - Epoch [170/260], Train Loss: 0.3161
2024-03-29 10:15:39,308 - config - INFO - Validation Loss: 0.4527
2024-03-29 10:15:39,309 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:39,337 - config - INFO - Epoch [171/260], Train Loss: 0.3158
2024-03-29 10:15:39,341 - config - INFO - Validation Loss: 0.4577
2024-03-29 10:15:39,341 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:39,370 - config - INFO - Epoch [172/260], Train Loss: 0.3157
2024-03-29 10:15:39,374 - config - INFO - Validation Loss: 0.4601
2024-03-29 10:15:39,374 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:39,402 - config - INFO - Epoch [173/260], Train Loss: 0.3163
2024-03-29 10:15:39,406 - config - INFO - Validation Loss: 0.4589
2024-03-29 10:15:39,406 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:39,435 - config - INFO - Epoch [174/260], Train Loss: 0.3148
2024-03-29 10:15:39,439 - config - INFO - Validation Loss: 0.4542
2024-03-29 10:15:39,439 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:39,467 - config - INFO - Epoch [175/260], Train Loss: 0.3161
2024-03-29 10:15:39,472 - config - INFO - Validation Loss: 0.4537
2024-03-29 10:15:39,472 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:15:39,500 - config - INFO - Epoch [176/260], Train Loss: 0.3158
2024-03-29 10:15:39,504 - config - INFO - Validation Loss: 0.4636
2024-03-29 10:15:39,504 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:39,533 - config - INFO - Epoch [177/260], Train Loss: 0.3126
2024-03-29 10:15:39,537 - config - INFO - Validation Loss: 0.4495
2024-03-29 10:15:39,537 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:39,565 - config - INFO - Epoch [178/260], Train Loss: 0.3142
2024-03-29 10:15:39,569 - config - INFO - Validation Loss: 0.4573
2024-03-29 10:15:39,569 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:39,598 - config - INFO - Epoch [179/260], Train Loss: 0.3129
2024-03-29 10:15:39,602 - config - INFO - Validation Loss: 0.4468
2024-03-29 10:15:39,602 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:39,631 - config - INFO - Epoch [180/260], Train Loss: 0.3161
2024-03-29 10:15:39,635 - config - INFO - Validation Loss: 0.4514
2024-03-29 10:15:39,635 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:39,663 - config - INFO - Epoch [181/260], Train Loss: 0.3150
2024-03-29 10:15:39,668 - config - INFO - Validation Loss: 0.4559
2024-03-29 10:15:39,668 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:39,696 - config - INFO - Epoch [182/260], Train Loss: 0.3120
2024-03-29 10:15:39,700 - config - INFO - Validation Loss: 0.4544
2024-03-29 10:15:39,700 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:39,730 - config - INFO - Epoch [183/260], Train Loss: 0.3109
2024-03-29 10:15:39,734 - config - INFO - Validation Loss: 0.4565
2024-03-29 10:15:39,734 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:39,763 - config - INFO - Epoch [184/260], Train Loss: 0.3147
2024-03-29 10:15:39,767 - config - INFO - Validation Loss: 0.4582
2024-03-29 10:15:39,767 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:39,795 - config - INFO - Epoch [185/260], Train Loss: 0.3131
2024-03-29 10:15:39,799 - config - INFO - Validation Loss: 0.4614
2024-03-29 10:15:39,800 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:39,828 - config - INFO - Epoch [186/260], Train Loss: 0.3124
2024-03-29 10:15:39,832 - config - INFO - Validation Loss: 0.4566
2024-03-29 10:15:39,832 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:39,865 - config - INFO - Epoch [187/260], Train Loss: 0.3128
2024-03-29 10:15:39,869 - config - INFO - Validation Loss: 0.4602
2024-03-29 10:15:39,869 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:39,898 - config - INFO - Epoch [188/260], Train Loss: 0.3113
2024-03-29 10:15:39,902 - config - INFO - Validation Loss: 0.4573
2024-03-29 10:15:39,902 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:39,930 - config - INFO - Epoch [189/260], Train Loss: 0.3107
2024-03-29 10:15:39,934 - config - INFO - Validation Loss: 0.4592
2024-03-29 10:15:39,935 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:39,963 - config - INFO - Epoch [190/260], Train Loss: 0.3099
2024-03-29 10:15:39,967 - config - INFO - Validation Loss: 0.4633
2024-03-29 10:15:39,967 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:39,996 - config - INFO - Epoch [191/260], Train Loss: 0.3093
2024-03-29 10:15:40,000 - config - INFO - Validation Loss: 0.4623
2024-03-29 10:15:40,000 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:40,028 - config - INFO - Epoch [192/260], Train Loss: 0.3108
2024-03-29 10:15:40,032 - config - INFO - Validation Loss: 0.4611
2024-03-29 10:15:40,032 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:40,061 - config - INFO - Epoch [193/260], Train Loss: 0.3088
2024-03-29 10:15:40,065 - config - INFO - Validation Loss: 0.4617
2024-03-29 10:15:40,065 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:40,093 - config - INFO - Epoch [194/260], Train Loss: 0.3117
2024-03-29 10:15:40,098 - config - INFO - Validation Loss: 0.4587
2024-03-29 10:15:40,098 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:40,126 - config - INFO - Epoch [195/260], Train Loss: 0.3102
2024-03-29 10:15:40,130 - config - INFO - Validation Loss: 0.4616
2024-03-29 10:15:40,130 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:40,159 - config - INFO - Epoch [196/260], Train Loss: 0.3102
2024-03-29 10:15:40,163 - config - INFO - Validation Loss: 0.4631
2024-03-29 10:15:40,163 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:40,191 - config - INFO - Epoch [197/260], Train Loss: 0.3109
2024-03-29 10:15:40,195 - config - INFO - Validation Loss: 0.4713
2024-03-29 10:15:40,195 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:40,224 - config - INFO - Epoch [198/260], Train Loss: 0.3118
2024-03-29 10:15:40,228 - config - INFO - Validation Loss: 0.4673
2024-03-29 10:15:40,228 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:40,256 - config - INFO - Epoch [199/260], Train Loss: 0.3095
2024-03-29 10:15:40,261 - config - INFO - Validation Loss: 0.4669
2024-03-29 10:15:40,261 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:40,289 - config - INFO - Epoch [200/260], Train Loss: 0.3069
2024-03-29 10:15:40,293 - config - INFO - Validation Loss: 0.4614
2024-03-29 10:15:40,294 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:40,326 - config - INFO - Epoch [201/260], Train Loss: 0.3088
2024-03-29 10:15:40,330 - config - INFO - Validation Loss: 0.4600
2024-03-29 10:15:40,330 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:40,358 - config - INFO - Epoch [202/260], Train Loss: 0.3099
2024-03-29 10:15:40,362 - config - INFO - Validation Loss: 0.4742
2024-03-29 10:15:40,362 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:40,391 - config - INFO - Epoch [203/260], Train Loss: 0.3083
2024-03-29 10:15:40,395 - config - INFO - Validation Loss: 0.4715
2024-03-29 10:15:40,395 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:40,423 - config - INFO - Epoch [204/260], Train Loss: 0.3064
2024-03-29 10:15:40,427 - config - INFO - Validation Loss: 0.4699
2024-03-29 10:15:40,427 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:40,456 - config - INFO - Epoch [205/260], Train Loss: 0.3089
2024-03-29 10:15:40,460 - config - INFO - Validation Loss: 0.4685
2024-03-29 10:15:40,460 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:40,488 - config - INFO - Epoch [206/260], Train Loss: 0.3074
2024-03-29 10:15:40,492 - config - INFO - Validation Loss: 0.4761
2024-03-29 10:15:40,493 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:40,521 - config - INFO - Epoch [207/260], Train Loss: 0.3071
2024-03-29 10:15:40,525 - config - INFO - Validation Loss: 0.4720
2024-03-29 10:15:40,525 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:40,554 - config - INFO - Epoch [208/260], Train Loss: 0.3057
2024-03-29 10:15:40,558 - config - INFO - Validation Loss: 0.4662
2024-03-29 10:15:40,558 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:40,586 - config - INFO - Epoch [209/260], Train Loss: 0.3047
2024-03-29 10:15:40,590 - config - INFO - Validation Loss: 0.4686
2024-03-29 10:15:40,591 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:40,619 - config - INFO - Epoch [210/260], Train Loss: 0.3053
2024-03-29 10:15:40,623 - config - INFO - Validation Loss: 0.4678
2024-03-29 10:15:40,623 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:40,651 - config - INFO - Epoch [211/260], Train Loss: 0.3052
2024-03-29 10:15:40,656 - config - INFO - Validation Loss: 0.4744
2024-03-29 10:15:40,656 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:40,684 - config - INFO - Epoch [212/260], Train Loss: 0.3070
2024-03-29 10:15:40,688 - config - INFO - Validation Loss: 0.4769
2024-03-29 10:15:40,688 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:40,717 - config - INFO - Epoch [213/260], Train Loss: 0.3048
2024-03-29 10:15:40,721 - config - INFO - Validation Loss: 0.4650
2024-03-29 10:15:40,721 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:40,749 - config - INFO - Epoch [214/260], Train Loss: 0.3026
2024-03-29 10:15:40,753 - config - INFO - Validation Loss: 0.4719
2024-03-29 10:15:40,753 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:40,782 - config - INFO - Epoch [215/260], Train Loss: 0.3048
2024-03-29 10:15:40,786 - config - INFO - Validation Loss: 0.4723
2024-03-29 10:15:40,786 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:40,814 - config - INFO - Epoch [216/260], Train Loss: 0.3044
2024-03-29 10:15:40,818 - config - INFO - Validation Loss: 0.4697
2024-03-29 10:15:40,818 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:40,847 - config - INFO - Epoch [217/260], Train Loss: 0.3031
2024-03-29 10:15:40,851 - config - INFO - Validation Loss: 0.4707
2024-03-29 10:15:40,851 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:40,879 - config - INFO - Epoch [218/260], Train Loss: 0.3017
2024-03-29 10:15:40,883 - config - INFO - Validation Loss: 0.4660
2024-03-29 10:15:40,884 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:40,912 - config - INFO - Epoch [219/260], Train Loss: 0.3024
2024-03-29 10:15:40,916 - config - INFO - Validation Loss: 0.4712
2024-03-29 10:15:40,916 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:40,944 - config - INFO - Epoch [220/260], Train Loss: 0.3049
2024-03-29 10:15:40,948 - config - INFO - Validation Loss: 0.4711
2024-03-29 10:15:40,949 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:40,977 - config - INFO - Epoch [221/260], Train Loss: 0.3048
2024-03-29 10:15:40,981 - config - INFO - Validation Loss: 0.4734
2024-03-29 10:15:40,981 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:41,009 - config - INFO - Epoch [222/260], Train Loss: 0.3082
2024-03-29 10:15:41,014 - config - INFO - Validation Loss: 0.4711
2024-03-29 10:15:41,014 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:41,042 - config - INFO - Epoch [223/260], Train Loss: 0.3029
2024-03-29 10:15:41,046 - config - INFO - Validation Loss: 0.4709
2024-03-29 10:15:41,046 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:41,075 - config - INFO - Epoch [224/260], Train Loss: 0.3045
2024-03-29 10:15:41,079 - config - INFO - Validation Loss: 0.4824
2024-03-29 10:15:41,079 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:15:41,107 - config - INFO - Epoch [225/260], Train Loss: 0.3034
2024-03-29 10:15:41,111 - config - INFO - Validation Loss: 0.4762
2024-03-29 10:15:41,111 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:41,140 - config - INFO - Epoch [226/260], Train Loss: 0.3035
2024-03-29 10:15:41,144 - config - INFO - Validation Loss: 0.4740
2024-03-29 10:15:41,144 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:41,172 - config - INFO - Epoch [227/260], Train Loss: 0.3029
2024-03-29 10:15:41,176 - config - INFO - Validation Loss: 0.4729
2024-03-29 10:15:41,176 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:41,205 - config - INFO - Epoch [228/260], Train Loss: 0.3026
2024-03-29 10:15:41,209 - config - INFO - Validation Loss: 0.4775
2024-03-29 10:15:41,209 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:41,237 - config - INFO - Epoch [229/260], Train Loss: 0.3055
2024-03-29 10:15:41,241 - config - INFO - Validation Loss: 0.4747
2024-03-29 10:15:41,241 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:41,270 - config - INFO - Epoch [230/260], Train Loss: 0.3022
2024-03-29 10:15:41,274 - config - INFO - Validation Loss: 0.4740
2024-03-29 10:15:41,274 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:41,302 - config - INFO - Epoch [231/260], Train Loss: 0.3007
2024-03-29 10:15:41,306 - config - INFO - Validation Loss: 0.4736
2024-03-29 10:15:41,306 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:41,343 - config - INFO - Epoch [232/260], Train Loss: 0.3003
2024-03-29 10:15:41,348 - config - INFO - Validation Loss: 0.4716
2024-03-29 10:15:41,348 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:41,377 - config - INFO - Epoch [233/260], Train Loss: 0.3018
2024-03-29 10:15:41,381 - config - INFO - Validation Loss: 0.4686
2024-03-29 10:15:41,381 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:41,410 - config - INFO - Epoch [234/260], Train Loss: 0.3011
2024-03-29 10:15:41,414 - config - INFO - Validation Loss: 0.4734
2024-03-29 10:15:41,415 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:41,443 - config - INFO - Epoch [235/260], Train Loss: 0.3025
2024-03-29 10:15:41,447 - config - INFO - Validation Loss: 0.4821
2024-03-29 10:15:41,448 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:41,476 - config - INFO - Epoch [236/260], Train Loss: 0.3015
2024-03-29 10:15:41,480 - config - INFO - Validation Loss: 0.4752
2024-03-29 10:15:41,481 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:41,510 - config - INFO - Epoch [237/260], Train Loss: 0.2983
2024-03-29 10:15:41,514 - config - INFO - Validation Loss: 0.4819
2024-03-29 10:15:41,514 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:41,543 - config - INFO - Epoch [238/260], Train Loss: 0.2973
2024-03-29 10:15:41,547 - config - INFO - Validation Loss: 0.4767
2024-03-29 10:15:41,547 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:41,576 - config - INFO - Epoch [239/260], Train Loss: 0.2974
2024-03-29 10:15:41,580 - config - INFO - Validation Loss: 0.4781
2024-03-29 10:15:41,580 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:41,609 - config - INFO - Epoch [240/260], Train Loss: 0.2986
2024-03-29 10:15:41,613 - config - INFO - Validation Loss: 0.4801
2024-03-29 10:15:41,613 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:41,642 - config - INFO - Epoch [241/260], Train Loss: 0.2993
2024-03-29 10:15:41,646 - config - INFO - Validation Loss: 0.4789
2024-03-29 10:15:41,646 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:41,675 - config - INFO - Epoch [242/260], Train Loss: 0.2969
2024-03-29 10:15:41,679 - config - INFO - Validation Loss: 0.4771
2024-03-29 10:15:41,679 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:41,708 - config - INFO - Epoch [243/260], Train Loss: 0.2989
2024-03-29 10:15:41,712 - config - INFO - Validation Loss: 0.4780
2024-03-29 10:15:41,712 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:41,741 - config - INFO - Epoch [244/260], Train Loss: 0.2998
2024-03-29 10:15:41,745 - config - INFO - Validation Loss: 0.4779
2024-03-29 10:15:41,745 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:41,774 - config - INFO - Epoch [245/260], Train Loss: 0.2987
2024-03-29 10:15:41,778 - config - INFO - Validation Loss: 0.4761
2024-03-29 10:15:41,778 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:41,807 - config - INFO - Epoch [246/260], Train Loss: 0.2970
2024-03-29 10:15:41,811 - config - INFO - Validation Loss: 0.4735
2024-03-29 10:15:41,811 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:41,840 - config - INFO - Epoch [247/260], Train Loss: 0.2966
2024-03-29 10:15:41,844 - config - INFO - Validation Loss: 0.4822
2024-03-29 10:15:41,844 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:15:41,873 - config - INFO - Epoch [248/260], Train Loss: 0.2955
2024-03-29 10:15:41,877 - config - INFO - Validation Loss: 0.4785
2024-03-29 10:15:41,877 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:41,906 - config - INFO - Epoch [249/260], Train Loss: 0.2971
2024-03-29 10:15:41,910 - config - INFO - Validation Loss: 0.4779
2024-03-29 10:15:41,910 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:41,939 - config - INFO - Epoch [250/260], Train Loss: 0.2947
2024-03-29 10:15:41,943 - config - INFO - Validation Loss: 0.4709
2024-03-29 10:15:41,943 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:41,972 - config - INFO - Epoch [251/260], Train Loss: 0.2992
2024-03-29 10:15:41,976 - config - INFO - Validation Loss: 0.4721
2024-03-29 10:15:41,976 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:42,005 - config - INFO - Epoch [252/260], Train Loss: 0.2988
2024-03-29 10:15:42,009 - config - INFO - Validation Loss: 0.4879
2024-03-29 10:15:42,009 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:42,038 - config - INFO - Epoch [253/260], Train Loss: 0.2997
2024-03-29 10:15:42,042 - config - INFO - Validation Loss: 0.4802
2024-03-29 10:15:42,042 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:42,071 - config - INFO - Epoch [254/260], Train Loss: 0.2959
2024-03-29 10:15:42,075 - config - INFO - Validation Loss: 0.4921
2024-03-29 10:15:42,075 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:42,104 - config - INFO - Epoch [255/260], Train Loss: 0.2961
2024-03-29 10:15:42,108 - config - INFO - Validation Loss: 0.4826
2024-03-29 10:15:42,108 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:42,137 - config - INFO - Epoch [256/260], Train Loss: 0.2957
2024-03-29 10:15:42,141 - config - INFO - Validation Loss: 0.4901
2024-03-29 10:15:42,141 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:42,170 - config - INFO - Epoch [257/260], Train Loss: 0.2959
2024-03-29 10:15:42,174 - config - INFO - Validation Loss: 0.4871
2024-03-29 10:15:42,174 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:42,203 - config - INFO - Epoch [258/260], Train Loss: 0.2951
2024-03-29 10:15:42,207 - config - INFO - Validation Loss: 0.4783
2024-03-29 10:15:42,207 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:15:42,236 - config - INFO - Epoch [259/260], Train Loss: 0.2961
2024-03-29 10:15:42,240 - config - INFO - Validation Loss: 0.4809
2024-03-29 10:15:42,240 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:15:42,269 - config - INFO - Epoch [260/260], Train Loss: 0.2953
2024-03-29 10:15:42,273 - config - INFO - Validation Loss: 0.4868
2024-03-29 10:15:42,273 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:17:27,082 - config - INFO - resume: None
2024-03-29 10:17:27,082 - config - INFO - device: cpu
2024-03-29 10:17:27,082 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-29 10:17:27,082 - config - INFO - learning_rate: 0.001
2024-03-29 10:17:27,082 - config - INFO - num_epochs: 260
2024-03-29 10:17:27,082 - config - INFO - batch_size: 64
2024-03-29 10:17:27,082 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-29 10:17:27,104 - config - INFO - Dataset size: 891
2024-03-29 10:17:27,127 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-29 10:17:27,127 - config - INFO - Training start
2024-03-29 10:17:29,506 - config - INFO - Epoch [1/260], Train Loss: 0.6928
2024-03-29 10:17:29,511 - config - INFO - Validation Loss: 0.6689
2024-03-29 10:17:29,511 - config - INFO - Validation Acc: 0.7200
2024-03-29 10:17:29,549 - config - INFO - Epoch [2/260], Train Loss: 0.6522
2024-03-29 10:17:29,554 - config - INFO - Validation Loss: 0.6331
2024-03-29 10:17:29,554 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:17:29,599 - config - INFO - Epoch [3/260], Train Loss: 0.6084
2024-03-29 10:17:29,604 - config - INFO - Validation Loss: 0.5897
2024-03-29 10:17:29,604 - config - INFO - Validation Acc: 0.8600
2024-03-29 10:17:29,647 - config - INFO - Epoch [4/260], Train Loss: 0.5594
2024-03-29 10:17:29,652 - config - INFO - Validation Loss: 0.5415
2024-03-29 10:17:29,652 - config - INFO - Validation Acc: 0.8800
2024-03-29 10:17:29,685 - config - INFO - Epoch [5/260], Train Loss: 0.5065
2024-03-29 10:17:29,689 - config - INFO - Validation Loss: 0.4991
2024-03-29 10:17:29,689 - config - INFO - Validation Acc: 0.8800
2024-03-29 10:17:29,723 - config - INFO - Epoch [6/260], Train Loss: 0.4671
2024-03-29 10:17:29,727 - config - INFO - Validation Loss: 0.4708
2024-03-29 10:17:29,727 - config - INFO - Validation Acc: 0.8800
2024-03-29 10:17:29,763 - config - INFO - Epoch [7/260], Train Loss: 0.4397
2024-03-29 10:17:29,768 - config - INFO - Validation Loss: 0.4578
2024-03-29 10:17:29,768 - config - INFO - Validation Acc: 0.8800
2024-03-29 10:17:29,806 - config - INFO - Epoch [8/260], Train Loss: 0.4261
2024-03-29 10:17:29,811 - config - INFO - Validation Loss: 0.4544
2024-03-29 10:17:29,811 - config - INFO - Validation Acc: 0.8800
2024-03-29 10:17:29,841 - config - INFO - Epoch [9/260], Train Loss: 0.4190
2024-03-29 10:17:29,845 - config - INFO - Validation Loss: 0.4572
2024-03-29 10:17:29,845 - config - INFO - Validation Acc: 0.8800
2024-03-29 10:17:29,874 - config - INFO - Epoch [10/260], Train Loss: 0.4145
2024-03-29 10:17:29,879 - config - INFO - Validation Loss: 0.4590
2024-03-29 10:17:29,879 - config - INFO - Validation Acc: 0.8600
2024-03-29 10:17:29,879 - config - INFO - Validation loss increased. Early stopping.
2024-03-29 10:17:40,957 - config - INFO - resume: None
2024-03-29 10:17:40,957 - config - INFO - device: cpu
2024-03-29 10:17:40,957 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-29 10:17:40,957 - config - INFO - learning_rate: 0.001
2024-03-29 10:17:40,957 - config - INFO - num_epochs: 260
2024-03-29 10:17:40,957 - config - INFO - batch_size: 64
2024-03-29 10:17:40,957 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-29 10:17:40,978 - config - INFO - Dataset size: 891
2024-03-29 10:17:41,003 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-29 10:17:41,003 - config - INFO - Training start
2024-03-29 10:17:43,293 - config - INFO - Epoch [1/260], Train Loss: 0.6842
2024-03-29 10:17:43,299 - config - INFO - Validation Loss: 0.6567
2024-03-29 10:17:43,299 - config - INFO - Validation Acc: 0.6400
2024-03-29 10:17:43,335 - config - INFO - Epoch [2/260], Train Loss: 0.6490
2024-03-29 10:17:43,341 - config - INFO - Validation Loss: 0.6239
2024-03-29 10:17:43,341 - config - INFO - Validation Acc: 0.7200
2024-03-29 10:17:43,379 - config - INFO - Epoch [3/260], Train Loss: 0.6122
2024-03-29 10:17:43,384 - config - INFO - Validation Loss: 0.5831
2024-03-29 10:17:43,384 - config - INFO - Validation Acc: 0.7200
2024-03-29 10:17:43,419 - config - INFO - Epoch [4/260], Train Loss: 0.5666
2024-03-29 10:17:43,424 - config - INFO - Validation Loss: 0.5370
2024-03-29 10:17:43,424 - config - INFO - Validation Acc: 0.8600
2024-03-29 10:17:43,460 - config - INFO - Epoch [5/260], Train Loss: 0.5177
2024-03-29 10:17:43,466 - config - INFO - Validation Loss: 0.4972
2024-03-29 10:17:43,466 - config - INFO - Validation Acc: 0.8200
2024-03-29 10:17:43,505 - config - INFO - Epoch [6/260], Train Loss: 0.4764
2024-03-29 10:17:43,510 - config - INFO - Validation Loss: 0.4723
2024-03-29 10:17:43,511 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:17:43,546 - config - INFO - Epoch [7/260], Train Loss: 0.4459
2024-03-29 10:17:43,551 - config - INFO - Validation Loss: 0.4580
2024-03-29 10:17:43,551 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:17:43,586 - config - INFO - Epoch [8/260], Train Loss: 0.4294
2024-03-29 10:17:43,591 - config - INFO - Validation Loss: 0.4536
2024-03-29 10:17:43,591 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:17:43,626 - config - INFO - Epoch [9/260], Train Loss: 0.4221
2024-03-29 10:17:43,631 - config - INFO - Validation Loss: 0.4547
2024-03-29 10:17:43,631 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:17:43,666 - config - INFO - Epoch [10/260], Train Loss: 0.4167
2024-03-29 10:17:43,671 - config - INFO - Validation Loss: 0.4540
2024-03-29 10:17:43,671 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:17:43,725 - config - INFO - Epoch [11/260], Train Loss: 0.4123
2024-03-29 10:17:43,733 - config - INFO - Validation Loss: 0.4532
2024-03-29 10:17:43,733 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:17:43,768 - config - INFO - Epoch [12/260], Train Loss: 0.4094
2024-03-29 10:17:43,773 - config - INFO - Validation Loss: 0.4519
2024-03-29 10:17:43,773 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:17:43,808 - config - INFO - Epoch [13/260], Train Loss: 0.4063
2024-03-29 10:17:43,813 - config - INFO - Validation Loss: 0.4471
2024-03-29 10:17:43,814 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:17:43,848 - config - INFO - Epoch [14/260], Train Loss: 0.4049
2024-03-29 10:17:43,854 - config - INFO - Validation Loss: 0.4475
2024-03-29 10:17:43,854 - config - INFO - Validation Acc: 0.8000
2024-03-29 10:17:43,883 - config - INFO - Epoch [15/260], Train Loss: 0.4005
2024-03-29 10:17:43,888 - config - INFO - Validation Loss: 0.4529
2024-03-29 10:17:43,888 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:17:43,888 - config - INFO - Validation loss increased. Early stopping.
2024-03-29 10:17:57,825 - config - INFO - resume: None
2024-03-29 10:17:57,825 - config - INFO - device: cpu
2024-03-29 10:17:57,825 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-29 10:17:57,825 - config - INFO - learning_rate: 0.001
2024-03-29 10:17:57,825 - config - INFO - num_epochs: 260
2024-03-29 10:17:57,825 - config - INFO - batch_size: 64
2024-03-29 10:17:57,825 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-29 10:17:57,847 - config - INFO - Dataset size: 891
2024-03-29 10:17:57,884 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-29 10:17:57,885 - config - INFO - Training start
2024-03-29 10:18:01,103 - config - INFO - Epoch [1/260], Train Loss: 33.1515
2024-03-29 10:18:01,155 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:18:01,155 - config - INFO - Validation Acc: 0.6200
2024-03-29 10:18:01,979 - config - INFO - Epoch [2/260], Train Loss: 38.4831
2024-03-29 10:18:02,026 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:18:02,026 - config - INFO - Validation Acc: 0.6200
2024-03-29 10:18:02,874 - config - INFO - Epoch [3/260], Train Loss: 38.4831
2024-03-29 10:18:02,919 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:18:02,919 - config - INFO - Validation Acc: 0.6200
2024-03-29 10:18:03,727 - config - INFO - Epoch [4/260], Train Loss: 38.4831
2024-03-29 10:18:03,767 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:18:03,768 - config - INFO - Validation Acc: 0.6200
2024-03-29 10:18:04,466 - config - INFO - Epoch [5/260], Train Loss: 38.4831
2024-03-29 10:18:04,509 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:18:04,510 - config - INFO - Validation Acc: 0.6200
2024-03-29 10:18:05,140 - config - INFO - Epoch [6/260], Train Loss: 38.4831
2024-03-29 10:18:05,183 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:18:05,184 - config - INFO - Validation Acc: 0.6200
2024-03-29 10:18:05,847 - config - INFO - Epoch [7/260], Train Loss: 38.4831
2024-03-29 10:18:05,887 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:18:05,887 - config - INFO - Validation Acc: 0.6200
2024-03-29 10:18:06,534 - config - INFO - Epoch [8/260], Train Loss: 38.4831
2024-03-29 10:18:06,573 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:18:06,573 - config - INFO - Validation Acc: 0.6200
2024-03-29 10:18:07,188 - config - INFO - Epoch [9/260], Train Loss: 38.4831
2024-03-29 10:18:07,230 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:18:07,231 - config - INFO - Validation Acc: 0.6200
2024-03-29 10:18:07,829 - config - INFO - Epoch [10/260], Train Loss: 38.4831
2024-03-29 10:18:07,867 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:18:07,867 - config - INFO - Validation Acc: 0.6200
2024-03-29 10:18:26,111 - config - INFO - resume: None
2024-03-29 10:18:26,111 - config - INFO - device: cpu
2024-03-29 10:18:26,111 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-29 10:18:26,111 - config - INFO - learning_rate: 0.001
2024-03-29 10:18:26,111 - config - INFO - num_epochs: 260
2024-03-29 10:18:26,111 - config - INFO - batch_size: 64
2024-03-29 10:18:26,111 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-29 10:18:26,132 - config - INFO - Dataset size: 891
2024-03-29 10:18:26,165 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 52800)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(52800, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-29 10:18:26,166 - config - INFO - Training start
2024-03-29 10:18:28,823 - config - INFO - Epoch [1/260], Train Loss: 4.2490
2024-03-29 10:18:28,853 - config - INFO - Validation Loss: 1.9608
2024-03-29 10:18:28,853 - config - INFO - Validation Acc: 0.4000
2024-03-29 10:18:29,204 - config - INFO - Epoch [2/260], Train Loss: 1.4314
2024-03-29 10:18:29,235 - config - INFO - Validation Loss: 0.9183
2024-03-29 10:18:29,235 - config - INFO - Validation Acc: 0.6200
2024-03-29 10:18:29,590 - config - INFO - Epoch [3/260], Train Loss: 0.8091
2024-03-29 10:18:29,617 - config - INFO - Validation Loss: 1.2944
2024-03-29 10:18:29,618 - config - INFO - Validation Acc: 0.6600
2024-03-29 10:18:29,618 - config - INFO - Validation loss increased. Early stopping.
2024-03-29 10:18:39,806 - config - INFO - resume: None
2024-03-29 10:18:39,806 - config - INFO - device: cpu
2024-03-29 10:18:39,806 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-29 10:18:39,806 - config - INFO - learning_rate: 0.001
2024-03-29 10:18:39,806 - config - INFO - num_epochs: 260
2024-03-29 10:18:39,806 - config - INFO - batch_size: 64
2024-03-29 10:18:39,806 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-29 10:18:39,827 - config - INFO - Dataset size: 891
2024-03-29 10:18:39,858 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 52800)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(52800, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-29 10:18:39,858 - config - INFO - Training start
2024-03-29 10:18:42,404 - config - INFO - Epoch [1/260], Train Loss: 2.4129
2024-03-29 10:18:42,435 - config - INFO - Validation Loss: 0.7623
2024-03-29 10:18:42,436 - config - INFO - Validation Acc: 0.7800
2024-03-29 10:18:42,759 - config - INFO - Epoch [2/260], Train Loss: 1.4088
2024-03-29 10:18:42,781 - config - INFO - Validation Loss: 1.5170
2024-03-29 10:18:42,781 - config - INFO - Validation Acc: 0.7200
2024-03-29 10:18:42,781 - config - INFO - Validation loss increased. Early stopping.
2024-03-29 10:18:57,749 - config - INFO - resume: None
2024-03-29 10:18:57,749 - config - INFO - device: cpu
2024-03-29 10:18:57,749 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-29 10:18:57,750 - config - INFO - learning_rate: 0.001
2024-03-29 10:18:57,750 - config - INFO - num_epochs: 260
2024-03-29 10:18:57,750 - config - INFO - batch_size: 64
2024-03-29 10:18:57,750 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.3

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-29 10:18:57,771 - config - INFO - Dataset size: 891
2024-03-29 10:18:57,801 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 52800)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(52800, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-29 10:18:57,802 - config - INFO - Training start
2024-03-29 10:19:00,551 - config - INFO - Epoch [1/260], Train Loss: 2.6599
2024-03-29 10:19:00,585 - config - INFO - Validation Loss: 0.5600
2024-03-29 10:19:00,586 - config - INFO - Validation Acc: 0.8400
2024-03-29 10:19:00,999 - config - INFO - Epoch [2/260], Train Loss: 0.5708
2024-03-29 10:19:01,029 - config - INFO - Validation Loss: 0.3699
2024-03-29 10:19:01,029 - config - INFO - Validation Acc: 0.8800
2024-03-29 10:19:01,387 - config - INFO - Epoch [3/260], Train Loss: 0.5252
2024-03-29 10:19:01,417 - config - INFO - Validation Loss: 0.5488
2024-03-29 10:19:01,417 - config - INFO - Validation Acc: 0.7400
2024-03-29 10:19:01,798 - config - INFO - Epoch [4/260], Train Loss: 0.5216
2024-03-29 10:19:01,829 - config - INFO - Validation Loss: 0.5728
2024-03-29 10:19:01,829 - config - INFO - Validation Acc: 0.8600
2024-03-29 10:19:02,226 - config - INFO - Epoch [5/260], Train Loss: 0.7548
2024-03-29 10:19:02,255 - config - INFO - Validation Loss: 0.7591
2024-03-29 10:19:02,255 - config - INFO - Validation Acc: 0.6800
2024-03-29 10:19:02,256 - config - INFO - Validation loss increased. Early stopping.
2024-03-29 10:19:19,218 - config - INFO - resume: None
2024-03-29 10:19:19,218 - config - INFO - device: cpu
2024-03-29 10:19:19,218 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-29 10:19:19,219 - config - INFO - learning_rate: 0.001
2024-03-29 10:19:19,219 - config - INFO - num_epochs: 260
2024-03-29 10:19:19,219 - config - INFO - batch_size: 64
2024-03-29 10:19:19,219 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-29 10:19:19,240 - config - INFO - Dataset size: 891
2024-03-29 10:19:19,275 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 52800)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(52800, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-29 10:19:19,275 - config - INFO - Training start
2024-03-29 10:19:21,947 - config - INFO - Epoch [1/260], Train Loss: 2.3684
2024-03-29 10:19:21,972 - config - INFO - Validation Loss: 1.5502
2024-03-29 10:19:21,973 - config - INFO - Validation Acc: 0.6400
2024-03-29 10:19:22,348 - config - INFO - Epoch [2/260], Train Loss: 1.0208
2024-03-29 10:19:22,372 - config - INFO - Validation Loss: 0.7526
2024-03-29 10:19:22,372 - config - INFO - Validation Acc: 0.7200
2024-03-29 10:19:22,759 - config - INFO - Epoch [3/260], Train Loss: 0.8160
2024-03-29 10:19:22,782 - config - INFO - Validation Loss: 0.7282
2024-03-29 10:19:22,782 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:19:23,148 - config - INFO - Epoch [4/260], Train Loss: 0.6538
2024-03-29 10:19:23,169 - config - INFO - Validation Loss: 0.6258
2024-03-29 10:19:23,169 - config - INFO - Validation Acc: 0.7400
2024-03-29 10:19:23,477 - config - INFO - Epoch [5/260], Train Loss: 0.6021
2024-03-29 10:19:23,498 - config - INFO - Validation Loss: 0.6013
2024-03-29 10:19:23,499 - config - INFO - Validation Acc: 0.7400
2024-03-29 10:19:23,814 - config - INFO - Epoch [6/260], Train Loss: 0.5134
2024-03-29 10:19:23,834 - config - INFO - Validation Loss: 0.5200
2024-03-29 10:19:23,834 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:19:24,169 - config - INFO - Epoch [7/260], Train Loss: 0.5414
2024-03-29 10:19:24,193 - config - INFO - Validation Loss: 0.5373
2024-03-29 10:19:24,194 - config - INFO - Validation Acc: 0.7400
2024-03-29 10:19:24,514 - config - INFO - Epoch [8/260], Train Loss: 0.4812
2024-03-29 10:19:24,536 - config - INFO - Validation Loss: 0.5917
2024-03-29 10:19:24,536 - config - INFO - Validation Acc: 0.6800
2024-03-29 10:19:24,849 - config - INFO - Epoch [9/260], Train Loss: 0.5043
2024-03-29 10:19:24,869 - config - INFO - Validation Loss: 0.9355
2024-03-29 10:19:24,870 - config - INFO - Validation Acc: 0.5000
2024-03-29 10:19:25,196 - config - INFO - Epoch [10/260], Train Loss: 0.5995
2024-03-29 10:19:25,216 - config - INFO - Validation Loss: 0.6840
2024-03-29 10:19:25,216 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:19:25,529 - config - INFO - Epoch [11/260], Train Loss: 0.4996
2024-03-29 10:19:25,551 - config - INFO - Validation Loss: 0.5293
2024-03-29 10:19:25,551 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:19:25,873 - config - INFO - Epoch [12/260], Train Loss: 0.5066
2024-03-29 10:19:25,894 - config - INFO - Validation Loss: 1.0720
2024-03-29 10:19:25,894 - config - INFO - Validation Acc: 0.4800
2024-03-29 10:19:26,206 - config - INFO - Epoch [13/260], Train Loss: 0.7568
2024-03-29 10:19:26,226 - config - INFO - Validation Loss: 0.8643
2024-03-29 10:19:26,226 - config - INFO - Validation Acc: 0.7200
2024-03-29 10:19:26,577 - config - INFO - Epoch [14/260], Train Loss: 0.7196
2024-03-29 10:19:26,596 - config - INFO - Validation Loss: 1.2649
2024-03-29 10:19:26,596 - config - INFO - Validation Acc: 0.6400
2024-03-29 10:19:26,920 - config - INFO - Epoch [15/260], Train Loss: 0.6909
2024-03-29 10:19:26,939 - config - INFO - Validation Loss: 0.7297
2024-03-29 10:19:26,939 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:19:27,263 - config - INFO - Epoch [16/260], Train Loss: 0.5110
2024-03-29 10:19:27,282 - config - INFO - Validation Loss: 0.6064
2024-03-29 10:19:27,282 - config - INFO - Validation Acc: 0.7600
2024-03-29 10:19:27,608 - config - INFO - Epoch [17/260], Train Loss: 0.6450
2024-03-29 10:19:27,627 - config - INFO - Validation Loss: 1.0679
2024-03-29 10:19:27,627 - config - INFO - Validation Acc: 0.6400
2024-03-29 10:19:27,954 - config - INFO - Epoch [18/260], Train Loss: 0.8879
2024-03-29 10:19:27,977 - config - INFO - Validation Loss: 1.0908
2024-03-29 10:19:27,978 - config - INFO - Validation Acc: 0.7400
2024-03-29 10:19:28,296 - config - INFO - Epoch [19/260], Train Loss: 0.7257
2024-03-29 10:19:28,317 - config - INFO - Validation Loss: 1.6727
2024-03-29 10:19:28,317 - config - INFO - Validation Acc: 0.6600
2024-03-29 10:19:28,318 - config - INFO - Validation loss increased. Early stopping.
2024-03-29 10:24:41,093 - config - INFO - resume: None
2024-03-29 10:24:41,093 - config - INFO - device: cpu
2024-03-29 10:24:41,093 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-29 10:24:41,093 - config - INFO - learning_rate: 0.001
2024-03-29 10:24:41,093 - config - INFO - num_epochs: 260
2024-03-29 10:24:41,093 - config - INFO - batch_size: 64
2024-03-29 10:24:41,093 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-29 10:24:41,115 - config - INFO - Dataset size: 891
2024-03-29 10:24:41,146 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 52800)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(52800, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                loss = nn.BCELoss()(batch_outputs, labels)
                val_loss += loss.item() * inputs.size(0)
                outputs += batch_outputs
                labels += labels
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-29 10:24:41,146 - config - INFO - Training start
2024-03-29 10:24:43,716 - config - INFO - Epoch [1/260], Train Loss: 7.6141
2024-03-29 10:24:43,744 - config - INFO - Validation Loss: 3.6776
2024-03-29 10:26:52,632 - config - INFO - resume: None
2024-03-29 10:26:52,632 - config - INFO - device: cpu
2024-03-29 10:26:52,632 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-29 10:26:52,632 - config - INFO - learning_rate: 0.001
2024-03-29 10:26:52,632 - config - INFO - num_epochs: 180
2024-03-29 10:26:52,632 - config - INFO - batch_size: 64
2024-03-29 10:26:52,632 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-29 10:26:52,676 - config - INFO - Dataset size: 891
2024-03-29 10:26:56,528 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 52800)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(52800, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                loss = nn.BCELoss()(batch_outputs, labels)
                val_loss += loss.item() * inputs.size(0)
                outputs += batch_outputs
                labels += labels
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-29 10:26:56,528 - config - INFO - Training start
2024-03-29 10:27:00,996 - config - INFO - Epoch [1/180], Train Loss: 2.4444
2024-03-29 10:35:14,101 - config - INFO - Validation Loss: 0.8252
2024-03-29 10:37:39,208 - config - INFO - resume: None
2024-03-29 10:37:39,208 - config - INFO - device: cpu
2024-03-29 10:37:39,208 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-29 10:37:39,208 - config - INFO - learning_rate: 0.001
2024-03-29 10:37:39,208 - config - INFO - num_epochs: 180
2024-03-29 10:37:39,208 - config - INFO - batch_size: 64
2024-03-29 10:37:39,208 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-29 10:37:39,250 - config - INFO - Dataset size: 891
2024-03-29 10:37:41,927 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 52800)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(52800, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                loss = nn.BCELoss()(batch_outputs, labels)
                val_loss += loss.item() * inputs.size(0)
                outputs += batch_outputs
                labels += labels
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-29 10:37:41,928 - config - INFO - Training start
2024-03-29 10:37:46,450 - config - INFO - Epoch [1/180], Train Loss: 3.3713
2024-03-29 10:37:59,508 - config - INFO - Validation Loss: 1.1416
2024-03-29 10:38:18,038 - config - INFO - resume: None
2024-03-29 10:38:18,038 - config - INFO - device: cpu
2024-03-29 10:38:18,038 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-29 10:38:18,038 - config - INFO - learning_rate: 0.001
2024-03-29 10:38:18,038 - config - INFO - num_epochs: 180
2024-03-29 10:38:18,039 - config - INFO - batch_size: 64
2024-03-29 10:38:18,039 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-29 10:38:18,082 - config - INFO - Dataset size: 891
2024-03-29 10:38:25,017 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 52800)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(52800, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                loss = nn.BCELoss()(batch_outputs, labels)
                val_loss += loss.item() * inputs.size(0)
                outputs += batch_outputs
                labels += labels
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-29 10:38:25,017 - config - INFO - Training start
2024-03-29 10:38:29,720 - config - INFO - Epoch [1/180], Train Loss: 55.6817
2024-03-29 10:44:28,661 - config - INFO - resume: None
2024-03-29 10:44:28,661 - config - INFO - device: cpu
2024-03-29 10:44:28,661 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-29 10:44:28,661 - config - INFO - learning_rate: 0.001
2024-03-29 10:44:28,661 - config - INFO - num_epochs: 260
2024-03-29 10:44:28,661 - config - INFO - batch_size: 64
2024-03-29 10:44:28,661 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-29 10:44:28,682 - config - INFO - Dataset size: 891
2024-03-29 10:44:28,713 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 52800)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(52800, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                loss = nn.BCELoss()(batch_outputs, labels)
                val_loss += loss.item() * inputs.size(0)
                outputs += batch_outputs
                labels += labels
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-29 10:44:28,714 - config - INFO - Training start
2024-03-29 10:44:31,331 - config - INFO - Epoch [1/260], Train Loss: 2.5442
2024-03-29 10:44:31,357 - config - INFO - Validation Loss: 2.0858
2024-03-29 10:44:31,361 - config - INFO - Validation Acc: 93.9600
2024-03-29 10:44:31,691 - config - INFO - Epoch [2/260], Train Loss: 1.0035
2024-03-29 10:44:31,720 - config - INFO - Validation Loss: 2.9781
2024-03-29 10:44:31,720 - config - INFO - Validation Acc: 0.0000
2024-03-29 10:44:32,063 - config - INFO - Epoch [3/260], Train Loss: 1.7987
2024-03-29 10:44:32,087 - config - INFO - Validation Loss: 0.9075
2024-03-29 10:44:32,087 - config - INFO - Validation Acc: 54.5400
2024-03-29 10:44:32,414 - config - INFO - Epoch [4/260], Train Loss: 0.7129
2024-03-29 10:44:32,438 - config - INFO - Validation Loss: 0.9672
2024-03-29 10:44:32,439 - config - INFO - Validation Acc: 62.6400
2024-03-29 10:44:32,765 - config - INFO - Epoch [5/260], Train Loss: 0.6703
2024-03-29 10:44:32,803 - config - INFO - Validation Loss: 0.7364
2024-03-29 10:44:32,803 - config - INFO - Validation Acc: 52.3800
2024-03-29 10:44:33,143 - config - INFO - Epoch [6/260], Train Loss: 0.5188
2024-03-29 10:44:33,166 - config - INFO - Validation Loss: 0.8263
2024-03-29 10:44:33,167 - config - INFO - Validation Acc: 72.9000
2024-03-29 10:44:33,487 - config - INFO - Epoch [7/260], Train Loss: 0.5756
2024-03-29 10:44:33,511 - config - INFO - Validation Loss: 0.5561
2024-03-29 10:44:33,512 - config - INFO - Validation Acc: 54.5400
2024-03-29 10:44:33,838 - config - INFO - Epoch [8/260], Train Loss: 0.4782
2024-03-29 10:44:33,870 - config - INFO - Validation Loss: 0.5543
2024-03-29 10:44:33,871 - config - INFO - Validation Acc: 59.9400
2024-03-29 10:44:34,190 - config - INFO - Epoch [9/260], Train Loss: 0.4502
2024-03-29 10:44:34,212 - config - INFO - Validation Loss: 0.5442
2024-03-29 10:44:34,212 - config - INFO - Validation Acc: 46.4400
2024-03-29 10:44:34,500 - config - INFO - Epoch [10/260], Train Loss: 0.4516
2024-03-29 10:44:34,523 - config - INFO - Validation Loss: 0.6937
2024-03-29 10:44:34,524 - config - INFO - Validation Acc: 74.5200
2024-03-29 10:44:34,841 - config - INFO - Epoch [11/260], Train Loss: 0.6429
2024-03-29 10:44:34,863 - config - INFO - Validation Loss: 0.8392
2024-03-29 10:44:34,863 - config - INFO - Validation Acc: 75.6000
2024-03-29 10:44:35,178 - config - INFO - Epoch [12/260], Train Loss: 0.6002
2024-03-29 10:44:35,200 - config - INFO - Validation Loss: 1.0100
2024-03-29 10:44:35,200 - config - INFO - Validation Acc: 79.9200
2024-03-29 10:44:35,514 - config - INFO - Epoch [13/260], Train Loss: 0.6285
2024-03-29 10:44:35,534 - config - INFO - Validation Loss: 0.6267
2024-03-29 10:44:35,535 - config - INFO - Validation Acc: 48.0600
2024-03-29 10:44:35,836 - config - INFO - Epoch [14/260], Train Loss: 0.6967
2024-03-29 10:44:35,855 - config - INFO - Validation Loss: 0.7854
2024-03-29 10:44:35,859 - config - INFO - Validation Acc: 66.4200
2024-03-29 10:44:36,194 - config - INFO - Epoch [15/260], Train Loss: 0.7054
2024-03-29 10:44:36,216 - config - INFO - Validation Loss: 1.1378
2024-03-29 10:44:36,216 - config - INFO - Validation Acc: 79.9200
2024-03-29 10:44:36,570 - config - INFO - Epoch [16/260], Train Loss: 0.5898
2024-03-29 10:44:36,593 - config - INFO - Validation Loss: 0.5927
2024-03-29 10:44:36,593 - config - INFO - Validation Acc: 56.7000
2024-03-29 10:44:36,957 - config - INFO - Epoch [17/260], Train Loss: 0.4939
2024-03-29 10:44:36,979 - config - INFO - Validation Loss: 0.6586
2024-03-29 10:44:36,979 - config - INFO - Validation Acc: 73.4400
2024-03-29 10:44:37,320 - config - INFO - Epoch [18/260], Train Loss: 0.5742
2024-03-29 10:44:37,341 - config - INFO - Validation Loss: 1.0124
2024-03-29 10:44:37,341 - config - INFO - Validation Acc: 85.3200
2024-03-29 10:44:37,656 - config - INFO - Epoch [19/260], Train Loss: 0.5880
2024-03-29 10:44:37,675 - config - INFO - Validation Loss: 0.5821
2024-03-29 10:44:37,676 - config - INFO - Validation Acc: 53.4600
2024-03-29 10:44:37,985 - config - INFO - Epoch [20/260], Train Loss: 0.4819
2024-03-29 10:44:38,006 - config - INFO - Validation Loss: 0.6258
2024-03-29 10:44:38,006 - config - INFO - Validation Acc: 41.0400
2024-03-29 10:44:38,306 - config - INFO - Epoch [21/260], Train Loss: 0.5771
2024-03-29 10:44:38,326 - config - INFO - Validation Loss: 0.5626
2024-03-29 10:44:38,327 - config - INFO - Validation Acc: 56.7000
2024-03-29 10:44:38,625 - config - INFO - Epoch [22/260], Train Loss: 0.6439
2024-03-29 10:44:38,645 - config - INFO - Validation Loss: 0.7472
2024-03-29 10:44:38,646 - config - INFO - Validation Acc: 38.3400
2024-03-29 10:44:38,957 - config - INFO - Epoch [23/260], Train Loss: 0.6292
2024-03-29 10:44:38,978 - config - INFO - Validation Loss: 1.0303
2024-03-29 10:44:38,978 - config - INFO - Validation Acc: 82.0800
2024-03-29 10:44:39,303 - config - INFO - Epoch [24/260], Train Loss: 0.5278
2024-03-29 10:44:39,324 - config - INFO - Validation Loss: 0.7894
2024-03-29 10:44:39,324 - config - INFO - Validation Acc: 75.0600
2024-03-29 10:44:39,633 - config - INFO - Epoch [25/260], Train Loss: 0.5317
2024-03-29 10:44:39,654 - config - INFO - Validation Loss: 0.6049
2024-03-29 10:44:39,654 - config - INFO - Validation Acc: 66.9600
2024-03-29 10:44:39,966 - config - INFO - Epoch [26/260], Train Loss: 0.4601
2024-03-29 10:44:39,987 - config - INFO - Validation Loss: 0.6663
2024-03-29 10:44:39,988 - config - INFO - Validation Acc: 73.9800
2024-03-29 10:44:40,303 - config - INFO - Epoch [27/260], Train Loss: 0.4832
2024-03-29 10:44:40,323 - config - INFO - Validation Loss: 0.6852
2024-03-29 10:44:40,327 - config - INFO - Validation Acc: 34.0200
2024-03-29 10:44:40,639 - config - INFO - Epoch [28/260], Train Loss: 0.5973
2024-03-29 10:44:40,659 - config - INFO - Validation Loss: 0.6970
2024-03-29 10:44:40,660 - config - INFO - Validation Acc: 72.3600
2024-03-29 10:44:40,964 - config - INFO - Epoch [29/260], Train Loss: 0.7882
2024-03-29 10:44:40,984 - config - INFO - Validation Loss: 0.6754
2024-03-29 10:44:40,984 - config - INFO - Validation Acc: 53.4600
2024-03-29 10:44:41,296 - config - INFO - Epoch [30/260], Train Loss: 0.6004
2024-03-29 10:44:41,315 - config - INFO - Validation Loss: 0.6405
2024-03-29 10:44:41,316 - config - INFO - Validation Acc: 57.7800
2024-03-29 10:44:41,604 - config - INFO - Epoch [31/260], Train Loss: 0.5507
2024-03-29 10:44:41,624 - config - INFO - Validation Loss: 0.8099
2024-03-29 10:44:41,624 - config - INFO - Validation Acc: 76.6800
2024-03-29 10:44:41,947 - config - INFO - Epoch [32/260], Train Loss: 0.5752
2024-03-29 10:44:41,970 - config - INFO - Validation Loss: 0.5801
2024-03-29 10:44:41,971 - config - INFO - Validation Acc: 63.1800
2024-03-29 10:44:42,293 - config - INFO - Epoch [33/260], Train Loss: 0.5788
2024-03-29 10:44:42,314 - config - INFO - Validation Loss: 0.6544
2024-03-29 10:44:42,315 - config - INFO - Validation Acc: 44.2800
2024-03-29 10:44:42,599 - config - INFO - Epoch [34/260], Train Loss: 0.5229
2024-03-29 10:44:42,619 - config - INFO - Validation Loss: 0.6128
2024-03-29 10:44:42,620 - config - INFO - Validation Acc: 64.8000
2024-03-29 10:44:42,931 - config - INFO - Epoch [35/260], Train Loss: 0.4492
2024-03-29 10:44:42,951 - config - INFO - Validation Loss: 0.6664
2024-03-29 10:44:42,951 - config - INFO - Validation Acc: 35.6400
2024-03-29 10:44:43,251 - config - INFO - Epoch [36/260], Train Loss: 0.6661
2024-03-29 10:44:43,272 - config - INFO - Validation Loss: 0.8083
2024-03-29 10:44:43,272 - config - INFO - Validation Acc: 73.9800
2024-03-29 10:44:43,575 - config - INFO - Epoch [37/260], Train Loss: 1.5409
2024-03-29 10:44:43,594 - config - INFO - Validation Loss: 2.0975
2024-03-29 10:44:43,595 - config - INFO - Validation Acc: 85.3200
2024-03-29 10:44:43,595 - config - INFO - Validation loss increased. Early stopping.
2024-03-29 10:45:22,094 - config - INFO - resume: None
2024-03-29 10:45:22,094 - config - INFO - device: cpu
2024-03-29 10:45:22,094 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-29 10:45:22,094 - config - INFO - learning_rate: 0.001
2024-03-29 10:45:22,094 - config - INFO - num_epochs: 260
2024-03-29 10:45:22,094 - config - INFO - batch_size: 64
2024-03-29 10:45:22,094 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-29 10:45:22,116 - config - INFO - Dataset size: 891
2024-03-29 10:45:22,153 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 92800)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(92800, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                loss = nn.BCELoss()(batch_outputs, labels)
                val_loss += loss.item() * inputs.size(0)
                outputs += batch_outputs
                labels += labels
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-29 10:45:22,154 - config - INFO - Training start
2024-03-29 10:45:24,951 - config - INFO - Epoch [1/260], Train Loss: 32.0830
2024-03-29 10:45:24,997 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:24,998 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:25,566 - config - INFO - Epoch [2/260], Train Loss: 38.4831
2024-03-29 10:45:25,606 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:25,606 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:26,151 - config - INFO - Epoch [3/260], Train Loss: 38.4831
2024-03-29 10:45:26,193 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:26,193 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:26,738 - config - INFO - Epoch [4/260], Train Loss: 38.4831
2024-03-29 10:45:26,775 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:26,775 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:27,276 - config - INFO - Epoch [5/260], Train Loss: 38.4831
2024-03-29 10:45:27,331 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:27,331 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:27,808 - config - INFO - Epoch [6/260], Train Loss: 38.4831
2024-03-29 10:45:27,845 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:27,845 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:28,322 - config - INFO - Epoch [7/260], Train Loss: 38.4831
2024-03-29 10:45:28,358 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:28,359 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:28,824 - config - INFO - Epoch [8/260], Train Loss: 38.4831
2024-03-29 10:45:28,858 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:28,859 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:29,310 - config - INFO - Epoch [9/260], Train Loss: 38.4831
2024-03-29 10:45:29,343 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:29,344 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:29,811 - config - INFO - Epoch [10/260], Train Loss: 38.4831
2024-03-29 10:45:29,844 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:29,844 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:30,273 - config - INFO - Epoch [11/260], Train Loss: 38.4831
2024-03-29 10:45:30,306 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:30,306 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:30,740 - config - INFO - Epoch [12/260], Train Loss: 38.4831
2024-03-29 10:45:30,771 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:30,771 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:31,210 - config - INFO - Epoch [13/260], Train Loss: 38.4831
2024-03-29 10:45:31,241 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:31,242 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:31,672 - config - INFO - Epoch [14/260], Train Loss: 38.4831
2024-03-29 10:45:31,700 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:31,700 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:32,121 - config - INFO - Epoch [15/260], Train Loss: 38.4831
2024-03-29 10:45:32,151 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:32,152 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:32,635 - config - INFO - Epoch [16/260], Train Loss: 38.4831
2024-03-29 10:45:32,671 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:32,671 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:33,118 - config - INFO - Epoch [17/260], Train Loss: 38.4831
2024-03-29 10:45:33,153 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:33,153 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:33,574 - config - INFO - Epoch [18/260], Train Loss: 38.4831
2024-03-29 10:45:33,603 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:33,603 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:34,027 - config - INFO - Epoch [19/260], Train Loss: 38.4831
2024-03-29 10:45:34,057 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:34,057 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:34,491 - config - INFO - Epoch [20/260], Train Loss: 38.4831
2024-03-29 10:45:34,519 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:34,519 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:34,945 - config - INFO - Epoch [21/260], Train Loss: 38.4831
2024-03-29 10:45:34,978 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:34,978 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:35,412 - config - INFO - Epoch [22/260], Train Loss: 38.4831
2024-03-29 10:45:35,446 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:35,447 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:35,884 - config - INFO - Epoch [23/260], Train Loss: 38.4831
2024-03-29 10:45:35,913 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:35,914 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:36,343 - config - INFO - Epoch [24/260], Train Loss: 38.4831
2024-03-29 10:45:36,372 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:36,372 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:36,806 - config - INFO - Epoch [25/260], Train Loss: 38.4831
2024-03-29 10:45:36,835 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:36,835 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:37,254 - config - INFO - Epoch [26/260], Train Loss: 38.4831
2024-03-29 10:45:37,283 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:37,284 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:37,702 - config - INFO - Epoch [27/260], Train Loss: 38.4831
2024-03-29 10:45:37,732 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:37,732 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:38,163 - config - INFO - Epoch [28/260], Train Loss: 38.4831
2024-03-29 10:45:38,191 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:38,191 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:38,597 - config - INFO - Epoch [29/260], Train Loss: 38.4831
2024-03-29 10:45:38,626 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:38,626 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:39,058 - config - INFO - Epoch [30/260], Train Loss: 38.4831
2024-03-29 10:45:39,092 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:39,093 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:45:39,506 - config - INFO - Epoch [31/260], Train Loss: 38.4831
2024-03-29 10:45:39,535 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:45:39,536 - config - INFO - Validation Acc: 103.2400
2024-03-29 10:46:10,655 - config - INFO - resume: None
2024-03-29 10:46:10,656 - config - INFO - device: cpu
2024-03-29 10:46:10,656 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-29 10:46:10,656 - config - INFO - learning_rate: 0.001
2024-03-29 10:46:10,656 - config - INFO - num_epochs: 180
2024-03-29 10:46:10,656 - config - INFO - batch_size: 64
2024-03-29 10:46:10,656 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-29 10:46:10,698 - config - INFO - Dataset size: 891
2024-03-29 10:46:14,775 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 92800)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(92800, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                loss = nn.BCELoss()(batch_outputs, labels)
                val_loss += loss.item() * inputs.size(0)
                outputs += batch_outputs
                labels += labels
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-29 10:46:14,775 - config - INFO - Training start
2024-03-29 10:46:19,591 - config - INFO - Epoch [1/180], Train Loss: 32.2674
2024-03-29 10:47:03,697 - config - INFO - Validation Loss: 38.2022
2024-03-29 10:52:42,869 - config - INFO - resume: None
2024-03-29 10:52:42,869 - config - INFO - device: cpu
2024-03-29 10:52:42,869 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-29 10:52:42,869 - config - INFO - learning_rate: 0.001
2024-03-29 10:52:42,869 - config - INFO - num_epochs: 180
2024-03-29 10:52:42,869 - config - INFO - batch_size: 64
2024-03-29 10:52:42,870 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-29 10:52:42,912 - config - INFO - Dataset size: 891
2024-03-29 10:52:49,792 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 92800)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(92800, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs += batch_outputs
                labels += batch_labels
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-29 10:52:49,792 - config - INFO - Training start
2024-03-29 10:52:54,644 - config - INFO - Epoch [1/180], Train Loss: 32.1348
2024-03-29 10:53:25,982 - config - INFO - Validation Loss: 42.1348
2024-03-29 10:54:12,048 - config - INFO - resume: None
2024-03-29 10:54:12,048 - config - INFO - device: cpu
2024-03-29 10:54:12,048 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-29 10:54:12,048 - config - INFO - learning_rate: 0.001
2024-03-29 10:54:12,048 - config - INFO - num_epochs: 260
2024-03-29 10:54:12,048 - config - INFO - batch_size: 64
2024-03-29 10:54:12,048 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-29 10:54:12,070 - config - INFO - Dataset size: 891
2024-03-29 10:54:12,104 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 92800)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(92800, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs += batch_outputs
                labels += batch_labels
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-29 10:54:12,105 - config - INFO - Training start
2024-03-29 10:54:14,877 - config - INFO - Epoch [1/260], Train Loss: 32.5076
2024-03-29 10:54:14,910 - config - INFO - Validation Loss: 38.7640
2024-03-29 10:54:14,911 - config - INFO - Validation Acc: 0.6124
2024-03-29 10:54:15,409 - config - INFO - Epoch [2/260], Train Loss: 38.3427
2024-03-29 10:54:15,439 - config - INFO - Validation Loss: 38.7640
2024-03-29 10:54:15,440 - config - INFO - Validation Acc: 0.6124
2024-03-29 10:54:15,939 - config - INFO - Epoch [3/260], Train Loss: 38.3427
2024-03-29 10:54:15,969 - config - INFO - Validation Loss: 38.7640
2024-03-29 10:54:15,970 - config - INFO - Validation Acc: 0.6124
2024-03-29 10:54:16,444 - config - INFO - Epoch [4/260], Train Loss: 38.3427
2024-03-29 10:54:16,474 - config - INFO - Validation Loss: 38.7640
2024-03-29 10:54:16,475 - config - INFO - Validation Acc: 0.6124
2024-03-29 10:54:16,971 - config - INFO - Epoch [5/260], Train Loss: 38.3427
2024-03-29 10:54:17,005 - config - INFO - Validation Loss: 38.7640
2024-03-29 10:54:17,006 - config - INFO - Validation Acc: 0.6124
2024-03-29 10:54:17,511 - config - INFO - Epoch [6/260], Train Loss: 38.3427
2024-03-29 10:54:17,543 - config - INFO - Validation Loss: 38.7640
2024-03-29 10:54:17,543 - config - INFO - Validation Acc: 0.6124
2024-03-29 10:54:18,048 - config - INFO - Epoch [7/260], Train Loss: 38.3427
2024-03-29 10:54:18,078 - config - INFO - Validation Loss: 38.7640
2024-03-29 10:54:18,078 - config - INFO - Validation Acc: 0.6124
2024-03-29 10:54:18,570 - config - INFO - Epoch [8/260], Train Loss: 38.3427
2024-03-29 10:54:18,599 - config - INFO - Validation Loss: 38.7640
2024-03-29 10:54:18,600 - config - INFO - Validation Acc: 0.6124
2024-03-29 10:54:19,088 - config - INFO - Epoch [9/260], Train Loss: 38.3427
2024-03-29 10:54:19,118 - config - INFO - Validation Loss: 38.7640
2024-03-29 10:54:19,118 - config - INFO - Validation Acc: 0.6124
2024-03-29 10:54:19,569 - config - INFO - Epoch [10/260], Train Loss: 38.3427
2024-03-29 10:54:19,599 - config - INFO - Validation Loss: 38.7640
2024-03-29 10:54:19,599 - config - INFO - Validation Acc: 0.6124
2024-03-29 10:54:20,032 - config - INFO - Epoch [11/260], Train Loss: 38.3427
2024-03-29 10:54:20,069 - config - INFO - Validation Loss: 38.7640
2024-03-29 10:54:20,070 - config - INFO - Validation Acc: 0.6124
2024-03-29 10:54:20,502 - config - INFO - Epoch [12/260], Train Loss: 38.3427
2024-03-29 10:54:20,532 - config - INFO - Validation Loss: 38.7640
2024-03-29 10:54:20,533 - config - INFO - Validation Acc: 0.6124
2024-03-29 10:54:21,023 - config - INFO - Epoch [13/260], Train Loss: 38.3427
2024-03-29 10:54:21,054 - config - INFO - Validation Loss: 38.7640
2024-03-29 10:54:21,054 - config - INFO - Validation Acc: 0.6124
2024-03-29 10:54:21,541 - config - INFO - Epoch [14/260], Train Loss: 38.3427
2024-03-29 10:54:21,575 - config - INFO - Validation Loss: 38.7640
2024-03-29 10:54:21,575 - config - INFO - Validation Acc: 0.6124
2024-03-29 10:54:22,035 - config - INFO - Epoch [15/260], Train Loss: 38.3427
2024-03-29 10:54:22,067 - config - INFO - Validation Loss: 38.7640
2024-03-29 10:54:22,067 - config - INFO - Validation Acc: 0.6124
2024-03-29 10:54:22,536 - config - INFO - Epoch [16/260], Train Loss: 38.3427
2024-03-29 10:54:22,565 - config - INFO - Validation Loss: 38.7640
2024-03-29 10:54:22,565 - config - INFO - Validation Acc: 0.6124
2024-03-29 10:54:22,975 - config - INFO - Epoch [17/260], Train Loss: 38.3427
2024-03-29 10:54:23,003 - config - INFO - Validation Loss: 38.7640
2024-03-29 10:54:23,004 - config - INFO - Validation Acc: 0.6124
2024-03-29 10:54:23,495 - config - INFO - Epoch [18/260], Train Loss: 38.3427
2024-03-29 10:54:23,526 - config - INFO - Validation Loss: 38.7640
2024-03-29 10:54:23,526 - config - INFO - Validation Acc: 0.6124
2024-03-29 10:54:23,993 - config - INFO - Epoch [19/260], Train Loss: 38.3427
2024-03-29 10:54:24,027 - config - INFO - Validation Loss: 38.7640
2024-03-29 10:54:24,027 - config - INFO - Validation Acc: 0.6124
2024-03-29 10:54:24,494 - config - INFO - Epoch [20/260], Train Loss: 38.3427
2024-03-29 10:54:24,524 - config - INFO - Validation Loss: 38.7640
2024-03-29 10:54:24,525 - config - INFO - Validation Acc: 0.6124
2024-03-29 10:54:24,982 - config - INFO - Epoch [21/260], Train Loss: 38.3427
2024-03-29 10:54:25,015 - config - INFO - Validation Loss: 38.7640
2024-03-29 10:54:25,016 - config - INFO - Validation Acc: 0.6124
2024-03-29 10:54:25,475 - config - INFO - Epoch [22/260], Train Loss: 38.3427
2024-03-29 10:54:25,506 - config - INFO - Validation Loss: 38.7640
2024-03-29 10:54:25,507 - config - INFO - Validation Acc: 0.6124
2024-03-29 10:54:25,957 - config - INFO - Epoch [23/260], Train Loss: 38.3427
2024-03-29 10:54:25,991 - config - INFO - Validation Loss: 38.7640
2024-03-29 10:54:25,991 - config - INFO - Validation Acc: 0.6124
2024-03-29 10:54:41,621 - config - INFO - resume: None
2024-03-29 10:54:41,622 - config - INFO - device: cpu
2024-03-29 10:54:41,622 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-29 10:54:41,622 - config - INFO - learning_rate: 0.001
2024-03-29 10:54:41,622 - config - INFO - num_epochs: 180
2024-03-29 10:54:41,622 - config - INFO - batch_size: 64
2024-03-29 10:54:41,622 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-29 10:54:41,663 - config - INFO - Dataset size: 891
2024-03-29 10:54:43,996 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 92800)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(92800, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs += batch_outputs
                labels += batch_labels
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-29 10:54:43,996 - config - INFO - Training start
2024-03-29 10:54:48,922 - config - INFO - Epoch [1/180], Train Loss: 33.2538
2024-03-29 10:55:00,669 - config - INFO - Validation Loss: 44.3820
2024-03-29 10:55:28,892 - config - INFO - Validation Acc: 0.5562
2024-03-29 10:55:29,510 - config - INFO - Epoch [2/180], Train Loss: 36.9382
2024-03-29 10:55:43,538 - config - INFO - Validation Loss: 44.3820
2024-03-29 10:56:27,097 - config - INFO - Validation Acc: 0.5562
2024-03-29 11:01:06,658 - config - INFO - Epoch [3/180], Train Loss: 36.9382
2024-03-29 11:01:06,706 - config - INFO - Validation Loss: 44.3820
2024-03-29 11:01:12,909 - config - INFO - Validation Acc: 0.5562
2024-03-29 11:01:16,159 - config - INFO - Epoch [4/180], Train Loss: 36.9382
2024-03-29 11:01:16,217 - config - INFO - Validation Loss: 44.3820
2024-03-29 11:01:16,218 - config - INFO - Validation Acc: 0.5562
2024-03-29 11:01:19,880 - config - INFO - Epoch [5/180], Train Loss: 36.9382
2024-03-29 11:01:19,914 - config - INFO - Validation Loss: 44.3820
2024-03-29 11:01:19,915 - config - INFO - Validation Acc: 0.5562
2024-03-29 11:01:26,038 - config - INFO - Epoch [6/180], Train Loss: 36.9382
2024-03-29 11:01:26,078 - config - INFO - Validation Loss: 44.3820
2024-03-29 11:01:26,078 - config - INFO - Validation Acc: 0.5562
2024-03-29 11:02:09,826 - config - INFO - Epoch [7/180], Train Loss: 36.9382
2024-03-29 11:02:09,867 - config - INFO - Validation Loss: 44.3820
2024-03-29 11:02:09,867 - config - INFO - Validation Acc: 0.5562
2024-03-29 11:08:37,623 - config - INFO - resume: None
2024-03-29 11:08:37,624 - config - INFO - device: cpu
2024-03-29 11:08:37,624 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-29 11:08:37,624 - config - INFO - learning_rate: 0.001
2024-03-29 11:08:37,624 - config - INFO - num_epochs: 180
2024-03-29 11:08:37,624 - config - INFO - batch_size: 64
2024-03-29 11:08:37,624 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-29 11:08:37,665 - config - INFO - Dataset size: 891
2024-03-29 11:08:39,546 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs += batch_outputs
                labels += batch_labels
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-29 11:08:39,546 - config - INFO - Training start
2024-03-29 11:11:02,517 - config - INFO - resume: None
2024-03-29 11:11:02,517 - config - INFO - device: cpu
2024-03-29 11:11:02,517 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-29 11:11:02,517 - config - INFO - learning_rate: 0.001
2024-03-29 11:11:02,517 - config - INFO - num_epochs: 180
2024-03-29 11:11:02,517 - config - INFO - batch_size: 64
2024-03-29 11:11:02,517 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-29 11:11:02,560 - config - INFO - Dataset size: 891
2024-03-29 11:11:04,897 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 12800)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(12800, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs += batch_outputs
                labels += batch_labels
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-29 11:11:04,897 - config - INFO - Training start
2024-03-29 11:11:53,047 - config - INFO - Epoch [1/180], Train Loss: 1.3932
2024-03-29 11:11:53,061 - config - INFO - Validation Loss: 0.5471
2024-03-29 11:11:53,062 - config - INFO - Validation Acc: 0.7022
2024-03-29 11:12:40,386 - config - INFO - resume: None
2024-03-29 11:12:40,386 - config - INFO - device: cpu
2024-03-29 11:12:40,386 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-03-29 11:12:40,386 - config - INFO - learning_rate: 0.001
2024-03-29 11:12:40,386 - config - INFO - num_epochs: 180
2024-03-29 11:12:40,386 - config - INFO - batch_size: 64
2024-03-29 11:12:40,387 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-29 11:12:40,429 - config - INFO - Dataset size: 891
2024-03-29 11:12:40,467 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs += batch_outputs
                labels += batch_labels
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-29 11:12:40,467 - config - INFO - Training start
2024-04-01 17:13:03,657 - config - INFO - resume: None
2024-04-01 17:13:03,657 - config - INFO - device: cpu
2024-04-01 17:13:03,657 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 17:13:03,657 - config - INFO - learning_rate: 0.001
2024-04-01 17:13:03,657 - config - INFO - num_epochs: 260
2024-04-01 17:13:03,657 - config - INFO - batch_size: 64
2024-04-01 17:13:03,657 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 17:13:03,679 - config - INFO - Dataset size: 891
2024-04-01 17:13:03,691 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs += batch_outputs
                labels += batch_labels
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 17:13:03,691 - config - INFO - Training start
2024-04-01 17:13:06,724 - config - INFO - Epoch [1/260], Train Loss: 0.0000
2024-04-01 17:13:06,773 - config - INFO - Validation Loss: 0.6834
2024-04-01 17:13:06,774 - config - INFO - Validation Acc: 0.6124
2024-04-01 17:13:07,471 - config - INFO - Epoch [2/260], Train Loss: 0.0000
2024-04-01 17:13:07,513 - config - INFO - Validation Loss: 0.6834
2024-04-01 17:13:07,520 - config - INFO - Validation Acc: 0.6124
2024-04-01 17:13:08,203 - config - INFO - Epoch [3/260], Train Loss: 0.0000
2024-04-01 17:13:08,246 - config - INFO - Validation Loss: 0.6834
2024-04-01 17:13:08,247 - config - INFO - Validation Acc: 0.6124
2024-04-01 17:13:08,939 - config - INFO - Epoch [4/260], Train Loss: 0.0000
2024-04-01 17:13:08,982 - config - INFO - Validation Loss: 0.6834
2024-04-01 17:13:08,983 - config - INFO - Validation Acc: 0.6124
2024-04-01 17:13:09,675 - config - INFO - Epoch [5/260], Train Loss: 0.0000
2024-04-01 17:13:09,715 - config - INFO - Validation Loss: 0.6834
2024-04-01 17:13:09,722 - config - INFO - Validation Acc: 0.6124
2024-04-01 17:13:10,361 - config - INFO - Epoch [6/260], Train Loss: 0.0000
2024-04-01 17:13:10,400 - config - INFO - Validation Loss: 0.6834
2024-04-01 17:13:10,400 - config - INFO - Validation Acc: 0.6124
2024-04-01 17:13:11,062 - config - INFO - Epoch [7/260], Train Loss: 0.0000
2024-04-01 17:13:11,100 - config - INFO - Validation Loss: 0.6834
2024-04-01 17:13:11,100 - config - INFO - Validation Acc: 0.6124
2024-04-01 17:13:11,735 - config - INFO - Epoch [8/260], Train Loss: 0.0000
2024-04-01 17:13:11,771 - config - INFO - Validation Loss: 0.6834
2024-04-01 17:13:11,772 - config - INFO - Validation Acc: 0.6124
2024-04-01 17:13:12,376 - config - INFO - Epoch [9/260], Train Loss: 0.0000
2024-04-01 17:13:12,415 - config - INFO - Validation Loss: 0.6834
2024-04-01 17:13:12,416 - config - INFO - Validation Acc: 0.6124
2024-04-01 17:13:13,041 - config - INFO - Epoch [10/260], Train Loss: 0.0000
2024-04-01 17:13:13,080 - config - INFO - Validation Loss: 0.6834
2024-04-01 17:13:13,081 - config - INFO - Validation Acc: 0.6124
2024-04-01 17:13:13,751 - config - INFO - Epoch [11/260], Train Loss: 0.0000
2024-04-01 17:13:13,789 - config - INFO - Validation Loss: 0.6834
2024-04-01 17:13:13,790 - config - INFO - Validation Acc: 0.6124
2024-04-01 17:13:14,419 - config - INFO - Epoch [12/260], Train Loss: 0.0000
2024-04-01 17:13:14,457 - config - INFO - Validation Loss: 0.6834
2024-04-01 17:13:14,465 - config - INFO - Validation Acc: 0.6124
2024-04-01 17:13:15,061 - config - INFO - Epoch [13/260], Train Loss: 0.0000
2024-04-01 17:13:15,098 - config - INFO - Validation Loss: 0.6834
2024-04-01 17:13:15,099 - config - INFO - Validation Acc: 0.6124
2024-04-01 17:13:15,702 - config - INFO - Epoch [14/260], Train Loss: 0.0000
2024-04-01 17:13:15,753 - config - INFO - Validation Loss: 0.6834
2024-04-01 17:13:15,753 - config - INFO - Validation Acc: 0.6124
2024-04-01 17:13:16,351 - config - INFO - Epoch [15/260], Train Loss: 0.0000
2024-04-01 17:13:16,390 - config - INFO - Validation Loss: 0.6834
2024-04-01 17:13:16,390 - config - INFO - Validation Acc: 0.6124
2024-04-01 17:13:17,003 - config - INFO - Epoch [16/260], Train Loss: 0.0000
2024-04-01 17:13:17,042 - config - INFO - Validation Loss: 0.6834
2024-04-01 17:13:17,043 - config - INFO - Validation Acc: 0.6124
2024-04-01 17:13:17,637 - config - INFO - Epoch [17/260], Train Loss: 0.0000
2024-04-01 17:13:17,678 - config - INFO - Validation Loss: 0.6834
2024-04-01 17:13:17,679 - config - INFO - Validation Acc: 0.6124
2024-04-01 17:13:18,282 - config - INFO - Epoch [18/260], Train Loss: 0.0000
2024-04-01 17:13:18,321 - config - INFO - Validation Loss: 0.6834
2024-04-01 17:13:18,321 - config - INFO - Validation Acc: 0.6124
2024-04-01 17:13:18,910 - config - INFO - Epoch [19/260], Train Loss: 0.0000
2024-04-01 17:13:18,949 - config - INFO - Validation Loss: 0.6834
2024-04-01 17:13:18,950 - config - INFO - Validation Acc: 0.6124
2024-04-01 17:13:19,610 - config - INFO - Epoch [20/260], Train Loss: 0.0000
2024-04-01 17:13:19,650 - config - INFO - Validation Loss: 0.6834
2024-04-01 17:13:19,657 - config - INFO - Validation Acc: 0.6124
2024-04-01 17:13:20,237 - config - INFO - Epoch [21/260], Train Loss: 0.0000
2024-04-01 17:13:20,276 - config - INFO - Validation Loss: 0.6834
2024-04-01 17:13:20,276 - config - INFO - Validation Acc: 0.6124
2024-04-01 17:14:11,292 - config - INFO - resume: None
2024-04-01 17:14:11,292 - config - INFO - device: cpu
2024-04-01 17:14:11,292 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 17:14:11,292 - config - INFO - learning_rate: 0.001
2024-04-01 17:14:11,292 - config - INFO - num_epochs: 260
2024-04-01 17:14:11,292 - config - INFO - batch_size: 64
2024-04-01 17:14:11,292 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 17:14:11,314 - config - INFO - Dataset size: 891
2024-04-01 17:14:34,993 - config - INFO - resume: None
2024-04-01 17:14:34,993 - config - INFO - device: cpu
2024-04-01 17:14:34,993 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 17:14:34,993 - config - INFO - learning_rate: 0.001
2024-04-01 17:14:34,993 - config - INFO - num_epochs: 260
2024-04-01 17:14:34,993 - config - INFO - batch_size: 64
2024-04-01 17:14:34,993 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 17:14:35,015 - config - INFO - Dataset size: 891
2024-04-01 17:16:10,748 - config - INFO - resume: None
2024-04-01 17:16:10,748 - config - INFO - device: cpu
2024-04-01 17:16:10,749 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 17:16:10,749 - config - INFO - learning_rate: 0.001
2024-04-01 17:16:10,749 - config - INFO - num_epochs: 260
2024-04-01 17:16:10,750 - config - INFO - batch_size: 64
2024-04-01 17:16:10,750 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 17:16:10,771 - config - INFO - Dataset size: 891
2024-04-01 17:16:10,808 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN1(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs)):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs += batch_outputs
                labels += batch_labels
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 17:16:10,808 - config - INFO - Training start
2024-04-01 17:18:01,421 - config - INFO - resume: None
2024-04-01 17:18:01,421 - config - INFO - device: cpu
2024-04-01 17:18:01,431 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 17:18:01,432 - config - INFO - learning_rate: 0.001
2024-04-01 17:18:01,432 - config - INFO - num_epochs: 180
2024-04-01 17:18:01,432 - config - INFO - batch_size: 64
2024-04-01 17:18:01,432 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 17:18:01,480 - config - INFO - Dataset size: 891
2024-04-01 17:18:01,493 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN1(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs += batch_outputs
                labels += batch_labels
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 17:18:01,494 - config - INFO - Training start
2024-04-01 17:27:37,737 - config - INFO - resume: None
2024-04-01 17:27:37,738 - config - INFO - device: cpu
2024-04-01 17:27:37,738 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 17:27:37,738 - config - INFO - learning_rate: 0.001
2024-04-01 17:27:37,738 - config - INFO - num_epochs: 260
2024-04-01 17:27:37,738 - config - INFO - batch_size: 64
2024-04-01 17:27:37,738 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 17:27:37,759 - config - INFO - Dataset size: 891
2024-04-01 17:27:37,795 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN1(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            loss = criterion(batch_outputs, batch_labels)
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs += batch_outputs
                labels += batch_labels
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 17:27:37,796 - config - INFO - Training start
2024-04-01 17:28:27,364 - config - INFO - resume: None
2024-04-01 17:28:27,364 - config - INFO - device: cpu
2024-04-01 17:28:27,365 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 17:28:27,365 - config - INFO - learning_rate: 0.001
2024-04-01 17:28:27,365 - config - INFO - num_epochs: 260
2024-04-01 17:28:27,365 - config - INFO - batch_size: 64
2024-04-01 17:28:27,365 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 17:28:27,386 - config - INFO - Dataset size: 891
2024-04-01 17:28:27,424 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN1(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs += batch_outputs
                labels += batch_labels
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 17:28:27,424 - config - INFO - Training start
2024-04-01 17:28:30,466 - config - INFO - Epoch [1/260], Train Loss: 12.3567
2024-04-01 17:29:33,089 - config - INFO - resume: None
2024-04-01 17:29:33,089 - config - INFO - device: cpu
2024-04-01 17:29:33,089 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 17:29:33,089 - config - INFO - learning_rate: 0.001
2024-04-01 17:29:33,089 - config - INFO - num_epochs: 260
2024-04-01 17:29:33,089 - config - INFO - batch_size: 64
2024-04-01 17:29:33,089 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 17:29:33,110 - config - INFO - Dataset size: 891
2024-04-01 17:29:33,140 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN1(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs += batch_outputs
                labels += batch_labels
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 17:29:33,141 - config - INFO - Training start
2024-04-01 17:29:36,103 - config - INFO - Epoch [1/260], Train Loss: 13.5975
2024-04-01 17:34:44,863 - config - INFO - resume: None
2024-04-01 17:34:44,864 - config - INFO - device: cpu
2024-04-01 17:34:44,864 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 17:34:44,864 - config - INFO - learning_rate: 0.001
2024-04-01 17:34:44,864 - config - INFO - num_epochs: 180
2024-04-01 17:34:44,864 - config - INFO - batch_size: 64
2024-04-01 17:34:44,864 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 17:34:44,907 - config - INFO - Dataset size: 891
2024-04-01 17:34:44,937 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN1(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs += batch_outputs
                labels += batch_labels
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 17:34:44,937 - config - INFO - Training start
2024-04-01 17:35:06,319 - config - INFO - Epoch [1/180], Train Loss: 13.4123
2024-04-01 17:38:33,507 - config - INFO - resume: None
2024-04-01 17:38:33,507 - config - INFO - device: cpu
2024-04-01 17:38:33,507 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 17:38:33,507 - config - INFO - learning_rate: 0.001
2024-04-01 17:38:33,507 - config - INFO - num_epochs: 260
2024-04-01 17:38:33,507 - config - INFO - batch_size: 64
2024-04-01 17:38:33,508 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 17:38:33,530 - config - INFO - Dataset size: 891
2024-04-01 17:38:33,568 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN1(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss()(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs += batch_outputs
                labels += batch_labels
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 17:38:33,568 - config - INFO - Training start
2024-04-01 17:38:36,460 - config - INFO - Epoch [1/260], Train Loss: 31.5904
2024-04-01 17:38:36,501 - config - INFO - Validation Loss: 33.7543
2024-04-01 17:40:04,928 - config - INFO - resume: None
2024-04-01 17:40:04,928 - config - INFO - device: cpu
2024-04-01 17:40:04,928 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 17:40:04,928 - config - INFO - learning_rate: 0.001
2024-04-01 17:40:04,929 - config - INFO - num_epochs: 180
2024-04-01 17:40:04,929 - config - INFO - batch_size: 64
2024-04-01 17:40:04,929 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 17:40:04,970 - config - INFO - Dataset size: 891
2024-04-01 17:40:04,983 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN1(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss()(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs += batch_outputs
                labels += batch_labels
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 17:40:04,983 - config - INFO - Training start
2024-04-01 17:40:22,095 - config - INFO - Epoch [1/180], Train Loss: 28.7722
2024-04-01 17:40:26,875 - config - INFO - Validation Loss: 39.6192
2024-04-01 17:42:50,731 - config - INFO - resume: None
2024-04-01 17:42:50,731 - config - INFO - device: cpu
2024-04-01 17:42:50,731 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 17:42:50,731 - config - INFO - learning_rate: 0.001
2024-04-01 17:42:50,731 - config - INFO - num_epochs: 180
2024-04-01 17:42:50,731 - config - INFO - batch_size: 64
2024-04-01 17:42:50,731 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 17:42:50,774 - config - INFO - Dataset size: 891
2024-04-01 17:42:50,805 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN1(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss()(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs += batch_outputs
                labels += batch_labels
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 17:42:50,805 - config - INFO - Training start
2024-04-01 17:42:58,422 - config - INFO - Epoch [1/180], Train Loss: 19.9559
2024-04-01 17:42:58,474 - config - INFO - Validation Loss: 19.1242
2024-04-01 17:47:57,173 - config - INFO - resume: None
2024-04-01 17:47:57,173 - config - INFO - device: cpu
2024-04-01 17:47:57,173 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 17:47:57,173 - config - INFO - learning_rate: 0.001
2024-04-01 17:47:57,173 - config - INFO - num_epochs: 180
2024-04-01 17:47:57,173 - config - INFO - batch_size: 64
2024-04-01 17:47:57,174 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 17:47:57,216 - config - INFO - Dataset size: 891
2024-04-01 17:47:57,256 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN1(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss()(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs.append(batch_outputs)
                labels.append(batch_labels)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 17:47:57,256 - config - INFO - Training start
2024-04-01 17:48:04,239 - config - INFO - Epoch [1/180], Train Loss: 20.7001
2024-04-01 17:48:04,311 - config - INFO - Validation Loss: 12.1739
2024-04-01 17:51:42,435 - config - INFO - resume: None
2024-04-01 17:51:42,435 - config - INFO - device: cpu
2024-04-01 17:51:42,435 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 17:51:42,435 - config - INFO - learning_rate: 0.001
2024-04-01 17:51:42,435 - config - INFO - num_epochs: 260
2024-04-01 17:51:42,435 - config - INFO - batch_size: 64
2024-04-01 17:51:42,435 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 17:51:42,462 - config - INFO - Dataset size: 891
2024-04-01 17:51:42,504 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN1(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss()(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs.append(batch_outputs)
                labels.append(batch_labels)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        if type(self.model).__name__ == 'MaNN1':
            val_acc = calculate_accuracy(torch.max(outputs, dim=1)[1], labels)
        else:
            val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 17:51:42,504 - config - INFO - Training start
2024-04-01 17:51:45,446 - config - INFO - Epoch [1/260], Train Loss: 22.2367
2024-04-01 17:51:45,490 - config - INFO - Validation Loss: 5.5202
2024-04-01 17:51:45,491 - config - INFO - Validation Acc: 0.4719
2024-04-01 17:51:46,156 - config - INFO - Epoch [2/260], Train Loss: 4.6071
2024-04-01 17:51:46,199 - config - INFO - Validation Loss: 2.9812
2024-04-01 17:51:46,200 - config - INFO - Validation Acc: 0.7022
2024-04-01 17:51:46,837 - config - INFO - Epoch [3/260], Train Loss: 2.7694
2024-04-01 17:51:46,881 - config - INFO - Validation Loss: 2.6075
2024-04-01 17:51:46,882 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:51:47,530 - config - INFO - Epoch [4/260], Train Loss: 2.7749
2024-04-01 17:51:47,574 - config - INFO - Validation Loss: 2.9201
2024-04-01 17:51:47,575 - config - INFO - Validation Acc: 0.7360
2024-04-01 17:51:48,214 - config - INFO - Epoch [5/260], Train Loss: 1.7382
2024-04-01 17:51:48,258 - config - INFO - Validation Loss: 1.8218
2024-04-01 17:51:48,259 - config - INFO - Validation Acc: 0.7360
2024-04-01 17:51:48,859 - config - INFO - Epoch [6/260], Train Loss: 1.5887
2024-04-01 17:51:48,902 - config - INFO - Validation Loss: 1.4419
2024-04-01 17:51:48,903 - config - INFO - Validation Acc: 0.7360
2024-04-01 17:51:49,479 - config - INFO - Epoch [7/260], Train Loss: 1.1273
2024-04-01 17:51:49,523 - config - INFO - Validation Loss: 3.0829
2024-04-01 17:51:49,523 - config - INFO - Validation Acc: 0.4607
2024-04-01 17:51:49,523 - config - INFO - Validation loss increased. Early stopping.
2024-04-01 17:52:39,477 - config - INFO - resume: None
2024-04-01 17:52:39,477 - config - INFO - device: cpu
2024-04-01 17:52:39,478 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 17:52:39,478 - config - INFO - learning_rate: 0.001
2024-04-01 17:52:39,478 - config - INFO - num_epochs: 260
2024-04-01 17:52:39,478 - config - INFO - batch_size: 64
2024-04-01 17:52:39,478 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 17:52:39,499 - config - INFO - Dataset size: 891
2024-04-01 17:52:39,540 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN1(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss()(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs.append(batch_outputs)
                labels.append(batch_labels)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        if type(self.model).__name__ == 'MaNN1':
            val_acc = calculate_accuracy(torch.max(outputs, dim=1)[1], labels)
        else:
            val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 17:52:39,540 - config - INFO - Training start
2024-04-01 17:52:42,534 - config - INFO - Epoch [1/260], Train Loss: 14.2633
2024-04-01 17:52:42,584 - config - INFO - Validation Loss: 6.4711
2024-04-01 17:52:42,585 - config - INFO - Validation Acc: 0.6517
2024-04-01 17:52:43,290 - config - INFO - Epoch [2/260], Train Loss: 4.0658
2024-04-01 17:52:43,337 - config - INFO - Validation Loss: 1.9432
2024-04-01 17:52:43,337 - config - INFO - Validation Acc: 0.7978
2024-04-01 17:52:44,011 - config - INFO - Epoch [3/260], Train Loss: 2.4487
2024-04-01 17:52:44,056 - config - INFO - Validation Loss: 1.4017
2024-04-01 17:52:44,057 - config - INFO - Validation Acc: 0.7865
2024-04-01 17:52:44,704 - config - INFO - Epoch [4/260], Train Loss: 1.5509
2024-04-01 17:52:44,748 - config - INFO - Validation Loss: 3.4675
2024-04-01 17:52:44,749 - config - INFO - Validation Acc: 0.6517
2024-04-01 17:52:44,749 - config - INFO - Validation loss increased. Early stopping.
2024-04-01 17:53:36,421 - config - INFO - resume: None
2024-04-01 17:53:36,421 - config - INFO - device: cpu
2024-04-01 17:53:36,421 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 17:53:36,421 - config - INFO - learning_rate: 0.001
2024-04-01 17:53:36,421 - config - INFO - num_epochs: 60
2024-04-01 17:53:36,421 - config - INFO - batch_size: 64
2024-04-01 17:53:36,422 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 10

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 17:53:36,443 - config - INFO - Dataset size: 891
2024-04-01 17:53:36,480 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN1(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss()(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs.append(batch_outputs)
                labels.append(batch_labels)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        if type(self.model).__name__ == 'MaNN1':
            val_acc = calculate_accuracy(torch.max(outputs, dim=1)[1], labels)
        else:
            val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 17:53:36,480 - config - INFO - Training start
2024-04-01 17:53:39,424 - config - INFO - Epoch [1/60], Train Loss: 27.0257
2024-04-01 17:53:39,482 - config - INFO - Validation Loss: 34.6442
2024-04-01 17:53:39,483 - config - INFO - Validation Acc: 0.5843
2024-04-01 17:53:40,138 - config - INFO - Epoch [2/60], Train Loss: 11.2100
2024-04-01 17:53:40,181 - config - INFO - Validation Loss: 3.8031
2024-04-01 17:53:40,182 - config - INFO - Validation Acc: 0.7416
2024-04-01 17:53:40,803 - config - INFO - Epoch [3/60], Train Loss: 4.6033
2024-04-01 17:53:40,850 - config - INFO - Validation Loss: 4.8376
2024-04-01 17:53:40,851 - config - INFO - Validation Acc: 0.7079
2024-04-01 17:53:41,465 - config - INFO - Epoch [4/60], Train Loss: 4.3614
2024-04-01 17:53:41,514 - config - INFO - Validation Loss: 4.2584
2024-04-01 17:53:41,515 - config - INFO - Validation Acc: 0.7528
2024-04-01 17:53:42,107 - config - INFO - Epoch [5/60], Train Loss: 2.6532
2024-04-01 17:53:42,151 - config - INFO - Validation Loss: 3.2320
2024-04-01 17:53:42,151 - config - INFO - Validation Acc: 0.7416
2024-04-01 17:53:42,737 - config - INFO - Epoch [6/60], Train Loss: 1.9632
2024-04-01 17:53:42,782 - config - INFO - Validation Loss: 3.5414
2024-04-01 17:53:42,783 - config - INFO - Validation Acc: 0.7360
2024-04-01 17:53:43,360 - config - INFO - Epoch [7/60], Train Loss: 2.1109
2024-04-01 17:53:43,412 - config - INFO - Validation Loss: 1.9037
2024-04-01 17:53:43,413 - config - INFO - Validation Acc: 0.7135
2024-04-01 17:53:43,967 - config - INFO - Epoch [8/60], Train Loss: 2.5893
2024-04-01 17:53:44,008 - config - INFO - Validation Loss: 3.2097
2024-04-01 17:53:44,008 - config - INFO - Validation Acc: 0.7809
2024-04-01 17:53:44,575 - config - INFO - Epoch [9/60], Train Loss: 3.1855
2024-04-01 17:53:44,615 - config - INFO - Validation Loss: 3.4282
2024-04-01 17:53:44,615 - config - INFO - Validation Acc: 0.7753
2024-04-01 17:53:45,183 - config - INFO - Epoch [10/60], Train Loss: 2.5055
2024-04-01 17:53:45,227 - config - INFO - Validation Loss: 2.5317
2024-04-01 17:53:45,228 - config - INFO - Validation Acc: 0.6966
2024-04-01 17:53:45,757 - config - INFO - Epoch [11/60], Train Loss: 1.5057
2024-04-01 17:53:45,803 - config - INFO - Validation Loss: 1.9017
2024-04-01 17:53:45,803 - config - INFO - Validation Acc: 0.7022
2024-04-01 17:53:46,341 - config - INFO - Epoch [12/60], Train Loss: 1.1587
2024-04-01 17:53:46,385 - config - INFO - Validation Loss: 3.2605
2024-04-01 17:53:46,385 - config - INFO - Validation Acc: 0.4719
2024-04-01 17:53:46,925 - config - INFO - Epoch [13/60], Train Loss: 1.6955
2024-04-01 17:53:46,967 - config - INFO - Validation Loss: 1.2045
2024-04-01 17:53:46,968 - config - INFO - Validation Acc: 0.7528
2024-04-01 17:53:47,491 - config - INFO - Epoch [14/60], Train Loss: 1.3682
2024-04-01 17:53:47,538 - config - INFO - Validation Loss: 2.2131
2024-04-01 17:53:47,539 - config - INFO - Validation Acc: 0.5787
2024-04-01 17:53:48,078 - config - INFO - Epoch [15/60], Train Loss: 1.5521
2024-04-01 17:53:48,120 - config - INFO - Validation Loss: 1.4528
2024-04-01 17:53:48,121 - config - INFO - Validation Acc: 0.7528
2024-04-01 17:53:48,679 - config - INFO - Epoch [16/60], Train Loss: 0.8448
2024-04-01 17:53:48,715 - config - INFO - Validation Loss: 1.1185
2024-04-01 17:53:48,715 - config - INFO - Validation Acc: 0.7191
2024-04-01 17:53:49,259 - config - INFO - Epoch [17/60], Train Loss: 4.0198
2024-04-01 17:53:49,301 - config - INFO - Validation Loss: 4.6187
2024-04-01 17:53:49,301 - config - INFO - Validation Acc: 0.5899
2024-04-01 17:53:49,839 - config - INFO - Epoch [18/60], Train Loss: 5.1911
2024-04-01 17:53:49,884 - config - INFO - Validation Loss: 4.5557
2024-04-01 17:53:49,885 - config - INFO - Validation Acc: 0.7360
2024-04-01 17:53:50,432 - config - INFO - Epoch [19/60], Train Loss: 2.6803
2024-04-01 17:53:50,477 - config - INFO - Validation Loss: 4.1323
2024-04-01 17:53:50,478 - config - INFO - Validation Acc: 0.6742
2024-04-01 17:53:51,037 - config - INFO - Epoch [20/60], Train Loss: 3.1931
2024-04-01 17:53:51,080 - config - INFO - Validation Loss: 2.8539
2024-04-01 17:53:51,081 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:53:51,640 - config - INFO - Epoch [21/60], Train Loss: 1.6576
2024-04-01 17:53:51,689 - config - INFO - Validation Loss: 5.3665
2024-04-01 17:53:51,689 - config - INFO - Validation Acc: 0.6629
2024-04-01 17:53:52,229 - config - INFO - Epoch [22/60], Train Loss: 4.3517
2024-04-01 17:53:52,278 - config - INFO - Validation Loss: 4.0282
2024-04-01 17:53:52,279 - config - INFO - Validation Acc: 0.7303
2024-04-01 17:53:52,799 - config - INFO - Epoch [23/60], Train Loss: 1.8653
2024-04-01 17:53:52,841 - config - INFO - Validation Loss: 3.1057
2024-04-01 17:53:52,841 - config - INFO - Validation Acc: 0.7753
2024-04-01 17:53:53,344 - config - INFO - Epoch [24/60], Train Loss: 2.3602
2024-04-01 17:53:53,386 - config - INFO - Validation Loss: 7.0289
2024-04-01 17:53:53,386 - config - INFO - Validation Acc: 0.6011
2024-04-01 17:53:53,921 - config - INFO - Epoch [25/60], Train Loss: 3.4820
2024-04-01 17:53:53,958 - config - INFO - Validation Loss: 4.9136
2024-04-01 17:53:53,959 - config - INFO - Validation Acc: 0.7303
2024-04-01 17:53:54,476 - config - INFO - Epoch [26/60], Train Loss: 2.2035
2024-04-01 17:53:54,525 - config - INFO - Validation Loss: 5.6063
2024-04-01 17:53:54,525 - config - INFO - Validation Acc: 0.6517
2024-04-01 17:53:55,011 - config - INFO - Epoch [27/60], Train Loss: 2.2773
2024-04-01 17:53:55,046 - config - INFO - Validation Loss: 6.3720
2024-04-01 17:53:55,047 - config - INFO - Validation Acc: 0.6180
2024-04-01 17:53:55,550 - config - INFO - Epoch [28/60], Train Loss: 3.1434
2024-04-01 17:53:55,597 - config - INFO - Validation Loss: 2.1870
2024-04-01 17:53:55,597 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:53:56,109 - config - INFO - Epoch [29/60], Train Loss: 1.8867
2024-04-01 17:53:56,150 - config - INFO - Validation Loss: 1.9625
2024-04-01 17:53:56,151 - config - INFO - Validation Acc: 0.7697
2024-04-01 17:53:56,666 - config - INFO - Epoch [30/60], Train Loss: 1.3935
2024-04-01 17:53:56,707 - config - INFO - Validation Loss: 1.3120
2024-04-01 17:53:56,707 - config - INFO - Validation Acc: 0.7416
2024-04-01 17:53:57,259 - config - INFO - Epoch [31/60], Train Loss: 1.1540
2024-04-01 17:53:57,292 - config - INFO - Validation Loss: 0.8919
2024-04-01 17:53:57,292 - config - INFO - Validation Acc: 0.7247
2024-04-01 17:53:57,796 - config - INFO - Epoch [32/60], Train Loss: 1.7860
2024-04-01 17:53:57,841 - config - INFO - Validation Loss: 7.2154
2024-04-01 17:53:57,842 - config - INFO - Validation Acc: 0.5843
2024-04-01 17:53:58,360 - config - INFO - Epoch [33/60], Train Loss: 3.2121
2024-04-01 17:53:58,406 - config - INFO - Validation Loss: 2.1154
2024-04-01 17:53:58,406 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:53:58,939 - config - INFO - Epoch [34/60], Train Loss: 1.6904
2024-04-01 17:53:58,974 - config - INFO - Validation Loss: 1.8185
2024-04-01 17:53:58,975 - config - INFO - Validation Acc: 0.7528
2024-04-01 17:53:59,499 - config - INFO - Epoch [35/60], Train Loss: 2.0864
2024-04-01 17:53:59,539 - config - INFO - Validation Loss: 1.6111
2024-04-01 17:53:59,539 - config - INFO - Validation Acc: 0.7360
2024-04-01 17:54:00,059 - config - INFO - Epoch [36/60], Train Loss: 1.8364
2024-04-01 17:54:00,100 - config - INFO - Validation Loss: 2.9178
2024-04-01 17:54:00,100 - config - INFO - Validation Acc: 0.7191
2024-04-01 17:54:00,611 - config - INFO - Epoch [37/60], Train Loss: 1.8289
2024-04-01 17:54:00,657 - config - INFO - Validation Loss: 2.8454
2024-04-01 17:54:00,658 - config - INFO - Validation Acc: 0.6236
2024-04-01 17:54:01,163 - config - INFO - Epoch [38/60], Train Loss: 3.4341
2024-04-01 17:54:01,198 - config - INFO - Validation Loss: 2.2994
2024-04-01 17:54:01,199 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:54:01,724 - config - INFO - Epoch [39/60], Train Loss: 2.0167
2024-04-01 17:54:01,772 - config - INFO - Validation Loss: 2.5871
2024-04-01 17:54:01,773 - config - INFO - Validation Acc: 0.6798
2024-04-01 17:54:02,271 - config - INFO - Epoch [40/60], Train Loss: 2.0296
2024-04-01 17:54:02,305 - config - INFO - Validation Loss: 1.7201
2024-04-01 17:54:02,313 - config - INFO - Validation Acc: 0.7416
2024-04-01 17:54:02,824 - config - INFO - Epoch [41/60], Train Loss: 1.4830
2024-04-01 17:54:02,866 - config - INFO - Validation Loss: 3.1067
2024-04-01 17:54:02,867 - config - INFO - Validation Acc: 0.4775
2024-04-01 17:54:03,391 - config - INFO - Epoch [42/60], Train Loss: 1.6358
2024-04-01 17:54:03,432 - config - INFO - Validation Loss: 1.5201
2024-04-01 17:54:03,432 - config - INFO - Validation Acc: 0.7416
2024-04-01 17:54:03,932 - config - INFO - Epoch [43/60], Train Loss: 1.4822
2024-04-01 17:54:03,973 - config - INFO - Validation Loss: 2.8557
2024-04-01 17:54:03,973 - config - INFO - Validation Acc: 0.6966
2024-04-01 17:54:04,473 - config - INFO - Epoch [44/60], Train Loss: 2.7532
2024-04-01 17:54:04,514 - config - INFO - Validation Loss: 5.5475
2024-04-01 17:54:04,515 - config - INFO - Validation Acc: 0.6348
2024-04-01 17:54:05,006 - config - INFO - Epoch [45/60], Train Loss: 3.2046
2024-04-01 17:54:05,057 - config - INFO - Validation Loss: 4.8317
2024-04-01 17:54:05,057 - config - INFO - Validation Acc: 0.7528
2024-04-01 17:54:05,566 - config - INFO - Epoch [46/60], Train Loss: 2.4450
2024-04-01 17:54:05,609 - config - INFO - Validation Loss: 6.7702
2024-04-01 17:54:05,610 - config - INFO - Validation Acc: 0.6798
2024-04-01 17:54:06,095 - config - INFO - Epoch [47/60], Train Loss: 4.6364
2024-04-01 17:54:06,141 - config - INFO - Validation Loss: 4.5247
2024-04-01 17:54:06,141 - config - INFO - Validation Acc: 0.7416
2024-04-01 17:54:06,641 - config - INFO - Epoch [48/60], Train Loss: 4.0875
2024-04-01 17:54:06,684 - config - INFO - Validation Loss: 7.0413
2024-04-01 17:54:06,684 - config - INFO - Validation Acc: 0.4719
2024-04-01 17:54:07,199 - config - INFO - Epoch [49/60], Train Loss: 3.4525
2024-04-01 17:54:07,235 - config - INFO - Validation Loss: 3.6173
2024-04-01 17:54:07,235 - config - INFO - Validation Acc: 0.7528
2024-04-01 17:54:07,758 - config - INFO - Epoch [50/60], Train Loss: 3.2734
2024-04-01 17:54:07,799 - config - INFO - Validation Loss: 2.7881
2024-04-01 17:54:07,799 - config - INFO - Validation Acc: 0.7697
2024-04-01 17:54:08,314 - config - INFO - Epoch [51/60], Train Loss: 1.8958
2024-04-01 17:54:08,348 - config - INFO - Validation Loss: 2.2334
2024-04-01 17:54:08,349 - config - INFO - Validation Acc: 0.7416
2024-04-01 17:54:08,856 - config - INFO - Epoch [52/60], Train Loss: 1.3357
2024-04-01 17:54:08,890 - config - INFO - Validation Loss: 1.7259
2024-04-01 17:54:08,890 - config - INFO - Validation Acc: 0.7079
2024-04-01 17:54:09,408 - config - INFO - Epoch [53/60], Train Loss: 1.0492
2024-04-01 17:54:09,455 - config - INFO - Validation Loss: 1.0139
2024-04-01 17:54:09,455 - config - INFO - Validation Acc: 0.7528
2024-04-01 17:54:09,966 - config - INFO - Epoch [54/60], Train Loss: 1.8977
2024-04-01 17:54:10,007 - config - INFO - Validation Loss: 5.2834
2024-04-01 17:54:10,008 - config - INFO - Validation Acc: 0.5843
2024-04-01 17:54:10,514 - config - INFO - Epoch [55/60], Train Loss: 1.8507
2024-04-01 17:54:10,555 - config - INFO - Validation Loss: 1.8215
2024-04-01 17:54:10,555 - config - INFO - Validation Acc: 0.7809
2024-04-01 17:54:11,046 - config - INFO - Epoch [56/60], Train Loss: 1.2307
2024-04-01 17:54:11,092 - config - INFO - Validation Loss: 1.3145
2024-04-01 17:54:11,092 - config - INFO - Validation Acc: 0.7528
2024-04-01 17:54:11,602 - config - INFO - Epoch [57/60], Train Loss: 0.9233
2024-04-01 17:54:11,642 - config - INFO - Validation Loss: 3.5367
2024-04-01 17:54:11,642 - config - INFO - Validation Acc: 0.5843
2024-04-01 17:54:12,157 - config - INFO - Epoch [58/60], Train Loss: 2.8202
2024-04-01 17:54:12,191 - config - INFO - Validation Loss: 7.1262
2024-04-01 17:54:12,192 - config - INFO - Validation Acc: 0.5843
2024-04-01 17:54:12,718 - config - INFO - Epoch [59/60], Train Loss: 2.5849
2024-04-01 17:54:12,753 - config - INFO - Validation Loss: 1.8618
2024-04-01 17:54:12,754 - config - INFO - Validation Acc: 0.7584
2024-04-01 17:54:13,233 - config - INFO - Epoch [60/60], Train Loss: 1.5552
2024-04-01 17:54:13,272 - config - INFO - Validation Loss: 3.9987
2024-04-01 17:54:13,273 - config - INFO - Validation Acc: 0.4775
2024-04-01 17:56:59,883 - config - INFO - resume: None
2024-04-01 17:56:59,884 - config - INFO - device: cpu
2024-04-01 17:56:59,884 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 17:56:59,884 - config - INFO - learning_rate: 0.001
2024-04-01 17:56:59,884 - config - INFO - num_epochs: 60
2024-04-01 17:56:59,884 - config - INFO - batch_size: 64
2024-04-01 17:56:59,884 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 10

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 17:56:59,905 - config - INFO - Dataset size: 891
2024-04-01 17:56:59,931 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128, 2)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN1(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss()(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs.append(batch_outputs)
                labels.append(batch_labels)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        if type(self.model).__name__ == 'MaNN1':
            val_acc = calculate_accuracy(torch.max(outputs, dim=1)[1], labels)
        else:
            val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 17:56:59,931 - config - INFO - Training start
2024-04-01 17:57:02,378 - config - INFO - Epoch [1/60], Train Loss: 0.6662
2024-04-01 17:57:02,383 - config - INFO - Validation Loss: 0.6388
2024-04-01 17:57:02,384 - config - INFO - Validation Acc: 0.6348
2024-04-01 17:57:02,424 - config - INFO - Epoch [2/60], Train Loss: 0.6310
2024-04-01 17:57:02,429 - config - INFO - Validation Loss: 0.6162
2024-04-01 17:57:02,430 - config - INFO - Validation Acc: 0.6348
2024-04-01 17:57:02,469 - config - INFO - Epoch [3/60], Train Loss: 0.6072
2024-04-01 17:57:02,474 - config - INFO - Validation Loss: 0.5992
2024-04-01 17:57:02,475 - config - INFO - Validation Acc: 0.6629
2024-04-01 17:57:02,514 - config - INFO - Epoch [4/60], Train Loss: 0.5866
2024-04-01 17:57:02,519 - config - INFO - Validation Loss: 0.5832
2024-04-01 17:57:02,520 - config - INFO - Validation Acc: 0.6910
2024-04-01 17:57:02,560 - config - INFO - Epoch [5/60], Train Loss: 0.5644
2024-04-01 17:57:02,565 - config - INFO - Validation Loss: 0.5688
2024-04-01 17:57:02,565 - config - INFO - Validation Acc: 0.6854
2024-04-01 17:57:02,605 - config - INFO - Epoch [6/60], Train Loss: 0.5506
2024-04-01 17:57:02,611 - config - INFO - Validation Loss: 0.5547
2024-04-01 17:57:02,611 - config - INFO - Validation Acc: 0.7079
2024-04-01 17:57:02,645 - config - INFO - Epoch [7/60], Train Loss: 0.5332
2024-04-01 17:57:02,649 - config - INFO - Validation Loss: 0.5448
2024-04-01 17:57:02,650 - config - INFO - Validation Acc: 0.7809
2024-04-01 17:57:02,679 - config - INFO - Epoch [8/60], Train Loss: 0.5203
2024-04-01 17:57:02,684 - config - INFO - Validation Loss: 0.5322
2024-04-01 17:57:02,684 - config - INFO - Validation Acc: 0.7809
2024-04-01 17:57:02,714 - config - INFO - Epoch [9/60], Train Loss: 0.5050
2024-04-01 17:57:02,719 - config - INFO - Validation Loss: 0.5251
2024-04-01 17:57:02,719 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:57:02,748 - config - INFO - Epoch [10/60], Train Loss: 0.4957
2024-04-01 17:57:02,753 - config - INFO - Validation Loss: 0.5152
2024-04-01 17:57:02,753 - config - INFO - Validation Acc: 0.7809
2024-04-01 17:57:02,784 - config - INFO - Epoch [11/60], Train Loss: 0.4852
2024-04-01 17:57:02,788 - config - INFO - Validation Loss: 0.5079
2024-04-01 17:57:02,789 - config - INFO - Validation Acc: 0.7921
2024-04-01 17:57:02,818 - config - INFO - Epoch [12/60], Train Loss: 0.4782
2024-04-01 17:57:02,823 - config - INFO - Validation Loss: 0.5034
2024-04-01 17:57:02,823 - config - INFO - Validation Acc: 0.7753
2024-04-01 17:57:02,853 - config - INFO - Epoch [13/60], Train Loss: 0.4731
2024-04-01 17:57:02,858 - config - INFO - Validation Loss: 0.4977
2024-04-01 17:57:02,858 - config - INFO - Validation Acc: 0.7697
2024-04-01 17:57:02,895 - config - INFO - Epoch [14/60], Train Loss: 0.4651
2024-04-01 17:57:02,904 - config - INFO - Validation Loss: 0.4932
2024-04-01 17:57:02,904 - config - INFO - Validation Acc: 0.7753
2024-04-01 17:57:02,932 - config - INFO - Epoch [15/60], Train Loss: 0.4596
2024-04-01 17:57:02,937 - config - INFO - Validation Loss: 0.4899
2024-04-01 17:57:02,937 - config - INFO - Validation Acc: 0.7753
2024-04-01 17:57:02,964 - config - INFO - Epoch [16/60], Train Loss: 0.4553
2024-04-01 17:57:02,968 - config - INFO - Validation Loss: 0.4864
2024-04-01 17:57:02,968 - config - INFO - Validation Acc: 0.7809
2024-04-01 17:57:02,997 - config - INFO - Epoch [17/60], Train Loss: 0.4524
2024-04-01 17:57:03,001 - config - INFO - Validation Loss: 0.4846
2024-04-01 17:57:03,001 - config - INFO - Validation Acc: 0.7697
2024-04-01 17:57:03,024 - config - INFO - Epoch [18/60], Train Loss: 0.4487
2024-04-01 17:57:03,028 - config - INFO - Validation Loss: 0.4835
2024-04-01 17:57:03,028 - config - INFO - Validation Acc: 0.7528
2024-04-01 17:57:03,051 - config - INFO - Epoch [19/60], Train Loss: 0.4471
2024-04-01 17:57:03,054 - config - INFO - Validation Loss: 0.4819
2024-04-01 17:57:03,055 - config - INFO - Validation Acc: 0.7528
2024-04-01 17:57:03,077 - config - INFO - Epoch [20/60], Train Loss: 0.4463
2024-04-01 17:57:03,081 - config - INFO - Validation Loss: 0.4811
2024-04-01 17:57:03,081 - config - INFO - Validation Acc: 0.7416
2024-04-01 17:57:03,104 - config - INFO - Epoch [21/60], Train Loss: 0.4437
2024-04-01 17:57:03,108 - config - INFO - Validation Loss: 0.4801
2024-04-01 17:57:03,108 - config - INFO - Validation Acc: 0.7640
2024-04-01 17:57:03,146 - config - INFO - Epoch [22/60], Train Loss: 0.4412
2024-04-01 17:57:03,150 - config - INFO - Validation Loss: 0.4803
2024-04-01 17:57:03,150 - config - INFO - Validation Acc: 0.7416
2024-04-01 17:57:03,172 - config - INFO - Epoch [23/60], Train Loss: 0.4398
2024-04-01 17:57:03,176 - config - INFO - Validation Loss: 0.4787
2024-04-01 17:57:03,176 - config - INFO - Validation Acc: 0.7584
2024-04-01 17:57:03,199 - config - INFO - Epoch [24/60], Train Loss: 0.4391
2024-04-01 17:57:03,202 - config - INFO - Validation Loss: 0.4791
2024-04-01 17:57:03,203 - config - INFO - Validation Acc: 0.7416
2024-04-01 17:57:03,226 - config - INFO - Epoch [25/60], Train Loss: 0.4384
2024-04-01 17:57:03,229 - config - INFO - Validation Loss: 0.4800
2024-04-01 17:57:03,229 - config - INFO - Validation Acc: 0.7416
2024-04-01 17:57:03,252 - config - INFO - Epoch [26/60], Train Loss: 0.4373
2024-04-01 17:57:03,256 - config - INFO - Validation Loss: 0.4792
2024-04-01 17:57:03,256 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:57:03,279 - config - INFO - Epoch [27/60], Train Loss: 0.4378
2024-04-01 17:57:03,282 - config - INFO - Validation Loss: 0.4787
2024-04-01 17:57:03,283 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:57:03,306 - config - INFO - Epoch [28/60], Train Loss: 0.4354
2024-04-01 17:57:03,310 - config - INFO - Validation Loss: 0.4817
2024-04-01 17:57:03,310 - config - INFO - Validation Acc: 0.7303
2024-04-01 17:57:03,333 - config - INFO - Epoch [29/60], Train Loss: 0.4365
2024-04-01 17:57:03,337 - config - INFO - Validation Loss: 0.4790
2024-04-01 17:57:03,337 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:57:03,360 - config - INFO - Epoch [30/60], Train Loss: 0.4352
2024-04-01 17:57:03,367 - config - INFO - Validation Loss: 0.4795
2024-04-01 17:57:03,368 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:57:03,396 - config - INFO - Epoch [31/60], Train Loss: 0.4345
2024-04-01 17:57:03,400 - config - INFO - Validation Loss: 0.4797
2024-04-01 17:57:03,400 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:57:03,423 - config - INFO - Epoch [32/60], Train Loss: 0.4361
2024-04-01 17:57:03,427 - config - INFO - Validation Loss: 0.4809
2024-04-01 17:57:03,427 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:57:03,450 - config - INFO - Epoch [33/60], Train Loss: 0.4351
2024-04-01 17:57:03,454 - config - INFO - Validation Loss: 0.4848
2024-04-01 17:57:03,454 - config - INFO - Validation Acc: 0.7303
2024-04-01 17:57:03,477 - config - INFO - Epoch [34/60], Train Loss: 0.4358
2024-04-01 17:57:03,481 - config - INFO - Validation Loss: 0.4806
2024-04-01 17:57:03,481 - config - INFO - Validation Acc: 0.7416
2024-04-01 17:57:03,504 - config - INFO - Epoch [35/60], Train Loss: 0.4338
2024-04-01 17:57:03,508 - config - INFO - Validation Loss: 0.4816
2024-04-01 17:57:03,508 - config - INFO - Validation Acc: 0.7360
2024-04-01 17:57:03,531 - config - INFO - Epoch [36/60], Train Loss: 0.4346
2024-04-01 17:57:03,534 - config - INFO - Validation Loss: 0.4830
2024-04-01 17:57:03,535 - config - INFO - Validation Acc: 0.7360
2024-04-01 17:57:03,559 - config - INFO - Epoch [37/60], Train Loss: 0.4341
2024-04-01 17:57:03,563 - config - INFO - Validation Loss: 0.4809
2024-04-01 17:57:03,564 - config - INFO - Validation Acc: 0.7416
2024-04-01 17:57:03,589 - config - INFO - Epoch [38/60], Train Loss: 0.4338
2024-04-01 17:57:03,593 - config - INFO - Validation Loss: 0.4814
2024-04-01 17:57:03,593 - config - INFO - Validation Acc: 0.7416
2024-04-01 17:57:03,619 - config - INFO - Epoch [39/60], Train Loss: 0.4340
2024-04-01 17:57:03,623 - config - INFO - Validation Loss: 0.4801
2024-04-01 17:57:03,624 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:57:03,652 - config - INFO - Epoch [40/60], Train Loss: 0.4335
2024-04-01 17:57:03,656 - config - INFO - Validation Loss: 0.4805
2024-04-01 17:57:03,657 - config - INFO - Validation Acc: 0.7528
2024-04-01 17:57:03,681 - config - INFO - Epoch [41/60], Train Loss: 0.4342
2024-04-01 17:57:03,685 - config - INFO - Validation Loss: 0.4816
2024-04-01 17:57:03,685 - config - INFO - Validation Acc: 0.7416
2024-04-01 17:57:03,711 - config - INFO - Epoch [42/60], Train Loss: 0.4335
2024-04-01 17:57:03,715 - config - INFO - Validation Loss: 0.4789
2024-04-01 17:57:03,715 - config - INFO - Validation Acc: 0.7528
2024-04-01 17:57:03,742 - config - INFO - Epoch [43/60], Train Loss: 0.4338
2024-04-01 17:57:03,746 - config - INFO - Validation Loss: 0.4790
2024-04-01 17:57:03,746 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:57:03,773 - config - INFO - Epoch [44/60], Train Loss: 0.4355
2024-04-01 17:57:03,777 - config - INFO - Validation Loss: 0.4807
2024-04-01 17:57:03,777 - config - INFO - Validation Acc: 0.7360
2024-04-01 17:57:03,804 - config - INFO - Epoch [45/60], Train Loss: 0.4349
2024-04-01 17:57:03,808 - config - INFO - Validation Loss: 0.4785
2024-04-01 17:57:03,808 - config - INFO - Validation Acc: 0.7528
2024-04-01 17:57:03,835 - config - INFO - Epoch [46/60], Train Loss: 0.4335
2024-04-01 17:57:03,839 - config - INFO - Validation Loss: 0.4783
2024-04-01 17:57:03,839 - config - INFO - Validation Acc: 0.7528
2024-04-01 17:57:03,865 - config - INFO - Epoch [47/60], Train Loss: 0.4334
2024-04-01 17:57:03,870 - config - INFO - Validation Loss: 0.4785
2024-04-01 17:57:03,870 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:57:03,896 - config - INFO - Epoch [48/60], Train Loss: 0.4339
2024-04-01 17:57:03,900 - config - INFO - Validation Loss: 0.4838
2024-04-01 17:57:03,900 - config - INFO - Validation Acc: 0.7191
2024-04-01 17:57:03,928 - config - INFO - Epoch [49/60], Train Loss: 0.4334
2024-04-01 17:57:03,932 - config - INFO - Validation Loss: 0.4783
2024-04-01 17:57:03,932 - config - INFO - Validation Acc: 0.7528
2024-04-01 17:57:03,958 - config - INFO - Epoch [50/60], Train Loss: 0.4335
2024-04-01 17:57:03,962 - config - INFO - Validation Loss: 0.4789
2024-04-01 17:57:03,963 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:57:03,989 - config - INFO - Epoch [51/60], Train Loss: 0.4321
2024-04-01 17:57:03,993 - config - INFO - Validation Loss: 0.4815
2024-04-01 17:57:03,993 - config - INFO - Validation Acc: 0.7416
2024-04-01 17:57:04,019 - config - INFO - Epoch [52/60], Train Loss: 0.4332
2024-04-01 17:57:04,023 - config - INFO - Validation Loss: 0.4790
2024-04-01 17:57:04,024 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:57:04,051 - config - INFO - Epoch [53/60], Train Loss: 0.4382
2024-04-01 17:57:04,055 - config - INFO - Validation Loss: 0.4793
2024-04-01 17:57:04,055 - config - INFO - Validation Acc: 0.7640
2024-04-01 17:57:04,082 - config - INFO - Epoch [54/60], Train Loss: 0.4327
2024-04-01 17:57:04,086 - config - INFO - Validation Loss: 0.4809
2024-04-01 17:57:04,086 - config - INFO - Validation Acc: 0.7303
2024-04-01 17:57:04,112 - config - INFO - Epoch [55/60], Train Loss: 0.4343
2024-04-01 17:57:04,117 - config - INFO - Validation Loss: 0.4796
2024-04-01 17:57:04,117 - config - INFO - Validation Acc: 0.7360
2024-04-01 17:57:04,148 - config - INFO - Epoch [56/60], Train Loss: 0.4316
2024-04-01 17:57:04,152 - config - INFO - Validation Loss: 0.4784
2024-04-01 17:57:04,153 - config - INFO - Validation Acc: 0.7528
2024-04-01 17:57:04,179 - config - INFO - Epoch [57/60], Train Loss: 0.4322
2024-04-01 17:57:04,183 - config - INFO - Validation Loss: 0.4790
2024-04-01 17:57:04,184 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:57:04,210 - config - INFO - Epoch [58/60], Train Loss: 0.4350
2024-04-01 17:57:04,214 - config - INFO - Validation Loss: 0.4810
2024-04-01 17:57:04,214 - config - INFO - Validation Acc: 0.7584
2024-04-01 17:57:04,240 - config - INFO - Epoch [59/60], Train Loss: 0.4337
2024-04-01 17:57:04,244 - config - INFO - Validation Loss: 0.4792
2024-04-01 17:57:04,245 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:57:04,271 - config - INFO - Epoch [60/60], Train Loss: 0.4329
2024-04-01 17:57:04,275 - config - INFO - Validation Loss: 0.4807
2024-04-01 17:57:04,275 - config - INFO - Validation Acc: 0.7416
2024-04-01 17:57:46,998 - config - INFO - resume: None
2024-04-01 17:57:46,998 - config - INFO - device: cpu
2024-04-01 17:57:47,008 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 17:57:47,008 - config - INFO - learning_rate: 0.001
2024-04-01 17:57:47,008 - config - INFO - num_epochs: 60
2024-04-01 17:57:47,008 - config - INFO - batch_size: 64
2024-04-01 17:57:47,008 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 10

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 17:57:47,033 - config - INFO - Dataset size: 891
2024-04-01 17:57:47,061 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 12800)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(12800, 2)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN1(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss()(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs.append(batch_outputs)
                labels.append(batch_labels)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        if type(self.model).__name__ == 'MaNN1':
            val_acc = calculate_accuracy(torch.max(outputs, dim=1)[1], labels)
        else:
            val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 17:57:47,061 - config - INFO - Training start
2024-04-01 17:57:49,354 - config - INFO - Epoch [1/60], Train Loss: 2.1255
2024-04-01 17:57:49,362 - config - INFO - Validation Loss: 0.6663
2024-04-01 17:57:49,363 - config - INFO - Validation Acc: 0.6742
2024-04-01 17:57:49,504 - config - INFO - Epoch [2/60], Train Loss: 0.8606
2024-04-01 17:57:49,511 - config - INFO - Validation Loss: 0.4674
2024-04-01 17:57:49,511 - config - INFO - Validation Acc: 0.8202
2024-04-01 17:57:49,660 - config - INFO - Epoch [3/60], Train Loss: 0.5119
2024-04-01 17:57:49,668 - config - INFO - Validation Loss: 0.4655
2024-04-01 17:57:49,668 - config - INFO - Validation Acc: 0.8202
2024-04-01 17:57:49,834 - config - INFO - Epoch [4/60], Train Loss: 0.4812
2024-04-01 17:57:49,841 - config - INFO - Validation Loss: 0.4502
2024-04-01 17:57:49,842 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:57:49,991 - config - INFO - Epoch [5/60], Train Loss: 0.4982
2024-04-01 17:57:49,999 - config - INFO - Validation Loss: 0.5306
2024-04-01 17:57:50,000 - config - INFO - Validation Acc: 0.7697
2024-04-01 17:57:50,142 - config - INFO - Epoch [6/60], Train Loss: 0.4966
2024-04-01 17:57:50,150 - config - INFO - Validation Loss: 0.4528
2024-04-01 17:57:50,150 - config - INFO - Validation Acc: 0.7865
2024-04-01 17:57:50,302 - config - INFO - Epoch [7/60], Train Loss: 0.4683
2024-04-01 17:57:50,310 - config - INFO - Validation Loss: 0.4426
2024-04-01 17:57:50,310 - config - INFO - Validation Acc: 0.8202
2024-04-01 17:57:50,463 - config - INFO - Epoch [8/60], Train Loss: 0.4789
2024-04-01 17:57:50,471 - config - INFO - Validation Loss: 0.5825
2024-04-01 17:57:50,471 - config - INFO - Validation Acc: 0.7528
2024-04-01 17:57:50,620 - config - INFO - Epoch [9/60], Train Loss: 0.5200
2024-04-01 17:57:50,628 - config - INFO - Validation Loss: 0.4264
2024-04-01 17:57:50,628 - config - INFO - Validation Acc: 0.8315
2024-04-01 17:57:50,787 - config - INFO - Epoch [10/60], Train Loss: 0.4727
2024-04-01 17:57:50,795 - config - INFO - Validation Loss: 0.4664
2024-04-01 17:57:50,795 - config - INFO - Validation Acc: 0.8202
2024-04-01 17:57:50,948 - config - INFO - Epoch [11/60], Train Loss: 0.4989
2024-04-01 17:57:50,957 - config - INFO - Validation Loss: 0.5823
2024-04-01 17:57:50,957 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:57:51,106 - config - INFO - Epoch [12/60], Train Loss: 0.5323
2024-04-01 17:57:51,113 - config - INFO - Validation Loss: 0.4365
2024-04-01 17:57:51,113 - config - INFO - Validation Acc: 0.8202
2024-04-01 17:57:51,261 - config - INFO - Epoch [13/60], Train Loss: 0.4579
2024-04-01 17:57:51,268 - config - INFO - Validation Loss: 0.4400
2024-04-01 17:57:51,268 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:57:51,426 - config - INFO - Epoch [14/60], Train Loss: 0.4854
2024-04-01 17:57:51,433 - config - INFO - Validation Loss: 0.6224
2024-04-01 17:57:51,433 - config - INFO - Validation Acc: 0.7135
2024-04-01 17:57:51,575 - config - INFO - Epoch [15/60], Train Loss: 0.5268
2024-04-01 17:57:51,582 - config - INFO - Validation Loss: 0.6210
2024-04-01 17:57:51,583 - config - INFO - Validation Acc: 0.7360
2024-04-01 17:57:51,727 - config - INFO - Epoch [16/60], Train Loss: 0.5972
2024-04-01 17:57:51,735 - config - INFO - Validation Loss: 0.4997
2024-04-01 17:57:51,735 - config - INFO - Validation Acc: 0.7697
2024-04-01 17:57:51,877 - config - INFO - Epoch [17/60], Train Loss: 0.5021
2024-04-01 17:57:51,884 - config - INFO - Validation Loss: 0.5162
2024-04-01 17:57:51,885 - config - INFO - Validation Acc: 0.7697
2024-04-01 17:57:52,034 - config - INFO - Epoch [18/60], Train Loss: 0.5393
2024-04-01 17:57:52,042 - config - INFO - Validation Loss: 0.5646
2024-04-01 17:57:52,045 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:57:52,185 - config - INFO - Epoch [19/60], Train Loss: 0.5014
2024-04-01 17:57:52,192 - config - INFO - Validation Loss: 0.4475
2024-04-01 17:57:52,192 - config - INFO - Validation Acc: 0.8202
2024-04-01 17:57:52,335 - config - INFO - Epoch [20/60], Train Loss: 0.4781
2024-04-01 17:57:52,343 - config - INFO - Validation Loss: 0.6017
2024-04-01 17:57:52,343 - config - INFO - Validation Acc: 0.7303
2024-04-01 17:57:52,485 - config - INFO - Epoch [21/60], Train Loss: 0.5668
2024-04-01 17:57:52,492 - config - INFO - Validation Loss: 0.6502
2024-04-01 17:57:52,492 - config - INFO - Validation Acc: 0.7135
2024-04-01 17:57:52,630 - config - INFO - Epoch [22/60], Train Loss: 0.5879
2024-04-01 17:57:52,637 - config - INFO - Validation Loss: 0.7111
2024-04-01 17:57:52,637 - config - INFO - Validation Acc: 0.7079
2024-04-01 17:57:52,778 - config - INFO - Epoch [23/60], Train Loss: 0.5819
2024-04-01 17:57:52,785 - config - INFO - Validation Loss: 0.4640
2024-04-01 17:57:52,785 - config - INFO - Validation Acc: 0.7978
2024-04-01 17:57:52,925 - config - INFO - Epoch [24/60], Train Loss: 0.5170
2024-04-01 17:57:52,933 - config - INFO - Validation Loss: 0.5374
2024-04-01 17:57:52,933 - config - INFO - Validation Acc: 0.7584
2024-04-01 17:57:53,075 - config - INFO - Epoch [25/60], Train Loss: 0.6014
2024-04-01 17:57:53,083 - config - INFO - Validation Loss: 0.8975
2024-04-01 17:57:53,083 - config - INFO - Validation Acc: 0.6910
2024-04-01 17:57:53,223 - config - INFO - Epoch [26/60], Train Loss: 0.7705
2024-04-01 17:57:53,232 - config - INFO - Validation Loss: 0.5455
2024-04-01 17:57:53,232 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:57:53,373 - config - INFO - Epoch [27/60], Train Loss: 0.8031
2024-04-01 17:57:53,381 - config - INFO - Validation Loss: 0.9656
2024-04-01 17:57:53,381 - config - INFO - Validation Acc: 0.6517
2024-04-01 17:57:53,520 - config - INFO - Epoch [28/60], Train Loss: 0.7389
2024-04-01 17:57:53,527 - config - INFO - Validation Loss: 0.6978
2024-04-01 17:57:53,528 - config - INFO - Validation Acc: 0.7528
2024-04-01 17:57:53,668 - config - INFO - Epoch [29/60], Train Loss: 0.6668
2024-04-01 17:57:53,675 - config - INFO - Validation Loss: 0.6266
2024-04-01 17:57:53,676 - config - INFO - Validation Acc: 0.7865
2024-04-01 17:57:53,814 - config - INFO - Epoch [30/60], Train Loss: 0.6193
2024-04-01 17:57:53,821 - config - INFO - Validation Loss: 0.4635
2024-04-01 17:57:53,822 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:57:53,962 - config - INFO - Epoch [31/60], Train Loss: 0.6400
2024-04-01 17:57:53,969 - config - INFO - Validation Loss: 0.5744
2024-04-01 17:57:53,970 - config - INFO - Validation Acc: 0.7640
2024-04-01 17:57:54,113 - config - INFO - Epoch [32/60], Train Loss: 0.5307
2024-04-01 17:57:54,120 - config - INFO - Validation Loss: 0.5799
2024-04-01 17:57:54,120 - config - INFO - Validation Acc: 0.7528
2024-04-01 17:57:54,260 - config - INFO - Epoch [33/60], Train Loss: 0.5816
2024-04-01 17:57:54,268 - config - INFO - Validation Loss: 0.4425
2024-04-01 17:57:54,268 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:57:54,407 - config - INFO - Epoch [34/60], Train Loss: 0.4760
2024-04-01 17:57:54,414 - config - INFO - Validation Loss: 0.4294
2024-04-01 17:57:54,415 - config - INFO - Validation Acc: 0.8202
2024-04-01 17:57:54,554 - config - INFO - Epoch [35/60], Train Loss: 0.5364
2024-04-01 17:57:54,561 - config - INFO - Validation Loss: 0.5986
2024-04-01 17:57:54,561 - config - INFO - Validation Acc: 0.7360
2024-04-01 17:57:54,704 - config - INFO - Epoch [36/60], Train Loss: 0.5957
2024-04-01 17:57:54,712 - config - INFO - Validation Loss: 0.7486
2024-04-01 17:57:54,712 - config - INFO - Validation Acc: 0.7079
2024-04-01 17:57:54,853 - config - INFO - Epoch [37/60], Train Loss: 0.5223
2024-04-01 17:57:54,860 - config - INFO - Validation Loss: 0.4383
2024-04-01 17:57:54,860 - config - INFO - Validation Acc: 0.8202
2024-04-01 17:57:55,001 - config - INFO - Epoch [38/60], Train Loss: 0.4753
2024-04-01 17:57:55,008 - config - INFO - Validation Loss: 0.4821
2024-04-01 17:57:55,008 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:57:55,149 - config - INFO - Epoch [39/60], Train Loss: 0.4906
2024-04-01 17:57:55,156 - config - INFO - Validation Loss: 0.4700
2024-04-01 17:57:55,156 - config - INFO - Validation Acc: 0.8258
2024-04-01 17:57:55,297 - config - INFO - Epoch [40/60], Train Loss: 0.5515
2024-04-01 17:57:55,304 - config - INFO - Validation Loss: 0.4262
2024-04-01 17:57:55,304 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:57:55,449 - config - INFO - Epoch [41/60], Train Loss: 0.5775
2024-04-01 17:57:55,458 - config - INFO - Validation Loss: 0.5390
2024-04-01 17:57:55,459 - config - INFO - Validation Acc: 0.7753
2024-04-01 17:57:55,596 - config - INFO - Epoch [42/60], Train Loss: 0.5154
2024-04-01 17:57:55,604 - config - INFO - Validation Loss: 0.5474
2024-04-01 17:57:55,604 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:57:55,748 - config - INFO - Epoch [43/60], Train Loss: 0.5652
2024-04-01 17:57:55,755 - config - INFO - Validation Loss: 0.5147
2024-04-01 17:57:55,755 - config - INFO - Validation Acc: 0.7865
2024-04-01 17:57:55,897 - config - INFO - Epoch [44/60], Train Loss: 0.4855
2024-04-01 17:57:55,904 - config - INFO - Validation Loss: 0.7583
2024-04-01 17:57:55,904 - config - INFO - Validation Acc: 0.6461
2024-04-01 17:57:56,045 - config - INFO - Epoch [45/60], Train Loss: 0.5770
2024-04-01 17:57:56,052 - config - INFO - Validation Loss: 0.6171
2024-04-01 17:57:56,053 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:57:56,191 - config - INFO - Epoch [46/60], Train Loss: 0.6072
2024-04-01 17:57:56,199 - config - INFO - Validation Loss: 0.8018
2024-04-01 17:57:56,199 - config - INFO - Validation Acc: 0.6180
2024-04-01 17:57:56,336 - config - INFO - Epoch [47/60], Train Loss: 0.6625
2024-04-01 17:57:56,344 - config - INFO - Validation Loss: 0.5762
2024-04-01 17:57:56,344 - config - INFO - Validation Acc: 0.7697
2024-04-01 17:57:56,485 - config - INFO - Epoch [48/60], Train Loss: 0.5857
2024-04-01 17:57:56,492 - config - INFO - Validation Loss: 0.4358
2024-04-01 17:57:56,493 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:57:56,624 - config - INFO - Epoch [49/60], Train Loss: 0.5031
2024-04-01 17:57:56,631 - config - INFO - Validation Loss: 1.0485
2024-04-01 17:57:56,632 - config - INFO - Validation Acc: 0.4663
2024-04-01 17:57:56,769 - config - INFO - Epoch [50/60], Train Loss: 0.7592
2024-04-01 17:57:56,777 - config - INFO - Validation Loss: 0.7610
2024-04-01 17:57:56,777 - config - INFO - Validation Acc: 0.6461
2024-04-01 17:57:56,922 - config - INFO - Epoch [51/60], Train Loss: 0.8127
2024-04-01 17:57:56,929 - config - INFO - Validation Loss: 0.8544
2024-04-01 17:57:56,930 - config - INFO - Validation Acc: 0.7191
2024-04-01 17:57:57,071 - config - INFO - Epoch [52/60], Train Loss: 0.6456
2024-04-01 17:57:57,078 - config - INFO - Validation Loss: 0.6662
2024-04-01 17:57:57,079 - config - INFO - Validation Acc: 0.7416
2024-04-01 17:57:57,220 - config - INFO - Epoch [53/60], Train Loss: 0.5462
2024-04-01 17:57:57,228 - config - INFO - Validation Loss: 0.5072
2024-04-01 17:57:57,228 - config - INFO - Validation Acc: 0.7697
2024-04-01 17:57:57,366 - config - INFO - Epoch [54/60], Train Loss: 0.4838
2024-04-01 17:57:57,374 - config - INFO - Validation Loss: 0.4429
2024-04-01 17:57:57,374 - config - INFO - Validation Acc: 0.8371
2024-04-01 17:57:57,517 - config - INFO - Epoch [55/60], Train Loss: 0.4649
2024-04-01 17:57:57,525 - config - INFO - Validation Loss: 0.5533
2024-04-01 17:57:57,525 - config - INFO - Validation Acc: 0.7360
2024-04-01 17:57:57,669 - config - INFO - Epoch [56/60], Train Loss: 0.5676
2024-04-01 17:57:57,677 - config - INFO - Validation Loss: 0.4970
2024-04-01 17:57:57,677 - config - INFO - Validation Acc: 0.7640
2024-04-01 17:57:57,820 - config - INFO - Epoch [57/60], Train Loss: 0.4707
2024-04-01 17:57:57,828 - config - INFO - Validation Loss: 0.4641
2024-04-01 17:57:57,828 - config - INFO - Validation Acc: 0.7640
2024-04-01 17:57:57,972 - config - INFO - Epoch [58/60], Train Loss: 0.5209
2024-04-01 17:57:57,979 - config - INFO - Validation Loss: 0.4704
2024-04-01 17:57:57,980 - config - INFO - Validation Acc: 0.8202
2024-04-01 17:57:58,129 - config - INFO - Epoch [59/60], Train Loss: 0.5160
2024-04-01 17:57:58,137 - config - INFO - Validation Loss: 0.4339
2024-04-01 17:57:58,138 - config - INFO - Validation Acc: 0.8258
2024-04-01 17:57:58,281 - config - INFO - Epoch [60/60], Train Loss: 0.4837
2024-04-01 17:57:58,288 - config - INFO - Validation Loss: 0.4597
2024-04-01 17:57:58,289 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:58:25,700 - config - INFO - resume: None
2024-04-01 17:58:25,700 - config - INFO - device: cpu
2024-04-01 17:58:25,700 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 17:58:25,700 - config - INFO - learning_rate: 0.001
2024-04-01 17:58:25,700 - config - INFO - num_epochs: 60
2024-04-01 17:58:25,700 - config - INFO - batch_size: 64
2024-04-01 17:58:25,700 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 10

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 17:58:25,722 - config - INFO - Dataset size: 891
2024-04-01 17:58:25,747 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128, 2)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN1(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss()(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs.append(batch_outputs)
                labels.append(batch_labels)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        if type(self.model).__name__ == 'MaNN1':
            val_acc = calculate_accuracy(torch.max(outputs, dim=1)[1], labels)
        else:
            val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 17:58:25,747 - config - INFO - Training start
2024-04-01 17:58:27,882 - config - INFO - Epoch [1/60], Train Loss: 0.6852
2024-04-01 17:58:27,886 - config - INFO - Validation Loss: 0.6515
2024-04-01 17:58:27,887 - config - INFO - Validation Acc: 0.6348
2024-04-01 17:58:27,914 - config - INFO - Epoch [2/60], Train Loss: 0.6519
2024-04-01 17:58:27,919 - config - INFO - Validation Loss: 0.6220
2024-04-01 17:58:27,919 - config - INFO - Validation Acc: 0.6461
2024-04-01 17:58:27,949 - config - INFO - Epoch [3/60], Train Loss: 0.6232
2024-04-01 17:58:27,954 - config - INFO - Validation Loss: 0.5948
2024-04-01 17:58:27,954 - config - INFO - Validation Acc: 0.6798
2024-04-01 17:58:27,980 - config - INFO - Epoch [4/60], Train Loss: 0.5997
2024-04-01 17:58:27,984 - config - INFO - Validation Loss: 0.5696
2024-04-01 17:58:27,984 - config - INFO - Validation Acc: 0.7022
2024-04-01 17:58:28,009 - config - INFO - Epoch [5/60], Train Loss: 0.5781
2024-04-01 17:58:28,012 - config - INFO - Validation Loss: 0.5503
2024-04-01 17:58:28,013 - config - INFO - Validation Acc: 0.7640
2024-04-01 17:58:28,038 - config - INFO - Epoch [6/60], Train Loss: 0.5591
2024-04-01 17:58:28,042 - config - INFO - Validation Loss: 0.5305
2024-04-01 17:58:28,042 - config - INFO - Validation Acc: 0.7640
2024-04-01 17:58:28,065 - config - INFO - Epoch [7/60], Train Loss: 0.5423
2024-04-01 17:58:28,069 - config - INFO - Validation Loss: 0.5138
2024-04-01 17:58:28,069 - config - INFO - Validation Acc: 0.7697
2024-04-01 17:58:28,093 - config - INFO - Epoch [8/60], Train Loss: 0.5311
2024-04-01 17:58:28,097 - config - INFO - Validation Loss: 0.4992
2024-04-01 17:58:28,097 - config - INFO - Validation Acc: 0.7640
2024-04-01 17:58:28,121 - config - INFO - Epoch [9/60], Train Loss: 0.5157
2024-04-01 17:58:28,124 - config - INFO - Validation Loss: 0.4885
2024-04-01 17:58:28,125 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:58:28,149 - config - INFO - Epoch [10/60], Train Loss: 0.5030
2024-04-01 17:58:28,154 - config - INFO - Validation Loss: 0.4774
2024-04-01 17:58:28,154 - config - INFO - Validation Acc: 0.7978
2024-04-01 17:58:28,181 - config - INFO - Epoch [11/60], Train Loss: 0.4934
2024-04-01 17:58:28,186 - config - INFO - Validation Loss: 0.4698
2024-04-01 17:58:28,186 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:58:28,211 - config - INFO - Epoch [12/60], Train Loss: 0.4852
2024-04-01 17:58:28,215 - config - INFO - Validation Loss: 0.4638
2024-04-01 17:58:28,215 - config - INFO - Validation Acc: 0.7978
2024-04-01 17:58:28,240 - config - INFO - Epoch [13/60], Train Loss: 0.4781
2024-04-01 17:58:28,244 - config - INFO - Validation Loss: 0.4576
2024-04-01 17:58:28,250 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:58:28,282 - config - INFO - Epoch [14/60], Train Loss: 0.4719
2024-04-01 17:58:28,286 - config - INFO - Validation Loss: 0.4523
2024-04-01 17:58:28,287 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:58:28,314 - config - INFO - Epoch [15/60], Train Loss: 0.4669
2024-04-01 17:58:28,319 - config - INFO - Validation Loss: 0.4483
2024-04-01 17:58:28,319 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:58:28,346 - config - INFO - Epoch [16/60], Train Loss: 0.4630
2024-04-01 17:58:28,351 - config - INFO - Validation Loss: 0.4456
2024-04-01 17:58:28,351 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:58:28,395 - config - INFO - Epoch [17/60], Train Loss: 0.4590
2024-04-01 17:58:28,399 - config - INFO - Validation Loss: 0.4442
2024-04-01 17:58:28,400 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:58:28,427 - config - INFO - Epoch [18/60], Train Loss: 0.4565
2024-04-01 17:58:28,432 - config - INFO - Validation Loss: 0.4428
2024-04-01 17:58:28,432 - config - INFO - Validation Acc: 0.8258
2024-04-01 17:58:28,459 - config - INFO - Epoch [19/60], Train Loss: 0.4542
2024-04-01 17:58:28,464 - config - INFO - Validation Loss: 0.4411
2024-04-01 17:58:28,464 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:58:28,492 - config - INFO - Epoch [20/60], Train Loss: 0.4528
2024-04-01 17:58:28,496 - config - INFO - Validation Loss: 0.4405
2024-04-01 17:58:28,497 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:58:28,524 - config - INFO - Epoch [21/60], Train Loss: 0.4495
2024-04-01 17:58:28,529 - config - INFO - Validation Loss: 0.4401
2024-04-01 17:58:28,529 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:58:28,557 - config - INFO - Epoch [22/60], Train Loss: 0.4480
2024-04-01 17:58:28,562 - config - INFO - Validation Loss: 0.4400
2024-04-01 17:58:28,562 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:58:28,589 - config - INFO - Epoch [23/60], Train Loss: 0.4472
2024-04-01 17:58:28,594 - config - INFO - Validation Loss: 0.4418
2024-04-01 17:58:28,594 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:58:28,622 - config - INFO - Epoch [24/60], Train Loss: 0.4465
2024-04-01 17:58:28,627 - config - INFO - Validation Loss: 0.4410
2024-04-01 17:58:28,627 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:58:28,658 - config - INFO - Epoch [25/60], Train Loss: 0.4465
2024-04-01 17:58:28,662 - config - INFO - Validation Loss: 0.4405
2024-04-01 17:58:28,663 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:58:28,691 - config - INFO - Epoch [26/60], Train Loss: 0.4452
2024-04-01 17:58:28,696 - config - INFO - Validation Loss: 0.4407
2024-04-01 17:58:28,696 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:58:28,724 - config - INFO - Epoch [27/60], Train Loss: 0.4478
2024-04-01 17:58:28,729 - config - INFO - Validation Loss: 0.4408
2024-04-01 17:58:28,729 - config - INFO - Validation Acc: 0.8202
2024-04-01 17:58:28,757 - config - INFO - Epoch [28/60], Train Loss: 0.4451
2024-04-01 17:58:28,761 - config - INFO - Validation Loss: 0.4421
2024-04-01 17:58:28,761 - config - INFO - Validation Acc: 0.8034
2024-04-01 17:58:28,788 - config - INFO - Epoch [29/60], Train Loss: 0.4446
2024-04-01 17:58:28,793 - config - INFO - Validation Loss: 0.4416
2024-04-01 17:58:28,793 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:58:28,821 - config - INFO - Epoch [30/60], Train Loss: 0.4453
2024-04-01 17:58:28,825 - config - INFO - Validation Loss: 0.4418
2024-04-01 17:58:28,825 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:58:28,854 - config - INFO - Epoch [31/60], Train Loss: 0.4430
2024-04-01 17:58:28,858 - config - INFO - Validation Loss: 0.4425
2024-04-01 17:58:28,858 - config - INFO - Validation Acc: 0.8034
2024-04-01 17:58:28,886 - config - INFO - Epoch [32/60], Train Loss: 0.4448
2024-04-01 17:58:28,891 - config - INFO - Validation Loss: 0.4428
2024-04-01 17:58:28,891 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:58:28,918 - config - INFO - Epoch [33/60], Train Loss: 0.4429
2024-04-01 17:58:28,923 - config - INFO - Validation Loss: 0.4429
2024-04-01 17:58:28,923 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:58:28,950 - config - INFO - Epoch [34/60], Train Loss: 0.4430
2024-04-01 17:58:28,955 - config - INFO - Validation Loss: 0.4433
2024-04-01 17:58:28,955 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:58:28,983 - config - INFO - Epoch [35/60], Train Loss: 0.4445
2024-04-01 17:58:28,988 - config - INFO - Validation Loss: 0.4462
2024-04-01 17:58:28,988 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:58:29,016 - config - INFO - Epoch [36/60], Train Loss: 0.4440
2024-04-01 17:58:29,020 - config - INFO - Validation Loss: 0.4437
2024-04-01 17:58:29,021 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:58:29,048 - config - INFO - Epoch [37/60], Train Loss: 0.4425
2024-04-01 17:58:29,052 - config - INFO - Validation Loss: 0.4434
2024-04-01 17:58:29,053 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:58:29,080 - config - INFO - Epoch [38/60], Train Loss: 0.4429
2024-04-01 17:58:29,084 - config - INFO - Validation Loss: 0.4443
2024-04-01 17:58:29,084 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:58:29,113 - config - INFO - Epoch [39/60], Train Loss: 0.4440
2024-04-01 17:58:29,118 - config - INFO - Validation Loss: 0.4427
2024-04-01 17:58:29,118 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:58:29,145 - config - INFO - Epoch [40/60], Train Loss: 0.4436
2024-04-01 17:58:29,150 - config - INFO - Validation Loss: 0.4426
2024-04-01 17:58:29,150 - config - INFO - Validation Acc: 0.8202
2024-04-01 17:58:29,178 - config - INFO - Epoch [41/60], Train Loss: 0.4410
2024-04-01 17:58:29,183 - config - INFO - Validation Loss: 0.4435
2024-04-01 17:58:29,184 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:58:29,211 - config - INFO - Epoch [42/60], Train Loss: 0.4442
2024-04-01 17:58:29,215 - config - INFO - Validation Loss: 0.4415
2024-04-01 17:58:29,216 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:58:29,244 - config - INFO - Epoch [43/60], Train Loss: 0.4416
2024-04-01 17:58:29,249 - config - INFO - Validation Loss: 0.4413
2024-04-01 17:58:29,249 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:58:29,278 - config - INFO - Epoch [44/60], Train Loss: 0.4456
2024-04-01 17:58:29,283 - config - INFO - Validation Loss: 0.4437
2024-04-01 17:58:29,283 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:58:29,311 - config - INFO - Epoch [45/60], Train Loss: 0.4419
2024-04-01 17:58:29,315 - config - INFO - Validation Loss: 0.4416
2024-04-01 17:58:29,316 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:58:29,343 - config - INFO - Epoch [46/60], Train Loss: 0.4428
2024-04-01 17:58:29,347 - config - INFO - Validation Loss: 0.4424
2024-04-01 17:58:29,348 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:58:29,382 - config - INFO - Epoch [47/60], Train Loss: 0.4412
2024-04-01 17:58:29,387 - config - INFO - Validation Loss: 0.4418
2024-04-01 17:58:29,387 - config - INFO - Validation Acc: 0.8034
2024-04-01 17:58:29,419 - config - INFO - Epoch [48/60], Train Loss: 0.4415
2024-04-01 17:58:29,424 - config - INFO - Validation Loss: 0.4417
2024-04-01 17:58:29,425 - config - INFO - Validation Acc: 0.8034
2024-04-01 17:58:29,455 - config - INFO - Epoch [49/60], Train Loss: 0.4409
2024-04-01 17:58:29,460 - config - INFO - Validation Loss: 0.4422
2024-04-01 17:58:29,460 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:58:29,490 - config - INFO - Epoch [50/60], Train Loss: 0.4415
2024-04-01 17:58:29,495 - config - INFO - Validation Loss: 0.4426
2024-04-01 17:58:29,495 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:58:29,525 - config - INFO - Epoch [51/60], Train Loss: 0.4434
2024-04-01 17:58:29,530 - config - INFO - Validation Loss: 0.4422
2024-04-01 17:58:29,530 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:58:29,557 - config - INFO - Epoch [52/60], Train Loss: 0.4433
2024-04-01 17:58:29,562 - config - INFO - Validation Loss: 0.4422
2024-04-01 17:58:29,562 - config - INFO - Validation Acc: 0.8202
2024-04-01 17:58:29,589 - config - INFO - Epoch [53/60], Train Loss: 0.4424
2024-04-01 17:58:29,594 - config - INFO - Validation Loss: 0.4432
2024-04-01 17:58:29,594 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:58:29,622 - config - INFO - Epoch [54/60], Train Loss: 0.4426
2024-04-01 17:58:29,626 - config - INFO - Validation Loss: 0.4417
2024-04-01 17:58:29,626 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:58:29,654 - config - INFO - Epoch [55/60], Train Loss: 0.4417
2024-04-01 17:58:29,658 - config - INFO - Validation Loss: 0.4417
2024-04-01 17:58:29,659 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:58:29,686 - config - INFO - Epoch [56/60], Train Loss: 0.4435
2024-04-01 17:58:29,690 - config - INFO - Validation Loss: 0.4421
2024-04-01 17:58:29,691 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:58:29,719 - config - INFO - Epoch [57/60], Train Loss: 0.4413
2024-04-01 17:58:29,723 - config - INFO - Validation Loss: 0.4439
2024-04-01 17:58:29,723 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:58:29,751 - config - INFO - Epoch [58/60], Train Loss: 0.4435
2024-04-01 17:58:29,755 - config - INFO - Validation Loss: 0.4441
2024-04-01 17:58:29,755 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:58:29,784 - config - INFO - Epoch [59/60], Train Loss: 0.4442
2024-04-01 17:58:29,788 - config - INFO - Validation Loss: 0.4448
2024-04-01 17:58:29,788 - config - INFO - Validation Acc: 0.8202
2024-04-01 17:58:29,816 - config - INFO - Epoch [60/60], Train Loss: 0.4412
2024-04-01 17:58:29,820 - config - INFO - Validation Loss: 0.4440
2024-04-01 17:58:29,821 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:59:09,073 - config - INFO - resume: None
2024-04-01 17:59:09,073 - config - INFO - device: cpu
2024-04-01 17:59:09,073 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 17:59:09,073 - config - INFO - learning_rate: 0.001
2024-04-01 17:59:09,073 - config - INFO - num_epochs: 60
2024-04-01 17:59:09,073 - config - INFO - batch_size: 64
2024-04-01 17:59:09,073 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 10

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 17:59:09,094 - config - INFO - Dataset size: 891
2024-04-01 17:59:09,119 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128, 2)
        self.sigmoid = nn.Sigmoid()
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN1(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss()(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs.append(batch_outputs)
                labels.append(batch_labels)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        if type(self.model).__name__ == 'MaNN1':
            val_acc = calculate_accuracy(torch.max(outputs, dim=1)[1], labels)
        else:
            val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 17:59:09,119 - config - INFO - Training start
2024-04-01 17:59:11,256 - config - INFO - Epoch [1/60], Train Loss: 0.6400
2024-04-01 17:59:11,260 - config - INFO - Validation Loss: 0.5745
2024-04-01 17:59:11,261 - config - INFO - Validation Acc: 0.7079
2024-04-01 17:59:11,292 - config - INFO - Epoch [2/60], Train Loss: 0.5624
2024-04-01 17:59:11,296 - config - INFO - Validation Loss: 0.5170
2024-04-01 17:59:11,297 - config - INFO - Validation Acc: 0.7640
2024-04-01 17:59:11,325 - config - INFO - Epoch [3/60], Train Loss: 0.5120
2024-04-01 17:59:11,329 - config - INFO - Validation Loss: 0.4859
2024-04-01 17:59:11,330 - config - INFO - Validation Acc: 0.7865
2024-04-01 17:59:11,356 - config - INFO - Epoch [4/60], Train Loss: 0.4782
2024-04-01 17:59:11,361 - config - INFO - Validation Loss: 0.4635
2024-04-01 17:59:11,361 - config - INFO - Validation Acc: 0.7978
2024-04-01 17:59:11,388 - config - INFO - Epoch [5/60], Train Loss: 0.4550
2024-04-01 17:59:11,393 - config - INFO - Validation Loss: 0.4553
2024-04-01 17:59:11,393 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:59:11,419 - config - INFO - Epoch [6/60], Train Loss: 0.4411
2024-04-01 17:59:11,424 - config - INFO - Validation Loss: 0.4485
2024-04-01 17:59:11,424 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:59:11,450 - config - INFO - Epoch [7/60], Train Loss: 0.4308
2024-04-01 17:59:11,455 - config - INFO - Validation Loss: 0.4430
2024-04-01 17:59:11,455 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:59:11,482 - config - INFO - Epoch [8/60], Train Loss: 0.4233
2024-04-01 17:59:11,486 - config - INFO - Validation Loss: 0.4392
2024-04-01 17:59:11,487 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:59:11,513 - config - INFO - Epoch [9/60], Train Loss: 0.4182
2024-04-01 17:59:11,518 - config - INFO - Validation Loss: 0.4372
2024-04-01 17:59:11,518 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:59:11,545 - config - INFO - Epoch [10/60], Train Loss: 0.4161
2024-04-01 17:59:11,549 - config - INFO - Validation Loss: 0.4457
2024-04-01 17:59:11,549 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:59:11,576 - config - INFO - Epoch [11/60], Train Loss: 0.4131
2024-04-01 17:59:11,580 - config - INFO - Validation Loss: 0.4432
2024-04-01 17:59:11,580 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:59:11,607 - config - INFO - Epoch [12/60], Train Loss: 0.4091
2024-04-01 17:59:11,611 - config - INFO - Validation Loss: 0.4363
2024-04-01 17:59:11,612 - config - INFO - Validation Acc: 0.8202
2024-04-01 17:59:11,639 - config - INFO - Epoch [13/60], Train Loss: 0.4052
2024-04-01 17:59:11,643 - config - INFO - Validation Loss: 0.4370
2024-04-01 17:59:11,643 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:59:11,670 - config - INFO - Epoch [14/60], Train Loss: 0.4031
2024-04-01 17:59:11,674 - config - INFO - Validation Loss: 0.4388
2024-04-01 17:59:11,674 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:59:11,701 - config - INFO - Epoch [15/60], Train Loss: 0.3996
2024-04-01 17:59:11,705 - config - INFO - Validation Loss: 0.4386
2024-04-01 17:59:11,705 - config - INFO - Validation Acc: 0.8258
2024-04-01 17:59:11,734 - config - INFO - Epoch [16/60], Train Loss: 0.3980
2024-04-01 17:59:11,738 - config - INFO - Validation Loss: 0.4410
2024-04-01 17:59:11,738 - config - INFO - Validation Acc: 0.8202
2024-04-01 17:59:11,766 - config - INFO - Epoch [17/60], Train Loss: 0.3974
2024-04-01 17:59:11,770 - config - INFO - Validation Loss: 0.4457
2024-04-01 17:59:11,770 - config - INFO - Validation Acc: 0.8034
2024-04-01 17:59:11,812 - config - INFO - Epoch [18/60], Train Loss: 0.3936
2024-04-01 17:59:11,816 - config - INFO - Validation Loss: 0.4416
2024-04-01 17:59:11,817 - config - INFO - Validation Acc: 0.8202
2024-04-01 17:59:11,844 - config - INFO - Epoch [19/60], Train Loss: 0.3925
2024-04-01 17:59:11,848 - config - INFO - Validation Loss: 0.4411
2024-04-01 17:59:11,848 - config - INFO - Validation Acc: 0.8315
2024-04-01 17:59:11,875 - config - INFO - Epoch [20/60], Train Loss: 0.3906
2024-04-01 17:59:11,880 - config - INFO - Validation Loss: 0.4430
2024-04-01 17:59:11,880 - config - INFO - Validation Acc: 0.8315
2024-04-01 17:59:11,906 - config - INFO - Epoch [21/60], Train Loss: 0.3906
2024-04-01 17:59:11,911 - config - INFO - Validation Loss: 0.4390
2024-04-01 17:59:11,911 - config - INFO - Validation Acc: 0.8315
2024-04-01 17:59:11,938 - config - INFO - Epoch [22/60], Train Loss: 0.3875
2024-04-01 17:59:11,942 - config - INFO - Validation Loss: 0.4454
2024-04-01 17:59:11,942 - config - INFO - Validation Acc: 0.8202
2024-04-01 17:59:11,969 - config - INFO - Epoch [23/60], Train Loss: 0.3866
2024-04-01 17:59:11,974 - config - INFO - Validation Loss: 0.4494
2024-04-01 17:59:11,974 - config - INFO - Validation Acc: 0.8258
2024-04-01 17:59:12,002 - config - INFO - Epoch [24/60], Train Loss: 0.3846
2024-04-01 17:59:12,006 - config - INFO - Validation Loss: 0.4455
2024-04-01 17:59:12,006 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:59:12,033 - config - INFO - Epoch [25/60], Train Loss: 0.3840
2024-04-01 17:59:12,037 - config - INFO - Validation Loss: 0.4442
2024-04-01 17:59:12,038 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:59:12,067 - config - INFO - Epoch [26/60], Train Loss: 0.3834
2024-04-01 17:59:12,072 - config - INFO - Validation Loss: 0.4473
2024-04-01 17:59:12,072 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:59:12,099 - config - INFO - Epoch [27/60], Train Loss: 0.3806
2024-04-01 17:59:12,103 - config - INFO - Validation Loss: 0.4479
2024-04-01 17:59:12,104 - config - INFO - Validation Acc: 0.8202
2024-04-01 17:59:12,131 - config - INFO - Epoch [28/60], Train Loss: 0.3795
2024-04-01 17:59:12,135 - config - INFO - Validation Loss: 0.4472
2024-04-01 17:59:12,135 - config - INFO - Validation Acc: 0.8315
2024-04-01 17:59:12,162 - config - INFO - Epoch [29/60], Train Loss: 0.3791
2024-04-01 17:59:12,166 - config - INFO - Validation Loss: 0.4469
2024-04-01 17:59:12,167 - config - INFO - Validation Acc: 0.8258
2024-04-01 17:59:12,193 - config - INFO - Epoch [30/60], Train Loss: 0.3776
2024-04-01 17:59:12,198 - config - INFO - Validation Loss: 0.4518
2024-04-01 17:59:12,198 - config - INFO - Validation Acc: 0.8258
2024-04-01 17:59:12,225 - config - INFO - Epoch [31/60], Train Loss: 0.3770
2024-04-01 17:59:12,229 - config - INFO - Validation Loss: 0.4485
2024-04-01 17:59:12,229 - config - INFO - Validation Acc: 0.8202
2024-04-01 17:59:12,257 - config - INFO - Epoch [32/60], Train Loss: 0.3752
2024-04-01 17:59:12,261 - config - INFO - Validation Loss: 0.4522
2024-04-01 17:59:12,261 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:59:12,288 - config - INFO - Epoch [33/60], Train Loss: 0.3753
2024-04-01 17:59:12,293 - config - INFO - Validation Loss: 0.4561
2024-04-01 17:59:12,293 - config - INFO - Validation Acc: 0.8034
2024-04-01 17:59:12,320 - config - INFO - Epoch [34/60], Train Loss: 0.3755
2024-04-01 17:59:12,324 - config - INFO - Validation Loss: 0.4510
2024-04-01 17:59:12,324 - config - INFO - Validation Acc: 0.8034
2024-04-01 17:59:12,351 - config - INFO - Epoch [35/60], Train Loss: 0.3733
2024-04-01 17:59:12,356 - config - INFO - Validation Loss: 0.4463
2024-04-01 17:59:12,356 - config - INFO - Validation Acc: 0.8258
2024-04-01 17:59:12,383 - config - INFO - Epoch [36/60], Train Loss: 0.3717
2024-04-01 17:59:12,388 - config - INFO - Validation Loss: 0.4493
2024-04-01 17:59:12,388 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:59:12,415 - config - INFO - Epoch [37/60], Train Loss: 0.3713
2024-04-01 17:59:12,419 - config - INFO - Validation Loss: 0.4517
2024-04-01 17:59:12,419 - config - INFO - Validation Acc: 0.8034
2024-04-01 17:59:12,446 - config - INFO - Epoch [38/60], Train Loss: 0.3701
2024-04-01 17:59:12,450 - config - INFO - Validation Loss: 0.4489
2024-04-01 17:59:12,450 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:59:12,477 - config - INFO - Epoch [39/60], Train Loss: 0.3695
2024-04-01 17:59:12,481 - config - INFO - Validation Loss: 0.4522
2024-04-01 17:59:12,482 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:59:12,509 - config - INFO - Epoch [40/60], Train Loss: 0.3679
2024-04-01 17:59:12,514 - config - INFO - Validation Loss: 0.4562
2024-04-01 17:59:12,515 - config - INFO - Validation Acc: 0.8034
2024-04-01 17:59:12,541 - config - INFO - Epoch [41/60], Train Loss: 0.3687
2024-04-01 17:59:12,546 - config - INFO - Validation Loss: 0.4526
2024-04-01 17:59:12,546 - config - INFO - Validation Acc: 0.8034
2024-04-01 17:59:12,573 - config - INFO - Epoch [42/60], Train Loss: 0.3674
2024-04-01 17:59:12,578 - config - INFO - Validation Loss: 0.4578
2024-04-01 17:59:12,578 - config - INFO - Validation Acc: 0.8034
2024-04-01 17:59:12,604 - config - INFO - Epoch [43/60], Train Loss: 0.3654
2024-04-01 17:59:12,609 - config - INFO - Validation Loss: 0.4553
2024-04-01 17:59:12,609 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:59:12,636 - config - INFO - Epoch [44/60], Train Loss: 0.3652
2024-04-01 17:59:12,640 - config - INFO - Validation Loss: 0.4557
2024-04-01 17:59:12,641 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:59:12,668 - config - INFO - Epoch [45/60], Train Loss: 0.3643
2024-04-01 17:59:12,673 - config - INFO - Validation Loss: 0.4589
2024-04-01 17:59:12,673 - config - INFO - Validation Acc: 0.8034
2024-04-01 17:59:12,702 - config - INFO - Epoch [46/60], Train Loss: 0.3651
2024-04-01 17:59:12,706 - config - INFO - Validation Loss: 0.4626
2024-04-01 17:59:12,706 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:59:12,733 - config - INFO - Epoch [47/60], Train Loss: 0.3646
2024-04-01 17:59:12,738 - config - INFO - Validation Loss: 0.4560
2024-04-01 17:59:12,738 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:59:12,765 - config - INFO - Epoch [48/60], Train Loss: 0.3632
2024-04-01 17:59:12,769 - config - INFO - Validation Loss: 0.4522
2024-04-01 17:59:12,770 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:59:12,798 - config - INFO - Epoch [49/60], Train Loss: 0.3614
2024-04-01 17:59:12,802 - config - INFO - Validation Loss: 0.4605
2024-04-01 17:59:12,803 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:59:12,830 - config - INFO - Epoch [50/60], Train Loss: 0.3615
2024-04-01 17:59:12,834 - config - INFO - Validation Loss: 0.4587
2024-04-01 17:59:12,835 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:59:12,862 - config - INFO - Epoch [51/60], Train Loss: 0.3623
2024-04-01 17:59:12,866 - config - INFO - Validation Loss: 0.4618
2024-04-01 17:59:12,866 - config - INFO - Validation Acc: 0.7921
2024-04-01 17:59:12,893 - config - INFO - Epoch [52/60], Train Loss: 0.3645
2024-04-01 17:59:12,898 - config - INFO - Validation Loss: 0.4519
2024-04-01 17:59:12,898 - config - INFO - Validation Acc: 0.8034
2024-04-01 17:59:12,924 - config - INFO - Epoch [53/60], Train Loss: 0.3652
2024-04-01 17:59:12,929 - config - INFO - Validation Loss: 0.4518
2024-04-01 17:59:12,929 - config - INFO - Validation Acc: 0.8034
2024-04-01 17:59:12,956 - config - INFO - Epoch [54/60], Train Loss: 0.3594
2024-04-01 17:59:12,960 - config - INFO - Validation Loss: 0.4624
2024-04-01 17:59:12,960 - config - INFO - Validation Acc: 0.7809
2024-04-01 17:59:12,987 - config - INFO - Epoch [55/60], Train Loss: 0.3584
2024-04-01 17:59:12,991 - config - INFO - Validation Loss: 0.4655
2024-04-01 17:59:12,992 - config - INFO - Validation Acc: 0.7809
2024-04-01 17:59:13,019 - config - INFO - Epoch [56/60], Train Loss: 0.3581
2024-04-01 17:59:13,029 - config - INFO - Validation Loss: 0.4655
2024-04-01 17:59:13,029 - config - INFO - Validation Acc: 0.7865
2024-04-01 17:59:13,057 - config - INFO - Epoch [57/60], Train Loss: 0.3576
2024-04-01 17:59:13,061 - config - INFO - Validation Loss: 0.4596
2024-04-01 17:59:13,061 - config - INFO - Validation Acc: 0.7865
2024-04-01 17:59:13,088 - config - INFO - Epoch [58/60], Train Loss: 0.3587
2024-04-01 17:59:13,092 - config - INFO - Validation Loss: 0.4569
2024-04-01 17:59:13,092 - config - INFO - Validation Acc: 0.7921
2024-04-01 17:59:13,119 - config - INFO - Epoch [59/60], Train Loss: 0.3566
2024-04-01 17:59:13,123 - config - INFO - Validation Loss: 0.4652
2024-04-01 17:59:13,123 - config - INFO - Validation Acc: 0.7809
2024-04-01 17:59:13,151 - config - INFO - Epoch [60/60], Train Loss: 0.3556
2024-04-01 17:59:13,156 - config - INFO - Validation Loss: 0.4627
2024-04-01 17:59:13,156 - config - INFO - Validation Acc: 0.7978
2024-04-01 17:59:28,716 - config - INFO - resume: None
2024-04-01 17:59:28,717 - config - INFO - device: cpu
2024-04-01 17:59:28,717 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 17:59:28,717 - config - INFO - learning_rate: 0.001
2024-04-01 17:59:28,717 - config - INFO - num_epochs: 60
2024-04-01 17:59:28,717 - config - INFO - batch_size: 64
2024-04-01 17:59:28,717 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 10

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 17:59:28,738 - config - INFO - Dataset size: 891
2024-04-01 17:59:28,775 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN1(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss()(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs.append(batch_outputs)
                labels.append(batch_labels)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        if type(self.model).__name__ == 'MaNN1':
            val_acc = calculate_accuracy(torch.max(outputs, dim=1)[1], labels)
        else:
            val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 17:59:28,775 - config - INFO - Training start
2024-04-01 17:59:31,784 - config - INFO - Epoch [1/60], Train Loss: 4.7584
2024-04-01 17:59:31,843 - config - INFO - Validation Loss: 3.5590
2024-04-01 17:59:31,844 - config - INFO - Validation Acc: 0.7640
2024-04-01 17:59:32,540 - config - INFO - Epoch [2/60], Train Loss: 2.4980
2024-04-01 17:59:32,587 - config - INFO - Validation Loss: 2.9316
2024-04-01 17:59:32,587 - config - INFO - Validation Acc: 0.7360
2024-04-01 17:59:33,265 - config - INFO - Epoch [3/60], Train Loss: 2.7422
2024-04-01 17:59:33,314 - config - INFO - Validation Loss: 3.8701
2024-04-01 17:59:33,315 - config - INFO - Validation Acc: 0.5618
2024-04-01 17:59:33,921 - config - INFO - Epoch [4/60], Train Loss: 2.9355
2024-04-01 17:59:33,966 - config - INFO - Validation Loss: 2.6787
2024-04-01 17:59:33,966 - config - INFO - Validation Acc: 0.7472
2024-04-01 17:59:34,562 - config - INFO - Epoch [5/60], Train Loss: 1.6696
2024-04-01 17:59:34,599 - config - INFO - Validation Loss: 1.7348
2024-04-01 17:59:34,600 - config - INFO - Validation Acc: 0.7978
2024-04-01 17:59:35,168 - config - INFO - Epoch [6/60], Train Loss: 1.6419
2024-04-01 17:59:35,213 - config - INFO - Validation Loss: 2.4015
2024-04-01 17:59:35,214 - config - INFO - Validation Acc: 0.5787
2024-04-01 17:59:35,802 - config - INFO - Epoch [7/60], Train Loss: 1.9900
2024-04-01 17:59:35,856 - config - INFO - Validation Loss: 2.0692
2024-04-01 17:59:35,857 - config - INFO - Validation Acc: 0.7360
2024-04-01 17:59:36,404 - config - INFO - Epoch [8/60], Train Loss: 1.6949
2024-04-01 17:59:36,452 - config - INFO - Validation Loss: 2.3980
2024-04-01 17:59:36,452 - config - INFO - Validation Acc: 0.7978
2024-04-01 17:59:36,997 - config - INFO - Epoch [9/60], Train Loss: 2.0343
2024-04-01 17:59:37,034 - config - INFO - Validation Loss: 2.2335
2024-04-01 17:59:37,035 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:59:37,594 - config - INFO - Epoch [10/60], Train Loss: 1.9594
2024-04-01 17:59:37,637 - config - INFO - Validation Loss: 4.6905
2024-04-01 17:59:37,637 - config - INFO - Validation Acc: 0.5730
2024-04-01 17:59:38,233 - config - INFO - Epoch [11/60], Train Loss: 2.4133
2024-04-01 17:59:38,278 - config - INFO - Validation Loss: 1.9569
2024-04-01 17:59:38,278 - config - INFO - Validation Acc: 0.8315
2024-04-01 17:59:38,830 - config - INFO - Epoch [12/60], Train Loss: 1.4512
2024-04-01 17:59:38,868 - config - INFO - Validation Loss: 1.6152
2024-04-01 17:59:38,869 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:59:39,439 - config - INFO - Epoch [13/60], Train Loss: 1.4539
2024-04-01 17:59:39,475 - config - INFO - Validation Loss: 3.7754
2024-04-01 17:59:39,476 - config - INFO - Validation Acc: 0.4438
2024-04-01 17:59:39,994 - config - INFO - Epoch [14/60], Train Loss: 2.4192
2024-04-01 17:59:40,031 - config - INFO - Validation Loss: 1.6836
2024-04-01 17:59:40,031 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:59:40,583 - config - INFO - Epoch [15/60], Train Loss: 1.1210
2024-04-01 17:59:40,620 - config - INFO - Validation Loss: 2.0298
2024-04-01 17:59:40,620 - config - INFO - Validation Acc: 0.7360
2024-04-01 17:59:41,140 - config - INFO - Epoch [16/60], Train Loss: 0.8932
2024-04-01 17:59:41,177 - config - INFO - Validation Loss: 1.3210
2024-04-01 17:59:41,177 - config - INFO - Validation Acc: 0.7697
2024-04-01 17:59:41,752 - config - INFO - Epoch [17/60], Train Loss: 1.1728
2024-04-01 17:59:41,787 - config - INFO - Validation Loss: 2.5986
2024-04-01 17:59:41,788 - config - INFO - Validation Acc: 0.5225
2024-04-01 17:59:42,315 - config - INFO - Epoch [18/60], Train Loss: 3.1686
2024-04-01 17:59:42,351 - config - INFO - Validation Loss: 2.4785
2024-04-01 17:59:42,358 - config - INFO - Validation Acc: 0.7921
2024-04-01 17:59:42,869 - config - INFO - Epoch [19/60], Train Loss: 1.6975
2024-04-01 17:59:42,904 - config - INFO - Validation Loss: 2.1146
2024-04-01 17:59:42,904 - config - INFO - Validation Acc: 0.8258
2024-04-01 17:59:43,420 - config - INFO - Epoch [20/60], Train Loss: 1.7313
2024-04-01 17:59:43,455 - config - INFO - Validation Loss: 3.7951
2024-04-01 17:59:43,455 - config - INFO - Validation Acc: 0.4831
2024-04-01 17:59:43,983 - config - INFO - Epoch [21/60], Train Loss: 1.7969
2024-04-01 17:59:44,025 - config - INFO - Validation Loss: 1.4020
2024-04-01 17:59:44,025 - config - INFO - Validation Acc: 0.7697
2024-04-01 17:59:44,523 - config - INFO - Epoch [22/60], Train Loss: 1.6268
2024-04-01 17:59:44,558 - config - INFO - Validation Loss: 2.0423
2024-04-01 17:59:44,558 - config - INFO - Validation Acc: 0.7809
2024-04-01 17:59:45,120 - config - INFO - Epoch [23/60], Train Loss: 0.8396
2024-04-01 17:59:45,152 - config - INFO - Validation Loss: 2.1240
2024-04-01 17:59:45,152 - config - INFO - Validation Acc: 0.8034
2024-04-01 17:59:45,750 - config - INFO - Epoch [24/60], Train Loss: 1.5904
2024-04-01 17:59:45,784 - config - INFO - Validation Loss: 3.6132
2024-04-01 17:59:45,785 - config - INFO - Validation Acc: 0.5056
2024-04-01 17:59:46,372 - config - INFO - Epoch [25/60], Train Loss: 1.5207
2024-04-01 17:59:46,414 - config - INFO - Validation Loss: 2.0760
2024-04-01 17:59:46,414 - config - INFO - Validation Acc: 0.7191
2024-04-01 17:59:46,988 - config - INFO - Epoch [26/60], Train Loss: 1.4269
2024-04-01 17:59:47,025 - config - INFO - Validation Loss: 2.4156
2024-04-01 17:59:47,033 - config - INFO - Validation Acc: 0.7921
2024-04-01 17:59:47,606 - config - INFO - Epoch [27/60], Train Loss: 1.9772
2024-04-01 17:59:47,643 - config - INFO - Validation Loss: 3.5929
2024-04-01 17:59:47,644 - config - INFO - Validation Acc: 0.7640
2024-04-01 17:59:48,203 - config - INFO - Epoch [28/60], Train Loss: 2.8574
2024-04-01 17:59:48,241 - config - INFO - Validation Loss: 3.0950
2024-04-01 17:59:48,242 - config - INFO - Validation Acc: 0.7865
2024-04-01 17:59:48,798 - config - INFO - Epoch [29/60], Train Loss: 2.8236
2024-04-01 17:59:48,844 - config - INFO - Validation Loss: 3.3465
2024-04-01 17:59:48,845 - config - INFO - Validation Acc: 0.6629
2024-04-01 17:59:49,402 - config - INFO - Epoch [30/60], Train Loss: 1.7003
2024-04-01 17:59:49,452 - config - INFO - Validation Loss: 1.9838
2024-04-01 17:59:49,452 - config - INFO - Validation Acc: 0.7135
2024-04-01 17:59:50,045 - config - INFO - Epoch [31/60], Train Loss: 1.9479
2024-04-01 17:59:50,095 - config - INFO - Validation Loss: 2.2761
2024-04-01 17:59:50,095 - config - INFO - Validation Acc: 0.8202
2024-04-01 17:59:50,638 - config - INFO - Epoch [32/60], Train Loss: 1.5331
2024-04-01 17:59:50,677 - config - INFO - Validation Loss: 1.6510
2024-04-01 17:59:50,685 - config - INFO - Validation Acc: 0.7640
2024-04-01 17:59:51,231 - config - INFO - Epoch [33/60], Train Loss: 1.0802
2024-04-01 17:59:51,270 - config - INFO - Validation Loss: 1.4922
2024-04-01 17:59:51,271 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:59:51,839 - config - INFO - Epoch [34/60], Train Loss: 0.9432
2024-04-01 17:59:51,876 - config - INFO - Validation Loss: 1.5395
2024-04-01 17:59:51,877 - config - INFO - Validation Acc: 0.8146
2024-04-01 17:59:52,410 - config - INFO - Epoch [35/60], Train Loss: 0.8058
2024-04-01 17:59:52,448 - config - INFO - Validation Loss: 2.8455
2024-04-01 17:59:52,448 - config - INFO - Validation Acc: 0.4494
2024-04-01 17:59:52,978 - config - INFO - Epoch [36/60], Train Loss: 2.4309
2024-04-01 17:59:53,020 - config - INFO - Validation Loss: 1.7986
2024-04-01 17:59:53,020 - config - INFO - Validation Acc: 0.7978
2024-04-01 17:59:53,522 - config - INFO - Epoch [37/60], Train Loss: 1.2055
2024-04-01 17:59:53,557 - config - INFO - Validation Loss: 1.9014
2024-04-01 17:59:53,557 - config - INFO - Validation Acc: 0.8034
2024-04-01 17:59:54,059 - config - INFO - Epoch [38/60], Train Loss: 1.0841
2024-04-01 17:59:54,101 - config - INFO - Validation Loss: 2.2106
2024-04-01 17:59:54,101 - config - INFO - Validation Acc: 0.6011
2024-04-01 17:59:54,574 - config - INFO - Epoch [39/60], Train Loss: 1.1892
2024-04-01 17:59:54,613 - config - INFO - Validation Loss: 1.9051
2024-04-01 17:59:54,614 - config - INFO - Validation Acc: 0.8202
2024-04-01 17:59:55,108 - config - INFO - Epoch [40/60], Train Loss: 1.1610
2024-04-01 17:59:55,143 - config - INFO - Validation Loss: 1.5793
2024-04-01 17:59:55,150 - config - INFO - Validation Acc: 0.7978
2024-04-01 17:59:55,627 - config - INFO - Epoch [41/60], Train Loss: 2.4276
2024-04-01 17:59:55,664 - config - INFO - Validation Loss: 2.7330
2024-04-01 17:59:55,664 - config - INFO - Validation Acc: 0.7921
2024-04-01 17:59:56,179 - config - INFO - Epoch [42/60], Train Loss: 1.9876
2024-04-01 17:59:56,213 - config - INFO - Validation Loss: 2.3403
2024-04-01 17:59:56,214 - config - INFO - Validation Acc: 0.8090
2024-04-01 17:59:56,703 - config - INFO - Epoch [43/60], Train Loss: 2.6732
2024-04-01 17:59:56,738 - config - INFO - Validation Loss: 3.1297
2024-04-01 17:59:56,739 - config - INFO - Validation Acc: 0.6629
2024-04-01 17:59:57,229 - config - INFO - Epoch [44/60], Train Loss: 2.5332
2024-04-01 17:59:57,262 - config - INFO - Validation Loss: 2.7485
2024-04-01 17:59:57,269 - config - INFO - Validation Acc: 0.7809
2024-04-01 17:59:57,743 - config - INFO - Epoch [45/60], Train Loss: 1.4930
2024-04-01 17:59:57,777 - config - INFO - Validation Loss: 1.8205
2024-04-01 17:59:57,778 - config - INFO - Validation Acc: 0.7753
2024-04-01 17:59:58,269 - config - INFO - Epoch [46/60], Train Loss: 0.9091
2024-04-01 17:59:58,304 - config - INFO - Validation Loss: 1.6832
2024-04-01 17:59:58,311 - config - INFO - Validation Acc: 0.7865
2024-04-01 17:59:58,776 - config - INFO - Epoch [47/60], Train Loss: 0.9242
2024-04-01 17:59:58,825 - config - INFO - Validation Loss: 1.7213
2024-04-01 17:59:58,826 - config - INFO - Validation Acc: 0.6854
2024-04-01 17:59:59,302 - config - INFO - Epoch [48/60], Train Loss: 0.8774
2024-04-01 17:59:59,337 - config - INFO - Validation Loss: 1.8398
2024-04-01 17:59:59,338 - config - INFO - Validation Acc: 0.7921
2024-04-01 17:59:59,814 - config - INFO - Epoch [49/60], Train Loss: 0.8958
2024-04-01 17:59:59,849 - config - INFO - Validation Loss: 2.0586
2024-04-01 17:59:59,850 - config - INFO - Validation Acc: 0.6685
2024-04-01 18:00:00,352 - config - INFO - Epoch [50/60], Train Loss: 0.9506
2024-04-01 18:00:00,387 - config - INFO - Validation Loss: 1.3401
2024-04-01 18:00:00,387 - config - INFO - Validation Acc: 0.7978
2024-04-01 18:00:00,893 - config - INFO - Epoch [51/60], Train Loss: 0.7274
2024-04-01 18:00:00,929 - config - INFO - Validation Loss: 1.4903
2024-04-01 18:00:00,929 - config - INFO - Validation Acc: 0.7865
2024-04-01 18:00:27,415 - config - INFO - resume: None
2024-04-01 18:00:27,415 - config - INFO - device: cpu
2024-04-01 18:00:27,415 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 18:00:27,415 - config - INFO - learning_rate: 1e-06
2024-04-01 18:00:27,415 - config - INFO - num_epochs: 60
2024-04-01 18:00:27,415 - config - INFO - batch_size: 64
2024-04-01 18:00:27,415 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 10

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 18:00:27,436 - config - INFO - Dataset size: 891
2024-04-01 18:00:27,479 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN1(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss()(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs.append(batch_outputs)
                labels.append(batch_labels)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        if type(self.model).__name__ == 'MaNN1':
            val_acc = calculate_accuracy(torch.max(outputs, dim=1)[1], labels)
        else:
            val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 18:00:27,479 - config - INFO - Training start
2024-04-01 18:00:30,389 - config - INFO - Epoch [1/60], Train Loss: 0.6557
2024-04-01 18:00:30,438 - config - INFO - Validation Loss: 0.6114
2024-04-01 18:00:30,439 - config - INFO - Validation Acc: 0.7528
2024-04-01 18:00:31,055 - config - INFO - Epoch [2/60], Train Loss: 0.5888
2024-04-01 18:00:31,096 - config - INFO - Validation Loss: 0.5648
2024-04-01 18:00:31,097 - config - INFO - Validation Acc: 0.7697
2024-04-01 18:00:31,698 - config - INFO - Epoch [3/60], Train Loss: 0.5443
2024-04-01 18:00:31,740 - config - INFO - Validation Loss: 0.5379
2024-04-01 18:00:31,741 - config - INFO - Validation Acc: 0.7809
2024-04-01 18:00:32,342 - config - INFO - Epoch [4/60], Train Loss: 0.5117
2024-04-01 18:00:32,384 - config - INFO - Validation Loss: 0.5135
2024-04-01 18:00:32,384 - config - INFO - Validation Acc: 0.7921
2024-04-01 18:00:32,924 - config - INFO - Epoch [5/60], Train Loss: 0.4890
2024-04-01 18:00:32,962 - config - INFO - Validation Loss: 0.4992
2024-04-01 18:00:32,962 - config - INFO - Validation Acc: 0.7978
2024-04-01 18:00:33,457 - config - INFO - Epoch [6/60], Train Loss: 0.4737
2024-04-01 18:00:33,494 - config - INFO - Validation Loss: 0.4896
2024-04-01 18:00:33,495 - config - INFO - Validation Acc: 0.7978
2024-04-01 18:00:34,003 - config - INFO - Epoch [7/60], Train Loss: 0.4626
2024-04-01 18:00:34,046 - config - INFO - Validation Loss: 0.4843
2024-04-01 18:00:34,046 - config - INFO - Validation Acc: 0.7921
2024-04-01 18:00:34,574 - config - INFO - Epoch [8/60], Train Loss: 0.4536
2024-04-01 18:00:34,613 - config - INFO - Validation Loss: 0.4813
2024-04-01 18:00:34,613 - config - INFO - Validation Acc: 0.7865
2024-04-01 18:00:35,133 - config - INFO - Epoch [9/60], Train Loss: 0.4472
2024-04-01 18:00:35,169 - config - INFO - Validation Loss: 0.4790
2024-04-01 18:00:35,170 - config - INFO - Validation Acc: 0.7809
2024-04-01 18:00:35,689 - config - INFO - Epoch [10/60], Train Loss: 0.4426
2024-04-01 18:00:35,728 - config - INFO - Validation Loss: 0.4797
2024-04-01 18:00:35,728 - config - INFO - Validation Acc: 0.7809
2024-04-01 18:00:36,259 - config - INFO - Epoch [11/60], Train Loss: 0.4376
2024-04-01 18:00:36,296 - config - INFO - Validation Loss: 0.4741
2024-04-01 18:00:36,297 - config - INFO - Validation Acc: 0.7809
2024-04-01 18:00:36,818 - config - INFO - Epoch [12/60], Train Loss: 0.4336
2024-04-01 18:00:36,853 - config - INFO - Validation Loss: 0.4711
2024-04-01 18:00:36,854 - config - INFO - Validation Acc: 0.7809
2024-04-01 18:00:37,356 - config - INFO - Epoch [13/60], Train Loss: 0.4310
2024-04-01 18:00:37,399 - config - INFO - Validation Loss: 0.4695
2024-04-01 18:00:37,399 - config - INFO - Validation Acc: 0.7865
2024-04-01 18:00:37,916 - config - INFO - Epoch [14/60], Train Loss: 0.4284
2024-04-01 18:00:37,957 - config - INFO - Validation Loss: 0.4711
2024-04-01 18:00:37,958 - config - INFO - Validation Acc: 0.7809
2024-04-01 18:00:38,463 - config - INFO - Epoch [15/60], Train Loss: 0.4262
2024-04-01 18:00:38,498 - config - INFO - Validation Loss: 0.4715
2024-04-01 18:00:38,498 - config - INFO - Validation Acc: 0.7809
2024-04-01 18:00:38,998 - config - INFO - Epoch [16/60], Train Loss: 0.4249
2024-04-01 18:00:39,034 - config - INFO - Validation Loss: 0.4724
2024-04-01 18:00:39,035 - config - INFO - Validation Acc: 0.7809
2024-04-01 18:00:39,531 - config - INFO - Epoch [17/60], Train Loss: 0.4221
2024-04-01 18:00:39,566 - config - INFO - Validation Loss: 0.4690
2024-04-01 18:00:39,566 - config - INFO - Validation Acc: 0.7753
2024-04-01 18:00:40,065 - config - INFO - Epoch [18/60], Train Loss: 0.4200
2024-04-01 18:00:40,101 - config - INFO - Validation Loss: 0.4675
2024-04-01 18:00:40,101 - config - INFO - Validation Acc: 0.7753
2024-04-01 18:00:40,583 - config - INFO - Epoch [19/60], Train Loss: 0.4186
2024-04-01 18:00:40,618 - config - INFO - Validation Loss: 0.4670
2024-04-01 18:00:40,619 - config - INFO - Validation Acc: 0.7753
2024-04-01 18:00:41,127 - config - INFO - Epoch [20/60], Train Loss: 0.4172
2024-04-01 18:00:41,163 - config - INFO - Validation Loss: 0.4679
2024-04-01 18:00:41,164 - config - INFO - Validation Acc: 0.7753
2024-04-01 18:00:41,687 - config - INFO - Epoch [21/60], Train Loss: 0.4156
2024-04-01 18:00:41,731 - config - INFO - Validation Loss: 0.4681
2024-04-01 18:00:41,731 - config - INFO - Validation Acc: 0.7753
2024-04-01 18:00:42,266 - config - INFO - Epoch [22/60], Train Loss: 0.4147
2024-04-01 18:00:42,303 - config - INFO - Validation Loss: 0.4681
2024-04-01 18:00:42,304 - config - INFO - Validation Acc: 0.7753
2024-04-01 18:00:42,861 - config - INFO - Epoch [23/60], Train Loss: 0.4132
2024-04-01 18:00:42,895 - config - INFO - Validation Loss: 0.4654
2024-04-01 18:00:42,896 - config - INFO - Validation Acc: 0.7865
2024-04-01 18:00:43,398 - config - INFO - Epoch [24/60], Train Loss: 0.4123
2024-04-01 18:00:43,434 - config - INFO - Validation Loss: 0.4659
2024-04-01 18:00:43,434 - config - INFO - Validation Acc: 0.7809
2024-04-01 18:00:43,927 - config - INFO - Epoch [25/60], Train Loss: 0.4111
2024-04-01 18:00:43,961 - config - INFO - Validation Loss: 0.4663
2024-04-01 18:00:43,961 - config - INFO - Validation Acc: 0.7753
2024-04-01 18:00:44,490 - config - INFO - Epoch [26/60], Train Loss: 0.4102
2024-04-01 18:00:44,522 - config - INFO - Validation Loss: 0.4692
2024-04-01 18:00:44,523 - config - INFO - Validation Acc: 0.7809
2024-04-01 18:00:45,020 - config - INFO - Epoch [27/60], Train Loss: 0.4101
2024-04-01 18:00:45,050 - config - INFO - Validation Loss: 0.4693
2024-04-01 18:00:45,050 - config - INFO - Validation Acc: 0.7809
2024-04-01 18:01:01,952 - config - INFO - resume: None
2024-04-01 18:01:01,952 - config - INFO - device: cpu
2024-04-01 18:01:01,952 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 18:01:01,952 - config - INFO - learning_rate: 1e-06
2024-04-01 18:01:01,952 - config - INFO - num_epochs: 60
2024-04-01 18:01:01,952 - config - INFO - batch_size: 64
2024-04-01 18:01:01,953 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 10

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 18:01:01,974 - config - INFO - Dataset size: 891
2024-04-01 18:01:02,004 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN1(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss()(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs.append(batch_outputs)
                labels.append(batch_labels)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        if type(self.model).__name__ == 'MaNN1':
            val_acc = calculate_accuracy(torch.max(outputs, dim=1)[1], labels)
        else:
            val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 18:01:02,005 - config - INFO - Training start
2024-04-01 18:01:05,006 - config - INFO - Epoch [1/60], Train Loss: 0.6548
2024-04-01 18:01:05,049 - config - INFO - Validation Loss: 0.6589
2024-04-01 18:01:05,049 - config - INFO - Validation Acc: 0.5899
2024-04-01 18:01:05,634 - config - INFO - Epoch [2/60], Train Loss: 0.6345
2024-04-01 18:01:05,672 - config - INFO - Validation Loss: 0.6426
2024-04-01 18:01:05,672 - config - INFO - Validation Acc: 0.5899
2024-04-01 18:01:06,293 - config - INFO - Epoch [3/60], Train Loss: 0.6202
2024-04-01 18:01:06,332 - config - INFO - Validation Loss: 0.6237
2024-04-01 18:01:06,333 - config - INFO - Validation Acc: 0.6236
2024-04-01 18:01:06,906 - config - INFO - Epoch [4/60], Train Loss: 0.6059
2024-04-01 18:01:06,953 - config - INFO - Validation Loss: 0.6143
2024-04-01 18:01:06,954 - config - INFO - Validation Acc: 0.6067
2024-04-01 18:01:07,512 - config - INFO - Epoch [5/60], Train Loss: 0.5966
2024-04-01 18:01:07,554 - config - INFO - Validation Loss: 0.5977
2024-04-01 18:01:07,554 - config - INFO - Validation Acc: 0.7079
2024-04-01 18:01:08,109 - config - INFO - Epoch [6/60], Train Loss: 0.5863
2024-04-01 18:01:08,145 - config - INFO - Validation Loss: 0.5899
2024-04-01 18:01:08,146 - config - INFO - Validation Acc: 0.6742
2024-04-01 18:01:08,678 - config - INFO - Epoch [7/60], Train Loss: 0.5806
2024-04-01 18:01:08,721 - config - INFO - Validation Loss: 0.5880
2024-04-01 18:01:08,721 - config - INFO - Validation Acc: 0.6573
2024-04-01 18:01:09,257 - config - INFO - Epoch [8/60], Train Loss: 0.5680
2024-04-01 18:01:09,294 - config - INFO - Validation Loss: 0.5712
2024-04-01 18:01:09,295 - config - INFO - Validation Acc: 0.7584
2024-04-01 18:01:09,832 - config - INFO - Epoch [9/60], Train Loss: 0.5641
2024-04-01 18:01:09,878 - config - INFO - Validation Loss: 0.5641
2024-04-01 18:01:09,879 - config - INFO - Validation Acc: 0.7247
2024-04-01 18:01:10,447 - config - INFO - Epoch [10/60], Train Loss: 0.5542
2024-04-01 18:01:10,498 - config - INFO - Validation Loss: 0.5595
2024-04-01 18:01:10,498 - config - INFO - Validation Acc: 0.7022
2024-04-01 18:01:11,071 - config - INFO - Epoch [11/60], Train Loss: 0.5487
2024-04-01 18:01:11,109 - config - INFO - Validation Loss: 0.5503
2024-04-01 18:01:11,109 - config - INFO - Validation Acc: 0.7247
2024-04-01 18:01:11,672 - config - INFO - Epoch [12/60], Train Loss: 0.5443
2024-04-01 18:01:11,719 - config - INFO - Validation Loss: 0.5465
2024-04-01 18:01:11,720 - config - INFO - Validation Acc: 0.7247
2024-04-01 18:01:12,247 - config - INFO - Epoch [13/60], Train Loss: 0.5381
2024-04-01 18:01:12,283 - config - INFO - Validation Loss: 0.5357
2024-04-01 18:01:12,284 - config - INFO - Validation Acc: 0.7921
2024-04-01 18:01:12,860 - config - INFO - Epoch [14/60], Train Loss: 0.5350
2024-04-01 18:01:12,910 - config - INFO - Validation Loss: 0.5307
2024-04-01 18:01:12,910 - config - INFO - Validation Acc: 0.7921
2024-04-01 18:01:13,465 - config - INFO - Epoch [15/60], Train Loss: 0.5290
2024-04-01 18:01:13,502 - config - INFO - Validation Loss: 0.5299
2024-04-01 18:01:13,502 - config - INFO - Validation Acc: 0.7360
2024-04-01 18:01:14,007 - config - INFO - Epoch [16/60], Train Loss: 0.5231
2024-04-01 18:01:14,054 - config - INFO - Validation Loss: 0.5190
2024-04-01 18:01:14,055 - config - INFO - Validation Acc: 0.8146
2024-04-01 18:01:14,542 - config - INFO - Epoch [17/60], Train Loss: 0.5193
2024-04-01 18:01:14,584 - config - INFO - Validation Loss: 0.5172
2024-04-01 18:01:14,584 - config - INFO - Validation Acc: 0.7753
2024-04-01 18:01:15,137 - config - INFO - Epoch [18/60], Train Loss: 0.5179
2024-04-01 18:01:15,188 - config - INFO - Validation Loss: 0.5176
2024-04-01 18:01:15,188 - config - INFO - Validation Acc: 0.7472
2024-04-01 18:01:15,744 - config - INFO - Epoch [19/60], Train Loss: 0.5116
2024-04-01 18:01:15,793 - config - INFO - Validation Loss: 0.5060
2024-04-01 18:01:15,794 - config - INFO - Validation Acc: 0.7809
2024-04-01 18:01:16,328 - config - INFO - Epoch [20/60], Train Loss: 0.5099
2024-04-01 18:01:16,363 - config - INFO - Validation Loss: 0.5031
2024-04-01 18:01:16,363 - config - INFO - Validation Acc: 0.8090
2024-04-01 18:01:16,859 - config - INFO - Epoch [21/60], Train Loss: 0.5050
2024-04-01 18:01:16,906 - config - INFO - Validation Loss: 0.4989
2024-04-01 18:01:16,906 - config - INFO - Validation Acc: 0.8146
2024-04-01 18:01:17,407 - config - INFO - Epoch [22/60], Train Loss: 0.5026
2024-04-01 18:01:17,456 - config - INFO - Validation Loss: 0.4944
2024-04-01 18:01:17,457 - config - INFO - Validation Acc: 0.8258
2024-04-01 18:01:18,012 - config - INFO - Epoch [23/60], Train Loss: 0.4987
2024-04-01 18:01:18,049 - config - INFO - Validation Loss: 0.4945
2024-04-01 18:01:18,049 - config - INFO - Validation Acc: 0.8090
2024-04-01 18:01:18,602 - config - INFO - Epoch [24/60], Train Loss: 0.4974
2024-04-01 18:01:18,638 - config - INFO - Validation Loss: 0.4871
2024-04-01 18:01:18,639 - config - INFO - Validation Acc: 0.8146
2024-04-01 18:01:19,163 - config - INFO - Epoch [25/60], Train Loss: 0.4938
2024-04-01 18:01:19,208 - config - INFO - Validation Loss: 0.4887
2024-04-01 18:01:19,208 - config - INFO - Validation Acc: 0.8034
2024-04-01 18:01:19,726 - config - INFO - Epoch [26/60], Train Loss: 0.4923
2024-04-01 18:01:19,772 - config - INFO - Validation Loss: 0.4828
2024-04-01 18:01:19,772 - config - INFO - Validation Acc: 0.8202
2024-04-01 18:01:20,282 - config - INFO - Epoch [27/60], Train Loss: 0.4889
2024-04-01 18:01:20,324 - config - INFO - Validation Loss: 0.4768
2024-04-01 18:01:20,324 - config - INFO - Validation Acc: 0.8090
2024-04-01 18:01:20,870 - config - INFO - Epoch [28/60], Train Loss: 0.4880
2024-04-01 18:01:20,922 - config - INFO - Validation Loss: 0.4759
2024-04-01 18:01:20,922 - config - INFO - Validation Acc: 0.8202
2024-04-01 18:01:21,471 - config - INFO - Epoch [29/60], Train Loss: 0.4842
2024-04-01 18:01:21,512 - config - INFO - Validation Loss: 0.4713
2024-04-01 18:01:21,512 - config - INFO - Validation Acc: 0.8034
2024-04-01 18:01:22,038 - config - INFO - Epoch [30/60], Train Loss: 0.4854
2024-04-01 18:01:22,084 - config - INFO - Validation Loss: 0.4701
2024-04-01 18:01:22,085 - config - INFO - Validation Acc: 0.8202
2024-04-01 18:01:22,609 - config - INFO - Epoch [31/60], Train Loss: 0.4845
2024-04-01 18:01:22,650 - config - INFO - Validation Loss: 0.4731
2024-04-01 18:01:22,651 - config - INFO - Validation Acc: 0.8258
2024-04-01 18:01:23,188 - config - INFO - Epoch [32/60], Train Loss: 0.4791
2024-04-01 18:01:23,235 - config - INFO - Validation Loss: 0.4646
2024-04-01 18:01:23,236 - config - INFO - Validation Acc: 0.8146
2024-04-01 18:01:23,770 - config - INFO - Epoch [33/60], Train Loss: 0.4789
2024-04-01 18:01:23,812 - config - INFO - Validation Loss: 0.4630
2024-04-01 18:01:23,813 - config - INFO - Validation Acc: 0.8146
2024-04-01 18:01:24,344 - config - INFO - Epoch [34/60], Train Loss: 0.4756
2024-04-01 18:01:24,381 - config - INFO - Validation Loss: 0.4636
2024-04-01 18:01:24,381 - config - INFO - Validation Acc: 0.8202
2024-04-01 18:01:24,906 - config - INFO - Epoch [35/60], Train Loss: 0.4741
2024-04-01 18:01:24,940 - config - INFO - Validation Loss: 0.4584
2024-04-01 18:01:24,940 - config - INFO - Validation Acc: 0.8146
2024-04-01 18:01:25,462 - config - INFO - Epoch [36/60], Train Loss: 0.4730
2024-04-01 18:01:25,500 - config - INFO - Validation Loss: 0.4596
2024-04-01 18:01:25,500 - config - INFO - Validation Acc: 0.8315
2024-04-01 18:01:26,038 - config - INFO - Epoch [37/60], Train Loss: 0.4725
2024-04-01 18:01:26,080 - config - INFO - Validation Loss: 0.4559
2024-04-01 18:01:26,081 - config - INFO - Validation Acc: 0.8202
2024-04-01 18:01:26,646 - config - INFO - Epoch [38/60], Train Loss: 0.4712
2024-04-01 18:01:26,686 - config - INFO - Validation Loss: 0.4576
2024-04-01 18:01:26,687 - config - INFO - Validation Acc: 0.8315
2024-04-01 18:01:27,214 - config - INFO - Epoch [39/60], Train Loss: 0.4708
2024-04-01 18:01:27,250 - config - INFO - Validation Loss: 0.4544
2024-04-01 18:01:27,250 - config - INFO - Validation Acc: 0.8371
2024-04-01 18:01:27,776 - config - INFO - Epoch [40/60], Train Loss: 0.4685
2024-04-01 18:01:27,816 - config - INFO - Validation Loss: 0.4512
2024-04-01 18:01:27,817 - config - INFO - Validation Acc: 0.8146
2024-04-01 18:01:28,312 - config - INFO - Epoch [41/60], Train Loss: 0.4681
2024-04-01 18:01:28,353 - config - INFO - Validation Loss: 0.4510
2024-04-01 18:01:28,353 - config - INFO - Validation Acc: 0.8258
2024-04-01 18:01:28,893 - config - INFO - Epoch [42/60], Train Loss: 0.4672
2024-04-01 18:01:28,928 - config - INFO - Validation Loss: 0.4484
2024-04-01 18:01:28,929 - config - INFO - Validation Acc: 0.8034
2024-04-01 18:01:29,428 - config - INFO - Epoch [43/60], Train Loss: 0.4684
2024-04-01 18:01:29,473 - config - INFO - Validation Loss: 0.4473
2024-04-01 18:01:29,474 - config - INFO - Validation Acc: 0.8090
2024-04-01 18:01:29,992 - config - INFO - Epoch [44/60], Train Loss: 0.4648
2024-04-01 18:01:30,028 - config - INFO - Validation Loss: 0.4537
2024-04-01 18:01:30,028 - config - INFO - Validation Acc: 0.8258
2024-04-01 18:01:30,556 - config - INFO - Epoch [45/60], Train Loss: 0.4696
2024-04-01 18:01:30,589 - config - INFO - Validation Loss: 0.4472
2024-04-01 18:01:30,590 - config - INFO - Validation Acc: 0.8258
2024-04-01 18:01:31,099 - config - INFO - Epoch [46/60], Train Loss: 0.4633
2024-04-01 18:01:31,145 - config - INFO - Validation Loss: 0.4449
2024-04-01 18:01:31,146 - config - INFO - Validation Acc: 0.8202
2024-04-01 18:01:31,645 - config - INFO - Epoch [47/60], Train Loss: 0.4630
2024-04-01 18:01:31,691 - config - INFO - Validation Loss: 0.4450
2024-04-01 18:01:31,691 - config - INFO - Validation Acc: 0.8146
2024-04-01 18:01:32,199 - config - INFO - Epoch [48/60], Train Loss: 0.4634
2024-04-01 18:01:32,238 - config - INFO - Validation Loss: 0.4441
2024-04-01 18:01:32,239 - config - INFO - Validation Acc: 0.8146
2024-04-01 18:01:32,701 - config - INFO - Epoch [49/60], Train Loss: 0.4613
2024-04-01 18:01:32,734 - config - INFO - Validation Loss: 0.4437
2024-04-01 18:01:32,735 - config - INFO - Validation Acc: 0.8146
2024-04-01 18:01:33,226 - config - INFO - Epoch [50/60], Train Loss: 0.4619
2024-04-01 18:01:33,265 - config - INFO - Validation Loss: 0.4423
2024-04-01 18:01:33,266 - config - INFO - Validation Acc: 0.8202
2024-04-01 18:01:33,759 - config - INFO - Epoch [51/60], Train Loss: 0.4601
2024-04-01 18:01:33,791 - config - INFO - Validation Loss: 0.4464
2024-04-01 18:01:33,791 - config - INFO - Validation Acc: 0.8427
2024-04-01 18:01:34,261 - config - INFO - Epoch [52/60], Train Loss: 0.4608
2024-04-01 18:01:34,306 - config - INFO - Validation Loss: 0.4449
2024-04-01 18:01:34,307 - config - INFO - Validation Acc: 0.8427
2024-04-01 18:01:34,776 - config - INFO - Epoch [53/60], Train Loss: 0.4601
2024-04-01 18:01:34,814 - config - INFO - Validation Loss: 0.4421
2024-04-01 18:01:34,815 - config - INFO - Validation Acc: 0.8258
2024-04-01 18:01:35,306 - config - INFO - Epoch [54/60], Train Loss: 0.4603
2024-04-01 18:01:35,350 - config - INFO - Validation Loss: 0.4408
2024-04-01 18:01:35,350 - config - INFO - Validation Acc: 0.8202
2024-04-01 18:01:35,832 - config - INFO - Epoch [55/60], Train Loss: 0.4579
2024-04-01 18:01:35,865 - config - INFO - Validation Loss: 0.4382
2024-04-01 18:01:35,865 - config - INFO - Validation Acc: 0.8202
2024-04-01 18:01:36,388 - config - INFO - Epoch [56/60], Train Loss: 0.4602
2024-04-01 18:01:36,424 - config - INFO - Validation Loss: 0.4372
2024-04-01 18:01:36,424 - config - INFO - Validation Acc: 0.8090
2024-04-01 18:02:26,144 - config - INFO - resume: None
2024-04-01 18:02:26,144 - config - INFO - device: cpu
2024-04-01 18:02:26,144 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 18:02:26,144 - config - INFO - learning_rate: 1e-06
2024-04-01 18:02:26,144 - config - INFO - num_epochs: 60
2024-04-01 18:02:26,144 - config - INFO - batch_size: 64
2024-04-01 18:02:26,144 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 10

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 18:02:26,165 - config - INFO - Dataset size: 891
2024-04-01 18:02:26,203 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss()(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs.append(batch_outputs)
                labels.append(batch_labels)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        if type(self.model).__name__ == 'MaNN1':
            val_acc = calculate_accuracy(torch.max(outputs, dim=1)[1], labels)
        else:
            val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 18:02:26,203 - config - INFO - Training start
2024-04-01 18:02:29,425 - config - INFO - Epoch [1/60], Train Loss: 0.7071
2024-04-01 18:02:29,480 - config - INFO - Validation Loss: 0.6720
2024-04-01 18:02:29,480 - config - INFO - Validation Acc: 0.6517
2024-04-01 18:02:30,293 - config - INFO - Epoch [2/60], Train Loss: 0.6872
2024-04-01 18:02:30,344 - config - INFO - Validation Loss: 0.6634
2024-04-01 18:02:30,344 - config - INFO - Validation Acc: 0.6517
2024-04-01 18:02:31,138 - config - INFO - Epoch [3/60], Train Loss: 0.6785
2024-04-01 18:02:31,185 - config - INFO - Validation Loss: 0.6533
2024-04-01 18:02:31,185 - config - INFO - Validation Acc: 0.6517
2024-04-01 18:02:31,965 - config - INFO - Epoch [4/60], Train Loss: 0.6701
2024-04-01 18:02:32,012 - config - INFO - Validation Loss: 0.6431
2024-04-01 18:02:32,013 - config - INFO - Validation Acc: 0.6517
2024-04-01 18:02:32,709 - config - INFO - Epoch [5/60], Train Loss: 0.6635
2024-04-01 18:02:32,757 - config - INFO - Validation Loss: 0.6349
2024-04-01 18:02:32,758 - config - INFO - Validation Acc: 0.6517
2024-04-01 18:02:33,417 - config - INFO - Epoch [6/60], Train Loss: 0.6542
2024-04-01 18:02:33,459 - config - INFO - Validation Loss: 0.6342
2024-04-01 18:02:33,466 - config - INFO - Validation Acc: 0.6517
2024-04-01 18:02:34,115 - config - INFO - Epoch [7/60], Train Loss: 0.6467
2024-04-01 18:02:34,158 - config - INFO - Validation Loss: 0.6215
2024-04-01 18:02:34,158 - config - INFO - Validation Acc: 0.6517
2024-04-01 18:02:34,810 - config - INFO - Epoch [8/60], Train Loss: 0.6440
2024-04-01 18:02:34,852 - config - INFO - Validation Loss: 0.6123
2024-04-01 18:02:34,853 - config - INFO - Validation Acc: 0.6517
2024-04-01 18:02:35,456 - config - INFO - Epoch [9/60], Train Loss: 0.6350
2024-04-01 18:02:35,502 - config - INFO - Validation Loss: 0.6126
2024-04-01 18:02:35,502 - config - INFO - Validation Acc: 0.6685
2024-04-01 18:02:36,097 - config - INFO - Epoch [10/60], Train Loss: 0.6280
2024-04-01 18:02:36,139 - config - INFO - Validation Loss: 0.6033
2024-04-01 18:02:36,139 - config - INFO - Validation Acc: 0.6629
2024-04-01 18:02:36,737 - config - INFO - Epoch [11/60], Train Loss: 0.6222
2024-04-01 18:02:36,784 - config - INFO - Validation Loss: 0.5984
2024-04-01 18:02:36,784 - config - INFO - Validation Acc: 0.6854
2024-04-01 18:02:37,413 - config - INFO - Epoch [12/60], Train Loss: 0.6168
2024-04-01 18:02:37,452 - config - INFO - Validation Loss: 0.5894
2024-04-01 18:02:37,452 - config - INFO - Validation Acc: 0.6742
2024-04-01 18:02:38,079 - config - INFO - Epoch [13/60], Train Loss: 0.6112
2024-04-01 18:02:38,120 - config - INFO - Validation Loss: 0.5868
2024-04-01 18:02:38,120 - config - INFO - Validation Acc: 0.6910
2024-04-01 18:02:38,751 - config - INFO - Epoch [14/60], Train Loss: 0.6065
2024-04-01 18:02:38,791 - config - INFO - Validation Loss: 0.5865
2024-04-01 18:02:38,791 - config - INFO - Validation Acc: 0.7303
2024-04-01 18:02:39,409 - config - INFO - Epoch [15/60], Train Loss: 0.6029
2024-04-01 18:02:39,448 - config - INFO - Validation Loss: 0.5780
2024-04-01 18:02:39,449 - config - INFO - Validation Acc: 0.7079
2024-04-01 18:02:40,049 - config - INFO - Epoch [16/60], Train Loss: 0.5974
2024-04-01 18:02:40,089 - config - INFO - Validation Loss: 0.5684
2024-04-01 18:02:40,090 - config - INFO - Validation Acc: 0.6966
2024-04-01 18:02:40,701 - config - INFO - Epoch [17/60], Train Loss: 0.5929
2024-04-01 18:02:40,741 - config - INFO - Validation Loss: 0.5655
2024-04-01 18:02:40,742 - config - INFO - Validation Acc: 0.7079
2024-04-01 18:02:41,340 - config - INFO - Epoch [18/60], Train Loss: 0.5879
2024-04-01 18:02:41,382 - config - INFO - Validation Loss: 0.5615
2024-04-01 18:02:41,382 - config - INFO - Validation Acc: 0.7303
2024-04-01 18:02:41,963 - config - INFO - Epoch [19/60], Train Loss: 0.5839
2024-04-01 18:02:42,005 - config - INFO - Validation Loss: 0.5551
2024-04-01 18:02:42,005 - config - INFO - Validation Acc: 0.7191
2024-04-01 18:02:42,619 - config - INFO - Epoch [20/60], Train Loss: 0.5795
2024-04-01 18:02:42,658 - config - INFO - Validation Loss: 0.5501
2024-04-01 18:02:42,658 - config - INFO - Validation Acc: 0.7303
2024-04-01 18:02:43,253 - config - INFO - Epoch [21/60], Train Loss: 0.5758
2024-04-01 18:02:43,296 - config - INFO - Validation Loss: 0.5454
2024-04-01 18:02:43,296 - config - INFO - Validation Acc: 0.7416
2024-04-01 18:02:43,892 - config - INFO - Epoch [22/60], Train Loss: 0.5719
2024-04-01 18:02:43,931 - config - INFO - Validation Loss: 0.5402
2024-04-01 18:02:43,931 - config - INFO - Validation Acc: 0.7303
2024-04-01 18:02:44,527 - config - INFO - Epoch [23/60], Train Loss: 0.5686
2024-04-01 18:02:44,567 - config - INFO - Validation Loss: 0.5356
2024-04-01 18:02:44,567 - config - INFO - Validation Acc: 0.7472
2024-04-01 18:02:45,160 - config - INFO - Epoch [24/60], Train Loss: 0.5658
2024-04-01 18:02:45,198 - config - INFO - Validation Loss: 0.5363
2024-04-01 18:02:45,199 - config - INFO - Validation Acc: 0.8146
2024-04-01 18:02:45,764 - config - INFO - Epoch [25/60], Train Loss: 0.5618
2024-04-01 18:02:45,801 - config - INFO - Validation Loss: 0.5269
2024-04-01 18:02:45,802 - config - INFO - Validation Acc: 0.7584
2024-04-01 18:02:46,395 - config - INFO - Epoch [26/60], Train Loss: 0.5585
2024-04-01 18:02:46,433 - config - INFO - Validation Loss: 0.5252
2024-04-01 18:02:46,434 - config - INFO - Validation Acc: 0.7584
2024-04-01 18:02:47,025 - config - INFO - Epoch [27/60], Train Loss: 0.5554
2024-04-01 18:02:47,064 - config - INFO - Validation Loss: 0.5230
2024-04-01 18:02:47,064 - config - INFO - Validation Acc: 0.7865
2024-04-01 18:02:47,657 - config - INFO - Epoch [28/60], Train Loss: 0.5526
2024-04-01 18:02:47,698 - config - INFO - Validation Loss: 0.5182
2024-04-01 18:02:47,699 - config - INFO - Validation Acc: 0.7697
2024-04-01 18:02:48,291 - config - INFO - Epoch [29/60], Train Loss: 0.5499
2024-04-01 18:02:48,329 - config - INFO - Validation Loss: 0.5153
2024-04-01 18:02:48,329 - config - INFO - Validation Acc: 0.7809
2024-04-01 18:02:48,893 - config - INFO - Epoch [30/60], Train Loss: 0.5477
2024-04-01 18:02:48,931 - config - INFO - Validation Loss: 0.5137
2024-04-01 18:02:48,932 - config - INFO - Validation Acc: 0.8427
2024-04-01 18:02:49,521 - config - INFO - Epoch [31/60], Train Loss: 0.5445
2024-04-01 18:02:49,558 - config - INFO - Validation Loss: 0.5078
2024-04-01 18:02:49,560 - config - INFO - Validation Acc: 0.7753
2024-04-01 18:02:50,161 - config - INFO - Epoch [32/60], Train Loss: 0.5429
2024-04-01 18:02:50,200 - config - INFO - Validation Loss: 0.5055
2024-04-01 18:02:50,201 - config - INFO - Validation Acc: 0.8090
2024-04-01 18:02:50,827 - config - INFO - Epoch [33/60], Train Loss: 0.5412
2024-04-01 18:02:50,865 - config - INFO - Validation Loss: 0.4998
2024-04-01 18:02:50,866 - config - INFO - Validation Acc: 0.7584
2024-04-01 18:02:51,516 - config - INFO - Epoch [34/60], Train Loss: 0.5379
2024-04-01 18:02:51,555 - config - INFO - Validation Loss: 0.4984
2024-04-01 18:02:51,556 - config - INFO - Validation Acc: 0.8090
2024-04-01 18:02:52,158 - config - INFO - Epoch [35/60], Train Loss: 0.5344
2024-04-01 18:02:52,196 - config - INFO - Validation Loss: 0.4954
2024-04-01 18:02:52,197 - config - INFO - Validation Acc: 0.8146
2024-04-01 18:02:52,807 - config - INFO - Epoch [36/60], Train Loss: 0.5322
2024-04-01 18:02:52,843 - config - INFO - Validation Loss: 0.4935
2024-04-01 18:02:52,843 - config - INFO - Validation Acc: 0.8483
2024-04-01 18:02:53,428 - config - INFO - Epoch [37/60], Train Loss: 0.5301
2024-04-01 18:02:53,464 - config - INFO - Validation Loss: 0.4892
2024-04-01 18:02:53,464 - config - INFO - Validation Acc: 0.8090
2024-04-01 18:02:54,048 - config - INFO - Epoch [38/60], Train Loss: 0.5315
2024-04-01 18:02:54,086 - config - INFO - Validation Loss: 0.4931
2024-04-01 18:02:54,086 - config - INFO - Validation Acc: 0.8371
2024-04-01 18:02:54,683 - config - INFO - Epoch [39/60], Train Loss: 0.5263
2024-04-01 18:02:54,720 - config - INFO - Validation Loss: 0.4851
2024-04-01 18:02:54,720 - config - INFO - Validation Acc: 0.8371
2024-04-01 18:02:55,309 - config - INFO - Epoch [40/60], Train Loss: 0.5242
2024-04-01 18:02:55,346 - config - INFO - Validation Loss: 0.4809
2024-04-01 18:02:55,347 - config - INFO - Validation Acc: 0.8090
2024-04-01 18:02:55,910 - config - INFO - Epoch [41/60], Train Loss: 0.5226
2024-04-01 18:02:55,947 - config - INFO - Validation Loss: 0.4809
2024-04-01 18:02:55,947 - config - INFO - Validation Acc: 0.8483
2024-04-01 18:02:56,528 - config - INFO - Epoch [42/60], Train Loss: 0.5204
2024-04-01 18:02:56,565 - config - INFO - Validation Loss: 0.4768
2024-04-01 18:02:56,566 - config - INFO - Validation Acc: 0.8371
2024-04-01 18:02:57,142 - config - INFO - Epoch [43/60], Train Loss: 0.5187
2024-04-01 18:02:57,179 - config - INFO - Validation Loss: 0.4739
2024-04-01 18:02:57,179 - config - INFO - Validation Acc: 0.8483
2024-04-01 18:02:57,769 - config - INFO - Epoch [44/60], Train Loss: 0.5167
2024-04-01 18:02:57,806 - config - INFO - Validation Loss: 0.4735
2024-04-01 18:02:57,806 - config - INFO - Validation Acc: 0.8483
2024-04-01 18:02:58,381 - config - INFO - Epoch [45/60], Train Loss: 0.5153
2024-04-01 18:02:58,418 - config - INFO - Validation Loss: 0.4705
2024-04-01 18:02:58,419 - config - INFO - Validation Acc: 0.8483
2024-04-01 18:02:59,001 - config - INFO - Epoch [46/60], Train Loss: 0.5145
2024-04-01 18:02:59,038 - config - INFO - Validation Loss: 0.4718
2024-04-01 18:02:59,038 - config - INFO - Validation Acc: 0.8371
2024-04-01 18:02:59,611 - config - INFO - Epoch [47/60], Train Loss: 0.5144
2024-04-01 18:02:59,648 - config - INFO - Validation Loss: 0.4698
2024-04-01 18:02:59,649 - config - INFO - Validation Acc: 0.8371
2024-04-01 18:03:00,236 - config - INFO - Epoch [48/60], Train Loss: 0.5115
2024-04-01 18:03:00,272 - config - INFO - Validation Loss: 0.4654
2024-04-01 18:03:00,273 - config - INFO - Validation Acc: 0.8483
2024-04-01 18:03:00,856 - config - INFO - Epoch [49/60], Train Loss: 0.5100
2024-04-01 18:03:00,894 - config - INFO - Validation Loss: 0.4630
2024-04-01 18:03:00,894 - config - INFO - Validation Acc: 0.8483
2024-04-01 18:03:01,471 - config - INFO - Epoch [50/60], Train Loss: 0.5088
2024-04-01 18:03:01,509 - config - INFO - Validation Loss: 0.4593
2024-04-01 18:03:01,518 - config - INFO - Validation Acc: 0.8483
2024-04-01 18:03:02,027 - config - INFO - Epoch [51/60], Train Loss: 0.5075
2024-04-01 18:03:02,063 - config - INFO - Validation Loss: 0.4588
2024-04-01 18:03:02,063 - config - INFO - Validation Acc: 0.8483
2024-04-01 18:03:02,629 - config - INFO - Epoch [52/60], Train Loss: 0.5066
2024-04-01 18:03:02,669 - config - INFO - Validation Loss: 0.4583
2024-04-01 18:03:02,670 - config - INFO - Validation Acc: 0.8427
2024-04-01 18:03:03,280 - config - INFO - Epoch [53/60], Train Loss: 0.5054
2024-04-01 18:03:03,317 - config - INFO - Validation Loss: 0.4558
2024-04-01 18:03:03,318 - config - INFO - Validation Acc: 0.8483
2024-04-01 18:03:03,906 - config - INFO - Epoch [54/60], Train Loss: 0.5066
2024-04-01 18:03:03,944 - config - INFO - Validation Loss: 0.4519
2024-04-01 18:03:03,944 - config - INFO - Validation Acc: 0.8483
2024-04-01 18:03:04,551 - config - INFO - Epoch [55/60], Train Loss: 0.5025
2024-04-01 18:03:04,587 - config - INFO - Validation Loss: 0.4515
2024-04-01 18:03:04,587 - config - INFO - Validation Acc: 0.8483
2024-04-01 18:03:05,228 - config - INFO - Epoch [56/60], Train Loss: 0.5013
2024-04-01 18:03:05,267 - config - INFO - Validation Loss: 0.4495
2024-04-01 18:03:05,267 - config - INFO - Validation Acc: 0.8483
2024-04-01 18:03:05,916 - config - INFO - Epoch [57/60], Train Loss: 0.5006
2024-04-01 18:03:05,955 - config - INFO - Validation Loss: 0.4473
2024-04-01 18:03:05,955 - config - INFO - Validation Acc: 0.8483
2024-04-01 18:03:06,582 - config - INFO - Epoch [58/60], Train Loss: 0.5000
2024-04-01 18:03:06,622 - config - INFO - Validation Loss: 0.4452
2024-04-01 18:03:06,623 - config - INFO - Validation Acc: 0.8596
2024-04-01 18:03:07,252 - config - INFO - Epoch [59/60], Train Loss: 0.4992
2024-04-01 18:03:07,290 - config - INFO - Validation Loss: 0.4460
2024-04-01 18:03:07,290 - config - INFO - Validation Acc: 0.8371
2024-04-01 18:03:07,873 - config - INFO - Epoch [60/60], Train Loss: 0.4976
2024-04-01 18:03:07,911 - config - INFO - Validation Loss: 0.4435
2024-04-01 18:03:07,911 - config - INFO - Validation Acc: 0.8371
2024-04-01 18:04:14,812 - config - INFO - resume: None
2024-04-01 18:04:14,812 - config - INFO - device: cpu
2024-04-01 18:04:14,812 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 18:04:14,812 - config - INFO - learning_rate: 1e-06
2024-04-01 18:04:14,812 - config - INFO - num_epochs: 60
2024-04-01 18:04:14,812 - config - INFO - batch_size: 64
2024-04-01 18:04:14,812 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 10

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 18:04:14,833 - config - INFO - Dataset size: 891
2024-04-01 18:04:14,948 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 1280000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(1280000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss()(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs.append(batch_outputs)
                labels.append(batch_labels)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        if type(self.model).__name__ == 'MaNN1':
            val_acc = calculate_accuracy(torch.max(outputs, dim=1)[1], labels)
        else:
            val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 18:04:14,948 - config - INFO - Training start
2024-04-01 18:04:24,889 - config - INFO - Epoch [1/60], Train Loss: 0.6746
2024-04-01 18:04:25,391 - config - INFO - Validation Loss: 0.6262
2024-04-01 18:04:25,392 - config - INFO - Validation Acc: 0.7978
2024-04-01 18:04:32,491 - config - INFO - Epoch [2/60], Train Loss: 0.6159
2024-04-01 18:04:32,983 - config - INFO - Validation Loss: 0.5678
2024-04-01 18:04:32,983 - config - INFO - Validation Acc: 0.7303
2024-04-01 18:04:39,858 - config - INFO - Epoch [3/60], Train Loss: 0.5735
2024-04-01 18:04:40,374 - config - INFO - Validation Loss: 0.5461
2024-04-01 18:04:40,374 - config - INFO - Validation Acc: 0.7640
2024-04-01 18:04:47,635 - config - INFO - Epoch [4/60], Train Loss: 0.5452
2024-04-01 18:04:48,132 - config - INFO - Validation Loss: 0.5312
2024-04-01 18:04:48,135 - config - INFO - Validation Acc: 0.7697
2024-04-01 18:04:55,758 - config - INFO - Epoch [5/60], Train Loss: 0.5224
2024-04-01 18:04:56,289 - config - INFO - Validation Loss: 0.5059
2024-04-01 18:04:56,291 - config - INFO - Validation Acc: 0.7753
2024-04-01 18:05:03,597 - config - INFO - Epoch [6/60], Train Loss: 0.5035
2024-04-01 18:05:04,108 - config - INFO - Validation Loss: 0.4944
2024-04-01 18:05:04,109 - config - INFO - Validation Acc: 0.7809
2024-04-01 18:06:37,865 - config - INFO - resume: None
2024-04-01 18:06:37,865 - config - INFO - device: cpu
2024-04-01 18:06:37,865 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 18:06:37,865 - config - INFO - learning_rate: 0.001
2024-04-01 18:06:37,865 - config - INFO - num_epochs: 60
2024-04-01 18:06:37,865 - config - INFO - batch_size: 64
2024-04-01 18:06:37,865 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 10

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 18:06:37,887 - config - INFO - Dataset size: 891
2024-04-01 18:06:37,998 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 1280000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(1280000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss()(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs.append(batch_outputs)
                labels.append(batch_labels)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        if type(self.model).__name__ == 'MaNN1':
            val_acc = calculate_accuracy(torch.max(outputs, dim=1)[1], labels)
        else:
            val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 18:06:37,998 - config - INFO - Training start
2024-04-01 18:06:48,342 - config - INFO - Epoch [1/60], Train Loss: 35.1823
2024-04-01 18:06:48,868 - config - INFO - Validation Loss: 38.7640
2024-04-01 18:06:48,868 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:06:55,849 - config - INFO - Epoch [2/60], Train Loss: 38.2022
2024-04-01 18:06:56,331 - config - INFO - Validation Loss: 38.7640
2024-04-01 18:06:56,331 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:07:03,615 - config - INFO - Epoch [3/60], Train Loss: 38.2022
2024-04-01 18:07:04,108 - config - INFO - Validation Loss: 38.7640
2024-04-01 18:07:04,108 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:07:10,920 - config - INFO - Epoch [4/60], Train Loss: 38.2022
2024-04-01 18:07:11,380 - config - INFO - Validation Loss: 38.7640
2024-04-01 18:07:11,380 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:09:14,081 - config - INFO - resume: None
2024-04-01 18:09:14,081 - config - INFO - device: cpu
2024-04-01 18:09:14,081 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 18:09:14,082 - config - INFO - learning_rate: 0.001
2024-04-01 18:09:14,082 - config - INFO - num_epochs: 180
2024-04-01 18:09:14,082 - config - INFO - batch_size: 64
2024-04-01 18:09:14,082 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 10

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 18:09:14,124 - config - INFO - Dataset size: 891
2024-04-01 18:09:14,156 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss()(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs.append(batch_outputs)
                labels.append(batch_labels)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        if type(self.model).__name__ == 'MaNN1':
            val_acc = calculate_accuracy(torch.max(outputs, dim=1)[1], labels)
        else:
            val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 18:09:14,156 - config - INFO - Training start
2024-04-01 18:10:26,522 - config - INFO - resume: None
2024-04-01 18:10:26,522 - config - INFO - device: cpu
2024-04-01 18:10:26,522 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 18:10:26,522 - config - INFO - learning_rate: 1e-05
2024-04-01 18:10:26,522 - config - INFO - num_epochs: 180
2024-04-01 18:10:26,522 - config - INFO - batch_size: 64
2024-04-01 18:10:26,522 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 10

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 18:10:26,563 - config - INFO - Dataset size: 891
2024-04-01 18:10:26,592 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss()(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs.append(batch_outputs)
                labels.append(batch_labels)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        if type(self.model).__name__ == 'MaNN1':
            val_acc = calculate_accuracy(torch.max(outputs, dim=1)[1], labels)
        else:
            val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 18:10:26,592 - config - INFO - Training start
2024-04-01 18:14:45,762 - config - INFO - resume: None
2024-04-01 18:14:45,762 - config - INFO - device: cpu
2024-04-01 18:14:45,762 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 18:14:45,762 - config - INFO - learning_rate: 0.001
2024-04-01 18:14:45,762 - config - INFO - num_epochs: 60
2024-04-01 18:14:45,763 - config - INFO - batch_size: 64
2024-04-01 18:14:45,763 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 10

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 18:14:45,784 - config - INFO - Dataset size: 891
2024-04-01 18:15:11,281 - config - INFO - resume: None
2024-04-01 18:15:11,282 - config - INFO - device: cpu
2024-04-01 18:15:11,282 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 18:15:11,282 - config - INFO - learning_rate: 0.001
2024-04-01 18:15:11,282 - config - INFO - num_epochs: 60
2024-04-01 18:15:11,282 - config - INFO - batch_size: 64
2024-04-01 18:15:11,282 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 10

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 18:15:11,303 - config - INFO - Dataset size: 891
2024-04-01 18:15:11,324 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x


class MaNN2(nn.Module):
    def __init__(self, input_size):
        super(MaNN2, self).__init__()
        self.fc1 = nn.Linear(input_size, 20)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(20, 20)
        self.sigmoid = nn.Sigmoid()
        self.fc2 = nn.Linear(20, 20)
        self.fc3 = nn.Linear(20, 20)
        self.fc4 = nn.Linear(20, 20)
        self.fc5 = nn.Linear(20, 20)
        self.fc6 = nn.Linear(20, 20)
        self.fc7 = nn.Linear(20, 20)
        self.fc8 = nn.Linear(20, 20)
        self.fc9 = nn.Linear(20, 20)
        self.fc10 = nn.Linear(20, 1)

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        x = self.fc4(x)
        x = self.sigmoid(x)
        x = self.fc5(x)
        x = self.sigmoid(x)
        x = self.fc6(x)
        x = self.sigmoid(x)
        x = self.fc7(x)
        x = self.sigmoid(x)
        x = self.fc8(x)
        x = self.sigmoid(x)
        x = self.fc9(x)
        x = self.sigmoid(x)
        x = self.fc10(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN2(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss()(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs.append(batch_outputs)
                labels.append(batch_labels)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        if type(self.model).__name__ == 'MaNN1':
            val_acc = calculate_accuracy(torch.max(outputs, dim=1)[1], labels)
        else:
            val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 18:15:11,324 - config - INFO - Training start
2024-04-01 18:15:13,758 - config - INFO - Epoch [1/60], Train Loss: 0.7285
2024-04-01 18:15:13,767 - config - INFO - Validation Loss: 0.7052
2024-04-01 18:15:13,767 - config - INFO - Validation Acc: 0.4045
2024-04-01 18:15:13,854 - config - INFO - Epoch [2/60], Train Loss: 0.6961
2024-04-01 18:15:13,862 - config - INFO - Validation Loss: 0.6857
2024-04-01 18:15:13,862 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:13,949 - config - INFO - Epoch [3/60], Train Loss: 0.6767
2024-04-01 18:15:13,956 - config - INFO - Validation Loss: 0.6771
2024-04-01 18:15:13,956 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:14,033 - config - INFO - Epoch [4/60], Train Loss: 0.6686
2024-04-01 18:15:14,039 - config - INFO - Validation Loss: 0.6748
2024-04-01 18:15:14,039 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:14,098 - config - INFO - Epoch [5/60], Train Loss: 0.6644
2024-04-01 18:15:14,104 - config - INFO - Validation Loss: 0.6753
2024-04-01 18:15:14,104 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:14,163 - config - INFO - Epoch [6/60], Train Loss: 0.6637
2024-04-01 18:15:14,168 - config - INFO - Validation Loss: 0.6764
2024-04-01 18:15:14,169 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:14,227 - config - INFO - Epoch [7/60], Train Loss: 0.6640
2024-04-01 18:15:14,233 - config - INFO - Validation Loss: 0.6773
2024-04-01 18:15:14,233 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:14,292 - config - INFO - Epoch [8/60], Train Loss: 0.6640
2024-04-01 18:15:14,298 - config - INFO - Validation Loss: 0.6778
2024-04-01 18:15:14,298 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:14,356 - config - INFO - Epoch [9/60], Train Loss: 0.6642
2024-04-01 18:15:14,362 - config - INFO - Validation Loss: 0.6784
2024-04-01 18:15:14,362 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:14,424 - config - INFO - Epoch [10/60], Train Loss: 0.6649
2024-04-01 18:15:14,430 - config - INFO - Validation Loss: 0.6792
2024-04-01 18:15:14,430 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:14,506 - config - INFO - Epoch [11/60], Train Loss: 0.6643
2024-04-01 18:15:14,512 - config - INFO - Validation Loss: 0.6776
2024-04-01 18:15:14,512 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:14,571 - config - INFO - Epoch [12/60], Train Loss: 0.6642
2024-04-01 18:15:14,577 - config - INFO - Validation Loss: 0.6769
2024-04-01 18:15:14,577 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:14,635 - config - INFO - Epoch [13/60], Train Loss: 0.6639
2024-04-01 18:15:14,641 - config - INFO - Validation Loss: 0.6776
2024-04-01 18:15:14,641 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:14,701 - config - INFO - Epoch [14/60], Train Loss: 0.6641
2024-04-01 18:15:14,707 - config - INFO - Validation Loss: 0.6768
2024-04-01 18:15:14,707 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:14,766 - config - INFO - Epoch [15/60], Train Loss: 0.6638
2024-04-01 18:15:14,772 - config - INFO - Validation Loss: 0.6762
2024-04-01 18:15:14,772 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:14,831 - config - INFO - Epoch [16/60], Train Loss: 0.6637
2024-04-01 18:15:14,837 - config - INFO - Validation Loss: 0.6763
2024-04-01 18:15:14,838 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:14,897 - config - INFO - Epoch [17/60], Train Loss: 0.6640
2024-04-01 18:15:14,902 - config - INFO - Validation Loss: 0.6768
2024-04-01 18:15:14,903 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:14,961 - config - INFO - Epoch [18/60], Train Loss: 0.6638
2024-04-01 18:15:14,967 - config - INFO - Validation Loss: 0.6763
2024-04-01 18:15:14,967 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:15,029 - config - INFO - Epoch [19/60], Train Loss: 0.6639
2024-04-01 18:15:15,035 - config - INFO - Validation Loss: 0.6757
2024-04-01 18:15:15,035 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:15,094 - config - INFO - Epoch [20/60], Train Loss: 0.6639
2024-04-01 18:15:15,100 - config - INFO - Validation Loss: 0.6755
2024-04-01 18:15:15,100 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:15,159 - config - INFO - Epoch [21/60], Train Loss: 0.6636
2024-04-01 18:15:15,165 - config - INFO - Validation Loss: 0.6760
2024-04-01 18:15:15,165 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:15,224 - config - INFO - Epoch [22/60], Train Loss: 0.6637
2024-04-01 18:15:15,230 - config - INFO - Validation Loss: 0.6764
2024-04-01 18:15:15,230 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:15,289 - config - INFO - Epoch [23/60], Train Loss: 0.6639
2024-04-01 18:15:15,295 - config - INFO - Validation Loss: 0.6770
2024-04-01 18:15:15,295 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:15,354 - config - INFO - Epoch [24/60], Train Loss: 0.6640
2024-04-01 18:15:15,360 - config - INFO - Validation Loss: 0.6767
2024-04-01 18:15:15,360 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:15,419 - config - INFO - Epoch [25/60], Train Loss: 0.6638
2024-04-01 18:15:15,425 - config - INFO - Validation Loss: 0.6752
2024-04-01 18:15:15,425 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:15,484 - config - INFO - Epoch [26/60], Train Loss: 0.6640
2024-04-01 18:15:15,490 - config - INFO - Validation Loss: 0.6753
2024-04-01 18:15:15,490 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:15,548 - config - INFO - Epoch [27/60], Train Loss: 0.6639
2024-04-01 18:15:15,554 - config - INFO - Validation Loss: 0.6754
2024-04-01 18:15:15,554 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:15,612 - config - INFO - Epoch [28/60], Train Loss: 0.6639
2024-04-01 18:15:15,618 - config - INFO - Validation Loss: 0.6755
2024-04-01 18:15:15,618 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:15,676 - config - INFO - Epoch [29/60], Train Loss: 0.6639
2024-04-01 18:15:15,682 - config - INFO - Validation Loss: 0.6762
2024-04-01 18:15:15,682 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:15,740 - config - INFO - Epoch [30/60], Train Loss: 0.6639
2024-04-01 18:15:15,745 - config - INFO - Validation Loss: 0.6757
2024-04-01 18:15:15,746 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:15,803 - config - INFO - Epoch [31/60], Train Loss: 0.6638
2024-04-01 18:15:15,809 - config - INFO - Validation Loss: 0.6758
2024-04-01 18:15:15,809 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:15,868 - config - INFO - Epoch [32/60], Train Loss: 0.6639
2024-04-01 18:15:15,874 - config - INFO - Validation Loss: 0.6756
2024-04-01 18:15:15,874 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:15,932 - config - INFO - Epoch [33/60], Train Loss: 0.6638
2024-04-01 18:15:15,938 - config - INFO - Validation Loss: 0.6757
2024-04-01 18:15:15,938 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:15,996 - config - INFO - Epoch [34/60], Train Loss: 0.6639
2024-04-01 18:15:16,002 - config - INFO - Validation Loss: 0.6755
2024-04-01 18:15:16,002 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:16,060 - config - INFO - Epoch [35/60], Train Loss: 0.6639
2024-04-01 18:15:16,066 - config - INFO - Validation Loss: 0.6754
2024-04-01 18:15:16,067 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:16,126 - config - INFO - Epoch [36/60], Train Loss: 0.6639
2024-04-01 18:15:16,132 - config - INFO - Validation Loss: 0.6754
2024-04-01 18:15:16,132 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:16,190 - config - INFO - Epoch [37/60], Train Loss: 0.6645
2024-04-01 18:15:16,195 - config - INFO - Validation Loss: 0.6750
2024-04-01 18:15:16,196 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:16,254 - config - INFO - Epoch [38/60], Train Loss: 0.6639
2024-04-01 18:15:16,260 - config - INFO - Validation Loss: 0.6755
2024-04-01 18:15:16,260 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:16,318 - config - INFO - Epoch [39/60], Train Loss: 0.6643
2024-04-01 18:15:16,324 - config - INFO - Validation Loss: 0.6776
2024-04-01 18:15:16,324 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:16,383 - config - INFO - Epoch [40/60], Train Loss: 0.6640
2024-04-01 18:15:16,388 - config - INFO - Validation Loss: 0.6772
2024-04-01 18:15:16,388 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:16,453 - config - INFO - Epoch [41/60], Train Loss: 0.6637
2024-04-01 18:15:16,459 - config - INFO - Validation Loss: 0.6764
2024-04-01 18:15:16,459 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:16,518 - config - INFO - Epoch [42/60], Train Loss: 0.6638
2024-04-01 18:15:16,523 - config - INFO - Validation Loss: 0.6760
2024-04-01 18:15:16,523 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:16,581 - config - INFO - Epoch [43/60], Train Loss: 0.6637
2024-04-01 18:15:16,586 - config - INFO - Validation Loss: 0.6763
2024-04-01 18:15:16,586 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:16,644 - config - INFO - Epoch [44/60], Train Loss: 0.6638
2024-04-01 18:15:16,650 - config - INFO - Validation Loss: 0.6765
2024-04-01 18:15:16,650 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:16,708 - config - INFO - Epoch [45/60], Train Loss: 0.6638
2024-04-01 18:15:16,713 - config - INFO - Validation Loss: 0.6766
2024-04-01 18:15:16,713 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:16,771 - config - INFO - Epoch [46/60], Train Loss: 0.6638
2024-04-01 18:15:16,777 - config - INFO - Validation Loss: 0.6768
2024-04-01 18:15:16,777 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:16,834 - config - INFO - Epoch [47/60], Train Loss: 0.6643
2024-04-01 18:15:16,840 - config - INFO - Validation Loss: 0.6773
2024-04-01 18:15:16,840 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:16,897 - config - INFO - Epoch [48/60], Train Loss: 0.6636
2024-04-01 18:15:16,903 - config - INFO - Validation Loss: 0.6759
2024-04-01 18:15:16,903 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:16,961 - config - INFO - Epoch [49/60], Train Loss: 0.6637
2024-04-01 18:15:16,966 - config - INFO - Validation Loss: 0.6752
2024-04-01 18:15:16,966 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:17,024 - config - INFO - Epoch [50/60], Train Loss: 0.6638
2024-04-01 18:15:17,030 - config - INFO - Validation Loss: 0.6759
2024-04-01 18:15:17,030 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:17,087 - config - INFO - Epoch [51/60], Train Loss: 0.6638
2024-04-01 18:15:17,093 - config - INFO - Validation Loss: 0.6763
2024-04-01 18:15:17,093 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:17,151 - config - INFO - Epoch [52/60], Train Loss: 0.6635
2024-04-01 18:15:17,156 - config - INFO - Validation Loss: 0.6761
2024-04-01 18:15:17,156 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:17,213 - config - INFO - Epoch [53/60], Train Loss: 0.6635
2024-04-01 18:15:17,219 - config - INFO - Validation Loss: 0.6760
2024-04-01 18:15:17,219 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:17,277 - config - INFO - Epoch [54/60], Train Loss: 0.6635
2024-04-01 18:15:17,282 - config - INFO - Validation Loss: 0.6768
2024-04-01 18:15:17,282 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:17,340 - config - INFO - Epoch [55/60], Train Loss: 0.6636
2024-04-01 18:15:17,346 - config - INFO - Validation Loss: 0.6766
2024-04-01 18:15:17,346 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:17,404 - config - INFO - Epoch [56/60], Train Loss: 0.6628
2024-04-01 18:15:17,409 - config - INFO - Validation Loss: 0.6741
2024-04-01 18:15:17,410 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:17,483 - config - INFO - Epoch [57/60], Train Loss: 0.6614
2024-04-01 18:15:17,489 - config - INFO - Validation Loss: 0.6735
2024-04-01 18:15:17,489 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:17,553 - config - INFO - Epoch [58/60], Train Loss: 0.6607
2024-04-01 18:15:17,559 - config - INFO - Validation Loss: 0.6715
2024-04-01 18:15:17,560 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:17,626 - config - INFO - Epoch [59/60], Train Loss: 0.6589
2024-04-01 18:15:17,633 - config - INFO - Validation Loss: 0.6699
2024-04-01 18:15:17,633 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:15:17,697 - config - INFO - Epoch [60/60], Train Loss: 0.6571
2024-04-01 18:15:17,702 - config - INFO - Validation Loss: 0.6671
2024-04-01 18:15:17,702 - config - INFO - Validation Acc: 0.5955
2024-04-01 18:18:39,395 - config - INFO - resume: None
2024-04-01 18:18:39,395 - config - INFO - device: cpu
2024-04-01 18:18:39,395 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 18:18:39,395 - config - INFO - learning_rate: 0.001
2024-04-01 18:18:39,395 - config - INFO - num_epochs: 60
2024-04-01 18:18:39,396 - config - INFO - batch_size: 64
2024-04-01 18:18:39,396 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 10

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 18:18:39,417 - config - INFO - Dataset size: 891
2024-04-01 18:18:39,457 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x


class MaNN2(nn.Module):
    def __init__(self, input_size, hidden_size=20, num_layers=100):
        super(MaNN2, self).__init__()

        self.fc = nn.ModuleList([nn.Linear(input_size, hidden_size)])
        self.relu = nn.ReLU()
        for _ in range(num_layers - 1):
            self.fc.append(nn.Linear(hidden_size, hidden_size))
        self.fc.append(nn.Linear(hidden_size, 1))
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        for layer in self.fc[:-1]:
            x = layer(x)
            x = self.sigmoid(x)
        x = self.fc[-1](x)
        x = self.sigmoid(x)
        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN2(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss()(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs.append(batch_outputs)
                labels.append(batch_labels)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        if type(self.model).__name__ == 'MaNN1':
            val_acc = calculate_accuracy(torch.max(outputs, dim=1)[1], labels)
        else:
            val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 18:18:39,458 - config - INFO - Training start
2024-04-01 18:18:42,421 - config - INFO - Epoch [1/60], Train Loss: 0.6700
2024-04-01 18:18:42,443 - config - INFO - Validation Loss: 0.6537
2024-04-01 18:18:42,444 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:42,891 - config - INFO - Epoch [2/60], Train Loss: 0.6695
2024-04-01 18:18:42,915 - config - INFO - Validation Loss: 0.6528
2024-04-01 18:18:42,915 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:43,408 - config - INFO - Epoch [3/60], Train Loss: 0.6696
2024-04-01 18:18:43,436 - config - INFO - Validation Loss: 0.6534
2024-04-01 18:18:43,437 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:43,959 - config - INFO - Epoch [4/60], Train Loss: 0.6698
2024-04-01 18:18:43,988 - config - INFO - Validation Loss: 0.6534
2024-04-01 18:18:43,988 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:44,471 - config - INFO - Epoch [5/60], Train Loss: 0.6702
2024-04-01 18:18:44,493 - config - INFO - Validation Loss: 0.6549
2024-04-01 18:18:44,493 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:44,917 - config - INFO - Epoch [6/60], Train Loss: 0.6699
2024-04-01 18:18:44,939 - config - INFO - Validation Loss: 0.6550
2024-04-01 18:18:44,939 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:45,365 - config - INFO - Epoch [7/60], Train Loss: 0.6697
2024-04-01 18:18:45,387 - config - INFO - Validation Loss: 0.6526
2024-04-01 18:18:45,387 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:45,814 - config - INFO - Epoch [8/60], Train Loss: 0.6697
2024-04-01 18:18:45,836 - config - INFO - Validation Loss: 0.6526
2024-04-01 18:18:45,836 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:46,267 - config - INFO - Epoch [9/60], Train Loss: 0.6698
2024-04-01 18:18:46,291 - config - INFO - Validation Loss: 0.6538
2024-04-01 18:18:46,291 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:46,743 - config - INFO - Epoch [10/60], Train Loss: 0.6699
2024-04-01 18:18:46,767 - config - INFO - Validation Loss: 0.6545
2024-04-01 18:18:46,767 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:47,204 - config - INFO - Epoch [11/60], Train Loss: 0.6700
2024-04-01 18:18:47,227 - config - INFO - Validation Loss: 0.6538
2024-04-01 18:18:47,227 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:47,672 - config - INFO - Epoch [12/60], Train Loss: 0.6698
2024-04-01 18:18:47,696 - config - INFO - Validation Loss: 0.6541
2024-04-01 18:18:47,696 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:48,133 - config - INFO - Epoch [13/60], Train Loss: 0.6698
2024-04-01 18:18:48,157 - config - INFO - Validation Loss: 0.6526
2024-04-01 18:18:48,157 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:48,609 - config - INFO - Epoch [14/60], Train Loss: 0.6697
2024-04-01 18:18:48,632 - config - INFO - Validation Loss: 0.6522
2024-04-01 18:18:48,633 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:49,064 - config - INFO - Epoch [15/60], Train Loss: 0.6698
2024-04-01 18:18:49,087 - config - INFO - Validation Loss: 0.6511
2024-04-01 18:18:49,087 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:49,532 - config - INFO - Epoch [16/60], Train Loss: 0.6698
2024-04-01 18:18:49,555 - config - INFO - Validation Loss: 0.6522
2024-04-01 18:18:49,556 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:49,984 - config - INFO - Epoch [17/60], Train Loss: 0.6697
2024-04-01 18:18:50,006 - config - INFO - Validation Loss: 0.6525
2024-04-01 18:18:50,006 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:50,434 - config - INFO - Epoch [18/60], Train Loss: 0.6698
2024-04-01 18:18:50,457 - config - INFO - Validation Loss: 0.6537
2024-04-01 18:18:50,457 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:50,885 - config - INFO - Epoch [19/60], Train Loss: 0.6697
2024-04-01 18:18:50,908 - config - INFO - Validation Loss: 0.6535
2024-04-01 18:18:50,908 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:51,340 - config - INFO - Epoch [20/60], Train Loss: 0.6699
2024-04-01 18:18:51,362 - config - INFO - Validation Loss: 0.6519
2024-04-01 18:18:51,362 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:51,790 - config - INFO - Epoch [21/60], Train Loss: 0.6698
2024-04-01 18:18:51,813 - config - INFO - Validation Loss: 0.6516
2024-04-01 18:18:51,813 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:52,241 - config - INFO - Epoch [22/60], Train Loss: 0.6699
2024-04-01 18:18:52,264 - config - INFO - Validation Loss: 0.6513
2024-04-01 18:18:52,264 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:52,696 - config - INFO - Epoch [23/60], Train Loss: 0.6701
2024-04-01 18:18:52,718 - config - INFO - Validation Loss: 0.6509
2024-04-01 18:18:52,719 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:53,147 - config - INFO - Epoch [24/60], Train Loss: 0.6700
2024-04-01 18:18:53,170 - config - INFO - Validation Loss: 0.6523
2024-04-01 18:18:53,170 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:53,607 - config - INFO - Epoch [25/60], Train Loss: 0.6698
2024-04-01 18:18:53,630 - config - INFO - Validation Loss: 0.6527
2024-04-01 18:18:53,630 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:54,064 - config - INFO - Epoch [26/60], Train Loss: 0.6700
2024-04-01 18:18:54,087 - config - INFO - Validation Loss: 0.6547
2024-04-01 18:18:54,087 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:54,518 - config - INFO - Epoch [27/60], Train Loss: 0.6699
2024-04-01 18:18:54,541 - config - INFO - Validation Loss: 0.6537
2024-04-01 18:18:54,541 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:54,970 - config - INFO - Epoch [28/60], Train Loss: 0.6695
2024-04-01 18:18:54,992 - config - INFO - Validation Loss: 0.6525
2024-04-01 18:18:54,992 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:55,421 - config - INFO - Epoch [29/60], Train Loss: 0.6695
2024-04-01 18:18:55,444 - config - INFO - Validation Loss: 0.6516
2024-04-01 18:18:55,444 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:55,879 - config - INFO - Epoch [30/60], Train Loss: 0.6697
2024-04-01 18:18:55,901 - config - INFO - Validation Loss: 0.6524
2024-04-01 18:18:55,901 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:56,330 - config - INFO - Epoch [31/60], Train Loss: 0.6697
2024-04-01 18:18:56,352 - config - INFO - Validation Loss: 0.6530
2024-04-01 18:18:56,352 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:56,785 - config - INFO - Epoch [32/60], Train Loss: 0.6697
2024-04-01 18:18:56,807 - config - INFO - Validation Loss: 0.6528
2024-04-01 18:18:56,808 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:57,238 - config - INFO - Epoch [33/60], Train Loss: 0.6702
2024-04-01 18:18:57,260 - config - INFO - Validation Loss: 0.6556
2024-04-01 18:18:57,260 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:57,689 - config - INFO - Epoch [34/60], Train Loss: 0.6702
2024-04-01 18:18:57,711 - config - INFO - Validation Loss: 0.6561
2024-04-01 18:18:57,711 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:58,171 - config - INFO - Epoch [35/60], Train Loss: 0.6704
2024-04-01 18:18:58,199 - config - INFO - Validation Loss: 0.6560
2024-04-01 18:18:58,199 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:58,706 - config - INFO - Epoch [36/60], Train Loss: 0.6700
2024-04-01 18:18:58,733 - config - INFO - Validation Loss: 0.6547
2024-04-01 18:18:58,734 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:59,209 - config - INFO - Epoch [37/60], Train Loss: 0.6700
2024-04-01 18:18:59,231 - config - INFO - Validation Loss: 0.6534
2024-04-01 18:18:59,231 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:18:59,666 - config - INFO - Epoch [38/60], Train Loss: 0.6697
2024-04-01 18:18:59,688 - config - INFO - Validation Loss: 0.6527
2024-04-01 18:18:59,688 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:19:00,119 - config - INFO - Epoch [39/60], Train Loss: 0.6695
2024-04-01 18:19:00,141 - config - INFO - Validation Loss: 0.6534
2024-04-01 18:19:00,141 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:19:00,573 - config - INFO - Epoch [40/60], Train Loss: 0.6698
2024-04-01 18:19:00,596 - config - INFO - Validation Loss: 0.6548
2024-04-01 18:19:00,596 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:19:01,027 - config - INFO - Epoch [41/60], Train Loss: 0.6698
2024-04-01 18:19:01,050 - config - INFO - Validation Loss: 0.6554
2024-04-01 18:19:01,050 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:19:01,480 - config - INFO - Epoch [42/60], Train Loss: 0.6702
2024-04-01 18:19:01,503 - config - INFO - Validation Loss: 0.6562
2024-04-01 18:19:01,503 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:19:01,933 - config - INFO - Epoch [43/60], Train Loss: 0.6702
2024-04-01 18:19:01,956 - config - INFO - Validation Loss: 0.6551
2024-04-01 18:19:01,956 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:19:02,386 - config - INFO - Epoch [44/60], Train Loss: 0.6698
2024-04-01 18:19:02,409 - config - INFO - Validation Loss: 0.6537
2024-04-01 18:19:02,409 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:19:02,839 - config - INFO - Epoch [45/60], Train Loss: 0.6697
2024-04-01 18:19:02,861 - config - INFO - Validation Loss: 0.6533
2024-04-01 18:19:02,862 - config - INFO - Validation Acc: 0.6461
2024-04-01 18:19:11,040 - config - INFO - resume: None
2024-04-01 18:19:11,040 - config - INFO - device: cpu
2024-04-01 18:19:11,040 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 18:19:11,041 - config - INFO - learning_rate: 0.001
2024-04-01 18:19:11,041 - config - INFO - num_epochs: 60
2024-04-01 18:19:11,041 - config - INFO - batch_size: 64
2024-04-01 18:19:11,041 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 10

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 18:19:11,062 - config - INFO - Dataset size: 891
2024-04-01 18:19:11,181 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x


class MaNN2(nn.Module):
    def __init__(self, input_size, hidden_size=20, num_layers=1000):
        super(MaNN2, self).__init__()

        self.fc = nn.ModuleList([nn.Linear(input_size, hidden_size)])
        self.relu = nn.ReLU()
        for _ in range(num_layers - 1):
            self.fc.append(nn.Linear(hidden_size, hidden_size))
        self.fc.append(nn.Linear(hidden_size, 1))
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        for layer in self.fc[:-1]:
            x = layer(x)
            x = self.sigmoid(x)
        x = self.fc[-1](x)
        x = self.sigmoid(x)
        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN2(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss()(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs.append(batch_outputs)
                labels.append(batch_labels)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        if type(self.model).__name__ == 'MaNN1':
            val_acc = calculate_accuracy(torch.max(outputs, dim=1)[1], labels)
        else:
            val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 18:19:11,182 - config - INFO - Training start
2024-04-01 18:19:18,338 - config - INFO - Epoch [1/60], Train Loss: 0.7227
2024-04-01 18:19:18,531 - config - INFO - Validation Loss: 0.7082
2024-04-01 18:19:18,532 - config - INFO - Validation Acc: 0.3596
2024-04-01 18:19:22,618 - config - INFO - Epoch [2/60], Train Loss: 0.6954
2024-04-01 18:19:22,802 - config - INFO - Validation Loss: 0.6827
2024-04-01 18:19:22,802 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:19:26,924 - config - INFO - Epoch [3/60], Train Loss: 0.6797
2024-04-01 18:19:27,122 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:19:27,122 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:19:31,364 - config - INFO - Epoch [4/60], Train Loss: 0.6716
2024-04-01 18:19:31,560 - config - INFO - Validation Loss: 0.6592
2024-04-01 18:19:31,560 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:19:35,790 - config - INFO - Epoch [5/60], Train Loss: 0.6687
2024-04-01 18:19:35,984 - config - INFO - Validation Loss: 0.6553
2024-04-01 18:19:35,984 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:19:40,226 - config - INFO - Epoch [6/60], Train Loss: 0.6684
2024-04-01 18:19:40,424 - config - INFO - Validation Loss: 0.6541
2024-04-01 18:19:40,425 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:19:44,638 - config - INFO - Epoch [7/60], Train Loss: 0.6685
2024-04-01 18:19:44,832 - config - INFO - Validation Loss: 0.6542
2024-04-01 18:19:44,832 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:19:49,053 - config - INFO - Epoch [8/60], Train Loss: 0.6685
2024-04-01 18:19:49,248 - config - INFO - Validation Loss: 0.6540
2024-04-01 18:19:49,248 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:19:53,604 - config - INFO - Epoch [9/60], Train Loss: 0.6687
2024-04-01 18:19:53,793 - config - INFO - Validation Loss: 0.6541
2024-04-01 18:19:53,793 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:19:58,035 - config - INFO - Epoch [10/60], Train Loss: 0.6687
2024-04-01 18:19:58,227 - config - INFO - Validation Loss: 0.6537
2024-04-01 18:19:58,228 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:20:02,794 - config - INFO - Epoch [11/60], Train Loss: 0.6687
2024-04-01 18:20:02,991 - config - INFO - Validation Loss: 0.6539
2024-04-01 18:20:02,992 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:20:07,355 - config - INFO - Epoch [12/60], Train Loss: 0.6686
2024-04-01 18:20:07,549 - config - INFO - Validation Loss: 0.6548
2024-04-01 18:20:07,550 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:20:11,900 - config - INFO - Epoch [13/60], Train Loss: 0.6685
2024-04-01 18:20:12,096 - config - INFO - Validation Loss: 0.6545
2024-04-01 18:20:12,097 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:20:16,513 - config - INFO - Epoch [14/60], Train Loss: 0.6687
2024-04-01 18:20:16,708 - config - INFO - Validation Loss: 0.6540
2024-04-01 18:20:16,708 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:20:21,082 - config - INFO - Epoch [15/60], Train Loss: 0.6686
2024-04-01 18:20:21,280 - config - INFO - Validation Loss: 0.6546
2024-04-01 18:20:21,281 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:20:25,665 - config - INFO - Epoch [16/60], Train Loss: 0.6688
2024-04-01 18:20:25,861 - config - INFO - Validation Loss: 0.6541
2024-04-01 18:20:25,862 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:20:30,241 - config - INFO - Epoch [17/60], Train Loss: 0.6689
2024-04-01 18:20:30,434 - config - INFO - Validation Loss: 0.6552
2024-04-01 18:20:30,434 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:20:34,796 - config - INFO - Epoch [18/60], Train Loss: 0.6684
2024-04-01 18:20:34,989 - config - INFO - Validation Loss: 0.6560
2024-04-01 18:20:34,989 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:20:39,351 - config - INFO - Epoch [19/60], Train Loss: 0.6690
2024-04-01 18:20:39,542 - config - INFO - Validation Loss: 0.6572
2024-04-01 18:20:39,543 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:20:43,908 - config - INFO - Epoch [20/60], Train Loss: 0.6687
2024-04-01 18:20:44,104 - config - INFO - Validation Loss: 0.6553
2024-04-01 18:20:44,104 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:20:48,476 - config - INFO - Epoch [21/60], Train Loss: 0.6685
2024-04-01 18:20:48,673 - config - INFO - Validation Loss: 0.6542
2024-04-01 18:20:48,673 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:20:53,048 - config - INFO - Epoch [22/60], Train Loss: 0.6686
2024-04-01 18:20:53,246 - config - INFO - Validation Loss: 0.6538
2024-04-01 18:20:53,246 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:20:57,621 - config - INFO - Epoch [23/60], Train Loss: 0.6687
2024-04-01 18:20:57,819 - config - INFO - Validation Loss: 0.6539
2024-04-01 18:20:57,819 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:21:02,201 - config - INFO - Epoch [24/60], Train Loss: 0.6690
2024-04-01 18:21:02,398 - config - INFO - Validation Loss: 0.6535
2024-04-01 18:21:02,399 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:21:06,790 - config - INFO - Epoch [25/60], Train Loss: 0.6687
2024-04-01 18:21:06,988 - config - INFO - Validation Loss: 0.6539
2024-04-01 18:21:06,988 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:21:11,689 - config - INFO - Epoch [26/60], Train Loss: 0.6687
2024-04-01 18:21:11,886 - config - INFO - Validation Loss: 0.6547
2024-04-01 18:21:11,887 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:21:16,260 - config - INFO - Epoch [27/60], Train Loss: 0.6687
2024-04-01 18:21:16,456 - config - INFO - Validation Loss: 0.6554
2024-04-01 18:21:16,457 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:21:20,859 - config - INFO - Epoch [28/60], Train Loss: 0.6684
2024-04-01 18:21:21,059 - config - INFO - Validation Loss: 0.6552
2024-04-01 18:21:21,059 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:21:25,567 - config - INFO - Epoch [29/60], Train Loss: 0.6686
2024-04-01 18:21:25,769 - config - INFO - Validation Loss: 0.6545
2024-04-01 18:21:25,770 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:21:30,142 - config - INFO - Epoch [30/60], Train Loss: 0.6686
2024-04-01 18:21:30,329 - config - INFO - Validation Loss: 0.6553
2024-04-01 18:21:30,329 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:21:34,419 - config - INFO - Epoch [31/60], Train Loss: 0.6685
2024-04-01 18:21:34,608 - config - INFO - Validation Loss: 0.6555
2024-04-01 18:21:34,608 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:21:38,696 - config - INFO - Epoch [32/60], Train Loss: 0.6684
2024-04-01 18:21:38,884 - config - INFO - Validation Loss: 0.6556
2024-04-01 18:21:38,884 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:21:42,994 - config - INFO - Epoch [33/60], Train Loss: 0.6684
2024-04-01 18:21:43,182 - config - INFO - Validation Loss: 0.6553
2024-04-01 18:21:43,183 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:21:47,311 - config - INFO - Epoch [34/60], Train Loss: 0.6684
2024-04-01 18:21:47,500 - config - INFO - Validation Loss: 0.6556
2024-04-01 18:21:47,501 - config - INFO - Validation Acc: 0.6404
2024-04-01 18:21:51,600 - config - INFO - Epoch [35/60], Train Loss: 0.6686
2024-04-01 18:22:00,545 - config - INFO - resume: None
2024-04-01 18:22:00,546 - config - INFO - device: cpu
2024-04-01 18:22:00,546 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 18:22:00,546 - config - INFO - learning_rate: 1e-06
2024-04-01 18:22:00,546 - config - INFO - num_epochs: 60
2024-04-01 18:22:00,546 - config - INFO - batch_size: 64
2024-04-01 18:22:00,546 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 10

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 18:22:00,567 - config - INFO - Dataset size: 891
2024-04-01 18:22:00,685 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x


class MaNN2(nn.Module):
    def __init__(self, input_size, hidden_size=20, num_layers=1000):
        super(MaNN2, self).__init__()

        self.fc = nn.ModuleList([nn.Linear(input_size, hidden_size)])
        self.relu = nn.ReLU()
        for _ in range(num_layers - 1):
            self.fc.append(nn.Linear(hidden_size, hidden_size))
        self.fc.append(nn.Linear(hidden_size, 1))
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        for layer in self.fc[:-1]:
            x = layer(x)
            x = self.sigmoid(x)
        x = self.fc[-1](x)
        x = self.sigmoid(x)
        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN2(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss()(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs.append(batch_outputs)
                labels.append(batch_labels)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        if type(self.model).__name__ == 'MaNN1':
            val_acc = calculate_accuracy(torch.max(outputs, dim=1)[1], labels)
        else:
            val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 18:22:00,686 - config - INFO - Training start
2024-04-01 18:22:06,384 - config - INFO - resume: None
2024-04-01 18:22:06,384 - config - INFO - device: cpu
2024-04-01 18:22:06,384 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 18:22:06,384 - config - INFO - learning_rate: 1e-06
2024-04-01 18:22:06,384 - config - INFO - num_epochs: 60
2024-04-01 18:22:06,384 - config - INFO - batch_size: 64
2024-04-01 18:22:06,384 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 10

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 18:22:06,406 - config - INFO - Dataset size: 891
2024-04-01 18:22:06,526 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x


class MaNN2(nn.Module):
    def __init__(self, input_size, hidden_size=20, num_layers=1000):
        super(MaNN2, self).__init__()

        self.fc = nn.ModuleList([nn.Linear(input_size, hidden_size)])
        self.relu = nn.ReLU()
        for _ in range(num_layers - 1):
            self.fc.append(nn.Linear(hidden_size, hidden_size))
        self.fc.append(nn.Linear(hidden_size, 1))
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        for layer in self.fc[:-1]:
            x = layer(x)
            x = self.sigmoid(x)
        x = self.fc[-1](x)
        x = self.sigmoid(x)
        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN2(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss()(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs.append(batch_outputs)
                labels.append(batch_labels)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        if type(self.model).__name__ == 'MaNN1':
            val_acc = calculate_accuracy(torch.max(outputs, dim=1)[1], labels)
        else:
            val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 18:22:06,526 - config - INFO - Training start
2024-04-01 18:22:13,461 - config - INFO - Epoch [1/60], Train Loss: 0.8979
2024-04-01 18:22:13,651 - config - INFO - Validation Loss: 0.8619
2024-04-01 18:22:13,651 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:22:17,931 - config - INFO - Epoch [2/60], Train Loss: 0.8978
2024-04-01 18:22:18,125 - config - INFO - Validation Loss: 0.8618
2024-04-01 18:22:18,125 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:22:22,275 - config - INFO - Epoch [3/60], Train Loss: 0.8977
2024-04-01 18:22:22,464 - config - INFO - Validation Loss: 0.8617
2024-04-01 18:22:22,464 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:22:26,569 - config - INFO - Epoch [4/60], Train Loss: 0.8976
2024-04-01 18:22:26,755 - config - INFO - Validation Loss: 0.8617
2024-04-01 18:22:26,756 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:22:30,845 - config - INFO - Epoch [5/60], Train Loss: 0.8976
2024-04-01 18:22:31,045 - config - INFO - Validation Loss: 0.8616
2024-04-01 18:22:31,046 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:22:35,167 - config - INFO - Epoch [6/60], Train Loss: 0.8975
2024-04-01 18:22:35,352 - config - INFO - Validation Loss: 0.8615
2024-04-01 18:22:35,352 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:22:39,424 - config - INFO - Epoch [7/60], Train Loss: 0.8974
2024-04-01 18:22:39,614 - config - INFO - Validation Loss: 0.8615
2024-04-01 18:22:39,614 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:22:43,693 - config - INFO - Epoch [8/60], Train Loss: 0.8973
2024-04-01 18:22:43,879 - config - INFO - Validation Loss: 0.8614
2024-04-01 18:22:43,879 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:22:47,966 - config - INFO - Epoch [9/60], Train Loss: 0.8973
2024-04-01 18:22:48,152 - config - INFO - Validation Loss: 0.8614
2024-04-01 18:22:48,152 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:22:52,257 - config - INFO - Epoch [10/60], Train Loss: 0.8972
2024-04-01 18:22:52,442 - config - INFO - Validation Loss: 0.8613
2024-04-01 18:22:52,442 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:22:56,720 - config - INFO - Epoch [11/60], Train Loss: 0.8971
2024-04-01 18:22:56,904 - config - INFO - Validation Loss: 0.8612
2024-04-01 18:22:56,904 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:23:01,078 - config - INFO - Epoch [12/60], Train Loss: 0.8971
2024-04-01 18:23:01,271 - config - INFO - Validation Loss: 0.8612
2024-04-01 18:23:01,271 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:23:05,509 - config - INFO - Epoch [13/60], Train Loss: 0.8970
2024-04-01 18:23:05,706 - config - INFO - Validation Loss: 0.8611
2024-04-01 18:23:05,706 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:23:09,919 - config - INFO - Epoch [14/60], Train Loss: 0.8969
2024-04-01 18:23:10,111 - config - INFO - Validation Loss: 0.8610
2024-04-01 18:23:10,111 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:23:14,302 - config - INFO - Epoch [15/60], Train Loss: 0.8968
2024-04-01 18:23:14,494 - config - INFO - Validation Loss: 0.8610
2024-04-01 18:23:14,494 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:23:18,683 - config - INFO - Epoch [16/60], Train Loss: 0.8968
2024-04-01 18:23:18,878 - config - INFO - Validation Loss: 0.8609
2024-04-01 18:23:18,879 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:23:23,065 - config - INFO - Epoch [17/60], Train Loss: 0.8967
2024-04-01 18:23:23,259 - config - INFO - Validation Loss: 0.8608
2024-04-01 18:23:23,259 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:23:27,377 - config - INFO - Epoch [18/60], Train Loss: 0.8966
2024-04-01 18:23:27,562 - config - INFO - Validation Loss: 0.8608
2024-04-01 18:23:27,563 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:23:31,647 - config - INFO - Epoch [19/60], Train Loss: 0.8965
2024-04-01 18:23:31,833 - config - INFO - Validation Loss: 0.8607
2024-04-01 18:23:31,833 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:23:35,909 - config - INFO - Epoch [20/60], Train Loss: 0.8965
2024-04-01 18:23:36,093 - config - INFO - Validation Loss: 0.8606
2024-04-01 18:23:36,094 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:23:40,169 - config - INFO - Epoch [21/60], Train Loss: 0.8964
2024-04-01 18:23:40,353 - config - INFO - Validation Loss: 0.8606
2024-04-01 18:23:40,354 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:23:44,420 - config - INFO - Epoch [22/60], Train Loss: 0.8963
2024-04-01 18:23:44,607 - config - INFO - Validation Loss: 0.8605
2024-04-01 18:23:44,607 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:23:48,715 - config - INFO - Epoch [23/60], Train Loss: 0.8962
2024-04-01 18:23:48,915 - config - INFO - Validation Loss: 0.8604
2024-04-01 18:23:48,915 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:23:53,160 - config - INFO - Epoch [24/60], Train Loss: 0.8962
2024-04-01 18:23:53,354 - config - INFO - Validation Loss: 0.8604
2024-04-01 18:23:53,354 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:23:57,589 - config - INFO - Epoch [25/60], Train Loss: 0.8961
2024-04-01 18:23:57,786 - config - INFO - Validation Loss: 0.8603
2024-04-01 18:23:57,787 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:24:02,562 - config - INFO - Epoch [26/60], Train Loss: 0.8960
2024-04-01 18:24:02,795 - config - INFO - Validation Loss: 0.8603
2024-04-01 18:24:02,796 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:24:06,888 - config - INFO - Epoch [27/60], Train Loss: 0.8959
2024-04-01 18:24:07,075 - config - INFO - Validation Loss: 0.8602
2024-04-01 18:24:07,076 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:24:11,165 - config - INFO - Epoch [28/60], Train Loss: 0.8959
2024-04-01 18:24:11,353 - config - INFO - Validation Loss: 0.8601
2024-04-01 18:24:11,354 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:24:15,442 - config - INFO - Epoch [29/60], Train Loss: 0.8958
2024-04-01 18:24:15,630 - config - INFO - Validation Loss: 0.8601
2024-04-01 18:24:15,630 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:24:19,717 - config - INFO - Epoch [30/60], Train Loss: 0.8957
2024-04-01 18:24:19,902 - config - INFO - Validation Loss: 0.8600
2024-04-01 18:24:19,902 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:24:23,980 - config - INFO - Epoch [31/60], Train Loss: 0.8956
2024-04-01 18:24:24,165 - config - INFO - Validation Loss: 0.8599
2024-04-01 18:24:24,166 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:24:28,252 - config - INFO - Epoch [32/60], Train Loss: 0.8956
2024-04-01 18:24:28,436 - config - INFO - Validation Loss: 0.8599
2024-04-01 18:24:28,436 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:24:32,511 - config - INFO - Epoch [33/60], Train Loss: 0.8955
2024-04-01 18:24:32,694 - config - INFO - Validation Loss: 0.8598
2024-04-01 18:24:32,695 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:24:36,767 - config - INFO - Epoch [34/60], Train Loss: 0.8954
2024-04-01 18:24:36,949 - config - INFO - Validation Loss: 0.8597
2024-04-01 18:24:36,949 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:24:41,036 - config - INFO - Epoch [35/60], Train Loss: 0.8953
2024-04-01 18:24:41,219 - config - INFO - Validation Loss: 0.8597
2024-04-01 18:24:41,220 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:24:45,300 - config - INFO - Epoch [36/60], Train Loss: 0.8953
2024-04-01 18:24:45,482 - config - INFO - Validation Loss: 0.8596
2024-04-01 18:24:45,483 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:24:49,560 - config - INFO - Epoch [37/60], Train Loss: 0.8952
2024-04-01 18:24:49,747 - config - INFO - Validation Loss: 0.8595
2024-04-01 18:24:49,747 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:24:53,820 - config - INFO - Epoch [38/60], Train Loss: 0.8951
2024-04-01 18:24:54,003 - config - INFO - Validation Loss: 0.8595
2024-04-01 18:24:54,004 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:24:58,076 - config - INFO - Epoch [39/60], Train Loss: 0.8951
2024-04-01 18:24:58,259 - config - INFO - Validation Loss: 0.8594
2024-04-01 18:24:58,259 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:25:02,358 - config - INFO - Epoch [40/60], Train Loss: 0.8950
2024-04-01 18:25:02,539 - config - INFO - Validation Loss: 0.8594
2024-04-01 18:25:02,540 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:25:06,677 - config - INFO - Epoch [41/60], Train Loss: 0.8949
2024-04-01 18:25:06,857 - config - INFO - Validation Loss: 0.8593
2024-04-01 18:25:06,858 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:25:11,077 - config - INFO - Epoch [42/60], Train Loss: 0.8949
2024-04-01 18:25:11,274 - config - INFO - Validation Loss: 0.8592
2024-04-01 18:25:11,274 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:25:15,503 - config - INFO - Epoch [43/60], Train Loss: 0.8948
2024-04-01 18:25:15,702 - config - INFO - Validation Loss: 0.8592
2024-04-01 18:25:15,703 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:25:19,814 - config - INFO - Epoch [44/60], Train Loss: 0.8947
2024-04-01 18:25:20,001 - config - INFO - Validation Loss: 0.8591
2024-04-01 18:25:20,001 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:25:24,063 - config - INFO - Epoch [45/60], Train Loss: 0.8946
2024-04-01 18:25:24,251 - config - INFO - Validation Loss: 0.8590
2024-04-01 18:25:24,251 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:25:28,357 - config - INFO - Epoch [46/60], Train Loss: 0.8946
2024-04-01 18:25:28,542 - config - INFO - Validation Loss: 0.8590
2024-04-01 18:25:28,543 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:25:32,648 - config - INFO - Epoch [47/60], Train Loss: 0.8945
2024-04-01 18:25:32,834 - config - INFO - Validation Loss: 0.8589
2024-04-01 18:25:32,834 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:25:37,102 - config - INFO - Epoch [48/60], Train Loss: 0.8944
2024-04-01 18:25:37,310 - config - INFO - Validation Loss: 0.8589
2024-04-01 18:25:37,311 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:25:41,564 - config - INFO - Epoch [49/60], Train Loss: 0.8943
2024-04-01 18:25:41,760 - config - INFO - Validation Loss: 0.8588
2024-04-01 18:25:41,760 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:25:46,004 - config - INFO - Epoch [50/60], Train Loss: 0.8943
2024-04-01 18:25:46,206 - config - INFO - Validation Loss: 0.8587
2024-04-01 18:25:46,206 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:25:50,745 - config - INFO - Epoch [51/60], Train Loss: 0.8942
2024-04-01 18:25:50,967 - config - INFO - Validation Loss: 0.8587
2024-04-01 18:25:50,967 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:25:55,186 - config - INFO - Epoch [52/60], Train Loss: 0.8941
2024-04-01 18:25:55,383 - config - INFO - Validation Loss: 0.8586
2024-04-01 18:25:55,383 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:25:59,529 - config - INFO - Epoch [53/60], Train Loss: 0.8941
2024-04-01 18:25:59,716 - config - INFO - Validation Loss: 0.8585
2024-04-01 18:25:59,716 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:26:03,827 - config - INFO - Epoch [54/60], Train Loss: 0.8940
2024-04-01 18:26:04,015 - config - INFO - Validation Loss: 0.8585
2024-04-01 18:26:04,015 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:26:08,110 - config - INFO - Epoch [55/60], Train Loss: 0.8939
2024-04-01 18:26:08,299 - config - INFO - Validation Loss: 0.8584
2024-04-01 18:26:08,299 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:26:12,503 - config - INFO - Epoch [56/60], Train Loss: 0.8938
2024-04-01 18:26:12,691 - config - INFO - Validation Loss: 0.8583
2024-04-01 18:26:12,692 - config - INFO - Validation Acc: 0.4157
2024-04-01 18:26:16,783 - config - INFO - Epoch [57/60], Train Loss: 0.8938
2024-04-01 18:26:54,085 - config - INFO - resume: None
2024-04-01 18:26:54,085 - config - INFO - device: cpu
2024-04-01 18:26:54,085 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/mann.txt
2024-04-01 18:26:54,085 - config - INFO - learning_rate: 1e-06
2024-04-01 18:26:54,085 - config - INFO - num_epochs: 600
2024-04-01 18:26:54,085 - config - INFO - batch_size: 64
2024-04-01 18:26:54,085 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 10

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-04-01 18:26:54,107 - config - INFO - Dataset size: 891
2024-04-01 18:26:54,224 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config
from tqdm import tqdm

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

class MaNN1(nn.Module):
    def __init__(self, input_size):
        super(MaNN1, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 2)
        self.sigmoid = nn.Sigmoid()
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)

        return x


class MaNN2(nn.Module):
    def __init__(self, input_size, hidden_size=20, num_layers=1000):
        super(MaNN2, self).__init__()

        self.fc = nn.ModuleList([nn.Linear(input_size, hidden_size)])
        self.relu = nn.ReLU()
        for _ in range(num_layers - 1):
            self.fc.append(nn.Linear(hidden_size, hidden_size))
        self.fc.append(nn.Linear(hidden_size, 1))
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        for layer in self.fc[:-1]:
            x = layer(x)
            x = self.sigmoid(x)
        x = self.fc[-1](x)
        x = self.sigmoid(x)
        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = MaNN2(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        if type(self.model).__name__ == 'MaNN1':
            criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in tqdm(range(self.config.num_epochs), ncols=100):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, batch_labels = batch['features'], batch['label']
            optimizer.zero_grad()
            batch_outputs = self.model(inputs)
            
            if type(self.model).__name__ == 'MaNN1':
                loss = criterion(batch_outputs, batch_labels.long().squeeze())
            else:
                loss = criterion(batch_outputs, batch_labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        outputs = []
        labels = []
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, batch_labels = batch['features'], batch['label']
                batch_outputs = self.model(inputs)
                if type(self.model).__name__ == 'MaNN1':
                    loss = nn.CrossEntropyLoss()(batch_outputs, batch_labels.long().squeeze())
                else:
                    loss = nn.BCELoss()(batch_outputs, batch_labels)
                val_loss += loss.item() * inputs.size(0)
                outputs.append(batch_outputs)
                labels.append(batch_labels)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        outputs = torch.cat(outputs, dim=0).squeeze()
        labels = torch.cat(labels, dim=0).squeeze()
        if type(self.model).__name__ == 'MaNN1':
            val_acc = calculate_accuracy(torch.max(outputs, dim=1)[1], labels)
        else:
            val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-04-01 18:26:54,225 - config - INFO - Training start
2024-04-01 18:27:00,494 - config - INFO - Epoch [1/600], Train Loss: 0.6661
2024-04-01 18:27:00,688 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:27:00,688 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:27:05,241 - config - INFO - Epoch [2/600], Train Loss: 0.6661
2024-04-01 18:27:05,436 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:27:05,436 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:27:09,556 - config - INFO - Epoch [3/600], Train Loss: 0.6661
2024-04-01 18:27:09,752 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:27:09,752 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:27:13,828 - config - INFO - Epoch [4/600], Train Loss: 0.6661
2024-04-01 18:27:14,011 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:27:14,011 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:27:18,080 - config - INFO - Epoch [5/600], Train Loss: 0.6661
2024-04-01 18:27:18,262 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:27:18,263 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:27:22,343 - config - INFO - Epoch [6/600], Train Loss: 0.6661
2024-04-01 18:27:22,528 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:27:22,528 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:27:26,584 - config - INFO - Epoch [7/600], Train Loss: 0.6661
2024-04-01 18:27:26,771 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:27:26,771 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:27:30,810 - config - INFO - Epoch [8/600], Train Loss: 0.6661
2024-04-01 18:27:30,993 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:27:30,994 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:27:35,013 - config - INFO - Epoch [9/600], Train Loss: 0.6661
2024-04-01 18:27:35,190 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:27:35,191 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:27:39,189 - config - INFO - Epoch [10/600], Train Loss: 0.6661
2024-04-01 18:27:39,366 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:27:39,366 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:27:43,552 - config - INFO - Epoch [11/600], Train Loss: 0.6661
2024-04-01 18:27:43,735 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:27:43,735 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:27:47,734 - config - INFO - Epoch [12/600], Train Loss: 0.6661
2024-04-01 18:27:47,915 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:27:47,915 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:27:51,927 - config - INFO - Epoch [13/600], Train Loss: 0.6661
2024-04-01 18:27:52,108 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:27:52,108 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:27:56,129 - config - INFO - Epoch [14/600], Train Loss: 0.6661
2024-04-01 18:27:56,310 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:27:56,310 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:28:00,320 - config - INFO - Epoch [15/600], Train Loss: 0.6661
2024-04-01 18:28:00,501 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:28:00,501 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:28:04,531 - config - INFO - Epoch [16/600], Train Loss: 0.6661
2024-04-01 18:28:04,725 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:28:04,725 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:28:08,713 - config - INFO - Epoch [17/600], Train Loss: 0.6661
2024-04-01 18:28:08,890 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:28:08,891 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:28:12,885 - config - INFO - Epoch [18/600], Train Loss: 0.6661
2024-04-01 18:28:13,062 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:28:13,062 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:28:17,058 - config - INFO - Epoch [19/600], Train Loss: 0.6661
2024-04-01 18:28:17,237 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:28:17,237 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:28:21,239 - config - INFO - Epoch [20/600], Train Loss: 0.6661
2024-04-01 18:28:21,417 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:28:21,418 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:28:25,435 - config - INFO - Epoch [21/600], Train Loss: 0.6661
2024-04-01 18:28:25,619 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:28:25,619 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:28:29,655 - config - INFO - Epoch [22/600], Train Loss: 0.6661
2024-04-01 18:28:29,837 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:28:29,837 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:28:33,848 - config - INFO - Epoch [23/600], Train Loss: 0.6661
2024-04-01 18:28:34,028 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:28:34,029 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:28:38,023 - config - INFO - Epoch [24/600], Train Loss: 0.6661
2024-04-01 18:28:38,204 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:28:38,205 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:28:42,210 - config - INFO - Epoch [25/600], Train Loss: 0.6661
2024-04-01 18:28:42,391 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:28:42,392 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:28:46,605 - config - INFO - Epoch [26/600], Train Loss: 0.6661
2024-04-01 18:28:46,787 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:28:46,787 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:28:50,811 - config - INFO - Epoch [27/600], Train Loss: 0.6661
2024-04-01 18:28:50,994 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:28:50,994 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:28:55,006 - config - INFO - Epoch [28/600], Train Loss: 0.6661
2024-04-01 18:28:55,189 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:28:55,189 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:28:59,210 - config - INFO - Epoch [29/600], Train Loss: 0.6661
2024-04-01 18:28:59,393 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:28:59,393 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:29:03,418 - config - INFO - Epoch [30/600], Train Loss: 0.6661
2024-04-01 18:29:03,598 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:29:03,599 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:29:07,633 - config - INFO - Epoch [31/600], Train Loss: 0.6661
2024-04-01 18:29:07,819 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:29:07,820 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:29:11,913 - config - INFO - Epoch [32/600], Train Loss: 0.6661
2024-04-01 18:29:12,093 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:29:12,093 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:29:16,130 - config - INFO - Epoch [33/600], Train Loss: 0.6661
2024-04-01 18:29:16,311 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:29:16,311 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:29:20,319 - config - INFO - Epoch [34/600], Train Loss: 0.6661
2024-04-01 18:29:20,498 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:29:20,499 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:29:24,518 - config - INFO - Epoch [35/600], Train Loss: 0.6661
2024-04-01 18:29:24,698 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:29:24,698 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:29:28,711 - config - INFO - Epoch [36/600], Train Loss: 0.6661
2024-04-01 18:29:28,890 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:29:28,890 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:29:32,915 - config - INFO - Epoch [37/600], Train Loss: 0.6661
2024-04-01 18:29:33,094 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:29:33,095 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:29:37,128 - config - INFO - Epoch [38/600], Train Loss: 0.6661
2024-04-01 18:29:37,317 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:29:37,318 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:29:41,352 - config - INFO - Epoch [39/600], Train Loss: 0.6661
2024-04-01 18:29:41,533 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:29:41,534 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:29:45,554 - config - INFO - Epoch [40/600], Train Loss: 0.6661
2024-04-01 18:29:45,736 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:29:45,736 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:29:49,856 - config - INFO - Epoch [41/600], Train Loss: 0.6661
2024-04-01 18:29:50,036 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:29:50,036 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:29:54,059 - config - INFO - Epoch [42/600], Train Loss: 0.6661
2024-04-01 18:29:54,239 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:29:54,239 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:29:58,247 - config - INFO - Epoch [43/600], Train Loss: 0.6661
2024-04-01 18:29:58,427 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:29:58,427 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:30:02,432 - config - INFO - Epoch [44/600], Train Loss: 0.6661
2024-04-01 18:30:02,611 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:30:02,611 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:30:06,660 - config - INFO - Epoch [45/600], Train Loss: 0.6661
2024-04-01 18:30:06,840 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:30:06,840 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:30:10,852 - config - INFO - Epoch [46/600], Train Loss: 0.6661
2024-04-01 18:30:11,034 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:30:11,034 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:30:15,036 - config - INFO - Epoch [47/600], Train Loss: 0.6661
2024-04-01 18:30:15,216 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:30:15,217 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:30:19,218 - config - INFO - Epoch [48/600], Train Loss: 0.6661
2024-04-01 18:30:19,397 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:30:19,398 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:30:23,393 - config - INFO - Epoch [49/600], Train Loss: 0.6661
2024-04-01 18:30:23,573 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:30:23,574 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:30:27,577 - config - INFO - Epoch [50/600], Train Loss: 0.6661
2024-04-01 18:30:27,761 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:30:27,761 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:30:31,766 - config - INFO - Epoch [51/600], Train Loss: 0.6661
2024-04-01 18:30:31,945 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:30:31,945 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:30:35,947 - config - INFO - Epoch [52/600], Train Loss: 0.6661
2024-04-01 18:30:36,123 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:30:36,124 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:30:40,112 - config - INFO - Epoch [53/600], Train Loss: 0.6661
2024-04-01 18:30:40,289 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:30:40,289 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:30:44,301 - config - INFO - Epoch [54/600], Train Loss: 0.6661
2024-04-01 18:30:44,479 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:30:44,479 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:30:48,477 - config - INFO - Epoch [55/600], Train Loss: 0.6661
2024-04-01 18:30:48,654 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:30:48,655 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:30:52,753 - config - INFO - Epoch [56/600], Train Loss: 0.6661
2024-04-01 18:30:52,934 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:30:52,935 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:30:56,940 - config - INFO - Epoch [57/600], Train Loss: 0.6661
2024-04-01 18:30:57,116 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:30:57,116 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:31:01,101 - config - INFO - Epoch [58/600], Train Loss: 0.6661
2024-04-01 18:31:01,277 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:31:01,278 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:31:05,316 - config - INFO - Epoch [59/600], Train Loss: 0.6661
2024-04-01 18:31:05,496 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:31:05,497 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:31:09,557 - config - INFO - Epoch [60/600], Train Loss: 0.6661
2024-04-01 18:31:09,741 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:31:09,741 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:31:13,750 - config - INFO - Epoch [61/600], Train Loss: 0.6661
2024-04-01 18:31:13,927 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:31:13,927 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:31:17,947 - config - INFO - Epoch [62/600], Train Loss: 0.6661
2024-04-01 18:31:18,124 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:31:18,125 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:31:22,118 - config - INFO - Epoch [63/600], Train Loss: 0.6661
2024-04-01 18:31:22,296 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:31:22,297 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:31:26,299 - config - INFO - Epoch [64/600], Train Loss: 0.6661
2024-04-01 18:31:26,478 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:31:26,478 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:31:30,484 - config - INFO - Epoch [65/600], Train Loss: 0.6661
2024-04-01 18:31:30,660 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:31:30,660 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:31:34,673 - config - INFO - Epoch [66/600], Train Loss: 0.6661
2024-04-01 18:31:34,850 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:31:34,851 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:31:38,867 - config - INFO - Epoch [67/600], Train Loss: 0.6661
2024-04-01 18:31:39,043 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:31:39,044 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:31:43,043 - config - INFO - Epoch [68/600], Train Loss: 0.6661
2024-04-01 18:31:43,220 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:31:43,220 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:31:47,232 - config - INFO - Epoch [69/600], Train Loss: 0.6661
2024-04-01 18:31:47,408 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:31:47,409 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:31:51,428 - config - INFO - Epoch [70/600], Train Loss: 0.6661
2024-04-01 18:31:51,607 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:31:51,607 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:31:55,629 - config - INFO - Epoch [71/600], Train Loss: 0.6661
2024-04-01 18:31:55,808 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:31:55,808 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:31:59,930 - config - INFO - Epoch [72/600], Train Loss: 0.6661
2024-04-01 18:32:00,108 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:32:00,109 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:32:04,140 - config - INFO - Epoch [73/600], Train Loss: 0.6661
2024-04-01 18:32:04,316 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:32:04,317 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:32:08,330 - config - INFO - Epoch [74/600], Train Loss: 0.6661
2024-04-01 18:32:08,508 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:32:08,508 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:32:12,514 - config - INFO - Epoch [75/600], Train Loss: 0.6661
2024-04-01 18:32:12,692 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:32:12,692 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:32:16,744 - config - INFO - Epoch [76/600], Train Loss: 0.6661
2024-04-01 18:32:16,929 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:32:16,929 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:32:21,006 - config - INFO - Epoch [77/600], Train Loss: 0.6661
2024-04-01 18:32:21,193 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:32:21,194 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:32:25,247 - config - INFO - Epoch [78/600], Train Loss: 0.6661
2024-04-01 18:32:25,432 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:32:25,433 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:32:29,479 - config - INFO - Epoch [79/600], Train Loss: 0.6661
2024-04-01 18:32:29,662 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:32:29,662 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:32:33,711 - config - INFO - Epoch [80/600], Train Loss: 0.6661
2024-04-01 18:32:33,894 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:32:33,895 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:32:37,969 - config - INFO - Epoch [81/600], Train Loss: 0.6661
2024-04-01 18:32:38,146 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:32:38,147 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:32:42,154 - config - INFO - Epoch [82/600], Train Loss: 0.6661
2024-04-01 18:32:42,330 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:32:42,330 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:32:46,334 - config - INFO - Epoch [83/600], Train Loss: 0.6661
2024-04-01 18:32:46,513 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:32:46,514 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:32:50,513 - config - INFO - Epoch [84/600], Train Loss: 0.6661
2024-04-01 18:32:50,690 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:32:50,691 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:32:54,697 - config - INFO - Epoch [85/600], Train Loss: 0.6661
2024-04-01 18:32:54,877 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:32:54,877 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:32:58,889 - config - INFO - Epoch [86/600], Train Loss: 0.6661
2024-04-01 18:32:59,067 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:32:59,067 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:33:03,168 - config - INFO - Epoch [87/600], Train Loss: 0.6661
2024-04-01 18:33:03,346 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:33:03,346 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:33:07,360 - config - INFO - Epoch [88/600], Train Loss: 0.6661
2024-04-01 18:33:07,536 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:33:07,537 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:33:11,542 - config - INFO - Epoch [89/600], Train Loss: 0.6661
2024-04-01 18:33:11,719 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:33:11,720 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:33:15,707 - config - INFO - Epoch [90/600], Train Loss: 0.6661
2024-04-01 18:33:15,887 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:33:15,888 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:33:19,885 - config - INFO - Epoch [91/600], Train Loss: 0.6661
2024-04-01 18:33:20,064 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:33:20,064 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:33:24,061 - config - INFO - Epoch [92/600], Train Loss: 0.6661
2024-04-01 18:33:24,241 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:33:24,241 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:33:28,249 - config - INFO - Epoch [93/600], Train Loss: 0.6661
2024-04-01 18:33:28,426 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:33:28,427 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:33:32,449 - config - INFO - Epoch [94/600], Train Loss: 0.6661
2024-04-01 18:33:32,628 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:33:32,628 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:33:36,646 - config - INFO - Epoch [95/600], Train Loss: 0.6661
2024-04-01 18:33:36,824 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:33:36,825 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:33:40,853 - config - INFO - Epoch [96/600], Train Loss: 0.6661
2024-04-01 18:33:41,032 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:33:41,032 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:33:45,052 - config - INFO - Epoch [97/600], Train Loss: 0.6661
2024-04-01 18:33:45,230 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:33:45,230 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:33:49,277 - config - INFO - Epoch [98/600], Train Loss: 0.6661
2024-04-01 18:33:49,455 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:33:49,455 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:33:53,494 - config - INFO - Epoch [99/600], Train Loss: 0.6661
2024-04-01 18:33:53,672 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:33:53,672 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:33:57,697 - config - INFO - Epoch [100/600], Train Loss: 0.6661
2024-04-01 18:33:57,877 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:33:57,877 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:34:01,916 - config - INFO - Epoch [101/600], Train Loss: 0.6661
2024-04-01 18:34:02,093 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:34:02,094 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:34:06,232 - config - INFO - Epoch [102/600], Train Loss: 0.6661
2024-04-01 18:34:06,411 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:34:06,412 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:34:10,443 - config - INFO - Epoch [103/600], Train Loss: 0.6661
2024-04-01 18:34:10,621 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:34:10,622 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:34:14,643 - config - INFO - Epoch [104/600], Train Loss: 0.6661
2024-04-01 18:34:14,818 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:34:14,818 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:34:18,878 - config - INFO - Epoch [105/600], Train Loss: 0.6661
2024-04-01 18:34:19,059 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:34:19,060 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:34:23,092 - config - INFO - Epoch [106/600], Train Loss: 0.6661
2024-04-01 18:34:23,269 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:34:23,269 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:34:27,277 - config - INFO - Epoch [107/600], Train Loss: 0.6661
2024-04-01 18:34:27,457 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:34:27,457 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:34:31,453 - config - INFO - Epoch [108/600], Train Loss: 0.6661
2024-04-01 18:34:31,629 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:34:31,629 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:34:35,623 - config - INFO - Epoch [109/600], Train Loss: 0.6661
2024-04-01 18:34:35,800 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:34:35,800 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:34:39,788 - config - INFO - Epoch [110/600], Train Loss: 0.6661
2024-04-01 18:34:39,963 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:34:39,964 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:34:43,964 - config - INFO - Epoch [111/600], Train Loss: 0.6661
2024-04-01 18:34:44,147 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:34:44,147 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:34:48,201 - config - INFO - Epoch [112/600], Train Loss: 0.6661
2024-04-01 18:34:48,384 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:34:48,385 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:34:52,448 - config - INFO - Epoch [113/600], Train Loss: 0.6661
2024-04-01 18:34:52,630 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:34:52,630 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:34:56,719 - config - INFO - Epoch [114/600], Train Loss: 0.6661
2024-04-01 18:34:56,901 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:34:56,901 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:35:00,967 - config - INFO - Epoch [115/600], Train Loss: 0.6661
2024-04-01 18:35:01,152 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:35:01,152 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:35:05,230 - config - INFO - Epoch [116/600], Train Loss: 0.6661
2024-04-01 18:35:05,413 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:35:05,414 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:35:09,579 - config - INFO - Epoch [117/600], Train Loss: 0.6661
2024-04-01 18:35:09,765 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:35:09,766 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:35:13,819 - config - INFO - Epoch [118/600], Train Loss: 0.6661
2024-04-01 18:35:14,002 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:35:14,002 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:35:18,065 - config - INFO - Epoch [119/600], Train Loss: 0.6661
2024-04-01 18:35:18,249 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:35:18,250 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:35:22,341 - config - INFO - Epoch [120/600], Train Loss: 0.6661
2024-04-01 18:35:22,523 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:35:22,523 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:35:26,576 - config - INFO - Epoch [121/600], Train Loss: 0.6661
2024-04-01 18:35:26,757 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:35:26,758 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:35:30,801 - config - INFO - Epoch [122/600], Train Loss: 0.6661
2024-04-01 18:35:30,984 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:35:30,984 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:35:35,042 - config - INFO - Epoch [123/600], Train Loss: 0.6661
2024-04-01 18:35:35,223 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:35:35,223 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:35:39,269 - config - INFO - Epoch [124/600], Train Loss: 0.6661
2024-04-01 18:35:39,452 - config - INFO - Validation Loss: 0.6679
2024-04-01 18:35:39,453 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:35:43,503 - config - INFO - Epoch [125/600], Train Loss: 0.6661
2024-04-01 18:35:43,683 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:35:43,684 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:35:47,756 - config - INFO - Epoch [126/600], Train Loss: 0.6661
2024-04-01 18:35:47,936 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:35:47,936 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:35:51,976 - config - INFO - Epoch [127/600], Train Loss: 0.6661
2024-04-01 18:35:52,157 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:35:52,157 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:35:56,195 - config - INFO - Epoch [128/600], Train Loss: 0.6661
2024-04-01 18:35:56,375 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:35:56,375 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:36:00,421 - config - INFO - Epoch [129/600], Train Loss: 0.6661
2024-04-01 18:36:00,601 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:36:00,601 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:36:04,652 - config - INFO - Epoch [130/600], Train Loss: 0.6661
2024-04-01 18:36:04,834 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:36:04,834 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:36:08,884 - config - INFO - Epoch [131/600], Train Loss: 0.6661
2024-04-01 18:36:09,065 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:36:09,066 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:36:13,231 - config - INFO - Epoch [132/600], Train Loss: 0.6661
2024-04-01 18:36:13,411 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:36:13,411 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:36:17,473 - config - INFO - Epoch [133/600], Train Loss: 0.6661
2024-04-01 18:36:17,655 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:36:17,655 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:36:21,722 - config - INFO - Epoch [134/600], Train Loss: 0.6661
2024-04-01 18:36:21,902 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:36:21,902 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:36:25,967 - config - INFO - Epoch [135/600], Train Loss: 0.6661
2024-04-01 18:36:26,148 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:36:26,148 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:36:30,186 - config - INFO - Epoch [136/600], Train Loss: 0.6661
2024-04-01 18:36:30,365 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:36:30,365 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:36:34,403 - config - INFO - Epoch [137/600], Train Loss: 0.6661
2024-04-01 18:36:34,582 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:36:34,582 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:36:38,622 - config - INFO - Epoch [138/600], Train Loss: 0.6661
2024-04-01 18:36:38,802 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:36:38,803 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:36:42,847 - config - INFO - Epoch [139/600], Train Loss: 0.6661
2024-04-01 18:36:43,027 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:36:43,027 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:36:47,082 - config - INFO - Epoch [140/600], Train Loss: 0.6661
2024-04-01 18:36:47,265 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:36:47,265 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:36:51,320 - config - INFO - Epoch [141/600], Train Loss: 0.6661
2024-04-01 18:36:51,499 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:36:51,500 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:36:55,525 - config - INFO - Epoch [142/600], Train Loss: 0.6661
2024-04-01 18:36:55,703 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:36:55,704 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:36:59,732 - config - INFO - Epoch [143/600], Train Loss: 0.6661
2024-04-01 18:36:59,912 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:36:59,912 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:37:03,945 - config - INFO - Epoch [144/600], Train Loss: 0.6661
2024-04-01 18:37:04,128 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:37:04,129 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:37:08,202 - config - INFO - Epoch [145/600], Train Loss: 0.6661
2024-04-01 18:37:08,389 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:37:08,389 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:37:12,434 - config - INFO - Epoch [146/600], Train Loss: 0.6661
2024-04-01 18:37:12,617 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:37:12,617 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:37:16,772 - config - INFO - Epoch [147/600], Train Loss: 0.6661
2024-04-01 18:37:16,954 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:37:16,954 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:37:20,996 - config - INFO - Epoch [148/600], Train Loss: 0.6661
2024-04-01 18:37:21,179 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:37:21,179 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:37:25,225 - config - INFO - Epoch [149/600], Train Loss: 0.6661
2024-04-01 18:37:25,410 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:37:25,410 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:37:29,453 - config - INFO - Epoch [150/600], Train Loss: 0.6661
2024-04-01 18:37:29,634 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:37:29,634 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:37:33,686 - config - INFO - Epoch [151/600], Train Loss: 0.6661
2024-04-01 18:37:33,875 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:37:33,875 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:37:37,946 - config - INFO - Epoch [152/600], Train Loss: 0.6661
2024-04-01 18:37:38,126 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:37:38,126 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:37:42,173 - config - INFO - Epoch [153/600], Train Loss: 0.6661
2024-04-01 18:37:42,354 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:37:42,355 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:37:46,394 - config - INFO - Epoch [154/600], Train Loss: 0.6661
2024-04-01 18:37:46,575 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:37:46,575 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:37:50,608 - config - INFO - Epoch [155/600], Train Loss: 0.6661
2024-04-01 18:37:50,795 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:37:50,795 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:37:54,836 - config - INFO - Epoch [156/600], Train Loss: 0.6661
2024-04-01 18:37:55,018 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:37:55,018 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:37:59,063 - config - INFO - Epoch [157/600], Train Loss: 0.6661
2024-04-01 18:37:59,242 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:37:59,243 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:38:03,291 - config - INFO - Epoch [158/600], Train Loss: 0.6661
2024-04-01 18:38:03,469 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:38:03,470 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:38:07,492 - config - INFO - Epoch [159/600], Train Loss: 0.6661
2024-04-01 18:38:07,671 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:38:07,671 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:38:11,699 - config - INFO - Epoch [160/600], Train Loss: 0.6661
2024-04-01 18:38:11,880 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:38:11,881 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:38:15,910 - config - INFO - Epoch [161/600], Train Loss: 0.6661
2024-04-01 18:38:16,090 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:38:16,090 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:38:20,221 - config - INFO - Epoch [162/600], Train Loss: 0.6661
2024-04-01 18:38:20,400 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:38:20,401 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:38:24,419 - config - INFO - Epoch [163/600], Train Loss: 0.6661
2024-04-01 18:38:24,599 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:38:24,599 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:38:28,675 - config - INFO - Epoch [164/600], Train Loss: 0.6661
2024-04-01 18:38:28,856 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:38:28,856 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:38:32,913 - config - INFO - Epoch [165/600], Train Loss: 0.6661
2024-04-01 18:38:33,092 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:38:33,092 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:38:37,138 - config - INFO - Epoch [166/600], Train Loss: 0.6661
2024-04-01 18:38:37,318 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:38:37,318 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:38:41,368 - config - INFO - Epoch [167/600], Train Loss: 0.6661
2024-04-01 18:38:41,547 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:38:41,548 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:38:45,600 - config - INFO - Epoch [168/600], Train Loss: 0.6661
2024-04-01 18:38:45,781 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:38:45,781 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:38:49,838 - config - INFO - Epoch [169/600], Train Loss: 0.6661
2024-04-01 18:38:50,019 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:38:50,019 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:38:54,058 - config - INFO - Epoch [170/600], Train Loss: 0.6661
2024-04-01 18:38:54,237 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:38:54,237 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:38:58,322 - config - INFO - Epoch [171/600], Train Loss: 0.6661
2024-04-01 18:38:58,507 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:38:58,508 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:39:02,582 - config - INFO - Epoch [172/600], Train Loss: 0.6661
2024-04-01 18:39:02,767 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:39:02,767 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:39:06,848 - config - INFO - Epoch [173/600], Train Loss: 0.6661
2024-04-01 18:39:07,033 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:39:07,033 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:39:11,111 - config - INFO - Epoch [174/600], Train Loss: 0.6661
2024-04-01 18:39:11,297 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:39:11,297 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:39:15,379 - config - INFO - Epoch [175/600], Train Loss: 0.6661
2024-04-01 18:39:15,565 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:39:15,565 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:39:19,655 - config - INFO - Epoch [176/600], Train Loss: 0.6661
2024-04-01 18:39:19,845 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:39:19,845 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:39:24,041 - config - INFO - Epoch [177/600], Train Loss: 0.6661
2024-04-01 18:39:24,223 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:39:24,223 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:39:28,278 - config - INFO - Epoch [178/600], Train Loss: 0.6661
2024-04-01 18:39:28,459 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:39:28,460 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:39:32,520 - config - INFO - Epoch [179/600], Train Loss: 0.6661
2024-04-01 18:39:32,701 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:39:32,701 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:39:36,756 - config - INFO - Epoch [180/600], Train Loss: 0.6661
2024-04-01 18:39:36,936 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:39:36,937 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:39:40,999 - config - INFO - Epoch [181/600], Train Loss: 0.6661
2024-04-01 18:39:41,181 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:39:41,181 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:39:45,246 - config - INFO - Epoch [182/600], Train Loss: 0.6661
2024-04-01 18:39:45,432 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:39:45,433 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:39:49,518 - config - INFO - Epoch [183/600], Train Loss: 0.6661
2024-04-01 18:39:49,702 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:39:49,702 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:39:53,794 - config - INFO - Epoch [184/600], Train Loss: 0.6661
2024-04-01 18:39:53,980 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:39:53,980 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:39:58,058 - config - INFO - Epoch [185/600], Train Loss: 0.6661
2024-04-01 18:39:58,242 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:39:58,242 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:40:02,323 - config - INFO - Epoch [186/600], Train Loss: 0.6661
2024-04-01 18:40:02,509 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:40:02,509 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:40:06,589 - config - INFO - Epoch [187/600], Train Loss: 0.6661
2024-04-01 18:40:06,766 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:40:06,767 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:40:10,789 - config - INFO - Epoch [188/600], Train Loss: 0.6661
2024-04-01 18:40:10,970 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:40:10,970 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:40:14,998 - config - INFO - Epoch [189/600], Train Loss: 0.6661
2024-04-01 18:40:15,179 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:40:15,180 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:40:19,219 - config - INFO - Epoch [190/600], Train Loss: 0.6661
2024-04-01 18:40:19,396 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:40:19,397 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:40:23,424 - config - INFO - Epoch [191/600], Train Loss: 0.6660
2024-04-01 18:40:23,603 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:40:23,603 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:40:27,733 - config - INFO - Epoch [192/600], Train Loss: 0.6660
2024-04-01 18:40:27,910 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:40:27,911 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:40:31,939 - config - INFO - Epoch [193/600], Train Loss: 0.6660
2024-04-01 18:40:32,118 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:40:32,118 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:40:36,144 - config - INFO - Epoch [194/600], Train Loss: 0.6660
2024-04-01 18:40:36,322 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:40:36,322 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:40:40,354 - config - INFO - Epoch [195/600], Train Loss: 0.6660
2024-04-01 18:40:40,533 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:40:40,534 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:40:44,556 - config - INFO - Epoch [196/600], Train Loss: 0.6660
2024-04-01 18:40:44,735 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:40:44,735 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:40:48,788 - config - INFO - Epoch [197/600], Train Loss: 0.6660
2024-04-01 18:40:48,969 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:40:48,969 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:40:53,001 - config - INFO - Epoch [198/600], Train Loss: 0.6660
2024-04-01 18:40:53,182 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:40:53,183 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:40:57,221 - config - INFO - Epoch [199/600], Train Loss: 0.6660
2024-04-01 18:40:57,403 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:40:57,403 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:41:01,443 - config - INFO - Epoch [200/600], Train Loss: 0.6660
2024-04-01 18:41:01,623 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:41:01,623 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:41:05,667 - config - INFO - Epoch [201/600], Train Loss: 0.6660
2024-04-01 18:41:05,849 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:41:05,849 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:41:09,893 - config - INFO - Epoch [202/600], Train Loss: 0.6660
2024-04-01 18:41:10,077 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:41:10,077 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:41:14,116 - config - INFO - Epoch [203/600], Train Loss: 0.6660
2024-04-01 18:41:14,297 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:41:14,297 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:41:18,355 - config - INFO - Epoch [204/600], Train Loss: 0.6660
2024-04-01 18:41:18,534 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:41:18,535 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:41:22,576 - config - INFO - Epoch [205/600], Train Loss: 0.6660
2024-04-01 18:41:22,755 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:41:22,755 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:41:26,793 - config - INFO - Epoch [206/600], Train Loss: 0.6660
2024-04-01 18:41:26,975 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:41:26,976 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:41:31,124 - config - INFO - Epoch [207/600], Train Loss: 0.6660
2024-04-01 18:41:31,305 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:41:31,305 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:41:35,344 - config - INFO - Epoch [208/600], Train Loss: 0.6660
2024-04-01 18:41:35,526 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:41:35,526 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:41:39,629 - config - INFO - Epoch [209/600], Train Loss: 0.6660
2024-04-01 18:41:39,815 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:41:39,815 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:41:43,915 - config - INFO - Epoch [210/600], Train Loss: 0.6660
2024-04-01 18:41:44,101 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:41:44,102 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:41:48,198 - config - INFO - Epoch [211/600], Train Loss: 0.6660
2024-04-01 18:41:48,381 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:41:48,382 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:41:52,470 - config - INFO - Epoch [212/600], Train Loss: 0.6660
2024-04-01 18:41:52,654 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:41:52,654 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:41:56,755 - config - INFO - Epoch [213/600], Train Loss: 0.6660
2024-04-01 18:41:56,939 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:41:56,939 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:42:01,039 - config - INFO - Epoch [214/600], Train Loss: 0.6660
2024-04-01 18:42:01,224 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:42:01,224 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:42:05,320 - config - INFO - Epoch [215/600], Train Loss: 0.6660
2024-04-01 18:42:05,515 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:42:05,515 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:42:09,636 - config - INFO - Epoch [216/600], Train Loss: 0.6660
2024-04-01 18:42:09,823 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:42:09,824 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:42:13,924 - config - INFO - Epoch [217/600], Train Loss: 0.6660
2024-04-01 18:42:14,107 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:42:14,108 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:42:18,200 - config - INFO - Epoch [218/600], Train Loss: 0.6660
2024-04-01 18:42:18,385 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:42:18,386 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:42:22,477 - config - INFO - Epoch [219/600], Train Loss: 0.6660
2024-04-01 18:42:22,661 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:42:22,661 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:42:26,751 - config - INFO - Epoch [220/600], Train Loss: 0.6660
2024-04-01 18:42:26,935 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:42:26,936 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:42:31,026 - config - INFO - Epoch [221/600], Train Loss: 0.6660
2024-04-01 18:42:31,211 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:42:31,211 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:42:35,420 - config - INFO - Epoch [222/600], Train Loss: 0.6660
2024-04-01 18:42:35,604 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:42:35,604 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:42:39,703 - config - INFO - Epoch [223/600], Train Loss: 0.6660
2024-04-01 18:42:39,890 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:42:39,890 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:42:43,991 - config - INFO - Epoch [224/600], Train Loss: 0.6660
2024-04-01 18:42:44,176 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:42:44,177 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:42:48,290 - config - INFO - Epoch [225/600], Train Loss: 0.6660
2024-04-01 18:42:48,476 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:42:48,477 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:42:52,577 - config - INFO - Epoch [226/600], Train Loss: 0.6660
2024-04-01 18:42:52,762 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:42:52,762 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:42:56,872 - config - INFO - Epoch [227/600], Train Loss: 0.6660
2024-04-01 18:42:57,057 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:42:57,058 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:43:01,151 - config - INFO - Epoch [228/600], Train Loss: 0.6660
2024-04-01 18:43:01,336 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:43:01,337 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:43:05,441 - config - INFO - Epoch [229/600], Train Loss: 0.6660
2024-04-01 18:43:05,624 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:43:05,625 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:43:09,723 - config - INFO - Epoch [230/600], Train Loss: 0.6660
2024-04-01 18:43:09,909 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:43:09,909 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:43:14,009 - config - INFO - Epoch [231/600], Train Loss: 0.6660
2024-04-01 18:43:14,194 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:43:14,194 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:43:18,320 - config - INFO - Epoch [232/600], Train Loss: 0.6660
2024-04-01 18:43:18,505 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:43:18,505 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:43:22,596 - config - INFO - Epoch [233/600], Train Loss: 0.6660
2024-04-01 18:43:22,782 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:43:22,782 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:43:26,883 - config - INFO - Epoch [234/600], Train Loss: 0.6660
2024-04-01 18:43:27,069 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:43:27,070 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:43:31,170 - config - INFO - Epoch [235/600], Train Loss: 0.6660
2024-04-01 18:43:31,356 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:43:31,356 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:43:35,452 - config - INFO - Epoch [236/600], Train Loss: 0.6660
2024-04-01 18:43:35,645 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:43:35,645 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:43:39,850 - config - INFO - Epoch [237/600], Train Loss: 0.6660
2024-04-01 18:43:40,033 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:43:40,033 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:43:44,129 - config - INFO - Epoch [238/600], Train Loss: 0.6660
2024-04-01 18:43:44,312 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:43:44,313 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:43:48,405 - config - INFO - Epoch [239/600], Train Loss: 0.6660
2024-04-01 18:43:48,588 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:43:48,588 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:43:52,681 - config - INFO - Epoch [240/600], Train Loss: 0.6660
2024-04-01 18:43:52,864 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:43:52,864 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:43:57,003 - config - INFO - Epoch [241/600], Train Loss: 0.6660
2024-04-01 18:43:57,189 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:43:57,189 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:44:01,299 - config - INFO - Epoch [242/600], Train Loss: 0.6660
2024-04-01 18:44:01,485 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:44:01,486 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:44:05,603 - config - INFO - Epoch [243/600], Train Loss: 0.6660
2024-04-01 18:44:05,790 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:44:05,791 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:44:09,898 - config - INFO - Epoch [244/600], Train Loss: 0.6660
2024-04-01 18:44:10,085 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:44:10,085 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:44:14,207 - config - INFO - Epoch [245/600], Train Loss: 0.6660
2024-04-01 18:44:14,395 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:44:14,395 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:44:18,515 - config - INFO - Epoch [246/600], Train Loss: 0.6660
2024-04-01 18:44:18,702 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:44:18,702 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:44:22,820 - config - INFO - Epoch [247/600], Train Loss: 0.6660
2024-04-01 18:44:23,007 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:44:23,008 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:44:27,123 - config - INFO - Epoch [248/600], Train Loss: 0.6660
2024-04-01 18:44:27,310 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:44:27,311 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:44:31,415 - config - INFO - Epoch [249/600], Train Loss: 0.6660
2024-04-01 18:44:31,601 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:44:31,601 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:44:35,712 - config - INFO - Epoch [250/600], Train Loss: 0.6660
2024-04-01 18:44:35,901 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:44:35,901 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:44:40,025 - config - INFO - Epoch [251/600], Train Loss: 0.6660
2024-04-01 18:44:40,212 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:44:40,212 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:44:44,441 - config - INFO - Epoch [252/600], Train Loss: 0.6660
2024-04-01 18:44:44,632 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:44:44,632 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:44:48,755 - config - INFO - Epoch [253/600], Train Loss: 0.6660
2024-04-01 18:44:48,942 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:44:48,943 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:44:53,057 - config - INFO - Epoch [254/600], Train Loss: 0.6660
2024-04-01 18:44:53,244 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:44:53,245 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:44:57,367 - config - INFO - Epoch [255/600], Train Loss: 0.6660
2024-04-01 18:44:57,553 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:44:57,553 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:45:01,666 - config - INFO - Epoch [256/600], Train Loss: 0.6660
2024-04-01 18:45:01,853 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:45:01,854 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:45:05,979 - config - INFO - Epoch [257/600], Train Loss: 0.6660
2024-04-01 18:45:06,165 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:45:06,165 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:45:10,296 - config - INFO - Epoch [258/600], Train Loss: 0.6660
2024-04-01 18:45:10,481 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:45:10,482 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:45:14,613 - config - INFO - Epoch [259/600], Train Loss: 0.6660
2024-04-01 18:45:14,799 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:45:14,800 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:45:18,907 - config - INFO - Epoch [260/600], Train Loss: 0.6660
2024-04-01 18:45:19,090 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:45:19,090 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:45:23,207 - config - INFO - Epoch [261/600], Train Loss: 0.6660
2024-04-01 18:45:23,389 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:45:23,390 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:45:27,487 - config - INFO - Epoch [262/600], Train Loss: 0.6660
2024-04-01 18:45:27,670 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:45:27,670 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:45:31,780 - config - INFO - Epoch [263/600], Train Loss: 0.6660
2024-04-01 18:45:31,964 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:45:31,964 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:45:36,070 - config - INFO - Epoch [264/600], Train Loss: 0.6660
2024-04-01 18:45:36,256 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:45:36,256 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:45:40,365 - config - INFO - Epoch [265/600], Train Loss: 0.6660
2024-04-01 18:45:40,549 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:45:40,550 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:45:44,663 - config - INFO - Epoch [266/600], Train Loss: 0.6660
2024-04-01 18:45:44,847 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:45:44,848 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:45:49,075 - config - INFO - Epoch [267/600], Train Loss: 0.6660
2024-04-01 18:45:49,260 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:45:49,260 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:45:53,366 - config - INFO - Epoch [268/600], Train Loss: 0.6660
2024-04-01 18:45:53,550 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:45:53,550 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:45:57,647 - config - INFO - Epoch [269/600], Train Loss: 0.6660
2024-04-01 18:45:57,833 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:45:57,834 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:46:01,933 - config - INFO - Epoch [270/600], Train Loss: 0.6660
2024-04-01 18:46:02,119 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:46:02,119 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:46:06,238 - config - INFO - Epoch [271/600], Train Loss: 0.6660
2024-04-01 18:46:06,419 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:46:06,419 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:46:10,464 - config - INFO - Epoch [272/600], Train Loss: 0.6660
2024-04-01 18:46:10,643 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:46:10,644 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:46:14,684 - config - INFO - Epoch [273/600], Train Loss: 0.6660
2024-04-01 18:46:14,864 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:46:14,864 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:46:18,922 - config - INFO - Epoch [274/600], Train Loss: 0.6660
2024-04-01 18:46:19,106 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:46:19,107 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:46:23,182 - config - INFO - Epoch [275/600], Train Loss: 0.6660
2024-04-01 18:46:23,363 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:46:23,363 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:46:27,427 - config - INFO - Epoch [276/600], Train Loss: 0.6660
2024-04-01 18:46:27,609 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:46:27,609 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:46:31,667 - config - INFO - Epoch [277/600], Train Loss: 0.6660
2024-04-01 18:46:31,851 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:46:31,851 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:46:35,910 - config - INFO - Epoch [278/600], Train Loss: 0.6660
2024-04-01 18:46:36,090 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:46:36,091 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:46:40,208 - config - INFO - Epoch [279/600], Train Loss: 0.6660
2024-04-01 18:46:40,394 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:46:40,394 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:46:44,486 - config - INFO - Epoch [280/600], Train Loss: 0.6660
2024-04-01 18:46:44,670 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:46:44,670 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:46:48,768 - config - INFO - Epoch [281/600], Train Loss: 0.6660
2024-04-01 18:46:48,952 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:46:48,952 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:46:53,144 - config - INFO - Epoch [282/600], Train Loss: 0.6660
2024-04-01 18:46:53,328 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:46:53,328 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:46:57,430 - config - INFO - Epoch [283/600], Train Loss: 0.6660
2024-04-01 18:46:57,617 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:46:57,617 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:47:01,716 - config - INFO - Epoch [284/600], Train Loss: 0.6660
2024-04-01 18:47:01,901 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:47:01,902 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:47:06,022 - config - INFO - Epoch [285/600], Train Loss: 0.6660
2024-04-01 18:47:06,204 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:47:06,205 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:47:10,276 - config - INFO - Epoch [286/600], Train Loss: 0.6660
2024-04-01 18:47:10,459 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:47:10,459 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:47:14,534 - config - INFO - Epoch [287/600], Train Loss: 0.6660
2024-04-01 18:47:14,714 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:47:14,715 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:47:18,786 - config - INFO - Epoch [288/600], Train Loss: 0.6660
2024-04-01 18:47:18,969 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:47:18,970 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:47:23,047 - config - INFO - Epoch [289/600], Train Loss: 0.6660
2024-04-01 18:47:23,228 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:47:23,228 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:47:27,320 - config - INFO - Epoch [290/600], Train Loss: 0.6660
2024-04-01 18:47:27,503 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:47:27,503 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:47:31,579 - config - INFO - Epoch [291/600], Train Loss: 0.6660
2024-04-01 18:47:31,762 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:47:31,762 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:47:35,821 - config - INFO - Epoch [292/600], Train Loss: 0.6660
2024-04-01 18:47:36,002 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:47:36,002 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:47:40,052 - config - INFO - Epoch [293/600], Train Loss: 0.6660
2024-04-01 18:47:40,234 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:47:40,235 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:47:44,286 - config - INFO - Epoch [294/600], Train Loss: 0.6660
2024-04-01 18:47:44,467 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:47:44,467 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:47:48,529 - config - INFO - Epoch [295/600], Train Loss: 0.6660
2024-04-01 18:47:48,708 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:47:48,709 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:47:52,763 - config - INFO - Epoch [296/600], Train Loss: 0.6660
2024-04-01 18:47:52,943 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:47:52,944 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:47:57,104 - config - INFO - Epoch [297/600], Train Loss: 0.6660
2024-04-01 18:47:57,286 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:47:57,286 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:48:01,307 - config - INFO - Epoch [298/600], Train Loss: 0.6660
2024-04-01 18:48:01,486 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:48:01,486 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:48:05,517 - config - INFO - Epoch [299/600], Train Loss: 0.6660
2024-04-01 18:48:05,695 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:48:05,696 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:48:09,725 - config - INFO - Epoch [300/600], Train Loss: 0.6660
2024-04-01 18:48:09,904 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:48:09,904 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:48:13,939 - config - INFO - Epoch [301/600], Train Loss: 0.6660
2024-04-01 18:48:14,119 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:48:14,119 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:48:18,179 - config - INFO - Epoch [302/600], Train Loss: 0.6660
2024-04-01 18:48:18,359 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:48:18,359 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:48:22,407 - config - INFO - Epoch [303/600], Train Loss: 0.6660
2024-04-01 18:48:22,587 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:48:22,587 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:48:26,615 - config - INFO - Epoch [304/600], Train Loss: 0.6660
2024-04-01 18:48:26,795 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:48:26,795 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:48:30,828 - config - INFO - Epoch [305/600], Train Loss: 0.6660
2024-04-01 18:48:31,008 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:48:31,009 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:48:35,032 - config - INFO - Epoch [306/600], Train Loss: 0.6660
2024-04-01 18:48:35,212 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:48:35,212 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:48:39,254 - config - INFO - Epoch [307/600], Train Loss: 0.6660
2024-04-01 18:48:39,435 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:48:39,435 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:48:43,466 - config - INFO - Epoch [308/600], Train Loss: 0.6660
2024-04-01 18:48:43,647 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:48:43,647 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:48:47,692 - config - INFO - Epoch [309/600], Train Loss: 0.6660
2024-04-01 18:48:47,880 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:48:47,880 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:48:51,925 - config - INFO - Epoch [310/600], Train Loss: 0.6660
2024-04-01 18:48:52,105 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:48:52,106 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:48:56,160 - config - INFO - Epoch [311/600], Train Loss: 0.6660
2024-04-01 18:48:56,340 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:48:56,340 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:49:00,480 - config - INFO - Epoch [312/600], Train Loss: 0.6660
2024-04-01 18:49:00,661 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:49:00,661 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:49:04,713 - config - INFO - Epoch [313/600], Train Loss: 0.6660
2024-04-01 18:49:04,893 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:49:04,893 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:49:08,927 - config - INFO - Epoch [314/600], Train Loss: 0.6660
2024-04-01 18:49:09,108 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:49:09,108 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:49:13,145 - config - INFO - Epoch [315/600], Train Loss: 0.6660
2024-04-01 18:49:13,326 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:49:13,326 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:49:17,381 - config - INFO - Epoch [316/600], Train Loss: 0.6660
2024-04-01 18:49:17,564 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:49:17,564 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:49:21,627 - config - INFO - Epoch [317/600], Train Loss: 0.6660
2024-04-01 18:49:21,814 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:49:21,815 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:49:25,878 - config - INFO - Epoch [318/600], Train Loss: 0.6660
2024-04-01 18:49:26,061 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:49:26,061 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:49:30,124 - config - INFO - Epoch [319/600], Train Loss: 0.6660
2024-04-01 18:49:30,306 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:49:30,307 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:49:34,364 - config - INFO - Epoch [320/600], Train Loss: 0.6660
2024-04-01 18:49:34,545 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:49:34,546 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:49:38,625 - config - INFO - Epoch [321/600], Train Loss: 0.6660
2024-04-01 18:49:38,807 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:49:38,808 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:49:42,881 - config - INFO - Epoch [322/600], Train Loss: 0.6660
2024-04-01 18:49:43,062 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:49:43,062 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:49:47,119 - config - INFO - Epoch [323/600], Train Loss: 0.6660
2024-04-01 18:49:47,302 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:49:47,303 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:49:51,365 - config - INFO - Epoch [324/600], Train Loss: 0.6660
2024-04-01 18:49:51,546 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:49:51,546 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:49:55,609 - config - INFO - Epoch [325/600], Train Loss: 0.6660
2024-04-01 18:49:55,793 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:49:55,793 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:49:59,849 - config - INFO - Epoch [326/600], Train Loss: 0.6660
2024-04-01 18:50:00,030 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:50:00,030 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:50:04,197 - config - INFO - Epoch [327/600], Train Loss: 0.6660
2024-04-01 18:50:04,376 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:50:04,376 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:50:08,422 - config - INFO - Epoch [328/600], Train Loss: 0.6660
2024-04-01 18:50:08,602 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:50:08,603 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:50:12,649 - config - INFO - Epoch [329/600], Train Loss: 0.6660
2024-04-01 18:50:12,831 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:50:12,831 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:50:16,880 - config - INFO - Epoch [330/600], Train Loss: 0.6660
2024-04-01 18:50:17,067 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:50:17,067 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:50:21,111 - config - INFO - Epoch [331/600], Train Loss: 0.6660
2024-04-01 18:50:21,291 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:50:21,292 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:50:25,350 - config - INFO - Epoch [332/600], Train Loss: 0.6660
2024-04-01 18:50:25,538 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:50:25,538 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:50:29,675 - config - INFO - Epoch [333/600], Train Loss: 0.6660
2024-04-01 18:50:29,862 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:50:29,862 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:50:33,993 - config - INFO - Epoch [334/600], Train Loss: 0.6660
2024-04-01 18:50:34,190 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:50:34,190 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:50:38,353 - config - INFO - Epoch [335/600], Train Loss: 0.6660
2024-04-01 18:50:38,538 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:50:38,539 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:50:42,693 - config - INFO - Epoch [336/600], Train Loss: 0.6660
2024-04-01 18:50:42,881 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:50:42,881 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:50:47,012 - config - INFO - Epoch [337/600], Train Loss: 0.6660
2024-04-01 18:50:47,201 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:50:47,201 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:50:51,347 - config - INFO - Epoch [338/600], Train Loss: 0.6660
2024-04-01 18:50:51,540 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:50:51,540 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:50:55,687 - config - INFO - Epoch [339/600], Train Loss: 0.6660
2024-04-01 18:50:55,877 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:50:55,878 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:51:00,026 - config - INFO - Epoch [340/600], Train Loss: 0.6660
2024-04-01 18:51:00,211 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:51:00,212 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:51:04,385 - config - INFO - Epoch [341/600], Train Loss: 0.6660
2024-04-01 18:51:04,578 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:51:04,579 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:51:08,815 - config - INFO - Epoch [342/600], Train Loss: 0.6660
2024-04-01 18:51:08,998 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:51:08,998 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:51:13,070 - config - INFO - Epoch [343/600], Train Loss: 0.6660
2024-04-01 18:51:13,250 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:51:13,250 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:51:17,313 - config - INFO - Epoch [344/600], Train Loss: 0.6660
2024-04-01 18:51:17,492 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:51:17,492 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:51:21,586 - config - INFO - Epoch [345/600], Train Loss: 0.6660
2024-04-01 18:51:21,769 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:51:21,769 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:51:25,868 - config - INFO - Epoch [346/600], Train Loss: 0.6660
2024-04-01 18:51:26,051 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:51:26,051 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:51:30,164 - config - INFO - Epoch [347/600], Train Loss: 0.6660
2024-04-01 18:51:30,346 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:51:30,346 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:51:34,477 - config - INFO - Epoch [348/600], Train Loss: 0.6660
2024-04-01 18:51:34,659 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:51:34,660 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:51:38,777 - config - INFO - Epoch [349/600], Train Loss: 0.6660
2024-04-01 18:51:38,960 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:51:38,960 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:51:43,070 - config - INFO - Epoch [350/600], Train Loss: 0.6660
2024-04-01 18:51:43,255 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:51:43,256 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:51:47,347 - config - INFO - Epoch [351/600], Train Loss: 0.6660
2024-04-01 18:51:47,527 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:51:47,528 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:51:51,591 - config - INFO - Epoch [352/600], Train Loss: 0.6660
2024-04-01 18:51:51,791 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:51:51,791 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:51:55,844 - config - INFO - Epoch [353/600], Train Loss: 0.6660
2024-04-01 18:51:56,023 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:51:56,023 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:52:00,073 - config - INFO - Epoch [354/600], Train Loss: 0.6660
2024-04-01 18:52:00,253 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:52:00,253 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:52:04,345 - config - INFO - Epoch [355/600], Train Loss: 0.6660
2024-04-01 18:52:04,525 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:52:04,525 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:52:08,626 - config - INFO - Epoch [356/600], Train Loss: 0.6660
2024-04-01 18:52:08,809 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:52:08,809 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:52:12,998 - config - INFO - Epoch [357/600], Train Loss: 0.6660
2024-04-01 18:52:13,180 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:52:13,180 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:52:17,282 - config - INFO - Epoch [358/600], Train Loss: 0.6660
2024-04-01 18:52:17,463 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:52:17,463 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:52:21,541 - config - INFO - Epoch [359/600], Train Loss: 0.6660
2024-04-01 18:52:21,726 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:52:21,726 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:52:25,857 - config - INFO - Epoch [360/600], Train Loss: 0.6660
2024-04-01 18:52:26,039 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:52:26,040 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:52:30,138 - config - INFO - Epoch [361/600], Train Loss: 0.6660
2024-04-01 18:52:30,320 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:52:30,320 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:52:34,416 - config - INFO - Epoch [362/600], Train Loss: 0.6660
2024-04-01 18:52:34,597 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:52:34,598 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:52:38,693 - config - INFO - Epoch [363/600], Train Loss: 0.6660
2024-04-01 18:52:38,874 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:52:38,875 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:52:42,950 - config - INFO - Epoch [364/600], Train Loss: 0.6660
2024-04-01 18:52:43,132 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:52:43,133 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:52:47,251 - config - INFO - Epoch [365/600], Train Loss: 0.6660
2024-04-01 18:52:47,434 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:52:47,435 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:52:51,537 - config - INFO - Epoch [366/600], Train Loss: 0.6660
2024-04-01 18:52:51,729 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:52:51,729 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:52:55,825 - config - INFO - Epoch [367/600], Train Loss: 0.6660
2024-04-01 18:52:56,006 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:52:56,007 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:53:00,094 - config - INFO - Epoch [368/600], Train Loss: 0.6660
2024-04-01 18:53:00,276 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:53:00,276 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:53:04,357 - config - INFO - Epoch [369/600], Train Loss: 0.6660
2024-04-01 18:53:04,538 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:53:04,539 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:53:08,638 - config - INFO - Epoch [370/600], Train Loss: 0.6660
2024-04-01 18:53:08,820 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:53:08,821 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:53:12,950 - config - INFO - Epoch [371/600], Train Loss: 0.6660
2024-04-01 18:53:13,132 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:53:13,132 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:53:17,366 - config - INFO - Epoch [372/600], Train Loss: 0.6660
2024-04-01 18:53:17,549 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:53:17,549 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:53:21,696 - config - INFO - Epoch [373/600], Train Loss: 0.6660
2024-04-01 18:53:21,881 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:53:21,882 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:53:25,960 - config - INFO - Epoch [374/600], Train Loss: 0.6660
2024-04-01 18:53:26,149 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:53:26,149 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:53:30,228 - config - INFO - Epoch [375/600], Train Loss: 0.6660
2024-04-01 18:53:30,410 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:53:30,410 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:53:34,482 - config - INFO - Epoch [376/600], Train Loss: 0.6660
2024-04-01 18:53:34,668 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:53:34,668 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:53:38,746 - config - INFO - Epoch [377/600], Train Loss: 0.6660
2024-04-01 18:53:38,929 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:53:38,929 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:53:43,034 - config - INFO - Epoch [378/600], Train Loss: 0.6660
2024-04-01 18:53:43,216 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:53:43,216 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:53:47,328 - config - INFO - Epoch [379/600], Train Loss: 0.6660
2024-04-01 18:53:47,515 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:53:47,515 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:53:51,614 - config - INFO - Epoch [380/600], Train Loss: 0.6660
2024-04-01 18:53:51,803 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:53:51,803 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:53:55,893 - config - INFO - Epoch [381/600], Train Loss: 0.6660
2024-04-01 18:53:56,076 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:53:56,076 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:54:00,157 - config - INFO - Epoch [382/600], Train Loss: 0.6660
2024-04-01 18:54:00,339 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:54:00,340 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:54:04,404 - config - INFO - Epoch [383/600], Train Loss: 0.6660
2024-04-01 18:54:04,588 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:54:04,589 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:54:08,681 - config - INFO - Epoch [384/600], Train Loss: 0.6660
2024-04-01 18:54:08,864 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:54:08,864 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:54:12,959 - config - INFO - Epoch [385/600], Train Loss: 0.6660
2024-04-01 18:54:13,141 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:54:13,141 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:54:17,229 - config - INFO - Epoch [386/600], Train Loss: 0.6660
2024-04-01 18:54:17,412 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:54:17,412 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:54:21,606 - config - INFO - Epoch [387/600], Train Loss: 0.6660
2024-04-01 18:54:21,799 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:54:21,799 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:54:25,918 - config - INFO - Epoch [388/600], Train Loss: 0.6660
2024-04-01 18:54:26,100 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:54:26,101 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:54:30,207 - config - INFO - Epoch [389/600], Train Loss: 0.6660
2024-04-01 18:54:30,389 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:54:30,389 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:54:34,476 - config - INFO - Epoch [390/600], Train Loss: 0.6660
2024-04-01 18:54:34,660 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:54:34,660 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:54:38,760 - config - INFO - Epoch [391/600], Train Loss: 0.6660
2024-04-01 18:54:38,941 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:54:38,941 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:54:43,065 - config - INFO - Epoch [392/600], Train Loss: 0.6660
2024-04-01 18:54:43,250 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:54:43,250 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:54:47,379 - config - INFO - Epoch [393/600], Train Loss: 0.6660
2024-04-01 18:54:47,561 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:54:47,562 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:54:51,654 - config - INFO - Epoch [394/600], Train Loss: 0.6660
2024-04-01 18:54:51,838 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:54:51,838 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:54:55,928 - config - INFO - Epoch [395/600], Train Loss: 0.6660
2024-04-01 18:54:56,109 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:54:56,109 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:55:00,186 - config - INFO - Epoch [396/600], Train Loss: 0.6660
2024-04-01 18:55:00,369 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:55:00,369 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:55:04,447 - config - INFO - Epoch [397/600], Train Loss: 0.6660
2024-04-01 18:55:04,634 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:55:04,635 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:55:08,760 - config - INFO - Epoch [398/600], Train Loss: 0.6660
2024-04-01 18:55:08,945 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:55:08,945 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:55:13,053 - config - INFO - Epoch [399/600], Train Loss: 0.6660
2024-04-01 18:55:13,239 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:55:13,239 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:55:17,381 - config - INFO - Epoch [400/600], Train Loss: 0.6660
2024-04-01 18:55:17,565 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:55:17,566 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:55:21,690 - config - INFO - Epoch [401/600], Train Loss: 0.6660
2024-04-01 18:55:21,875 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:55:21,875 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:55:26,132 - config - INFO - Epoch [402/600], Train Loss: 0.6660
2024-04-01 18:55:26,318 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:55:26,318 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:55:30,430 - config - INFO - Epoch [403/600], Train Loss: 0.6660
2024-04-01 18:55:30,618 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:55:30,618 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:55:34,711 - config - INFO - Epoch [404/600], Train Loss: 0.6660
2024-04-01 18:55:34,900 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:55:34,900 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:55:39,045 - config - INFO - Epoch [405/600], Train Loss: 0.6660
2024-04-01 18:55:39,230 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:55:39,230 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:55:43,357 - config - INFO - Epoch [406/600], Train Loss: 0.6660
2024-04-01 18:55:43,541 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:55:43,542 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:55:47,665 - config - INFO - Epoch [407/600], Train Loss: 0.6660
2024-04-01 18:55:47,850 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:55:47,851 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:55:51,966 - config - INFO - Epoch [408/600], Train Loss: 0.6660
2024-04-01 18:55:52,153 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:55:52,153 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:55:56,293 - config - INFO - Epoch [409/600], Train Loss: 0.6660
2024-04-01 18:55:56,482 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:55:56,482 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:56:00,609 - config - INFO - Epoch [410/600], Train Loss: 0.6660
2024-04-01 18:56:00,794 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:56:00,795 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:56:04,938 - config - INFO - Epoch [411/600], Train Loss: 0.6660
2024-04-01 18:56:05,126 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:56:05,127 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:56:09,282 - config - INFO - Epoch [412/600], Train Loss: 0.6660
2024-04-01 18:56:09,469 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:56:09,469 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:56:13,586 - config - INFO - Epoch [413/600], Train Loss: 0.6660
2024-04-01 18:56:13,783 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:56:13,784 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:56:17,919 - config - INFO - Epoch [414/600], Train Loss: 0.6660
2024-04-01 18:56:18,106 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:56:18,106 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:56:22,251 - config - INFO - Epoch [415/600], Train Loss: 0.6660
2024-04-01 18:56:22,438 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:56:22,439 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:56:26,560 - config - INFO - Epoch [416/600], Train Loss: 0.6660
2024-04-01 18:56:26,748 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:56:26,748 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:56:30,994 - config - INFO - Epoch [417/600], Train Loss: 0.6660
2024-04-01 18:56:31,185 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:56:31,185 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:56:35,308 - config - INFO - Epoch [418/600], Train Loss: 0.6660
2024-04-01 18:56:35,495 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:56:35,496 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:56:39,667 - config - INFO - Epoch [419/600], Train Loss: 0.6660
2024-04-01 18:56:39,857 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:56:39,858 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:56:44,012 - config - INFO - Epoch [420/600], Train Loss: 0.6660
2024-04-01 18:56:44,203 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:56:44,203 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:56:48,333 - config - INFO - Epoch [421/600], Train Loss: 0.6660
2024-04-01 18:56:48,522 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:56:48,522 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:56:52,660 - config - INFO - Epoch [422/600], Train Loss: 0.6660
2024-04-01 18:56:52,849 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:56:52,849 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:56:56,982 - config - INFO - Epoch [423/600], Train Loss: 0.6660
2024-04-01 18:56:57,169 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:56:57,170 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:57:01,295 - config - INFO - Epoch [424/600], Train Loss: 0.6660
2024-04-01 18:57:01,481 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:57:01,481 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:57:05,606 - config - INFO - Epoch [425/600], Train Loss: 0.6660
2024-04-01 18:57:05,800 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:57:05,801 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:57:09,950 - config - INFO - Epoch [426/600], Train Loss: 0.6660
2024-04-01 18:57:10,137 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:57:10,137 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:57:14,274 - config - INFO - Epoch [427/600], Train Loss: 0.6660
2024-04-01 18:57:14,464 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:57:14,464 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:57:18,614 - config - INFO - Epoch [428/600], Train Loss: 0.6660
2024-04-01 18:57:18,805 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:57:18,806 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:57:22,940 - config - INFO - Epoch [429/600], Train Loss: 0.6660
2024-04-01 18:57:23,129 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:57:23,129 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:57:27,249 - config - INFO - Epoch [430/600], Train Loss: 0.6660
2024-04-01 18:57:27,436 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:57:27,436 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:57:31,553 - config - INFO - Epoch [431/600], Train Loss: 0.6660
2024-04-01 18:57:31,744 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:57:31,744 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:57:36,011 - config - INFO - Epoch [432/600], Train Loss: 0.6660
2024-04-01 18:57:36,199 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:57:36,199 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:57:40,373 - config - INFO - Epoch [433/600], Train Loss: 0.6660
2024-04-01 18:57:40,560 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:57:40,561 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:57:44,701 - config - INFO - Epoch [434/600], Train Loss: 0.6660
2024-04-01 18:57:44,890 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:57:44,891 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:57:49,028 - config - INFO - Epoch [435/600], Train Loss: 0.6660
2024-04-01 18:57:49,217 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:57:49,217 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:57:53,342 - config - INFO - Epoch [436/600], Train Loss: 0.6660
2024-04-01 18:57:53,533 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:57:53,533 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:57:57,667 - config - INFO - Epoch [437/600], Train Loss: 0.6660
2024-04-01 18:57:57,857 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:57:57,857 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:58:01,984 - config - INFO - Epoch [438/600], Train Loss: 0.6660
2024-04-01 18:58:02,174 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:58:02,174 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:58:06,335 - config - INFO - Epoch [439/600], Train Loss: 0.6660
2024-04-01 18:58:06,522 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:58:06,523 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:58:10,663 - config - INFO - Epoch [440/600], Train Loss: 0.6659
2024-04-01 18:58:10,851 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:58:10,851 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:58:14,978 - config - INFO - Epoch [441/600], Train Loss: 0.6659
2024-04-01 18:58:15,167 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:58:15,167 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:58:19,294 - config - INFO - Epoch [442/600], Train Loss: 0.6659
2024-04-01 18:58:19,484 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:58:19,485 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:58:23,643 - config - INFO - Epoch [443/600], Train Loss: 0.6659
2024-04-01 18:58:23,831 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:58:23,831 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:58:27,945 - config - INFO - Epoch [444/600], Train Loss: 0.6659
2024-04-01 18:58:28,131 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:58:28,132 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:58:32,263 - config - INFO - Epoch [445/600], Train Loss: 0.6659
2024-04-01 18:58:32,450 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:58:32,450 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:58:36,580 - config - INFO - Epoch [446/600], Train Loss: 0.6659
2024-04-01 18:58:36,767 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:58:36,767 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:58:41,007 - config - INFO - Epoch [447/600], Train Loss: 0.6659
2024-04-01 18:58:41,197 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:58:41,197 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:58:45,342 - config - INFO - Epoch [448/600], Train Loss: 0.6659
2024-04-01 18:58:45,534 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:58:45,535 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:58:49,683 - config - INFO - Epoch [449/600], Train Loss: 0.6659
2024-04-01 18:58:49,872 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:58:49,872 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:58:54,025 - config - INFO - Epoch [450/600], Train Loss: 0.6659
2024-04-01 18:58:54,220 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:58:54,220 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:58:58,368 - config - INFO - Epoch [451/600], Train Loss: 0.6659
2024-04-01 18:58:58,556 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:58:58,557 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:59:02,687 - config - INFO - Epoch [452/600], Train Loss: 0.6659
2024-04-01 18:59:02,874 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:59:02,874 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:59:07,005 - config - INFO - Epoch [453/600], Train Loss: 0.6659
2024-04-01 18:59:07,194 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:59:07,195 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:59:11,343 - config - INFO - Epoch [454/600], Train Loss: 0.6659
2024-04-01 18:59:11,531 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:59:11,532 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:59:15,632 - config - INFO - Epoch [455/600], Train Loss: 0.6659
2024-04-01 18:59:15,818 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:59:15,819 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:59:19,955 - config - INFO - Epoch [456/600], Train Loss: 0.6659
2024-04-01 18:59:20,139 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:59:20,140 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:59:24,259 - config - INFO - Epoch [457/600], Train Loss: 0.6659
2024-04-01 18:59:24,444 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:59:24,444 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:59:28,549 - config - INFO - Epoch [458/600], Train Loss: 0.6659
2024-04-01 18:59:28,734 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:59:28,735 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:59:32,871 - config - INFO - Epoch [459/600], Train Loss: 0.6659
2024-04-01 18:59:33,059 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:59:33,060 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:59:37,178 - config - INFO - Epoch [460/600], Train Loss: 0.6659
2024-04-01 18:59:37,369 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:59:37,370 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:59:41,497 - config - INFO - Epoch [461/600], Train Loss: 0.6659
2024-04-01 18:59:41,684 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:59:41,684 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:59:45,977 - config - INFO - Epoch [462/600], Train Loss: 0.6659
2024-04-01 18:59:46,162 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:59:46,163 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:59:50,279 - config - INFO - Epoch [463/600], Train Loss: 0.6659
2024-04-01 18:59:50,463 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:59:50,463 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:59:54,596 - config - INFO - Epoch [464/600], Train Loss: 0.6659
2024-04-01 18:59:54,781 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:59:54,782 - config - INFO - Validation Acc: 0.6124
2024-04-01 18:59:58,904 - config - INFO - Epoch [465/600], Train Loss: 0.6659
2024-04-01 18:59:59,092 - config - INFO - Validation Loss: 0.6678
2024-04-01 18:59:59,093 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:00:03,228 - config - INFO - Epoch [466/600], Train Loss: 0.6659
2024-04-01 19:00:03,416 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:00:03,416 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:00:07,567 - config - INFO - Epoch [467/600], Train Loss: 0.6659
2024-04-01 19:00:07,755 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:00:07,755 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:00:11,874 - config - INFO - Epoch [468/600], Train Loss: 0.6659
2024-04-01 19:00:12,059 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:00:12,059 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:00:16,178 - config - INFO - Epoch [469/600], Train Loss: 0.6659
2024-04-01 19:00:16,365 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:00:16,365 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:00:20,504 - config - INFO - Epoch [470/600], Train Loss: 0.6659
2024-04-01 19:00:20,688 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:00:20,689 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:00:24,828 - config - INFO - Epoch [471/600], Train Loss: 0.6659
2024-04-01 19:00:25,013 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:00:25,013 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:00:29,193 - config - INFO - Epoch [472/600], Train Loss: 0.6659
2024-04-01 19:00:29,382 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:00:29,382 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:00:33,508 - config - INFO - Epoch [473/600], Train Loss: 0.6659
2024-04-01 19:00:33,703 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:00:33,703 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:00:37,850 - config - INFO - Epoch [474/600], Train Loss: 0.6659
2024-04-01 19:00:38,034 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:00:38,034 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:00:42,186 - config - INFO - Epoch [475/600], Train Loss: 0.6659
2024-04-01 19:00:42,370 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:00:42,370 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:00:46,507 - config - INFO - Epoch [476/600], Train Loss: 0.6659
2024-04-01 19:00:46,691 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:00:46,692 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:00:50,968 - config - INFO - Epoch [477/600], Train Loss: 0.6659
2024-04-01 19:00:51,152 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:00:51,152 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:00:55,276 - config - INFO - Epoch [478/600], Train Loss: 0.6659
2024-04-01 19:00:55,462 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:00:55,462 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:00:59,586 - config - INFO - Epoch [479/600], Train Loss: 0.6659
2024-04-01 19:00:59,770 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:00:59,771 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:01:03,894 - config - INFO - Epoch [480/600], Train Loss: 0.6659
2024-04-01 19:01:04,079 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:01:04,079 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:01:08,194 - config - INFO - Epoch [481/600], Train Loss: 0.6659
2024-04-01 19:01:08,378 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:01:08,378 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:01:12,508 - config - INFO - Epoch [482/600], Train Loss: 0.6659
2024-04-01 19:01:12,692 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:01:12,693 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:01:16,818 - config - INFO - Epoch [483/600], Train Loss: 0.6659
2024-04-01 19:01:17,002 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:01:17,003 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:01:21,104 - config - INFO - Epoch [484/600], Train Loss: 0.6659
2024-04-01 19:01:21,288 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:01:21,288 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:01:25,422 - config - INFO - Epoch [485/600], Train Loss: 0.6659
2024-04-01 19:01:25,605 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:01:25,605 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:01:29,729 - config - INFO - Epoch [486/600], Train Loss: 0.6659
2024-04-01 19:01:29,914 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:01:29,914 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:01:34,033 - config - INFO - Epoch [487/600], Train Loss: 0.6659
2024-04-01 19:01:34,219 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:01:34,219 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:01:38,324 - config - INFO - Epoch [488/600], Train Loss: 0.6659
2024-04-01 19:01:38,509 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:01:38,509 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:01:42,615 - config - INFO - Epoch [489/600], Train Loss: 0.6659
2024-04-01 19:01:42,800 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:01:42,800 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:01:46,923 - config - INFO - Epoch [490/600], Train Loss: 0.6659
2024-04-01 19:01:47,107 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:01:47,107 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:01:51,238 - config - INFO - Epoch [491/600], Train Loss: 0.6659
2024-04-01 19:01:51,422 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:01:51,422 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:01:55,652 - config - INFO - Epoch [492/600], Train Loss: 0.6659
2024-04-01 19:01:55,837 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:01:55,838 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:01:59,942 - config - INFO - Epoch [493/600], Train Loss: 0.6659
2024-04-01 19:02:00,128 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:02:00,128 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:02:04,268 - config - INFO - Epoch [494/600], Train Loss: 0.6659
2024-04-01 19:02:04,458 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:02:04,458 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:02:08,610 - config - INFO - Epoch [495/600], Train Loss: 0.6659
2024-04-01 19:02:08,794 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:02:08,795 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:02:12,914 - config - INFO - Epoch [496/600], Train Loss: 0.6659
2024-04-01 19:02:13,097 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:02:13,098 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:02:17,216 - config - INFO - Epoch [497/600], Train Loss: 0.6659
2024-04-01 19:02:17,404 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:02:17,404 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:02:21,530 - config - INFO - Epoch [498/600], Train Loss: 0.6659
2024-04-01 19:02:21,716 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:02:21,717 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:02:25,837 - config - INFO - Epoch [499/600], Train Loss: 0.6659
2024-04-01 19:02:26,024 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:02:26,024 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:02:30,138 - config - INFO - Epoch [500/600], Train Loss: 0.6659
2024-04-01 19:02:30,321 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:02:30,322 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:02:34,452 - config - INFO - Epoch [501/600], Train Loss: 0.6659
2024-04-01 19:02:34,635 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:02:34,636 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:02:38,785 - config - INFO - Epoch [502/600], Train Loss: 0.6659
2024-04-01 19:02:38,972 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:02:38,973 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:02:43,105 - config - INFO - Epoch [503/600], Train Loss: 0.6659
2024-04-01 19:02:43,289 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:02:43,290 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:02:47,415 - config - INFO - Epoch [504/600], Train Loss: 0.6659
2024-04-01 19:02:47,598 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:02:47,598 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:02:51,702 - config - INFO - Epoch [505/600], Train Loss: 0.6659
2024-04-01 19:02:51,889 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:02:51,889 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:02:56,006 - config - INFO - Epoch [506/600], Train Loss: 0.6659
2024-04-01 19:02:56,189 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:02:56,190 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:03:00,408 - config - INFO - Epoch [507/600], Train Loss: 0.6659
2024-04-01 19:03:00,592 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:03:00,593 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:03:04,704 - config - INFO - Epoch [508/600], Train Loss: 0.6659
2024-04-01 19:03:04,890 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:03:04,891 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:03:09,004 - config - INFO - Epoch [509/600], Train Loss: 0.6659
2024-04-01 19:03:09,192 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:03:09,192 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:03:13,309 - config - INFO - Epoch [510/600], Train Loss: 0.6659
2024-04-01 19:03:13,493 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:03:13,493 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:03:17,608 - config - INFO - Epoch [511/600], Train Loss: 0.6659
2024-04-01 19:03:17,793 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:03:17,794 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:03:21,901 - config - INFO - Epoch [512/600], Train Loss: 0.6659
2024-04-01 19:03:22,085 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:03:22,085 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:03:26,230 - config - INFO - Epoch [513/600], Train Loss: 0.6659
2024-04-01 19:03:26,415 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:03:26,416 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:03:30,545 - config - INFO - Epoch [514/600], Train Loss: 0.6659
2024-04-01 19:03:30,731 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:03:30,731 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:03:34,871 - config - INFO - Epoch [515/600], Train Loss: 0.6659
2024-04-01 19:03:35,057 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:03:35,057 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:03:39,181 - config - INFO - Epoch [516/600], Train Loss: 0.6659
2024-04-01 19:03:39,366 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:03:39,366 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:03:43,484 - config - INFO - Epoch [517/600], Train Loss: 0.6659
2024-04-01 19:03:43,673 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:03:43,674 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:03:47,797 - config - INFO - Epoch [518/600], Train Loss: 0.6659
2024-04-01 19:03:47,984 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:03:47,985 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:03:52,148 - config - INFO - Epoch [519/600], Train Loss: 0.6659
2024-04-01 19:03:52,333 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:03:52,334 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:03:56,466 - config - INFO - Epoch [520/600], Train Loss: 0.6659
2024-04-01 19:03:56,649 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:03:56,649 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:04:00,758 - config - INFO - Epoch [521/600], Train Loss: 0.6659
2024-04-01 19:04:00,939 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:04:00,939 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:04:05,183 - config - INFO - Epoch [522/600], Train Loss: 0.6659
2024-04-01 19:04:05,371 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:04:05,371 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:04:09,508 - config - INFO - Epoch [523/600], Train Loss: 0.6659
2024-04-01 19:04:09,691 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:04:09,691 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:04:13,808 - config - INFO - Epoch [524/600], Train Loss: 0.6659
2024-04-01 19:04:13,990 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:04:13,990 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:04:18,124 - config - INFO - Epoch [525/600], Train Loss: 0.6659
2024-04-01 19:04:18,306 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:04:18,306 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:04:22,428 - config - INFO - Epoch [526/600], Train Loss: 0.6659
2024-04-01 19:04:22,610 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:04:22,610 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:04:26,763 - config - INFO - Epoch [527/600], Train Loss: 0.6659
2024-04-01 19:04:26,954 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:04:26,954 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:04:31,137 - config - INFO - Epoch [528/600], Train Loss: 0.6659
2024-04-01 19:04:31,319 - config - INFO - Validation Loss: 0.6678
2024-04-01 19:04:31,320 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:04:35,417 - config - INFO - Epoch [529/600], Train Loss: 0.6659
2024-04-01 19:04:35,597 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:04:35,598 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:04:39,717 - config - INFO - Epoch [530/600], Train Loss: 0.6659
2024-04-01 19:04:39,898 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:04:39,898 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:04:44,024 - config - INFO - Epoch [531/600], Train Loss: 0.6659
2024-04-01 19:04:44,204 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:04:44,205 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:04:48,316 - config - INFO - Epoch [532/600], Train Loss: 0.6659
2024-04-01 19:04:48,497 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:04:48,497 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:04:52,595 - config - INFO - Epoch [533/600], Train Loss: 0.6659
2024-04-01 19:04:52,778 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:04:52,778 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:04:56,877 - config - INFO - Epoch [534/600], Train Loss: 0.6659
2024-04-01 19:04:57,061 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:04:57,062 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:05:01,165 - config - INFO - Epoch [535/600], Train Loss: 0.6659
2024-04-01 19:05:01,347 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:05:01,347 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:05:05,467 - config - INFO - Epoch [536/600], Train Loss: 0.6659
2024-04-01 19:05:05,649 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:05:05,649 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:05:09,883 - config - INFO - Epoch [537/600], Train Loss: 0.6659
2024-04-01 19:05:10,065 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:05:10,065 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:05:14,214 - config - INFO - Epoch [538/600], Train Loss: 0.6659
2024-04-01 19:05:14,398 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:05:14,399 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:05:18,505 - config - INFO - Epoch [539/600], Train Loss: 0.6659
2024-04-01 19:05:18,688 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:05:18,689 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:05:22,804 - config - INFO - Epoch [540/600], Train Loss: 0.6659
2024-04-01 19:05:22,986 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:05:22,987 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:05:27,131 - config - INFO - Epoch [541/600], Train Loss: 0.6659
2024-04-01 19:05:27,315 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:05:27,315 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:05:31,423 - config - INFO - Epoch [542/600], Train Loss: 0.6659
2024-04-01 19:05:31,607 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:05:31,607 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:05:35,711 - config - INFO - Epoch [543/600], Train Loss: 0.6659
2024-04-01 19:05:35,894 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:05:35,894 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:05:40,029 - config - INFO - Epoch [544/600], Train Loss: 0.6659
2024-04-01 19:05:40,211 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:05:40,212 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:05:44,359 - config - INFO - Epoch [545/600], Train Loss: 0.6659
2024-04-01 19:05:44,541 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:05:44,541 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:05:48,668 - config - INFO - Epoch [546/600], Train Loss: 0.6659
2024-04-01 19:05:48,856 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:05:48,856 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:05:52,957 - config - INFO - Epoch [547/600], Train Loss: 0.6659
2024-04-01 19:05:53,139 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:05:53,140 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:05:57,235 - config - INFO - Epoch [548/600], Train Loss: 0.6659
2024-04-01 19:05:57,417 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:05:57,418 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:06:01,558 - config - INFO - Epoch [549/600], Train Loss: 0.6659
2024-04-01 19:06:01,741 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:06:01,741 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:06:05,875 - config - INFO - Epoch [550/600], Train Loss: 0.6659
2024-04-01 19:06:06,058 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:06:06,058 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:06:10,169 - config - INFO - Epoch [551/600], Train Loss: 0.6659
2024-04-01 19:06:10,357 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:06:10,357 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:06:14,618 - config - INFO - Epoch [552/600], Train Loss: 0.6659
2024-04-01 19:06:14,800 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:06:14,800 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:06:18,928 - config - INFO - Epoch [553/600], Train Loss: 0.6659
2024-04-01 19:06:19,113 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:06:19,113 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:06:23,238 - config - INFO - Epoch [554/600], Train Loss: 0.6659
2024-04-01 19:06:23,420 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:06:23,421 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:06:27,541 - config - INFO - Epoch [555/600], Train Loss: 0.6659
2024-04-01 19:06:27,724 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:06:27,724 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:06:31,843 - config - INFO - Epoch [556/600], Train Loss: 0.6659
2024-04-01 19:06:32,025 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:06:32,026 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:06:36,176 - config - INFO - Epoch [557/600], Train Loss: 0.6659
2024-04-01 19:06:36,358 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:06:36,359 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:06:40,480 - config - INFO - Epoch [558/600], Train Loss: 0.6659
2024-04-01 19:06:40,662 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:06:40,663 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:06:44,781 - config - INFO - Epoch [559/600], Train Loss: 0.6659
2024-04-01 19:06:44,966 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:06:44,967 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:06:49,079 - config - INFO - Epoch [560/600], Train Loss: 0.6659
2024-04-01 19:06:49,269 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:06:49,269 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:06:53,409 - config - INFO - Epoch [561/600], Train Loss: 0.6659
2024-04-01 19:06:53,591 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:06:53,591 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:06:57,696 - config - INFO - Epoch [562/600], Train Loss: 0.6659
2024-04-01 19:06:57,879 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:06:57,880 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:07:02,005 - config - INFO - Epoch [563/600], Train Loss: 0.6659
2024-04-01 19:07:02,192 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:07:02,193 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:07:06,294 - config - INFO - Epoch [564/600], Train Loss: 0.6659
2024-04-01 19:07:06,476 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:07:06,476 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:07:10,602 - config - INFO - Epoch [565/600], Train Loss: 0.6659
2024-04-01 19:07:10,785 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:07:10,786 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:07:14,892 - config - INFO - Epoch [566/600], Train Loss: 0.6659
2024-04-01 19:07:15,074 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:07:15,074 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:07:19,329 - config - INFO - Epoch [567/600], Train Loss: 0.6659
2024-04-01 19:07:19,515 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:07:19,515 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:07:23,647 - config - INFO - Epoch [568/600], Train Loss: 0.6659
2024-04-01 19:07:23,829 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:07:23,830 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:07:27,985 - config - INFO - Epoch [569/600], Train Loss: 0.6659
2024-04-01 19:07:28,169 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:07:28,170 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:07:32,288 - config - INFO - Epoch [570/600], Train Loss: 0.6659
2024-04-01 19:07:32,475 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:07:32,475 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:07:36,602 - config - INFO - Epoch [571/600], Train Loss: 0.6659
2024-04-01 19:07:36,783 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:07:36,783 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:07:40,895 - config - INFO - Epoch [572/600], Train Loss: 0.6659
2024-04-01 19:07:41,078 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:07:41,079 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:07:45,226 - config - INFO - Epoch [573/600], Train Loss: 0.6659
2024-04-01 19:07:45,408 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:07:45,408 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:07:49,525 - config - INFO - Epoch [574/600], Train Loss: 0.6659
2024-04-01 19:07:49,707 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:07:49,707 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:07:53,819 - config - INFO - Epoch [575/600], Train Loss: 0.6659
2024-04-01 19:07:54,006 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:07:54,007 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:07:58,128 - config - INFO - Epoch [576/600], Train Loss: 0.6659
2024-04-01 19:07:58,318 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:07:58,318 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:08:02,440 - config - INFO - Epoch [577/600], Train Loss: 0.6659
2024-04-01 19:08:02,624 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:08:02,624 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:08:06,748 - config - INFO - Epoch [578/600], Train Loss: 0.6659
2024-04-01 19:08:06,930 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:08:06,930 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:08:11,047 - config - INFO - Epoch [579/600], Train Loss: 0.6659
2024-04-01 19:08:11,233 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:08:11,233 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:08:15,357 - config - INFO - Epoch [580/600], Train Loss: 0.6659
2024-04-01 19:08:15,539 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:08:15,540 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:08:19,675 - config - INFO - Epoch [581/600], Train Loss: 0.6659
2024-04-01 19:08:19,858 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:08:19,858 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:08:24,073 - config - INFO - Epoch [582/600], Train Loss: 0.6659
2024-04-01 19:08:24,255 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:08:24,255 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:08:28,379 - config - INFO - Epoch [583/600], Train Loss: 0.6659
2024-04-01 19:08:28,559 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:08:28,560 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:08:32,708 - config - INFO - Epoch [584/600], Train Loss: 0.6659
2024-04-01 19:08:32,889 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:08:32,890 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:08:37,015 - config - INFO - Epoch [585/600], Train Loss: 0.6659
2024-04-01 19:08:37,200 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:08:37,200 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:08:41,324 - config - INFO - Epoch [586/600], Train Loss: 0.6659
2024-04-01 19:08:41,508 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:08:41,509 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:08:45,633 - config - INFO - Epoch [587/600], Train Loss: 0.6659
2024-04-01 19:08:45,824 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:08:45,825 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:08:49,932 - config - INFO - Epoch [588/600], Train Loss: 0.6659
2024-04-01 19:08:50,120 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:08:50,121 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:08:54,231 - config - INFO - Epoch [589/600], Train Loss: 0.6659
2024-04-01 19:08:54,413 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:08:54,414 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:08:58,547 - config - INFO - Epoch [590/600], Train Loss: 0.6659
2024-04-01 19:08:58,730 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:08:58,730 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:09:02,861 - config - INFO - Epoch [591/600], Train Loss: 0.6659
2024-04-01 19:09:03,043 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:09:03,043 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:09:07,185 - config - INFO - Epoch [592/600], Train Loss: 0.6659
2024-04-01 19:09:07,373 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:09:07,373 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:09:11,496 - config - INFO - Epoch [593/600], Train Loss: 0.6659
2024-04-01 19:09:11,679 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:09:11,679 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:09:15,801 - config - INFO - Epoch [594/600], Train Loss: 0.6659
2024-04-01 19:09:15,984 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:09:15,984 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:09:20,136 - config - INFO - Epoch [595/600], Train Loss: 0.6659
2024-04-01 19:09:20,317 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:09:20,318 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:09:24,446 - config - INFO - Epoch [596/600], Train Loss: 0.6659
2024-04-01 19:09:24,635 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:09:24,635 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:09:28,857 - config - INFO - Epoch [597/600], Train Loss: 0.6659
2024-04-01 19:09:29,038 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:09:29,038 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:09:33,157 - config - INFO - Epoch [598/600], Train Loss: 0.6659
2024-04-01 19:09:33,339 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:09:33,340 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:09:37,453 - config - INFO - Epoch [599/600], Train Loss: 0.6659
2024-04-01 19:09:37,635 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:09:37,635 - config - INFO - Validation Acc: 0.6124
2024-04-01 19:09:41,741 - config - INFO - Epoch [600/600], Train Loss: 0.6659
2024-04-01 19:09:41,923 - config - INFO - Validation Loss: 0.6677
2024-04-01 19:09:41,923 - config - INFO - Validation Acc: 0.6124
