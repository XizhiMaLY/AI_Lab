2024-03-28 17:22:02,784 - config - INFO - resume: None
2024-03-28 17:22:02,784 - config - INFO - device: cpu
2024-03-28 17:22:02,784 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 17:22:02,784 - config - INFO - learning_rate: 0.001
2024-03-28 17:22:02,784 - config - INFO - num_epochs: 20
2024-03-28 17:22:02,784 - config - INFO - batch_size: 64
2024-03-28 17:22:02,784 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = None
        self.prev_val_loss = float('inf')

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 17:22:02,798 - config - INFO - Dataset size: 891
2024-03-28 17:22:19,604 - config - INFO - resume: None
2024-03-28 17:22:19,604 - config - INFO - device: cpu
2024-03-28 17:22:19,604 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 17:22:19,605 - config - INFO - learning_rate: 0.001
2024-03-28 17:22:19,605 - config - INFO - num_epochs: 20
2024-03-28 17:22:19,605 - config - INFO - batch_size: 64
2024-03-28 17:22:19,605 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = None
        self.prev_val_loss = float('inf')

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 17:22:19,618 - config - INFO - Dataset size: 891
2024-03-28 17:22:42,187 - config - INFO - resume: None
2024-03-28 17:22:42,187 - config - INFO - device: cpu
2024-03-28 17:22:42,187 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 17:22:42,188 - config - INFO - learning_rate: 0.001
2024-03-28 17:22:42,188 - config - INFO - num_epochs: 20
2024-03-28 17:22:42,188 - config - INFO - batch_size: 64
2024-03-28 17:22:42,188 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = None
        self.prev_val_loss = float('inf')

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 17:22:42,201 - config - INFO - Dataset size: 891
2024-03-28 17:22:42,227 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.6 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = val_loss
            return False


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.eval()
    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 17:22:42,227 - config - INFO - Training start
2024-03-28 17:22:44,499 - config - INFO - Epoch [1/20], Train Loss: 0.6956
2024-03-28 17:22:44,526 - config - INFO - Epoch [2/20], Train Loss: 0.6606
2024-03-28 17:22:44,552 - config - INFO - Epoch [3/20], Train Loss: 0.6263
2024-03-28 17:22:44,578 - config - INFO - Epoch [4/20], Train Loss: 0.5886
2024-03-28 17:22:44,603 - config - INFO - Epoch [5/20], Train Loss: 0.5506
2024-03-28 17:22:44,627 - config - INFO - Epoch [6/20], Train Loss: 0.5127
2024-03-28 17:22:44,652 - config - INFO - Epoch [7/20], Train Loss: 0.4774
2024-03-28 17:22:44,676 - config - INFO - Epoch [8/20], Train Loss: 0.4510
2024-03-28 17:22:44,701 - config - INFO - Epoch [9/20], Train Loss: 0.4336
2024-03-28 17:22:44,727 - config - INFO - Epoch [10/20], Train Loss: 0.4247
2024-03-28 17:22:44,752 - config - INFO - Epoch [11/20], Train Loss: 0.4167
2024-03-28 17:22:44,775 - config - INFO - Epoch [12/20], Train Loss: 0.4116
2024-03-28 17:22:44,799 - config - INFO - Epoch [13/20], Train Loss: 0.4079
2024-03-28 17:22:44,823 - config - INFO - Epoch [14/20], Train Loss: 0.4052
2024-03-28 17:22:44,846 - config - INFO - Epoch [15/20], Train Loss: 0.4017
2024-03-28 17:22:44,870 - config - INFO - Epoch [16/20], Train Loss: 0.3992
2024-03-28 17:22:44,893 - config - INFO - Epoch [17/20], Train Loss: 0.3971
2024-03-28 17:22:44,917 - config - INFO - Epoch [18/20], Train Loss: 0.3944
2024-03-28 17:22:44,955 - config - INFO - Epoch [19/20], Train Loss: 0.3920
2024-03-28 17:22:44,978 - config - INFO - Epoch [20/20], Train Loss: 0.3903
2024-03-28 17:22:44,983 - config - INFO - Validation Loss: 0.4661
2024-03-28 17:57:40,691 - config - INFO - resume: None
2024-03-28 17:57:40,691 - config - INFO - device: cpu
2024-03-28 17:57:40,691 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 17:57:40,691 - config - INFO - learning_rate: 0.001
2024-03-28 17:57:40,691 - config - INFO - num_epochs: 200
2024-03-28 17:57:40,691 - config - INFO - batch_size: 64
2024-03-28 17:57:40,691 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = None
        self.prev_val_loss = float('inf')
        self.tolerance = 0.1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 17:57:40,704 - config - INFO - Dataset size: 891
2024-03-28 17:57:40,731 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.6 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = val_loss
            return False


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()

    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 17:57:40,731 - config - INFO - Training start
2024-03-28 17:57:43,050 - config - INFO - Epoch [1/200], Train Loss: 0.6840
2024-03-28 17:57:43,055 - config - INFO - Validation Loss: 0.6573
2024-03-28 17:57:43,086 - config - INFO - Epoch [2/200], Train Loss: 0.6479
2024-03-28 17:57:43,091 - config - INFO - Validation Loss: 0.6269
2024-03-28 17:57:43,121 - config - INFO - Epoch [3/200], Train Loss: 0.6165
2024-03-28 17:57:43,127 - config - INFO - Validation Loss: 0.5963
2024-03-28 17:57:43,157 - config - INFO - Epoch [4/200], Train Loss: 0.5852
2024-03-28 17:57:43,162 - config - INFO - Validation Loss: 0.5642
2024-03-28 17:57:43,192 - config - INFO - Epoch [5/200], Train Loss: 0.5542
2024-03-28 17:57:43,197 - config - INFO - Validation Loss: 0.5278
2024-03-28 17:57:43,226 - config - INFO - Epoch [6/200], Train Loss: 0.5240
2024-03-28 17:57:43,232 - config - INFO - Validation Loss: 0.4927
2024-03-28 17:57:43,262 - config - INFO - Epoch [7/200], Train Loss: 0.4972
2024-03-28 17:57:43,268 - config - INFO - Validation Loss: 0.4644
2024-03-28 17:57:43,295 - config - INFO - Epoch [8/200], Train Loss: 0.4766
2024-03-28 17:57:43,300 - config - INFO - Validation Loss: 0.4368
2024-03-28 17:57:43,327 - config - INFO - Epoch [9/200], Train Loss: 0.4603
2024-03-28 17:57:43,332 - config - INFO - Validation Loss: 0.4204
2024-03-28 17:57:43,358 - config - INFO - Epoch [10/200], Train Loss: 0.4493
2024-03-28 17:57:43,363 - config - INFO - Validation Loss: 0.4089
2024-03-28 17:57:43,389 - config - INFO - Epoch [11/200], Train Loss: 0.4398
2024-03-28 17:57:43,394 - config - INFO - Validation Loss: 0.3998
2024-03-28 17:57:43,424 - config - INFO - Epoch [12/200], Train Loss: 0.4343
2024-03-28 17:57:43,429 - config - INFO - Validation Loss: 0.3917
2024-03-28 17:57:43,456 - config - INFO - Epoch [13/200], Train Loss: 0.4288
2024-03-28 17:57:43,461 - config - INFO - Validation Loss: 0.3841
2024-03-28 17:57:43,489 - config - INFO - Epoch [14/200], Train Loss: 0.4267
2024-03-28 17:57:43,494 - config - INFO - Validation Loss: 0.3811
2024-03-28 17:57:43,519 - config - INFO - Epoch [15/200], Train Loss: 0.4234
2024-03-28 17:57:43,524 - config - INFO - Validation Loss: 0.3907
2024-03-28 17:57:43,549 - config - INFO - Epoch [16/200], Train Loss: 0.4197
2024-03-28 17:57:43,554 - config - INFO - Validation Loss: 0.3860
2024-03-28 17:57:43,579 - config - INFO - Epoch [17/200], Train Loss: 0.4171
2024-03-28 17:57:43,584 - config - INFO - Validation Loss: 0.3850
2024-03-28 17:57:43,609 - config - INFO - Epoch [18/200], Train Loss: 0.4137
2024-03-28 17:57:43,614 - config - INFO - Validation Loss: 0.3848
2024-03-28 17:57:43,639 - config - INFO - Epoch [19/200], Train Loss: 0.4114
2024-03-28 17:57:43,644 - config - INFO - Validation Loss: 0.3863
2024-03-28 17:57:43,669 - config - INFO - Epoch [20/200], Train Loss: 0.4094
2024-03-28 17:57:43,674 - config - INFO - Validation Loss: 0.3841
2024-03-28 17:57:43,699 - config - INFO - Epoch [21/200], Train Loss: 0.4080
2024-03-28 17:57:43,704 - config - INFO - Validation Loss: 0.3857
2024-03-28 17:57:43,730 - config - INFO - Epoch [22/200], Train Loss: 0.4050
2024-03-28 17:57:43,735 - config - INFO - Validation Loss: 0.3839
2024-03-28 17:57:43,760 - config - INFO - Epoch [23/200], Train Loss: 0.4056
2024-03-28 17:57:43,765 - config - INFO - Validation Loss: 0.3794
2024-03-28 17:57:43,790 - config - INFO - Epoch [24/200], Train Loss: 0.4028
2024-03-28 17:57:43,795 - config - INFO - Validation Loss: 0.3889
2024-03-28 17:57:43,820 - config - INFO - Epoch [25/200], Train Loss: 0.4016
2024-03-28 17:57:43,825 - config - INFO - Validation Loss: 0.3848
2024-03-28 17:57:43,850 - config - INFO - Epoch [26/200], Train Loss: 0.4003
2024-03-28 17:57:43,856 - config - INFO - Validation Loss: 0.3858
2024-03-28 17:57:43,881 - config - INFO - Epoch [27/200], Train Loss: 0.3980
2024-03-28 17:57:43,886 - config - INFO - Validation Loss: 0.3810
2024-03-28 17:57:43,911 - config - INFO - Epoch [28/200], Train Loss: 0.3977
2024-03-28 17:57:43,916 - config - INFO - Validation Loss: 0.3780
2024-03-28 17:57:43,957 - config - INFO - Epoch [29/200], Train Loss: 0.3968
2024-03-28 17:57:43,962 - config - INFO - Validation Loss: 0.3800
2024-03-28 17:57:43,987 - config - INFO - Epoch [30/200], Train Loss: 0.3954
2024-03-28 17:57:43,992 - config - INFO - Validation Loss: 0.3784
2024-03-28 17:57:44,017 - config - INFO - Epoch [31/200], Train Loss: 0.3944
2024-03-28 17:57:44,022 - config - INFO - Validation Loss: 0.3814
2024-03-28 17:57:44,048 - config - INFO - Epoch [32/200], Train Loss: 0.3938
2024-03-28 17:57:44,053 - config - INFO - Validation Loss: 0.3831
2024-03-28 17:57:44,078 - config - INFO - Epoch [33/200], Train Loss: 0.3946
2024-03-28 17:57:44,083 - config - INFO - Validation Loss: 0.3835
2024-03-28 17:57:44,108 - config - INFO - Epoch [34/200], Train Loss: 0.3919
2024-03-28 17:57:44,113 - config - INFO - Validation Loss: 0.3881
2024-03-28 17:57:44,139 - config - INFO - Epoch [35/200], Train Loss: 0.3904
2024-03-28 17:57:44,144 - config - INFO - Validation Loss: 0.3859
2024-03-28 17:57:44,168 - config - INFO - Epoch [36/200], Train Loss: 0.3893
2024-03-28 17:57:44,173 - config - INFO - Validation Loss: 0.3850
2024-03-28 17:57:44,200 - config - INFO - Epoch [37/200], Train Loss: 0.3884
2024-03-28 17:57:44,205 - config - INFO - Validation Loss: 0.3837
2024-03-28 17:57:44,228 - config - INFO - Epoch [38/200], Train Loss: 0.3877
2024-03-28 17:57:44,232 - config - INFO - Validation Loss: 0.3864
2024-03-28 17:57:44,255 - config - INFO - Epoch [39/200], Train Loss: 0.3874
2024-03-28 17:57:44,259 - config - INFO - Validation Loss: 0.3897
2024-03-28 17:57:44,282 - config - INFO - Epoch [40/200], Train Loss: 0.3862
2024-03-28 17:57:44,286 - config - INFO - Validation Loss: 0.3857
2024-03-28 17:57:44,309 - config - INFO - Epoch [41/200], Train Loss: 0.3858
2024-03-28 17:57:44,314 - config - INFO - Validation Loss: 0.3842
2024-03-28 17:57:44,337 - config - INFO - Epoch [42/200], Train Loss: 0.3856
2024-03-28 17:57:44,341 - config - INFO - Validation Loss: 0.3889
2024-03-28 17:57:44,364 - config - INFO - Epoch [43/200], Train Loss: 0.3844
2024-03-28 17:57:44,369 - config - INFO - Validation Loss: 0.3865
2024-03-28 17:57:44,392 - config - INFO - Epoch [44/200], Train Loss: 0.3832
2024-03-28 17:57:44,396 - config - INFO - Validation Loss: 0.3874
2024-03-28 17:57:44,419 - config - INFO - Epoch [45/200], Train Loss: 0.3828
2024-03-28 17:57:44,423 - config - INFO - Validation Loss: 0.3888
2024-03-28 17:57:44,446 - config - INFO - Epoch [46/200], Train Loss: 0.3822
2024-03-28 17:57:44,452 - config - INFO - Validation Loss: 0.3894
2024-03-28 17:57:44,475 - config - INFO - Epoch [47/200], Train Loss: 0.3815
2024-03-28 17:57:44,479 - config - INFO - Validation Loss: 0.3873
2024-03-28 17:57:44,503 - config - INFO - Epoch [48/200], Train Loss: 0.3807
2024-03-28 17:57:44,507 - config - INFO - Validation Loss: 0.3888
2024-03-28 17:57:44,527 - config - INFO - Epoch [49/200], Train Loss: 0.3791
2024-03-28 17:57:44,531 - config - INFO - Validation Loss: 0.3945
2024-03-28 17:57:44,550 - config - INFO - Epoch [50/200], Train Loss: 0.3795
2024-03-28 17:57:44,554 - config - INFO - Validation Loss: 0.3945
2024-03-28 17:57:44,573 - config - INFO - Epoch [51/200], Train Loss: 0.3783
2024-03-28 17:57:44,577 - config - INFO - Validation Loss: 0.3928
2024-03-28 17:57:44,596 - config - INFO - Epoch [52/200], Train Loss: 0.3782
2024-03-28 17:57:44,600 - config - INFO - Validation Loss: 0.3941
2024-03-28 17:57:44,619 - config - INFO - Epoch [53/200], Train Loss: 0.3770
2024-03-28 17:57:44,623 - config - INFO - Validation Loss: 0.3934
2024-03-28 17:57:44,642 - config - INFO - Epoch [54/200], Train Loss: 0.3768
2024-03-28 17:57:44,646 - config - INFO - Validation Loss: 0.3960
2024-03-28 17:57:44,665 - config - INFO - Epoch [55/200], Train Loss: 0.3750
2024-03-28 17:57:44,669 - config - INFO - Validation Loss: 0.3940
2024-03-28 17:57:44,688 - config - INFO - Epoch [56/200], Train Loss: 0.3761
2024-03-28 17:57:44,692 - config - INFO - Validation Loss: 0.3975
2024-03-28 17:57:44,711 - config - INFO - Epoch [57/200], Train Loss: 0.3761
2024-03-28 17:57:44,715 - config - INFO - Validation Loss: 0.3977
2024-03-28 17:57:44,734 - config - INFO - Epoch [58/200], Train Loss: 0.3747
2024-03-28 17:57:44,738 - config - INFO - Validation Loss: 0.3947
2024-03-28 17:57:44,757 - config - INFO - Epoch [59/200], Train Loss: 0.3745
2024-03-28 17:57:44,761 - config - INFO - Validation Loss: 0.3993
2024-03-28 17:57:44,780 - config - INFO - Epoch [60/200], Train Loss: 0.3735
2024-03-28 17:57:44,784 - config - INFO - Validation Loss: 0.3956
2024-03-28 17:57:44,803 - config - INFO - Epoch [61/200], Train Loss: 0.3724
2024-03-28 17:57:44,807 - config - INFO - Validation Loss: 0.3985
2024-03-28 17:57:44,827 - config - INFO - Epoch [62/200], Train Loss: 0.3728
2024-03-28 17:57:44,832 - config - INFO - Validation Loss: 0.4015
2024-03-28 17:57:44,854 - config - INFO - Epoch [63/200], Train Loss: 0.3718
2024-03-28 17:57:44,859 - config - INFO - Validation Loss: 0.4033
2024-03-28 17:57:44,882 - config - INFO - Epoch [64/200], Train Loss: 0.3721
2024-03-28 17:57:44,886 - config - INFO - Validation Loss: 0.4077
2024-03-28 17:57:44,909 - config - INFO - Epoch [65/200], Train Loss: 0.3703
2024-03-28 17:57:44,913 - config - INFO - Validation Loss: 0.4005
2024-03-28 17:57:44,936 - config - INFO - Epoch [66/200], Train Loss: 0.3708
2024-03-28 17:57:44,940 - config - INFO - Validation Loss: 0.3996
2024-03-28 17:57:44,971 - config - INFO - Epoch [67/200], Train Loss: 0.3705
2024-03-28 17:57:44,976 - config - INFO - Validation Loss: 0.4023
2024-03-28 17:57:44,999 - config - INFO - Epoch [68/200], Train Loss: 0.3676
2024-03-28 17:57:45,003 - config - INFO - Validation Loss: 0.4038
2024-03-28 17:57:45,026 - config - INFO - Epoch [69/200], Train Loss: 0.3681
2024-03-28 17:57:45,030 - config - INFO - Validation Loss: 0.4092
2024-03-28 17:57:45,052 - config - INFO - Epoch [70/200], Train Loss: 0.3679
2024-03-28 17:57:45,057 - config - INFO - Validation Loss: 0.3997
2024-03-28 17:57:45,079 - config - INFO - Epoch [71/200], Train Loss: 0.3679
2024-03-28 17:57:45,084 - config - INFO - Validation Loss: 0.3978
2024-03-28 17:57:45,106 - config - INFO - Epoch [72/200], Train Loss: 0.3656
2024-03-28 17:57:45,111 - config - INFO - Validation Loss: 0.4000
2024-03-28 17:57:45,133 - config - INFO - Epoch [73/200], Train Loss: 0.3657
2024-03-28 17:57:45,138 - config - INFO - Validation Loss: 0.4015
2024-03-28 17:57:45,160 - config - INFO - Epoch [74/200], Train Loss: 0.3653
2024-03-28 17:57:45,165 - config - INFO - Validation Loss: 0.4015
2024-03-28 17:57:45,187 - config - INFO - Epoch [75/200], Train Loss: 0.3655
2024-03-28 17:57:45,191 - config - INFO - Validation Loss: 0.4015
2024-03-28 17:57:45,214 - config - INFO - Epoch [76/200], Train Loss: 0.3639
2024-03-28 17:57:45,218 - config - INFO - Validation Loss: 0.4047
2024-03-28 17:57:45,241 - config - INFO - Epoch [77/200], Train Loss: 0.3627
2024-03-28 17:57:45,245 - config - INFO - Validation Loss: 0.4077
2024-03-28 17:57:45,268 - config - INFO - Epoch [78/200], Train Loss: 0.3621
2024-03-28 17:57:45,272 - config - INFO - Validation Loss: 0.4086
2024-03-28 17:57:45,295 - config - INFO - Epoch [79/200], Train Loss: 0.3641
2024-03-28 17:57:45,299 - config - INFO - Validation Loss: 0.4095
2024-03-28 17:57:45,322 - config - INFO - Epoch [80/200], Train Loss: 0.3610
2024-03-28 17:57:45,326 - config - INFO - Validation Loss: 0.4040
2024-03-28 17:57:45,349 - config - INFO - Epoch [81/200], Train Loss: 0.3610
2024-03-28 17:57:45,353 - config - INFO - Validation Loss: 0.4087
2024-03-28 17:57:45,376 - config - INFO - Epoch [82/200], Train Loss: 0.3614
2024-03-28 17:57:45,380 - config - INFO - Validation Loss: 0.4071
2024-03-28 17:57:45,402 - config - INFO - Epoch [83/200], Train Loss: 0.3596
2024-03-28 17:57:45,407 - config - INFO - Validation Loss: 0.4065
2024-03-28 17:57:45,429 - config - INFO - Epoch [84/200], Train Loss: 0.3590
2024-03-28 17:57:45,434 - config - INFO - Validation Loss: 0.4058
2024-03-28 17:57:45,456 - config - INFO - Epoch [85/200], Train Loss: 0.3595
2024-03-28 17:57:45,475 - config - INFO - Validation Loss: 0.4160
2024-03-28 17:57:45,503 - config - INFO - Epoch [86/200], Train Loss: 0.3581
2024-03-28 17:57:45,508 - config - INFO - Validation Loss: 0.4133
2024-03-28 17:57:45,533 - config - INFO - Epoch [87/200], Train Loss: 0.3574
2024-03-28 17:57:45,538 - config - INFO - Validation Loss: 0.4113
2024-03-28 17:57:45,563 - config - INFO - Epoch [88/200], Train Loss: 0.3571
2024-03-28 17:57:45,568 - config - INFO - Validation Loss: 0.4140
2024-03-28 17:57:45,593 - config - INFO - Epoch [89/200], Train Loss: 0.3558
2024-03-28 17:57:45,598 - config - INFO - Validation Loss: 0.4104
2024-03-28 17:57:45,623 - config - INFO - Epoch [90/200], Train Loss: 0.3548
2024-03-28 17:57:45,628 - config - INFO - Validation Loss: 0.4125
2024-03-28 17:57:45,653 - config - INFO - Epoch [91/200], Train Loss: 0.3546
2024-03-28 17:57:45,658 - config - INFO - Validation Loss: 0.4176
2024-03-28 17:57:45,683 - config - INFO - Epoch [92/200], Train Loss: 0.3547
2024-03-28 17:57:45,688 - config - INFO - Validation Loss: 0.4148
2024-03-28 17:57:45,713 - config - INFO - Epoch [93/200], Train Loss: 0.3551
2024-03-28 17:57:45,718 - config - INFO - Validation Loss: 0.4135
2024-03-28 17:57:45,748 - config - INFO - Epoch [94/200], Train Loss: 0.3543
2024-03-28 17:57:45,753 - config - INFO - Validation Loss: 0.4138
2024-03-28 17:57:45,778 - config - INFO - Epoch [95/200], Train Loss: 0.3530
2024-03-28 17:57:45,783 - config - INFO - Validation Loss: 0.4177
2024-03-28 17:57:45,808 - config - INFO - Epoch [96/200], Train Loss: 0.3532
2024-03-28 17:57:45,813 - config - INFO - Validation Loss: 0.4219
2024-03-28 17:57:45,839 - config - INFO - Epoch [97/200], Train Loss: 0.3524
2024-03-28 17:57:45,844 - config - INFO - Validation Loss: 0.4175
2024-03-28 17:57:45,869 - config - INFO - Epoch [98/200], Train Loss: 0.3519
2024-03-28 17:57:45,874 - config - INFO - Validation Loss: 0.4177
2024-03-28 17:57:45,899 - config - INFO - Epoch [99/200], Train Loss: 0.3510
2024-03-28 17:57:45,904 - config - INFO - Validation Loss: 0.4224
2024-03-28 17:57:45,929 - config - INFO - Epoch [100/200], Train Loss: 0.3511
2024-03-28 17:57:45,934 - config - INFO - Validation Loss: 0.4195
2024-03-28 17:57:45,959 - config - INFO - Epoch [101/200], Train Loss: 0.3501
2024-03-28 17:57:45,964 - config - INFO - Validation Loss: 0.4190
2024-03-28 17:57:45,989 - config - INFO - Epoch [102/200], Train Loss: 0.3490
2024-03-28 17:57:45,994 - config - INFO - Validation Loss: 0.4196
2024-03-28 17:57:46,019 - config - INFO - Epoch [103/200], Train Loss: 0.3483
2024-03-28 17:57:46,024 - config - INFO - Validation Loss: 0.4202
2024-03-28 17:57:46,049 - config - INFO - Epoch [104/200], Train Loss: 0.3495
2024-03-28 17:57:46,054 - config - INFO - Validation Loss: 0.4182
2024-03-28 17:57:46,079 - config - INFO - Epoch [105/200], Train Loss: 0.3473
2024-03-28 17:57:46,084 - config - INFO - Validation Loss: 0.4253
2024-03-28 17:57:46,109 - config - INFO - Epoch [106/200], Train Loss: 0.3472
2024-03-28 17:57:46,114 - config - INFO - Validation Loss: 0.4261
2024-03-28 17:57:46,139 - config - INFO - Epoch [107/200], Train Loss: 0.3460
2024-03-28 17:57:46,144 - config - INFO - Validation Loss: 0.4250
2024-03-28 17:57:46,169 - config - INFO - Epoch [108/200], Train Loss: 0.3460
2024-03-28 17:57:46,174 - config - INFO - Validation Loss: 0.4260
2024-03-28 17:57:46,199 - config - INFO - Epoch [109/200], Train Loss: 0.3465
2024-03-28 17:57:46,204 - config - INFO - Validation Loss: 0.4260
2024-03-28 17:57:46,230 - config - INFO - Epoch [110/200], Train Loss: 0.3461
2024-03-28 17:57:46,234 - config - INFO - Validation Loss: 0.4260
2024-03-28 17:57:46,260 - config - INFO - Epoch [111/200], Train Loss: 0.3459
2024-03-28 17:57:46,265 - config - INFO - Validation Loss: 0.4241
2024-03-28 17:57:46,290 - config - INFO - Epoch [112/200], Train Loss: 0.3444
2024-03-28 17:57:46,295 - config - INFO - Validation Loss: 0.4276
2024-03-28 17:57:46,320 - config - INFO - Epoch [113/200], Train Loss: 0.3450
2024-03-28 17:57:46,325 - config - INFO - Validation Loss: 0.4228
2024-03-28 17:57:46,350 - config - INFO - Epoch [114/200], Train Loss: 0.3433
2024-03-28 17:57:46,355 - config - INFO - Validation Loss: 0.4257
2024-03-28 17:57:46,380 - config - INFO - Epoch [115/200], Train Loss: 0.3435
2024-03-28 17:57:46,385 - config - INFO - Validation Loss: 0.4317
2024-03-28 17:57:46,410 - config - INFO - Epoch [116/200], Train Loss: 0.3427
2024-03-28 17:57:46,415 - config - INFO - Validation Loss: 0.4281
2024-03-28 17:57:46,440 - config - INFO - Epoch [117/200], Train Loss: 0.3424
2024-03-28 17:57:46,445 - config - INFO - Validation Loss: 0.4275
2024-03-28 17:57:46,470 - config - INFO - Epoch [118/200], Train Loss: 0.3414
2024-03-28 17:57:46,475 - config - INFO - Validation Loss: 0.4313
2024-03-28 17:57:46,508 - config - INFO - Epoch [119/200], Train Loss: 0.3421
2024-03-28 17:57:46,513 - config - INFO - Validation Loss: 0.4317
2024-03-28 17:57:46,536 - config - INFO - Epoch [120/200], Train Loss: 0.3404
2024-03-28 17:57:46,541 - config - INFO - Validation Loss: 0.4362
2024-03-28 17:57:46,563 - config - INFO - Epoch [121/200], Train Loss: 0.3402
2024-03-28 17:57:46,567 - config - INFO - Validation Loss: 0.4363
2024-03-28 17:57:46,591 - config - INFO - Epoch [122/200], Train Loss: 0.3398
2024-03-28 17:57:46,601 - config - INFO - Validation Loss: 0.4347
2024-03-28 17:57:46,626 - config - INFO - Epoch [123/200], Train Loss: 0.3401
2024-03-28 17:57:46,630 - config - INFO - Validation Loss: 0.4336
2024-03-28 17:57:46,660 - config - INFO - Epoch [124/200], Train Loss: 0.3385
2024-03-28 17:57:46,665 - config - INFO - Validation Loss: 0.4382
2024-03-28 17:57:46,687 - config - INFO - Epoch [125/200], Train Loss: 0.3387
2024-03-28 17:57:46,691 - config - INFO - Validation Loss: 0.4410
2024-03-28 17:57:46,714 - config - INFO - Epoch [126/200], Train Loss: 0.3391
2024-03-28 17:57:46,718 - config - INFO - Validation Loss: 0.4399
2024-03-28 17:57:46,740 - config - INFO - Epoch [127/200], Train Loss: 0.3375
2024-03-28 17:57:46,744 - config - INFO - Validation Loss: 0.4413
2024-03-28 17:57:46,766 - config - INFO - Epoch [128/200], Train Loss: 0.3378
2024-03-28 17:57:46,771 - config - INFO - Validation Loss: 0.4366
2024-03-28 17:57:46,793 - config - INFO - Epoch [129/200], Train Loss: 0.3381
2024-03-28 17:57:46,797 - config - INFO - Validation Loss: 0.4391
2024-03-28 17:57:46,819 - config - INFO - Epoch [130/200], Train Loss: 0.3364
2024-03-28 17:57:46,824 - config - INFO - Validation Loss: 0.4427
2024-03-28 17:57:46,846 - config - INFO - Epoch [131/200], Train Loss: 0.3359
2024-03-28 17:57:46,850 - config - INFO - Validation Loss: 0.4511
2024-03-28 17:57:46,872 - config - INFO - Epoch [132/200], Train Loss: 0.3367
2024-03-28 17:57:46,876 - config - INFO - Validation Loss: 0.4487
2024-03-28 17:57:46,899 - config - INFO - Epoch [133/200], Train Loss: 0.3368
2024-03-28 17:57:46,903 - config - INFO - Validation Loss: 0.4391
2024-03-28 17:57:46,925 - config - INFO - Epoch [134/200], Train Loss: 0.3337
2024-03-28 17:57:46,929 - config - INFO - Validation Loss: 0.4419
2024-03-28 17:57:46,951 - config - INFO - Epoch [135/200], Train Loss: 0.3354
2024-03-28 17:57:46,956 - config - INFO - Validation Loss: 0.4376
2024-03-28 17:57:46,978 - config - INFO - Epoch [136/200], Train Loss: 0.3336
2024-03-28 17:57:46,982 - config - INFO - Validation Loss: 0.4467
2024-03-28 17:57:47,004 - config - INFO - Epoch [137/200], Train Loss: 0.3364
2024-03-28 17:57:47,008 - config - INFO - Validation Loss: 0.4569
2024-03-28 17:57:47,031 - config - INFO - Epoch [138/200], Train Loss: 0.3330
2024-03-28 17:57:47,035 - config - INFO - Validation Loss: 0.4485
2024-03-28 17:57:47,057 - config - INFO - Epoch [139/200], Train Loss: 0.3343
2024-03-28 17:57:47,061 - config - INFO - Validation Loss: 0.4430
2024-03-28 17:57:47,083 - config - INFO - Epoch [140/200], Train Loss: 0.3338
2024-03-28 17:57:47,088 - config - INFO - Validation Loss: 0.4478
2024-03-28 17:57:47,110 - config - INFO - Epoch [141/200], Train Loss: 0.3311
2024-03-28 17:57:47,114 - config - INFO - Validation Loss: 0.4495
2024-03-28 17:57:47,136 - config - INFO - Epoch [142/200], Train Loss: 0.3323
2024-03-28 17:57:47,140 - config - INFO - Validation Loss: 0.4484
2024-03-28 17:57:47,162 - config - INFO - Epoch [143/200], Train Loss: 0.3306
2024-03-28 17:57:47,167 - config - INFO - Validation Loss: 0.4469
2024-03-28 17:57:47,189 - config - INFO - Epoch [144/200], Train Loss: 0.3330
2024-03-28 17:57:47,193 - config - INFO - Validation Loss: 0.4454
2024-03-28 17:57:47,215 - config - INFO - Epoch [145/200], Train Loss: 0.3292
2024-03-28 17:57:47,219 - config - INFO - Validation Loss: 0.4502
2024-03-28 17:57:47,242 - config - INFO - Epoch [146/200], Train Loss: 0.3300
2024-03-28 17:57:47,246 - config - INFO - Validation Loss: 0.4529
2024-03-28 17:57:47,268 - config - INFO - Epoch [147/200], Train Loss: 0.3286
2024-03-28 17:57:47,272 - config - INFO - Validation Loss: 0.4508
2024-03-28 17:57:47,294 - config - INFO - Epoch [148/200], Train Loss: 0.3279
2024-03-28 17:57:47,299 - config - INFO - Validation Loss: 0.4538
2024-03-28 17:57:47,321 - config - INFO - Epoch [149/200], Train Loss: 0.3286
2024-03-28 17:57:47,325 - config - INFO - Validation Loss: 0.4585
2024-03-28 17:57:47,347 - config - INFO - Epoch [150/200], Train Loss: 0.3281
2024-03-28 17:57:47,351 - config - INFO - Validation Loss: 0.4519
2024-03-28 17:57:47,373 - config - INFO - Epoch [151/200], Train Loss: 0.3270
2024-03-28 17:57:47,378 - config - INFO - Validation Loss: 0.4491
2024-03-28 17:57:47,400 - config - INFO - Epoch [152/200], Train Loss: 0.3272
2024-03-28 17:57:47,404 - config - INFO - Validation Loss: 0.4483
2024-03-28 17:57:47,426 - config - INFO - Epoch [153/200], Train Loss: 0.3262
2024-03-28 17:57:47,430 - config - INFO - Validation Loss: 0.4546
2024-03-28 17:57:47,452 - config - INFO - Epoch [154/200], Train Loss: 0.3263
2024-03-28 17:57:47,456 - config - INFO - Validation Loss: 0.4545
2024-03-28 17:57:47,479 - config - INFO - Epoch [155/200], Train Loss: 0.3259
2024-03-28 17:57:47,486 - config - INFO - Validation Loss: 0.4552
2024-03-28 17:57:47,508 - config - INFO - Epoch [156/200], Train Loss: 0.3256
2024-03-28 17:57:47,512 - config - INFO - Validation Loss: 0.4572
2024-03-28 17:57:47,534 - config - INFO - Epoch [157/200], Train Loss: 0.3239
2024-03-28 17:57:47,539 - config - INFO - Validation Loss: 0.4607
2024-03-28 17:57:47,561 - config - INFO - Epoch [158/200], Train Loss: 0.3252
2024-03-28 17:57:47,565 - config - INFO - Validation Loss: 0.4571
2024-03-28 17:57:47,587 - config - INFO - Epoch [159/200], Train Loss: 0.3238
2024-03-28 17:57:47,591 - config - INFO - Validation Loss: 0.4559
2024-03-28 17:57:47,613 - config - INFO - Epoch [160/200], Train Loss: 0.3240
2024-03-28 17:57:47,618 - config - INFO - Validation Loss: 0.4640
2024-03-28 17:57:47,640 - config - INFO - Epoch [161/200], Train Loss: 0.3238
2024-03-28 17:57:47,644 - config - INFO - Validation Loss: 0.4612
2024-03-28 17:57:47,666 - config - INFO - Epoch [162/200], Train Loss: 0.3235
2024-03-28 17:57:47,671 - config - INFO - Validation Loss: 0.4557
2024-03-28 17:57:47,693 - config - INFO - Epoch [163/200], Train Loss: 0.3222
2024-03-28 17:57:47,697 - config - INFO - Validation Loss: 0.4572
2024-03-28 17:57:47,719 - config - INFO - Epoch [164/200], Train Loss: 0.3217
2024-03-28 17:57:47,723 - config - INFO - Validation Loss: 0.4647
2024-03-28 17:57:47,747 - config - INFO - Epoch [165/200], Train Loss: 0.3225
2024-03-28 17:57:47,751 - config - INFO - Validation Loss: 0.4617
2024-03-28 17:57:47,773 - config - INFO - Epoch [166/200], Train Loss: 0.3215
2024-03-28 17:57:47,777 - config - INFO - Validation Loss: 0.4633
2024-03-28 17:57:47,800 - config - INFO - Epoch [167/200], Train Loss: 0.3219
2024-03-28 17:57:47,804 - config - INFO - Validation Loss: 0.4714
2024-03-28 17:57:47,826 - config - INFO - Epoch [168/200], Train Loss: 0.3205
2024-03-28 17:57:47,830 - config - INFO - Validation Loss: 0.4596
2024-03-28 17:57:47,852 - config - INFO - Epoch [169/200], Train Loss: 0.3226
2024-03-28 17:57:47,856 - config - INFO - Validation Loss: 0.4578
2024-03-28 17:57:47,878 - config - INFO - Epoch [170/200], Train Loss: 0.3207
2024-03-28 17:57:47,883 - config - INFO - Validation Loss: 0.4680
2024-03-28 17:57:47,905 - config - INFO - Epoch [171/200], Train Loss: 0.3208
2024-03-28 17:57:47,909 - config - INFO - Validation Loss: 0.4685
2024-03-28 17:57:47,931 - config - INFO - Epoch [172/200], Train Loss: 0.3194
2024-03-28 17:57:47,935 - config - INFO - Validation Loss: 0.4609
2024-03-28 17:57:47,957 - config - INFO - Epoch [173/200], Train Loss: 0.3186
2024-03-28 17:57:47,962 - config - INFO - Validation Loss: 0.4601
2024-03-28 17:57:47,984 - config - INFO - Epoch [174/200], Train Loss: 0.3181
2024-03-28 17:57:47,988 - config - INFO - Validation Loss: 0.4650
2024-03-28 17:57:48,010 - config - INFO - Epoch [175/200], Train Loss: 0.3195
2024-03-28 17:57:48,014 - config - INFO - Validation Loss: 0.4762
2024-03-28 17:57:48,036 - config - INFO - Epoch [176/200], Train Loss: 0.3211
2024-03-28 17:57:48,041 - config - INFO - Validation Loss: 0.4707
2024-03-28 17:57:48,063 - config - INFO - Epoch [177/200], Train Loss: 0.3185
2024-03-28 17:57:48,067 - config - INFO - Validation Loss: 0.4708
2024-03-28 17:57:48,089 - config - INFO - Epoch [178/200], Train Loss: 0.3186
2024-03-28 17:57:48,093 - config - INFO - Validation Loss: 0.4741
2024-03-28 17:57:48,115 - config - INFO - Epoch [179/200], Train Loss: 0.3163
2024-03-28 17:57:48,120 - config - INFO - Validation Loss: 0.4715
2024-03-28 17:57:48,142 - config - INFO - Epoch [180/200], Train Loss: 0.3173
2024-03-28 17:57:48,146 - config - INFO - Validation Loss: 0.4681
2024-03-28 17:57:48,168 - config - INFO - Epoch [181/200], Train Loss: 0.3168
2024-03-28 17:57:48,172 - config - INFO - Validation Loss: 0.4730
2024-03-28 17:57:48,194 - config - INFO - Epoch [182/200], Train Loss: 0.3165
2024-03-28 17:57:48,199 - config - INFO - Validation Loss: 0.4755
2024-03-28 17:57:48,221 - config - INFO - Epoch [183/200], Train Loss: 0.3181
2024-03-28 17:57:48,225 - config - INFO - Validation Loss: 0.4717
2024-03-28 17:57:48,247 - config - INFO - Epoch [184/200], Train Loss: 0.3161
2024-03-28 17:57:48,251 - config - INFO - Validation Loss: 0.4783
2024-03-28 17:57:48,273 - config - INFO - Epoch [185/200], Train Loss: 0.3149
2024-03-28 17:57:48,278 - config - INFO - Validation Loss: 0.4810
2024-03-28 17:57:48,299 - config - INFO - Epoch [186/200], Train Loss: 0.3157
2024-03-28 17:57:48,304 - config - INFO - Validation Loss: 0.4794
2024-03-28 17:57:48,326 - config - INFO - Epoch [187/200], Train Loss: 0.3132
2024-03-28 17:57:48,330 - config - INFO - Validation Loss: 0.4792
2024-03-28 17:57:48,352 - config - INFO - Epoch [188/200], Train Loss: 0.3148
2024-03-28 17:57:48,356 - config - INFO - Validation Loss: 0.4792
2024-03-28 17:57:48,378 - config - INFO - Epoch [189/200], Train Loss: 0.3161
2024-03-28 17:57:48,383 - config - INFO - Validation Loss: 0.4739
2024-03-28 17:57:48,405 - config - INFO - Epoch [190/200], Train Loss: 0.3137
2024-03-28 17:57:48,409 - config - INFO - Validation Loss: 0.4854
2024-03-28 17:57:48,431 - config - INFO - Epoch [191/200], Train Loss: 0.3126
2024-03-28 17:57:48,435 - config - INFO - Validation Loss: 0.4825
2024-03-28 17:57:48,457 - config - INFO - Epoch [192/200], Train Loss: 0.3150
2024-03-28 17:57:48,461 - config - INFO - Validation Loss: 0.4797
2024-03-28 17:57:48,483 - config - INFO - Epoch [193/200], Train Loss: 0.3119
2024-03-28 17:57:48,496 - config - INFO - Validation Loss: 0.4803
2024-03-28 17:57:48,520 - config - INFO - Epoch [194/200], Train Loss: 0.3136
2024-03-28 17:57:48,524 - config - INFO - Validation Loss: 0.4766
2024-03-28 17:57:48,547 - config - INFO - Epoch [195/200], Train Loss: 0.3147
2024-03-28 17:57:48,551 - config - INFO - Validation Loss: 0.4863
2024-03-28 17:57:48,573 - config - INFO - Epoch [196/200], Train Loss: 0.3101
2024-03-28 17:57:48,578 - config - INFO - Validation Loss: 0.4791
2024-03-28 17:57:48,600 - config - INFO - Epoch [197/200], Train Loss: 0.3114
2024-03-28 17:57:48,604 - config - INFO - Validation Loss: 0.4820
2024-03-28 17:57:48,626 - config - INFO - Epoch [198/200], Train Loss: 0.3103
2024-03-28 17:57:48,631 - config - INFO - Validation Loss: 0.4869
2024-03-28 17:57:48,653 - config - INFO - Epoch [199/200], Train Loss: 0.3098
2024-03-28 17:57:48,657 - config - INFO - Validation Loss: 0.4789
2024-03-28 17:57:48,680 - config - INFO - Epoch [200/200], Train Loss: 0.3102
2024-03-28 17:57:48,684 - config - INFO - Validation Loss: 0.4853
2024-03-28 17:59:37,517 - config - INFO - resume: None
2024-03-28 17:59:37,517 - config - INFO - device: cpu
2024-03-28 17:59:37,517 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 17:59:37,517 - config - INFO - learning_rate: 0.001
2024-03-28 17:59:37,517 - config - INFO - num_epochs: 200
2024-03-28 17:59:37,517 - config - INFO - batch_size: 64
2024-03-28 17:59:37,517 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = None
        self.prev_val_loss = float('inf')
        self.tolerance = 0.1

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 17:59:37,530 - config - INFO - Dataset size: 891
2024-03-28 17:59:37,552 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.6 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()

    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 17:59:37,552 - config - INFO - Training start
2024-03-28 17:59:39,823 - config - INFO - Epoch [1/200], Train Loss: 0.6848
2024-03-28 17:59:39,831 - config - INFO - Validation Loss: 0.6636
2024-03-28 17:59:39,859 - config - INFO - Epoch [2/200], Train Loss: 0.6503
2024-03-28 17:59:39,865 - config - INFO - Validation Loss: 0.6296
2024-03-28 17:59:39,893 - config - INFO - Epoch [3/200], Train Loss: 0.6144
2024-03-28 17:59:39,898 - config - INFO - Validation Loss: 0.5908
2024-03-28 17:59:39,925 - config - INFO - Epoch [4/200], Train Loss: 0.5711
2024-03-28 17:59:39,930 - config - INFO - Validation Loss: 0.5502
2024-03-28 17:59:39,958 - config - INFO - Epoch [5/200], Train Loss: 0.5264
2024-03-28 17:59:39,963 - config - INFO - Validation Loss: 0.5125
2024-03-28 17:59:39,990 - config - INFO - Epoch [6/200], Train Loss: 0.4853
2024-03-28 17:59:39,995 - config - INFO - Validation Loss: 0.4825
2024-03-28 17:59:40,022 - config - INFO - Epoch [7/200], Train Loss: 0.4536
2024-03-28 17:59:40,027 - config - INFO - Validation Loss: 0.4621
2024-03-28 17:59:40,054 - config - INFO - Epoch [8/200], Train Loss: 0.4294
2024-03-28 17:59:40,058 - config - INFO - Validation Loss: 0.4533
2024-03-28 17:59:40,085 - config - INFO - Epoch [9/200], Train Loss: 0.4152
2024-03-28 17:59:40,089 - config - INFO - Validation Loss: 0.4476
2024-03-28 17:59:40,116 - config - INFO - Epoch [10/200], Train Loss: 0.4059
2024-03-28 17:59:40,121 - config - INFO - Validation Loss: 0.4454
2024-03-28 17:59:40,141 - config - INFO - Epoch [11/200], Train Loss: 0.3993
2024-03-28 17:59:40,145 - config - INFO - Validation Loss: 0.4438
2024-03-28 17:59:40,164 - config - INFO - Epoch [12/200], Train Loss: 0.3943
2024-03-28 17:59:40,167 - config - INFO - Validation Loss: 0.4444
2024-03-28 17:59:40,186 - config - INFO - Epoch [13/200], Train Loss: 0.3895
2024-03-28 17:59:40,190 - config - INFO - Validation Loss: 0.4446
2024-03-28 17:59:40,208 - config - INFO - Epoch [14/200], Train Loss: 0.3850
2024-03-28 17:59:40,212 - config - INFO - Validation Loss: 0.4418
2024-03-28 17:59:40,230 - config - INFO - Epoch [15/200], Train Loss: 0.3812
2024-03-28 17:59:40,234 - config - INFO - Validation Loss: 0.4415
2024-03-28 17:59:40,253 - config - INFO - Epoch [16/200], Train Loss: 0.3773
2024-03-28 17:59:40,256 - config - INFO - Validation Loss: 0.4420
2024-03-28 17:59:40,275 - config - INFO - Epoch [17/200], Train Loss: 0.3750
2024-03-28 17:59:40,278 - config - INFO - Validation Loss: 0.4433
2024-03-28 17:59:40,310 - config - INFO - Epoch [18/200], Train Loss: 0.3720
2024-03-28 17:59:40,314 - config - INFO - Validation Loss: 0.4410
2024-03-28 17:59:40,332 - config - INFO - Epoch [19/200], Train Loss: 0.3690
2024-03-28 17:59:40,336 - config - INFO - Validation Loss: 0.4416
2024-03-28 17:59:40,354 - config - INFO - Epoch [20/200], Train Loss: 0.3683
2024-03-28 17:59:40,358 - config - INFO - Validation Loss: 0.4431
2024-03-28 17:59:40,376 - config - INFO - Epoch [21/200], Train Loss: 0.3644
2024-03-28 17:59:40,380 - config - INFO - Validation Loss: 0.4404
2024-03-28 17:59:40,398 - config - INFO - Epoch [22/200], Train Loss: 0.3647
2024-03-28 17:59:40,402 - config - INFO - Validation Loss: 0.4397
2024-03-28 17:59:40,420 - config - INFO - Epoch [23/200], Train Loss: 0.3619
2024-03-28 17:59:40,424 - config - INFO - Validation Loss: 0.4414
2024-03-28 17:59:40,443 - config - INFO - Epoch [24/200], Train Loss: 0.3624
2024-03-28 17:59:40,446 - config - INFO - Validation Loss: 0.4425
2024-03-28 17:59:40,465 - config - INFO - Epoch [25/200], Train Loss: 0.3607
2024-03-28 17:59:40,468 - config - INFO - Validation Loss: 0.4410
2024-03-28 17:59:40,487 - config - INFO - Epoch [26/200], Train Loss: 0.3587
2024-03-28 17:59:40,494 - config - INFO - Validation Loss: 0.4397
2024-03-28 17:59:40,517 - config - INFO - Epoch [27/200], Train Loss: 0.3563
2024-03-28 17:59:40,520 - config - INFO - Validation Loss: 0.4413
2024-03-28 17:59:40,539 - config - INFO - Epoch [28/200], Train Loss: 0.3551
2024-03-28 17:59:40,543 - config - INFO - Validation Loss: 0.4428
2024-03-28 17:59:40,561 - config - INFO - Epoch [29/200], Train Loss: 0.3538
2024-03-28 17:59:40,565 - config - INFO - Validation Loss: 0.4419
2024-03-28 17:59:40,583 - config - INFO - Epoch [30/200], Train Loss: 0.3538
2024-03-28 17:59:40,587 - config - INFO - Validation Loss: 0.4441
2024-03-28 17:59:40,606 - config - INFO - Epoch [31/200], Train Loss: 0.3515
2024-03-28 17:59:40,609 - config - INFO - Validation Loss: 0.4428
2024-03-28 17:59:40,628 - config - INFO - Epoch [32/200], Train Loss: 0.3504
2024-03-28 17:59:40,631 - config - INFO - Validation Loss: 0.4409
2024-03-28 17:59:40,650 - config - INFO - Epoch [33/200], Train Loss: 0.3494
2024-03-28 17:59:40,654 - config - INFO - Validation Loss: 0.4414
2024-03-28 17:59:40,672 - config - INFO - Epoch [34/200], Train Loss: 0.3480
2024-03-28 17:59:40,676 - config - INFO - Validation Loss: 0.4432
2024-03-28 17:59:40,694 - config - INFO - Epoch [35/200], Train Loss: 0.3471
2024-03-28 17:59:40,698 - config - INFO - Validation Loss: 0.4446
2024-03-28 17:59:40,717 - config - INFO - Epoch [36/200], Train Loss: 0.3461
2024-03-28 17:59:40,720 - config - INFO - Validation Loss: 0.4470
2024-03-28 17:59:40,739 - config - INFO - Epoch [37/200], Train Loss: 0.3453
2024-03-28 17:59:40,742 - config - INFO - Validation Loss: 0.4483
2024-03-28 17:59:40,761 - config - INFO - Epoch [38/200], Train Loss: 0.3445
2024-03-28 17:59:40,764 - config - INFO - Validation Loss: 0.4491
2024-03-28 17:59:40,783 - config - INFO - Epoch [39/200], Train Loss: 0.3441
2024-03-28 17:59:40,788 - config - INFO - Validation Loss: 0.4493
2024-03-28 17:59:40,806 - config - INFO - Epoch [40/200], Train Loss: 0.3430
2024-03-28 17:59:40,810 - config - INFO - Validation Loss: 0.4502
2024-03-28 17:59:40,828 - config - INFO - Epoch [41/200], Train Loss: 0.3414
2024-03-28 17:59:40,832 - config - INFO - Validation Loss: 0.4509
2024-03-28 17:59:40,851 - config - INFO - Epoch [42/200], Train Loss: 0.3412
2024-03-28 17:59:40,854 - config - INFO - Validation Loss: 0.4484
2024-03-28 17:59:40,873 - config - INFO - Epoch [43/200], Train Loss: 0.3405
2024-03-28 17:59:40,876 - config - INFO - Validation Loss: 0.4491
2024-03-28 17:59:40,895 - config - INFO - Epoch [44/200], Train Loss: 0.3396
2024-03-28 17:59:40,898 - config - INFO - Validation Loss: 0.4494
2024-03-28 17:59:40,917 - config - INFO - Epoch [45/200], Train Loss: 0.3391
2024-03-28 17:59:40,921 - config - INFO - Validation Loss: 0.4491
2024-03-28 17:59:40,939 - config - INFO - Epoch [46/200], Train Loss: 0.3374
2024-03-28 17:59:40,943 - config - INFO - Validation Loss: 0.4532
2024-03-28 17:59:40,961 - config - INFO - Epoch [47/200], Train Loss: 0.3378
2024-03-28 17:59:40,965 - config - INFO - Validation Loss: 0.4521
2024-03-28 17:59:40,984 - config - INFO - Epoch [48/200], Train Loss: 0.3366
2024-03-28 17:59:40,987 - config - INFO - Validation Loss: 0.4527
2024-03-28 17:59:41,006 - config - INFO - Epoch [49/200], Train Loss: 0.3357
2024-03-28 17:59:41,009 - config - INFO - Validation Loss: 0.4521
2024-03-28 17:59:41,028 - config - INFO - Epoch [50/200], Train Loss: 0.3352
2024-03-28 17:59:41,032 - config - INFO - Validation Loss: 0.4500
2024-03-28 17:59:41,050 - config - INFO - Epoch [51/200], Train Loss: 0.3341
2024-03-28 17:59:41,054 - config - INFO - Validation Loss: 0.4513
2024-03-28 17:59:41,072 - config - INFO - Epoch [52/200], Train Loss: 0.3331
2024-03-28 17:59:41,076 - config - INFO - Validation Loss: 0.4526
2024-03-28 17:59:41,094 - config - INFO - Epoch [53/200], Train Loss: 0.3325
2024-03-28 17:59:41,098 - config - INFO - Validation Loss: 0.4535
2024-03-28 17:59:41,116 - config - INFO - Epoch [54/200], Train Loss: 0.3324
2024-03-28 17:59:41,120 - config - INFO - Validation Loss: 0.4541
2024-03-28 17:59:41,139 - config - INFO - Epoch [55/200], Train Loss: 0.3310
2024-03-28 17:59:41,142 - config - INFO - Validation Loss: 0.4519
2024-03-28 17:59:41,161 - config - INFO - Epoch [56/200], Train Loss: 0.3306
2024-03-28 17:59:41,164 - config - INFO - Validation Loss: 0.4560
2024-03-28 17:59:41,183 - config - INFO - Epoch [57/200], Train Loss: 0.3301
2024-03-28 17:59:41,186 - config - INFO - Validation Loss: 0.4563
2024-03-28 17:59:41,205 - config - INFO - Epoch [58/200], Train Loss: 0.3291
2024-03-28 17:59:41,209 - config - INFO - Validation Loss: 0.4542
2024-03-28 17:59:41,227 - config - INFO - Epoch [59/200], Train Loss: 0.3285
2024-03-28 17:59:41,231 - config - INFO - Validation Loss: 0.4566
2024-03-28 17:59:41,249 - config - INFO - Epoch [60/200], Train Loss: 0.3271
2024-03-28 17:59:41,253 - config - INFO - Validation Loss: 0.4555
2024-03-28 17:59:41,273 - config - INFO - Epoch [61/200], Train Loss: 0.3257
2024-03-28 17:59:41,278 - config - INFO - Validation Loss: 0.4561
2024-03-28 17:59:41,305 - config - INFO - Epoch [62/200], Train Loss: 0.3256
2024-03-28 17:59:41,309 - config - INFO - Validation Loss: 0.4564
2024-03-28 17:59:41,329 - config - INFO - Epoch [63/200], Train Loss: 0.3242
2024-03-28 17:59:41,333 - config - INFO - Validation Loss: 0.4575
2024-03-28 17:59:41,355 - config - INFO - Epoch [64/200], Train Loss: 0.3239
2024-03-28 17:59:41,359 - config - INFO - Validation Loss: 0.4597
2024-03-28 17:59:41,381 - config - INFO - Epoch [65/200], Train Loss: 0.3237
2024-03-28 17:59:41,385 - config - INFO - Validation Loss: 0.4606
2024-03-28 17:59:41,407 - config - INFO - Epoch [66/200], Train Loss: 0.3215
2024-03-28 17:59:41,411 - config - INFO - Validation Loss: 0.4614
2024-03-28 17:59:41,432 - config - INFO - Epoch [67/200], Train Loss: 0.3221
2024-03-28 17:59:41,437 - config - INFO - Validation Loss: 0.4611
2024-03-28 17:59:41,459 - config - INFO - Epoch [68/200], Train Loss: 0.3208
2024-03-28 17:59:41,463 - config - INFO - Validation Loss: 0.4623
2024-03-28 17:59:41,484 - config - INFO - Epoch [69/200], Train Loss: 0.3202
2024-03-28 17:59:41,489 - config - INFO - Validation Loss: 0.4633
2024-03-28 17:59:41,510 - config - INFO - Epoch [70/200], Train Loss: 0.3204
2024-03-28 17:59:41,515 - config - INFO - Validation Loss: 0.4654
2024-03-28 17:59:41,536 - config - INFO - Epoch [71/200], Train Loss: 0.3188
2024-03-28 17:59:41,540 - config - INFO - Validation Loss: 0.4647
2024-03-28 17:59:41,562 - config - INFO - Epoch [72/200], Train Loss: 0.3193
2024-03-28 17:59:41,566 - config - INFO - Validation Loss: 0.4657
2024-03-28 17:59:41,587 - config - INFO - Epoch [73/200], Train Loss: 0.3193
2024-03-28 17:59:41,591 - config - INFO - Validation Loss: 0.4647
2024-03-28 17:59:41,613 - config - INFO - Epoch [74/200], Train Loss: 0.3161
2024-03-28 17:59:41,617 - config - INFO - Validation Loss: 0.4665
2024-03-28 17:59:41,638 - config - INFO - Epoch [75/200], Train Loss: 0.3157
2024-03-28 17:59:41,643 - config - INFO - Validation Loss: 0.4685
2024-03-28 17:59:41,664 - config - INFO - Epoch [76/200], Train Loss: 0.3157
2024-03-28 17:59:41,668 - config - INFO - Validation Loss: 0.4693
2024-03-28 17:59:41,690 - config - INFO - Epoch [77/200], Train Loss: 0.3149
2024-03-28 17:59:41,694 - config - INFO - Validation Loss: 0.4730
2024-03-28 17:59:41,715 - config - INFO - Epoch [78/200], Train Loss: 0.3148
2024-03-28 17:59:41,719 - config - INFO - Validation Loss: 0.4691
2024-03-28 17:59:41,741 - config - INFO - Epoch [79/200], Train Loss: 0.3126
2024-03-28 17:59:41,745 - config - INFO - Validation Loss: 0.4718
2024-03-28 17:59:41,766 - config - INFO - Epoch [80/200], Train Loss: 0.3132
2024-03-28 17:59:41,771 - config - INFO - Validation Loss: 0.4720
2024-03-28 17:59:41,808 - config - INFO - Epoch [81/200], Train Loss: 0.3106
2024-03-28 17:59:41,813 - config - INFO - Validation Loss: 0.4707
2024-03-28 17:59:41,834 - config - INFO - Epoch [82/200], Train Loss: 0.3111
2024-03-28 17:59:41,839 - config - INFO - Validation Loss: 0.4720
2024-03-28 17:59:41,860 - config - INFO - Epoch [83/200], Train Loss: 0.3115
2024-03-28 17:59:41,865 - config - INFO - Validation Loss: 0.4703
2024-03-28 17:59:41,886 - config - INFO - Epoch [84/200], Train Loss: 0.3114
2024-03-28 17:59:41,890 - config - INFO - Validation Loss: 0.4731
2024-03-28 17:59:41,912 - config - INFO - Epoch [85/200], Train Loss: 0.3090
2024-03-28 17:59:41,916 - config - INFO - Validation Loss: 0.4693
2024-03-28 17:59:41,938 - config - INFO - Epoch [86/200], Train Loss: 0.3083
2024-03-28 17:59:41,942 - config - INFO - Validation Loss: 0.4711
2024-03-28 17:59:41,964 - config - INFO - Epoch [87/200], Train Loss: 0.3069
2024-03-28 17:59:41,968 - config - INFO - Validation Loss: 0.4725
2024-03-28 17:59:41,989 - config - INFO - Epoch [88/200], Train Loss: 0.3066
2024-03-28 17:59:41,993 - config - INFO - Validation Loss: 0.4728
2024-03-28 17:59:42,014 - config - INFO - Epoch [89/200], Train Loss: 0.3080
2024-03-28 17:59:42,018 - config - INFO - Validation Loss: 0.4705
2024-03-28 17:59:42,040 - config - INFO - Epoch [90/200], Train Loss: 0.3077
2024-03-28 17:59:42,044 - config - INFO - Validation Loss: 0.4750
2024-03-28 17:59:42,065 - config - INFO - Epoch [91/200], Train Loss: 0.3047
2024-03-28 17:59:42,069 - config - INFO - Validation Loss: 0.4719
2024-03-28 17:59:42,091 - config - INFO - Epoch [92/200], Train Loss: 0.3034
2024-03-28 17:59:42,095 - config - INFO - Validation Loss: 0.4746
2024-03-28 17:59:42,116 - config - INFO - Epoch [93/200], Train Loss: 0.3040
2024-03-28 17:59:42,120 - config - INFO - Validation Loss: 0.4791
2024-03-28 17:59:42,142 - config - INFO - Epoch [94/200], Train Loss: 0.3033
2024-03-28 17:59:42,146 - config - INFO - Validation Loss: 0.4755
2024-03-28 17:59:42,167 - config - INFO - Epoch [95/200], Train Loss: 0.3023
2024-03-28 17:59:42,171 - config - INFO - Validation Loss: 0.4789
2024-03-28 17:59:42,193 - config - INFO - Epoch [96/200], Train Loss: 0.3023
2024-03-28 17:59:42,197 - config - INFO - Validation Loss: 0.4805
2024-03-28 17:59:42,218 - config - INFO - Epoch [97/200], Train Loss: 0.3023
2024-03-28 17:59:42,222 - config - INFO - Validation Loss: 0.4809
2024-03-28 17:59:42,244 - config - INFO - Epoch [98/200], Train Loss: 0.3006
2024-03-28 17:59:42,248 - config - INFO - Validation Loss: 0.4792
2024-03-28 17:59:42,269 - config - INFO - Epoch [99/200], Train Loss: 0.3018
2024-03-28 17:59:42,273 - config - INFO - Validation Loss: 0.4805
2024-03-28 17:59:42,294 - config - INFO - Epoch [100/200], Train Loss: 0.3003
2024-03-28 17:59:42,299 - config - INFO - Validation Loss: 0.4873
2024-03-28 17:59:42,320 - config - INFO - Epoch [101/200], Train Loss: 0.3011
2024-03-28 17:59:42,324 - config - INFO - Validation Loss: 0.4835
2024-03-28 17:59:42,346 - config - INFO - Epoch [102/200], Train Loss: 0.2989
2024-03-28 17:59:42,350 - config - INFO - Validation Loss: 0.4799
2024-03-28 17:59:42,372 - config - INFO - Epoch [103/200], Train Loss: 0.2979
2024-03-28 17:59:42,376 - config - INFO - Validation Loss: 0.4810
2024-03-28 17:59:42,398 - config - INFO - Epoch [104/200], Train Loss: 0.2971
2024-03-28 17:59:42,402 - config - INFO - Validation Loss: 0.4796
2024-03-28 17:59:42,423 - config - INFO - Epoch [105/200], Train Loss: 0.2974
2024-03-28 17:59:42,427 - config - INFO - Validation Loss: 0.4851
2024-03-28 17:59:42,449 - config - INFO - Epoch [106/200], Train Loss: 0.2963
2024-03-28 17:59:42,453 - config - INFO - Validation Loss: 0.4868
2024-03-28 17:59:42,474 - config - INFO - Epoch [107/200], Train Loss: 0.2957
2024-03-28 17:59:42,478 - config - INFO - Validation Loss: 0.4864
2024-03-28 17:59:42,499 - config - INFO - Epoch [108/200], Train Loss: 0.2958
2024-03-28 17:59:42,504 - config - INFO - Validation Loss: 0.4840
2024-03-28 17:59:42,525 - config - INFO - Epoch [109/200], Train Loss: 0.2949
2024-03-28 17:59:42,529 - config - INFO - Validation Loss: 0.4850
2024-03-28 17:59:42,550 - config - INFO - Epoch [110/200], Train Loss: 0.2968
2024-03-28 17:59:42,555 - config - INFO - Validation Loss: 0.4908
2024-03-28 17:59:42,576 - config - INFO - Epoch [111/200], Train Loss: 0.2930
2024-03-28 17:59:42,580 - config - INFO - Validation Loss: 0.4915
2024-03-28 17:59:42,602 - config - INFO - Epoch [112/200], Train Loss: 0.2950
2024-03-28 17:59:42,606 - config - INFO - Validation Loss: 0.4977
2024-03-28 17:59:42,627 - config - INFO - Epoch [113/200], Train Loss: 0.2943
2024-03-28 17:59:42,631 - config - INFO - Validation Loss: 0.4925
2024-03-28 17:59:42,653 - config - INFO - Epoch [114/200], Train Loss: 0.2921
2024-03-28 17:59:42,657 - config - INFO - Validation Loss: 0.4953
2024-03-28 17:59:42,678 - config - INFO - Epoch [115/200], Train Loss: 0.2926
2024-03-28 17:59:42,683 - config - INFO - Validation Loss: 0.4916
2024-03-28 17:59:42,704 - config - INFO - Epoch [116/200], Train Loss: 0.2915
2024-03-28 17:59:42,708 - config - INFO - Validation Loss: 0.4922
2024-03-28 17:59:42,729 - config - INFO - Epoch [117/200], Train Loss: 0.2911
2024-03-28 17:59:42,733 - config - INFO - Validation Loss: 0.4948
2024-03-28 17:59:42,755 - config - INFO - Epoch [118/200], Train Loss: 0.2900
2024-03-28 17:59:42,759 - config - INFO - Validation Loss: 0.4925
2024-03-28 17:59:42,780 - config - INFO - Epoch [119/200], Train Loss: 0.2896
2024-03-28 17:59:42,784 - config - INFO - Validation Loss: 0.4924
2024-03-28 17:59:42,805 - config - INFO - Epoch [120/200], Train Loss: 0.2886
2024-03-28 17:59:42,812 - config - INFO - Validation Loss: 0.4979
2024-03-28 17:59:42,835 - config - INFO - Epoch [121/200], Train Loss: 0.2911
2024-03-28 17:59:42,839 - config - INFO - Validation Loss: 0.5030
2024-03-28 17:59:42,861 - config - INFO - Epoch [122/200], Train Loss: 0.2885
2024-03-28 17:59:42,866 - config - INFO - Validation Loss: 0.4999
2024-03-28 17:59:42,887 - config - INFO - Epoch [123/200], Train Loss: 0.2887
2024-03-28 17:59:42,892 - config - INFO - Validation Loss: 0.4995
2024-03-28 17:59:42,913 - config - INFO - Epoch [124/200], Train Loss: 0.2875
2024-03-28 17:59:42,917 - config - INFO - Validation Loss: 0.4967
2024-03-28 17:59:42,939 - config - INFO - Epoch [125/200], Train Loss: 0.2870
2024-03-28 17:59:42,943 - config - INFO - Validation Loss: 0.4994
2024-03-28 17:59:42,964 - config - INFO - Epoch [126/200], Train Loss: 0.2864
2024-03-28 17:59:42,969 - config - INFO - Validation Loss: 0.4982
2024-03-28 17:59:42,990 - config - INFO - Epoch [127/200], Train Loss: 0.2862
2024-03-28 17:59:42,994 - config - INFO - Validation Loss: 0.5016
2024-03-28 17:59:43,016 - config - INFO - Epoch [128/200], Train Loss: 0.2865
2024-03-28 17:59:43,020 - config - INFO - Validation Loss: 0.5054
2024-03-28 17:59:43,041 - config - INFO - Epoch [129/200], Train Loss: 0.2862
2024-03-28 17:59:43,045 - config - INFO - Validation Loss: 0.5020
2024-03-28 17:59:43,067 - config - INFO - Epoch [130/200], Train Loss: 0.2864
2024-03-28 17:59:43,071 - config - INFO - Validation Loss: 0.5008
2024-03-28 17:59:43,092 - config - INFO - Epoch [131/200], Train Loss: 0.2839
2024-03-28 17:59:43,096 - config - INFO - Validation Loss: 0.5048
2024-03-28 17:59:43,118 - config - INFO - Epoch [132/200], Train Loss: 0.2848
2024-03-28 17:59:43,122 - config - INFO - Validation Loss: 0.5063
2024-03-28 17:59:43,143 - config - INFO - Epoch [133/200], Train Loss: 0.2819
2024-03-28 17:59:43,147 - config - INFO - Validation Loss: 0.5075
2024-03-28 17:59:43,169 - config - INFO - Epoch [134/200], Train Loss: 0.2830
2024-03-28 17:59:43,173 - config - INFO - Validation Loss: 0.5064
2024-03-28 17:59:43,195 - config - INFO - Epoch [135/200], Train Loss: 0.2845
2024-03-28 17:59:43,199 - config - INFO - Validation Loss: 0.5098
2024-03-28 17:59:43,220 - config - INFO - Epoch [136/200], Train Loss: 0.2804
2024-03-28 17:59:43,224 - config - INFO - Validation Loss: 0.5090
2024-03-28 17:59:43,246 - config - INFO - Epoch [137/200], Train Loss: 0.2832
2024-03-28 17:59:43,250 - config - INFO - Validation Loss: 0.5079
2024-03-28 17:59:43,271 - config - INFO - Epoch [138/200], Train Loss: 0.2806
2024-03-28 17:59:43,275 - config - INFO - Validation Loss: 0.5121
2024-03-28 17:59:43,297 - config - INFO - Epoch [139/200], Train Loss: 0.2818
2024-03-28 17:59:43,301 - config - INFO - Validation Loss: 0.5142
2024-03-28 17:59:43,323 - config - INFO - Epoch [140/200], Train Loss: 0.2833
2024-03-28 17:59:43,327 - config - INFO - Validation Loss: 0.5113
2024-03-28 17:59:43,348 - config - INFO - Epoch [141/200], Train Loss: 0.2802
2024-03-28 17:59:43,353 - config - INFO - Validation Loss: 0.5080
2024-03-28 17:59:43,374 - config - INFO - Epoch [142/200], Train Loss: 0.2790
2024-03-28 17:59:43,378 - config - INFO - Validation Loss: 0.5086
2024-03-28 17:59:43,399 - config - INFO - Epoch [143/200], Train Loss: 0.2795
2024-03-28 17:59:43,403 - config - INFO - Validation Loss: 0.5126
2024-03-28 17:59:43,425 - config - INFO - Epoch [144/200], Train Loss: 0.2785
2024-03-28 17:59:43,429 - config - INFO - Validation Loss: 0.5146
2024-03-28 17:59:43,451 - config - INFO - Epoch [145/200], Train Loss: 0.2830
2024-03-28 17:59:43,455 - config - INFO - Validation Loss: 0.5051
2024-03-28 17:59:43,476 - config - INFO - Epoch [146/200], Train Loss: 0.2866
2024-03-28 17:59:43,481 - config - INFO - Validation Loss: 0.5078
2024-03-28 17:59:43,502 - config - INFO - Epoch [147/200], Train Loss: 0.2761
2024-03-28 17:59:43,506 - config - INFO - Validation Loss: 0.5176
2024-03-28 17:59:43,528 - config - INFO - Epoch [148/200], Train Loss: 0.2776
2024-03-28 17:59:43,532 - config - INFO - Validation Loss: 0.5161
2024-03-28 17:59:43,553 - config - INFO - Epoch [149/200], Train Loss: 0.2772
2024-03-28 17:59:43,558 - config - INFO - Validation Loss: 0.5165
2024-03-28 17:59:43,579 - config - INFO - Epoch [150/200], Train Loss: 0.2786
2024-03-28 17:59:43,583 - config - INFO - Validation Loss: 0.5206
2024-03-28 17:59:43,604 - config - INFO - Epoch [151/200], Train Loss: 0.2773
2024-03-28 17:59:43,609 - config - INFO - Validation Loss: 0.5165
2024-03-28 17:59:43,630 - config - INFO - Epoch [152/200], Train Loss: 0.2766
2024-03-28 17:59:43,634 - config - INFO - Validation Loss: 0.5149
2024-03-28 17:59:43,656 - config - INFO - Epoch [153/200], Train Loss: 0.2747
2024-03-28 17:59:43,660 - config - INFO - Validation Loss: 0.5137
2024-03-28 17:59:43,681 - config - INFO - Epoch [154/200], Train Loss: 0.2742
2024-03-28 17:59:43,685 - config - INFO - Validation Loss: 0.5189
2024-03-28 17:59:43,707 - config - INFO - Epoch [155/200], Train Loss: 0.2762
2024-03-28 17:59:43,711 - config - INFO - Validation Loss: 0.5276
2024-03-28 17:59:43,734 - config - INFO - Epoch [156/200], Train Loss: 0.2747
2024-03-28 17:59:43,738 - config - INFO - Validation Loss: 0.5278
2024-03-28 17:59:43,759 - config - INFO - Epoch [157/200], Train Loss: 0.2732
2024-03-28 17:59:43,763 - config - INFO - Validation Loss: 0.5257
2024-03-28 17:59:43,784 - config - INFO - Epoch [158/200], Train Loss: 0.2730
2024-03-28 17:59:43,789 - config - INFO - Validation Loss: 0.5260
2024-03-28 17:59:43,810 - config - INFO - Epoch [159/200], Train Loss: 0.2736
2024-03-28 17:59:43,818 - config - INFO - Validation Loss: 0.5216
2024-03-28 17:59:43,839 - config - INFO - Epoch [160/200], Train Loss: 0.2732
2024-03-28 17:59:43,844 - config - INFO - Validation Loss: 0.5221
2024-03-28 17:59:43,865 - config - INFO - Epoch [161/200], Train Loss: 0.2734
2024-03-28 17:59:43,870 - config - INFO - Validation Loss: 0.5226
2024-03-28 17:59:43,891 - config - INFO - Epoch [162/200], Train Loss: 0.2717
2024-03-28 17:59:43,895 - config - INFO - Validation Loss: 0.5312
2024-03-28 17:59:43,917 - config - INFO - Epoch [163/200], Train Loss: 0.2719
2024-03-28 17:59:43,921 - config - INFO - Validation Loss: 0.5304
2024-03-28 17:59:43,942 - config - INFO - Epoch [164/200], Train Loss: 0.2715
2024-03-28 17:59:43,947 - config - INFO - Validation Loss: 0.5303
2024-03-28 17:59:43,968 - config - INFO - Epoch [165/200], Train Loss: 0.2710
2024-03-28 17:59:43,972 - config - INFO - Validation Loss: 0.5331
2024-03-28 17:59:43,993 - config - INFO - Epoch [166/200], Train Loss: 0.2706
2024-03-28 17:59:43,998 - config - INFO - Validation Loss: 0.5341
2024-03-28 17:59:44,019 - config - INFO - Epoch [167/200], Train Loss: 0.2705
2024-03-28 17:59:44,023 - config - INFO - Validation Loss: 0.5310
2024-03-28 17:59:44,044 - config - INFO - Epoch [168/200], Train Loss: 0.2709
2024-03-28 17:59:44,049 - config - INFO - Validation Loss: 0.5304
2024-03-28 17:59:44,070 - config - INFO - Epoch [169/200], Train Loss: 0.2686
2024-03-28 17:59:44,074 - config - INFO - Validation Loss: 0.5342
2024-03-28 17:59:44,095 - config - INFO - Epoch [170/200], Train Loss: 0.2710
2024-03-28 17:59:44,100 - config - INFO - Validation Loss: 0.5413
2024-03-28 17:59:44,100 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 18:01:46,116 - config - INFO - resume: None
2024-03-28 18:01:46,116 - config - INFO - device: cpu
2024-03-28 18:01:46,116 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 18:01:46,116 - config - INFO - learning_rate: 0.001
2024-03-28 18:01:46,117 - config - INFO - num_epochs: 200
2024-03-28 18:01:46,117 - config - INFO - batch_size: 64
2024-03-28 18:01:46,117 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = None
        self.prev_val_loss = float('inf')
        self.tolerance = 0.03

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 18:01:46,130 - config - INFO - Dataset size: 891
2024-03-28 18:01:46,155 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.6 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()

    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 18:01:46,155 - config - INFO - Training start
2024-03-28 18:01:48,560 - config - INFO - Epoch [1/200], Train Loss: 0.6997
2024-03-28 18:01:48,566 - config - INFO - Validation Loss: 0.6782
2024-03-28 18:01:48,599 - config - INFO - Epoch [2/200], Train Loss: 0.6656
2024-03-28 18:01:48,604 - config - INFO - Validation Loss: 0.6503
2024-03-28 18:01:48,635 - config - INFO - Epoch [3/200], Train Loss: 0.6342
2024-03-28 18:01:48,640 - config - INFO - Validation Loss: 0.6223
2024-03-28 18:01:48,671 - config - INFO - Epoch [4/200], Train Loss: 0.6012
2024-03-28 18:01:48,676 - config - INFO - Validation Loss: 0.5925
2024-03-28 18:01:48,709 - config - INFO - Epoch [5/200], Train Loss: 0.5642
2024-03-28 18:01:48,714 - config - INFO - Validation Loss: 0.5622
2024-03-28 18:01:48,745 - config - INFO - Epoch [6/200], Train Loss: 0.5272
2024-03-28 18:01:48,750 - config - INFO - Validation Loss: 0.5334
2024-03-28 18:01:48,782 - config - INFO - Epoch [7/200], Train Loss: 0.4909
2024-03-28 18:01:48,787 - config - INFO - Validation Loss: 0.5101
2024-03-28 18:01:48,817 - config - INFO - Epoch [8/200], Train Loss: 0.4607
2024-03-28 18:01:48,822 - config - INFO - Validation Loss: 0.4942
2024-03-28 18:01:48,851 - config - INFO - Epoch [9/200], Train Loss: 0.4383
2024-03-28 18:01:48,856 - config - INFO - Validation Loss: 0.4848
2024-03-28 18:01:48,886 - config - INFO - Epoch [10/200], Train Loss: 0.4241
2024-03-28 18:01:48,891 - config - INFO - Validation Loss: 0.4802
2024-03-28 18:01:48,921 - config - INFO - Epoch [11/200], Train Loss: 0.4144
2024-03-28 18:01:48,926 - config - INFO - Validation Loss: 0.4785
2024-03-28 18:01:48,951 - config - INFO - Epoch [12/200], Train Loss: 0.4089
2024-03-28 18:01:48,956 - config - INFO - Validation Loss: 0.4778
2024-03-28 18:01:48,981 - config - INFO - Epoch [13/200], Train Loss: 0.4045
2024-03-28 18:01:48,986 - config - INFO - Validation Loss: 0.4785
2024-03-28 18:01:49,011 - config - INFO - Epoch [14/200], Train Loss: 0.4009
2024-03-28 18:01:49,017 - config - INFO - Validation Loss: 0.4761
2024-03-28 18:01:49,047 - config - INFO - Epoch [15/200], Train Loss: 0.3978
2024-03-28 18:01:49,052 - config - INFO - Validation Loss: 0.4731
2024-03-28 18:01:49,074 - config - INFO - Epoch [16/200], Train Loss: 0.3944
2024-03-28 18:01:49,079 - config - INFO - Validation Loss: 0.4747
2024-03-28 18:01:49,101 - config - INFO - Epoch [17/200], Train Loss: 0.3943
2024-03-28 18:01:49,106 - config - INFO - Validation Loss: 0.4749
2024-03-28 18:01:49,128 - config - INFO - Epoch [18/200], Train Loss: 0.3906
2024-03-28 18:01:49,132 - config - INFO - Validation Loss: 0.4723
2024-03-28 18:01:49,155 - config - INFO - Epoch [19/200], Train Loss: 0.3889
2024-03-28 18:01:49,159 - config - INFO - Validation Loss: 0.4700
2024-03-28 18:01:49,182 - config - INFO - Epoch [20/200], Train Loss: 0.3874
2024-03-28 18:01:49,186 - config - INFO - Validation Loss: 0.4690
2024-03-28 18:01:49,208 - config - INFO - Epoch [21/200], Train Loss: 0.3841
2024-03-28 18:01:49,213 - config - INFO - Validation Loss: 0.4707
2024-03-28 18:01:49,235 - config - INFO - Epoch [22/200], Train Loss: 0.3822
2024-03-28 18:01:49,240 - config - INFO - Validation Loss: 0.4691
2024-03-28 18:01:49,262 - config - INFO - Epoch [23/200], Train Loss: 0.3806
2024-03-28 18:01:49,267 - config - INFO - Validation Loss: 0.4658
2024-03-28 18:01:49,289 - config - INFO - Epoch [24/200], Train Loss: 0.3805
2024-03-28 18:01:49,294 - config - INFO - Validation Loss: 0.4655
2024-03-28 18:01:49,317 - config - INFO - Epoch [25/200], Train Loss: 0.3781
2024-03-28 18:01:49,321 - config - INFO - Validation Loss: 0.4673
2024-03-28 18:01:49,344 - config - INFO - Epoch [26/200], Train Loss: 0.3760
2024-03-28 18:01:49,348 - config - INFO - Validation Loss: 0.4682
2024-03-28 18:01:49,371 - config - INFO - Epoch [27/200], Train Loss: 0.3746
2024-03-28 18:01:49,375 - config - INFO - Validation Loss: 0.4701
2024-03-28 18:01:49,398 - config - INFO - Epoch [28/200], Train Loss: 0.3732
2024-03-28 18:01:49,417 - config - INFO - Validation Loss: 0.4720
2024-03-28 18:01:49,440 - config - INFO - Epoch [29/200], Train Loss: 0.3733
2024-03-28 18:01:49,444 - config - INFO - Validation Loss: 0.4694
2024-03-28 18:01:49,467 - config - INFO - Epoch [30/200], Train Loss: 0.3710
2024-03-28 18:01:49,471 - config - INFO - Validation Loss: 0.4689
2024-03-28 18:01:49,493 - config - INFO - Epoch [31/200], Train Loss: 0.3699
2024-03-28 18:01:49,498 - config - INFO - Validation Loss: 0.4674
2024-03-28 18:01:49,520 - config - INFO - Epoch [32/200], Train Loss: 0.3683
2024-03-28 18:01:49,525 - config - INFO - Validation Loss: 0.4654
2024-03-28 18:01:49,547 - config - INFO - Epoch [33/200], Train Loss: 0.3674
2024-03-28 18:01:49,551 - config - INFO - Validation Loss: 0.4653
2024-03-28 18:01:49,574 - config - INFO - Epoch [34/200], Train Loss: 0.3675
2024-03-28 18:01:49,578 - config - INFO - Validation Loss: 0.4672
2024-03-28 18:01:49,600 - config - INFO - Epoch [35/200], Train Loss: 0.3657
2024-03-28 18:01:49,604 - config - INFO - Validation Loss: 0.4663
2024-03-28 18:01:49,627 - config - INFO - Epoch [36/200], Train Loss: 0.3634
2024-03-28 18:01:49,631 - config - INFO - Validation Loss: 0.4688
2024-03-28 18:01:49,654 - config - INFO - Epoch [37/200], Train Loss: 0.3634
2024-03-28 18:01:49,658 - config - INFO - Validation Loss: 0.4708
2024-03-28 18:01:49,680 - config - INFO - Epoch [38/200], Train Loss: 0.3629
2024-03-28 18:01:49,685 - config - INFO - Validation Loss: 0.4666
2024-03-28 18:01:49,707 - config - INFO - Epoch [39/200], Train Loss: 0.3605
2024-03-28 18:01:49,712 - config - INFO - Validation Loss: 0.4674
2024-03-28 18:01:49,734 - config - INFO - Epoch [40/200], Train Loss: 0.3607
2024-03-28 18:01:49,739 - config - INFO - Validation Loss: 0.4674
2024-03-28 18:01:49,761 - config - INFO - Epoch [41/200], Train Loss: 0.3598
2024-03-28 18:01:49,765 - config - INFO - Validation Loss: 0.4678
2024-03-28 18:01:49,795 - config - INFO - Epoch [42/200], Train Loss: 0.3586
2024-03-28 18:01:49,799 - config - INFO - Validation Loss: 0.4726
2024-03-28 18:01:49,822 - config - INFO - Epoch [43/200], Train Loss: 0.3578
2024-03-28 18:01:49,826 - config - INFO - Validation Loss: 0.4722
2024-03-28 18:01:49,848 - config - INFO - Epoch [44/200], Train Loss: 0.3572
2024-03-28 18:01:49,853 - config - INFO - Validation Loss: 0.4703
2024-03-28 18:01:49,875 - config - INFO - Epoch [45/200], Train Loss: 0.3560
2024-03-28 18:01:49,879 - config - INFO - Validation Loss: 0.4712
2024-03-28 18:01:49,902 - config - INFO - Epoch [46/200], Train Loss: 0.3567
2024-03-28 18:01:49,906 - config - INFO - Validation Loss: 0.4728
2024-03-28 18:01:49,928 - config - INFO - Epoch [47/200], Train Loss: 0.3546
2024-03-28 18:01:49,933 - config - INFO - Validation Loss: 0.4716
2024-03-28 18:01:49,955 - config - INFO - Epoch [48/200], Train Loss: 0.3535
2024-03-28 18:01:49,960 - config - INFO - Validation Loss: 0.4736
2024-03-28 18:01:49,982 - config - INFO - Epoch [49/200], Train Loss: 0.3534
2024-03-28 18:01:49,986 - config - INFO - Validation Loss: 0.4751
2024-03-28 18:01:50,009 - config - INFO - Epoch [50/200], Train Loss: 0.3519
2024-03-28 18:01:50,013 - config - INFO - Validation Loss: 0.4733
2024-03-28 18:01:50,035 - config - INFO - Epoch [51/200], Train Loss: 0.3514
2024-03-28 18:01:50,040 - config - INFO - Validation Loss: 0.4749
2024-03-28 18:01:50,062 - config - INFO - Epoch [52/200], Train Loss: 0.3498
2024-03-28 18:01:50,067 - config - INFO - Validation Loss: 0.4758
2024-03-28 18:01:50,089 - config - INFO - Epoch [53/200], Train Loss: 0.3499
2024-03-28 18:01:50,094 - config - INFO - Validation Loss: 0.4760
2024-03-28 18:01:50,116 - config - INFO - Epoch [54/200], Train Loss: 0.3484
2024-03-28 18:01:50,121 - config - INFO - Validation Loss: 0.4812
2024-03-28 18:01:50,143 - config - INFO - Epoch [55/200], Train Loss: 0.3489
2024-03-28 18:01:50,148 - config - INFO - Validation Loss: 0.4819
2024-03-28 18:01:50,170 - config - INFO - Epoch [56/200], Train Loss: 0.3470
2024-03-28 18:01:50,175 - config - INFO - Validation Loss: 0.4759
2024-03-28 18:01:50,197 - config - INFO - Epoch [57/200], Train Loss: 0.3467
2024-03-28 18:01:50,202 - config - INFO - Validation Loss: 0.4740
2024-03-28 18:01:50,224 - config - INFO - Epoch [58/200], Train Loss: 0.3461
2024-03-28 18:01:50,229 - config - INFO - Validation Loss: 0.4751
2024-03-28 18:01:50,251 - config - INFO - Epoch [59/200], Train Loss: 0.3452
2024-03-28 18:01:50,255 - config - INFO - Validation Loss: 0.4785
2024-03-28 18:01:50,278 - config - INFO - Epoch [60/200], Train Loss: 0.3445
2024-03-28 18:01:50,283 - config - INFO - Validation Loss: 0.4789
2024-03-28 18:01:50,305 - config - INFO - Epoch [61/200], Train Loss: 0.3457
2024-03-28 18:01:50,310 - config - INFO - Validation Loss: 0.4771
2024-03-28 18:01:50,332 - config - INFO - Epoch [62/200], Train Loss: 0.3430
2024-03-28 18:01:50,336 - config - INFO - Validation Loss: 0.4812
2024-03-28 18:01:50,359 - config - INFO - Epoch [63/200], Train Loss: 0.3419
2024-03-28 18:01:50,363 - config - INFO - Validation Loss: 0.4773
2024-03-28 18:01:50,386 - config - INFO - Epoch [64/200], Train Loss: 0.3415
2024-03-28 18:01:50,390 - config - INFO - Validation Loss: 0.4772
2024-03-28 18:01:50,421 - config - INFO - Epoch [65/200], Train Loss: 0.3406
2024-03-28 18:01:50,426 - config - INFO - Validation Loss: 0.4774
2024-03-28 18:01:50,449 - config - INFO - Epoch [66/200], Train Loss: 0.3406
2024-03-28 18:01:50,453 - config - INFO - Validation Loss: 0.4773
2024-03-28 18:01:50,475 - config - INFO - Epoch [67/200], Train Loss: 0.3388
2024-03-28 18:01:50,479 - config - INFO - Validation Loss: 0.4798
2024-03-28 18:01:50,501 - config - INFO - Epoch [68/200], Train Loss: 0.3375
2024-03-28 18:01:50,506 - config - INFO - Validation Loss: 0.4824
2024-03-28 18:01:50,528 - config - INFO - Epoch [69/200], Train Loss: 0.3374
2024-03-28 18:01:50,532 - config - INFO - Validation Loss: 0.4851
2024-03-28 18:01:50,554 - config - INFO - Epoch [70/200], Train Loss: 0.3387
2024-03-28 18:01:50,559 - config - INFO - Validation Loss: 0.4824
2024-03-28 18:01:50,581 - config - INFO - Epoch [71/200], Train Loss: 0.3367
2024-03-28 18:01:50,585 - config - INFO - Validation Loss: 0.4844
2024-03-28 18:01:50,608 - config - INFO - Epoch [72/200], Train Loss: 0.3387
2024-03-28 18:01:50,612 - config - INFO - Validation Loss: 0.4874
2024-03-28 18:01:50,635 - config - INFO - Epoch [73/200], Train Loss: 0.3358
2024-03-28 18:01:50,639 - config - INFO - Validation Loss: 0.4801
2024-03-28 18:01:50,662 - config - INFO - Epoch [74/200], Train Loss: 0.3361
2024-03-28 18:01:50,666 - config - INFO - Validation Loss: 0.4827
2024-03-28 18:01:50,688 - config - INFO - Epoch [75/200], Train Loss: 0.3341
2024-03-28 18:01:50,693 - config - INFO - Validation Loss: 0.4821
2024-03-28 18:01:50,715 - config - INFO - Epoch [76/200], Train Loss: 0.3343
2024-03-28 18:01:50,719 - config - INFO - Validation Loss: 0.4850
2024-03-28 18:01:50,741 - config - INFO - Epoch [77/200], Train Loss: 0.3331
2024-03-28 18:01:50,746 - config - INFO - Validation Loss: 0.4861
2024-03-28 18:01:50,768 - config - INFO - Epoch [78/200], Train Loss: 0.3349
2024-03-28 18:01:50,772 - config - INFO - Validation Loss: 0.4907
2024-03-28 18:01:50,795 - config - INFO - Epoch [79/200], Train Loss: 0.3314
2024-03-28 18:01:50,799 - config - INFO - Validation Loss: 0.4905
2024-03-28 18:01:50,821 - config - INFO - Epoch [80/200], Train Loss: 0.3315
2024-03-28 18:01:50,826 - config - INFO - Validation Loss: 0.4864
2024-03-28 18:01:50,848 - config - INFO - Epoch [81/200], Train Loss: 0.3306
2024-03-28 18:01:50,852 - config - INFO - Validation Loss: 0.4838
2024-03-28 18:01:50,874 - config - INFO - Epoch [82/200], Train Loss: 0.3300
2024-03-28 18:01:50,879 - config - INFO - Validation Loss: 0.4885
2024-03-28 18:01:50,901 - config - INFO - Epoch [83/200], Train Loss: 0.3302
2024-03-28 18:01:50,905 - config - INFO - Validation Loss: 0.4868
2024-03-28 18:01:50,928 - config - INFO - Epoch [84/200], Train Loss: 0.3279
2024-03-28 18:01:50,932 - config - INFO - Validation Loss: 0.4838
2024-03-28 18:01:50,954 - config - INFO - Epoch [85/200], Train Loss: 0.3281
2024-03-28 18:01:50,958 - config - INFO - Validation Loss: 0.4865
2024-03-28 18:01:50,980 - config - INFO - Epoch [86/200], Train Loss: 0.3274
2024-03-28 18:01:50,985 - config - INFO - Validation Loss: 0.4896
2024-03-28 18:01:51,007 - config - INFO - Epoch [87/200], Train Loss: 0.3268
2024-03-28 18:01:51,011 - config - INFO - Validation Loss: 0.4895
2024-03-28 18:01:51,034 - config - INFO - Epoch [88/200], Train Loss: 0.3266
2024-03-28 18:01:51,038 - config - INFO - Validation Loss: 0.4921
2024-03-28 18:01:51,060 - config - INFO - Epoch [89/200], Train Loss: 0.3255
2024-03-28 18:01:51,065 - config - INFO - Validation Loss: 0.4954
2024-03-28 18:01:51,065 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 22:18:08,240 - config - INFO - resume: None
2024-03-28 22:18:08,240 - config - INFO - device: cpu
2024-03-28 22:18:08,240 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:18:08,240 - config - INFO - learning_rate: 0.001
2024-03-28 22:18:08,240 - config - INFO - num_epochs: 200
2024-03-28 22:18:08,240 - config - INFO - batch_size: 64
2024-03-28 22:18:08,240 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.03

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:18:08,240 - config - INFO - Training start
2024-03-28 22:18:40,040 - config - INFO - resume: None
2024-03-28 22:18:40,040 - config - INFO - device: cpu
2024-03-28 22:18:40,040 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:18:40,040 - config - INFO - learning_rate: 0.001
2024-03-28 22:18:40,040 - config - INFO - num_epochs: 200
2024-03-28 22:18:40,040 - config - INFO - batch_size: 64
2024-03-28 22:18:40,040 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.03

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:19:12,563 - config - INFO - resume: None
2024-03-28 22:19:12,563 - config - INFO - device: cpu
2024-03-28 22:19:12,563 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:19:12,563 - config - INFO - learning_rate: 0.001
2024-03-28 22:19:12,563 - config - INFO - num_epochs: 200
2024-03-28 22:19:12,563 - config - INFO - batch_size: 64
2024-03-28 22:19:12,564 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.03

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:19:12,585 - config - INFO - Dataset size: 891
2024-03-28 22:19:12,611 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=self.config.batch_size)
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs = batch['features']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(test_dataloader)
        self.logger.info(f"test Loss: {val_loss:.4f}")
        predictions = (outputs > threshold).float()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1242)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions})

        # Save DataFrame with no index
        df.to_csv('predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 22:19:12,611 - config - INFO - Training start
2024-03-28 22:19:14,956 - config - INFO - Epoch [1/200], Train Loss: 0.7003
2024-03-28 22:19:14,960 - config - INFO - Validation Loss: 0.6852
2024-03-28 22:19:14,961 - config - INFO - Validation Acc: 0.5400
2024-03-28 22:19:14,993 - config - INFO - Epoch [2/200], Train Loss: 0.6629
2024-03-28 22:19:14,997 - config - INFO - Validation Loss: 0.6484
2024-03-28 22:19:14,998 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:19:15,030 - config - INFO - Epoch [3/200], Train Loss: 0.6234
2024-03-28 22:19:15,034 - config - INFO - Validation Loss: 0.6081
2024-03-28 22:19:15,034 - config - INFO - Validation Acc: 0.7200
2024-03-28 22:19:15,066 - config - INFO - Epoch [4/200], Train Loss: 0.5749
2024-03-28 22:19:15,071 - config - INFO - Validation Loss: 0.5636
2024-03-28 22:19:15,071 - config - INFO - Validation Acc: 0.7200
2024-03-28 22:19:15,105 - config - INFO - Epoch [5/200], Train Loss: 0.5227
2024-03-28 22:19:15,110 - config - INFO - Validation Loss: 0.5307
2024-03-28 22:19:15,110 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:19:15,143 - config - INFO - Epoch [6/200], Train Loss: 0.4792
2024-03-28 22:19:15,148 - config - INFO - Validation Loss: 0.5152
2024-03-28 22:19:15,148 - config - INFO - Validation Acc: 0.7200
2024-03-28 22:19:15,181 - config - INFO - Epoch [7/200], Train Loss: 0.4514
2024-03-28 22:19:15,186 - config - INFO - Validation Loss: 0.5073
2024-03-28 22:19:15,186 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:19:15,219 - config - INFO - Epoch [8/200], Train Loss: 0.4334
2024-03-28 22:19:15,224 - config - INFO - Validation Loss: 0.5043
2024-03-28 22:19:15,224 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:19:15,258 - config - INFO - Epoch [9/200], Train Loss: 0.4243
2024-03-28 22:19:15,263 - config - INFO - Validation Loss: 0.5023
2024-03-28 22:19:15,263 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:19:15,297 - config - INFO - Epoch [10/200], Train Loss: 0.4136
2024-03-28 22:19:15,302 - config - INFO - Validation Loss: 0.5038
2024-03-28 22:19:15,302 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:19:15,335 - config - INFO - Epoch [11/200], Train Loss: 0.4092
2024-03-28 22:19:15,340 - config - INFO - Validation Loss: 0.4982
2024-03-28 22:19:15,340 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:19:15,391 - config - INFO - Epoch [12/200], Train Loss: 0.4053
2024-03-28 22:19:15,396 - config - INFO - Validation Loss: 0.4913
2024-03-28 22:19:15,396 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:19:15,429 - config - INFO - Epoch [13/200], Train Loss: 0.4008
2024-03-28 22:19:15,434 - config - INFO - Validation Loss: 0.4934
2024-03-28 22:19:15,434 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:19:15,467 - config - INFO - Epoch [14/200], Train Loss: 0.3973
2024-03-28 22:19:15,472 - config - INFO - Validation Loss: 0.4917
2024-03-28 22:19:15,472 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:19:15,505 - config - INFO - Epoch [15/200], Train Loss: 0.3943
2024-03-28 22:19:15,510 - config - INFO - Validation Loss: 0.4885
2024-03-28 22:19:15,510 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:19:15,544 - config - INFO - Epoch [16/200], Train Loss: 0.3943
2024-03-28 22:19:15,550 - config - INFO - Validation Loss: 0.4900
2024-03-28 22:19:15,550 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:19:15,588 - config - INFO - Epoch [17/200], Train Loss: 0.3915
2024-03-28 22:19:15,595 - config - INFO - Validation Loss: 0.4887
2024-03-28 22:19:15,596 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:19:15,624 - config - INFO - Epoch [18/200], Train Loss: 0.3891
2024-03-28 22:19:15,628 - config - INFO - Validation Loss: 0.4903
2024-03-28 22:19:15,628 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:19:15,656 - config - INFO - Epoch [19/200], Train Loss: 0.3862
2024-03-28 22:19:15,660 - config - INFO - Validation Loss: 0.4872
2024-03-28 22:19:15,660 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:19:15,688 - config - INFO - Epoch [20/200], Train Loss: 0.3847
2024-03-28 22:19:15,692 - config - INFO - Validation Loss: 0.4854
2024-03-28 22:19:15,692 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:19:15,720 - config - INFO - Epoch [21/200], Train Loss: 0.3823
2024-03-28 22:19:15,724 - config - INFO - Validation Loss: 0.4873
2024-03-28 22:19:15,724 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:19:15,753 - config - INFO - Epoch [22/200], Train Loss: 0.3801
2024-03-28 22:19:15,757 - config - INFO - Validation Loss: 0.4878
2024-03-28 22:19:15,757 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:19:15,785 - config - INFO - Epoch [23/200], Train Loss: 0.3781
2024-03-28 22:19:15,789 - config - INFO - Validation Loss: 0.4893
2024-03-28 22:19:15,789 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:19:15,817 - config - INFO - Epoch [24/200], Train Loss: 0.3769
2024-03-28 22:19:15,821 - config - INFO - Validation Loss: 0.4926
2024-03-28 22:19:15,821 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:19:15,849 - config - INFO - Epoch [25/200], Train Loss: 0.3756
2024-03-28 22:19:15,853 - config - INFO - Validation Loss: 0.4886
2024-03-28 22:19:15,853 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:19:15,883 - config - INFO - Epoch [26/200], Train Loss: 0.3737
2024-03-28 22:19:15,887 - config - INFO - Validation Loss: 0.4885
2024-03-28 22:19:15,887 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:19:15,916 - config - INFO - Epoch [27/200], Train Loss: 0.3727
2024-03-28 22:19:15,920 - config - INFO - Validation Loss: 0.4904
2024-03-28 22:19:15,920 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:19:15,948 - config - INFO - Epoch [28/200], Train Loss: 0.3710
2024-03-28 22:19:15,952 - config - INFO - Validation Loss: 0.4885
2024-03-28 22:19:15,952 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:19:15,980 - config - INFO - Epoch [29/200], Train Loss: 0.3695
2024-03-28 22:19:15,984 - config - INFO - Validation Loss: 0.4850
2024-03-28 22:19:15,984 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:19:16,012 - config - INFO - Epoch [30/200], Train Loss: 0.3699
2024-03-28 22:19:16,016 - config - INFO - Validation Loss: 0.4841
2024-03-28 22:19:16,017 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:19:16,045 - config - INFO - Epoch [31/200], Train Loss: 0.3696
2024-03-28 22:19:16,049 - config - INFO - Validation Loss: 0.4874
2024-03-28 22:19:16,049 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:19:16,077 - config - INFO - Epoch [32/200], Train Loss: 0.3681
2024-03-28 22:19:16,081 - config - INFO - Validation Loss: 0.4912
2024-03-28 22:19:16,081 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:19:16,109 - config - INFO - Epoch [33/200], Train Loss: 0.3658
2024-03-28 22:19:16,113 - config - INFO - Validation Loss: 0.4926
2024-03-28 22:19:16,113 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:19:16,141 - config - INFO - Epoch [34/200], Train Loss: 0.3656
2024-03-28 22:19:16,145 - config - INFO - Validation Loss: 0.4982
2024-03-28 22:19:16,145 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:19:16,173 - config - INFO - Epoch [35/200], Train Loss: 0.3662
2024-03-28 22:19:16,177 - config - INFO - Validation Loss: 0.4967
2024-03-28 22:19:16,177 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:19:16,205 - config - INFO - Epoch [36/200], Train Loss: 0.3651
2024-03-28 22:19:16,209 - config - INFO - Validation Loss: 0.4966
2024-03-28 22:19:16,210 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:19:16,238 - config - INFO - Epoch [37/200], Train Loss: 0.3693
2024-03-28 22:19:16,242 - config - INFO - Validation Loss: 0.4974
2024-03-28 22:19:16,242 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:19:16,270 - config - INFO - Epoch [38/200], Train Loss: 0.3642
2024-03-28 22:19:16,274 - config - INFO - Validation Loss: 0.4999
2024-03-28 22:19:16,274 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:19:16,302 - config - INFO - Epoch [39/200], Train Loss: 0.3628
2024-03-28 22:19:16,306 - config - INFO - Validation Loss: 0.4988
2024-03-28 22:19:16,306 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:19:16,334 - config - INFO - Epoch [40/200], Train Loss: 0.3621
2024-03-28 22:19:16,338 - config - INFO - Validation Loss: 0.5013
2024-03-28 22:19:16,338 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:19:16,366 - config - INFO - Epoch [41/200], Train Loss: 0.3608
2024-03-28 22:19:16,379 - config - INFO - Validation Loss: 0.4925
2024-03-28 22:19:16,379 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:19:16,408 - config - INFO - Epoch [42/200], Train Loss: 0.3608
2024-03-28 22:19:16,412 - config - INFO - Validation Loss: 0.4959
2024-03-28 22:19:16,412 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:19:16,440 - config - INFO - Epoch [43/200], Train Loss: 0.3602
2024-03-28 22:19:16,444 - config - INFO - Validation Loss: 0.4958
2024-03-28 22:19:16,444 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:19:16,472 - config - INFO - Epoch [44/200], Train Loss: 0.3587
2024-03-28 22:19:16,476 - config - INFO - Validation Loss: 0.5014
2024-03-28 22:19:16,476 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:19:16,504 - config - INFO - Epoch [45/200], Train Loss: 0.3584
2024-03-28 22:19:16,508 - config - INFO - Validation Loss: 0.5077
2024-03-28 22:19:16,508 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:19:16,536 - config - INFO - Epoch [46/200], Train Loss: 0.3599
2024-03-28 22:19:16,540 - config - INFO - Validation Loss: 0.5045
2024-03-28 22:19:16,541 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:19:16,568 - config - INFO - Epoch [47/200], Train Loss: 0.3569
2024-03-28 22:19:16,572 - config - INFO - Validation Loss: 0.5055
2024-03-28 22:19:16,573 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:19:16,601 - config - INFO - Epoch [48/200], Train Loss: 0.3570
2024-03-28 22:19:16,605 - config - INFO - Validation Loss: 0.5043
2024-03-28 22:19:16,605 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:19:16,633 - config - INFO - Epoch [49/200], Train Loss: 0.3564
2024-03-28 22:19:16,637 - config - INFO - Validation Loss: 0.4996
2024-03-28 22:19:16,637 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:19:16,666 - config - INFO - Epoch [50/200], Train Loss: 0.3572
2024-03-28 22:19:16,670 - config - INFO - Validation Loss: 0.5050
2024-03-28 22:19:16,670 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:19:16,698 - config - INFO - Epoch [51/200], Train Loss: 0.3543
2024-03-28 22:19:16,702 - config - INFO - Validation Loss: 0.5084
2024-03-28 22:19:16,702 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:19:16,730 - config - INFO - Epoch [52/200], Train Loss: 0.3539
2024-03-28 22:19:16,734 - config - INFO - Validation Loss: 0.5139
2024-03-28 22:19:16,734 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:19:16,762 - config - INFO - Epoch [53/200], Train Loss: 0.3552
2024-03-28 22:19:16,766 - config - INFO - Validation Loss: 0.5147
2024-03-28 22:19:16,766 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:19:16,766 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 22:20:35,105 - config - INFO - resume: None
2024-03-28 22:20:35,106 - config - INFO - device: cpu
2024-03-28 22:20:35,106 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:20:35,106 - config - INFO - learning_rate: 0.001
2024-03-28 22:20:35,106 - config - INFO - num_epochs: 200
2024-03-28 22:20:35,106 - config - INFO - batch_size: 64
2024-03-28 22:20:35,106 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.03

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:20:35,127 - config - INFO - Dataset size: 891
2024-03-28 22:20:35,148 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=self.config.batch_size)
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs = batch['features']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(test_dataloader)
        self.logger.info(f"test Loss: {val_loss:.4f}")
        predictions = (outputs > threshold).float()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1242)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions})

        # Save DataFrame with no index
        df.to_csv('predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 22:20:35,148 - config - INFO - Training start
2024-03-28 22:20:37,579 - config - INFO - Epoch [1/200], Train Loss: 0.6650
2024-03-28 22:20:37,585 - config - INFO - Validation Loss: 0.6601
2024-03-28 22:20:37,585 - config - INFO - Validation Acc: 0.5600
2024-03-28 22:20:37,624 - config - INFO - Epoch [2/200], Train Loss: 0.6305
2024-03-28 22:20:37,630 - config - INFO - Validation Loss: 0.6323
2024-03-28 22:20:37,630 - config - INFO - Validation Acc: 0.5800
2024-03-28 22:20:37,663 - config - INFO - Epoch [3/200], Train Loss: 0.5935
2024-03-28 22:20:37,668 - config - INFO - Validation Loss: 0.5926
2024-03-28 22:20:37,669 - config - INFO - Validation Acc: 0.7200
2024-03-28 22:20:37,706 - config - INFO - Epoch [4/200], Train Loss: 0.5534
2024-03-28 22:20:37,710 - config - INFO - Validation Loss: 0.5476
2024-03-28 22:20:37,711 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:20:37,745 - config - INFO - Epoch [5/200], Train Loss: 0.5135
2024-03-28 22:20:37,750 - config - INFO - Validation Loss: 0.5117
2024-03-28 22:20:37,750 - config - INFO - Validation Acc: 0.8400
2024-03-28 22:20:37,781 - config - INFO - Epoch [6/200], Train Loss: 0.4786
2024-03-28 22:20:37,785 - config - INFO - Validation Loss: 0.4757
2024-03-28 22:20:37,785 - config - INFO - Validation Acc: 0.8600
2024-03-28 22:20:37,817 - config - INFO - Epoch [7/200], Train Loss: 0.4532
2024-03-28 22:20:37,821 - config - INFO - Validation Loss: 0.4570
2024-03-28 22:20:37,821 - config - INFO - Validation Acc: 0.8400
2024-03-28 22:20:37,852 - config - INFO - Epoch [8/200], Train Loss: 0.4389
2024-03-28 22:20:37,857 - config - INFO - Validation Loss: 0.4466
2024-03-28 22:20:37,858 - config - INFO - Validation Acc: 0.8400
2024-03-28 22:20:37,898 - config - INFO - Epoch [9/200], Train Loss: 0.4313
2024-03-28 22:20:37,903 - config - INFO - Validation Loss: 0.4416
2024-03-28 22:20:37,903 - config - INFO - Validation Acc: 0.8400
2024-03-28 22:20:37,936 - config - INFO - Epoch [10/200], Train Loss: 0.4261
2024-03-28 22:20:37,940 - config - INFO - Validation Loss: 0.4391
2024-03-28 22:20:37,941 - config - INFO - Validation Acc: 0.8400
2024-03-28 22:20:37,971 - config - INFO - Epoch [11/200], Train Loss: 0.4206
2024-03-28 22:20:37,976 - config - INFO - Validation Loss: 0.4370
2024-03-28 22:20:37,976 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:20:38,005 - config - INFO - Epoch [12/200], Train Loss: 0.4165
2024-03-28 22:20:38,009 - config - INFO - Validation Loss: 0.4353
2024-03-28 22:20:38,009 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:38,038 - config - INFO - Epoch [13/200], Train Loss: 0.4120
2024-03-28 22:20:38,043 - config - INFO - Validation Loss: 0.4369
2024-03-28 22:20:38,043 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:20:38,072 - config - INFO - Epoch [14/200], Train Loss: 0.4103
2024-03-28 22:20:38,077 - config - INFO - Validation Loss: 0.4405
2024-03-28 22:20:38,077 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:20:38,109 - config - INFO - Epoch [15/200], Train Loss: 0.4075
2024-03-28 22:20:38,114 - config - INFO - Validation Loss: 0.4376
2024-03-28 22:20:38,114 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:20:38,145 - config - INFO - Epoch [16/200], Train Loss: 0.4044
2024-03-28 22:20:38,149 - config - INFO - Validation Loss: 0.4356
2024-03-28 22:20:38,149 - config - INFO - Validation Acc: 0.8400
2024-03-28 22:20:38,179 - config - INFO - Epoch [17/200], Train Loss: 0.4029
2024-03-28 22:20:38,183 - config - INFO - Validation Loss: 0.4364
2024-03-28 22:20:38,183 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:20:38,213 - config - INFO - Epoch [18/200], Train Loss: 0.3994
2024-03-28 22:20:38,217 - config - INFO - Validation Loss: 0.4386
2024-03-28 22:20:38,218 - config - INFO - Validation Acc: 0.8400
2024-03-28 22:20:38,248 - config - INFO - Epoch [19/200], Train Loss: 0.3976
2024-03-28 22:20:38,253 - config - INFO - Validation Loss: 0.4437
2024-03-28 22:20:38,253 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:20:38,283 - config - INFO - Epoch [20/200], Train Loss: 0.3961
2024-03-28 22:20:38,288 - config - INFO - Validation Loss: 0.4446
2024-03-28 22:20:38,288 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:38,319 - config - INFO - Epoch [21/200], Train Loss: 0.3951
2024-03-28 22:20:38,324 - config - INFO - Validation Loss: 0.4458
2024-03-28 22:20:38,324 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:38,353 - config - INFO - Epoch [22/200], Train Loss: 0.3930
2024-03-28 22:20:38,358 - config - INFO - Validation Loss: 0.4440
2024-03-28 22:20:38,358 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:38,406 - config - INFO - Epoch [23/200], Train Loss: 0.3924
2024-03-28 22:20:38,410 - config - INFO - Validation Loss: 0.4442
2024-03-28 22:20:38,410 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:20:38,439 - config - INFO - Epoch [24/200], Train Loss: 0.3912
2024-03-28 22:20:38,444 - config - INFO - Validation Loss: 0.4433
2024-03-28 22:20:38,444 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:20:38,473 - config - INFO - Epoch [25/200], Train Loss: 0.3899
2024-03-28 22:20:38,477 - config - INFO - Validation Loss: 0.4402
2024-03-28 22:20:38,477 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:20:38,506 - config - INFO - Epoch [26/200], Train Loss: 0.3891
2024-03-28 22:20:38,510 - config - INFO - Validation Loss: 0.4422
2024-03-28 22:20:38,511 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:38,539 - config - INFO - Epoch [27/200], Train Loss: 0.3948
2024-03-28 22:20:38,544 - config - INFO - Validation Loss: 0.4458
2024-03-28 22:20:38,544 - config - INFO - Validation Acc: 0.8400
2024-03-28 22:20:38,573 - config - INFO - Epoch [28/200], Train Loss: 0.3864
2024-03-28 22:20:38,577 - config - INFO - Validation Loss: 0.4331
2024-03-28 22:20:38,577 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:38,608 - config - INFO - Epoch [29/200], Train Loss: 0.3887
2024-03-28 22:20:38,613 - config - INFO - Validation Loss: 0.4330
2024-03-28 22:20:38,613 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:38,642 - config - INFO - Epoch [30/200], Train Loss: 0.3852
2024-03-28 22:20:38,647 - config - INFO - Validation Loss: 0.4337
2024-03-28 22:20:38,647 - config - INFO - Validation Acc: 0.8600
2024-03-28 22:20:38,677 - config - INFO - Epoch [31/200], Train Loss: 0.3854
2024-03-28 22:20:38,681 - config - INFO - Validation Loss: 0.4314
2024-03-28 22:20:38,681 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:20:38,711 - config - INFO - Epoch [32/200], Train Loss: 0.3837
2024-03-28 22:20:38,716 - config - INFO - Validation Loss: 0.4294
2024-03-28 22:20:38,716 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:20:38,747 - config - INFO - Epoch [33/200], Train Loss: 0.3832
2024-03-28 22:20:38,752 - config - INFO - Validation Loss: 0.4296
2024-03-28 22:20:38,752 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:38,782 - config - INFO - Epoch [34/200], Train Loss: 0.3817
2024-03-28 22:20:38,786 - config - INFO - Validation Loss: 0.4340
2024-03-28 22:20:38,786 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:20:38,815 - config - INFO - Epoch [35/200], Train Loss: 0.3830
2024-03-28 22:20:38,819 - config - INFO - Validation Loss: 0.4336
2024-03-28 22:20:38,825 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:20:38,859 - config - INFO - Epoch [36/200], Train Loss: 0.3816
2024-03-28 22:20:38,864 - config - INFO - Validation Loss: 0.4338
2024-03-28 22:20:38,864 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:20:38,899 - config - INFO - Epoch [37/200], Train Loss: 0.3804
2024-03-28 22:20:38,904 - config - INFO - Validation Loss: 0.4342
2024-03-28 22:20:38,904 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:38,933 - config - INFO - Epoch [38/200], Train Loss: 0.3793
2024-03-28 22:20:38,937 - config - INFO - Validation Loss: 0.4406
2024-03-28 22:20:38,937 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:20:38,966 - config - INFO - Epoch [39/200], Train Loss: 0.3805
2024-03-28 22:20:38,971 - config - INFO - Validation Loss: 0.4396
2024-03-28 22:20:38,971 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:38,999 - config - INFO - Epoch [40/200], Train Loss: 0.3797
2024-03-28 22:20:39,004 - config - INFO - Validation Loss: 0.4364
2024-03-28 22:20:39,004 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:39,034 - config - INFO - Epoch [41/200], Train Loss: 0.3770
2024-03-28 22:20:39,038 - config - INFO - Validation Loss: 0.4433
2024-03-28 22:20:39,039 - config - INFO - Validation Acc: 0.8400
2024-03-28 22:20:39,072 - config - INFO - Epoch [42/200], Train Loss: 0.3797
2024-03-28 22:20:39,077 - config - INFO - Validation Loss: 0.4440
2024-03-28 22:20:39,077 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:20:39,111 - config - INFO - Epoch [43/200], Train Loss: 0.3769
2024-03-28 22:20:39,116 - config - INFO - Validation Loss: 0.4391
2024-03-28 22:20:39,116 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:39,149 - config - INFO - Epoch [44/200], Train Loss: 0.3805
2024-03-28 22:20:39,154 - config - INFO - Validation Loss: 0.4432
2024-03-28 22:20:39,155 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:39,188 - config - INFO - Epoch [45/200], Train Loss: 0.3788
2024-03-28 22:20:39,193 - config - INFO - Validation Loss: 0.4392
2024-03-28 22:20:39,193 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:39,227 - config - INFO - Epoch [46/200], Train Loss: 0.3762
2024-03-28 22:20:39,232 - config - INFO - Validation Loss: 0.4384
2024-03-28 22:20:39,232 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:20:39,266 - config - INFO - Epoch [47/200], Train Loss: 0.3748
2024-03-28 22:20:39,271 - config - INFO - Validation Loss: 0.4350
2024-03-28 22:20:39,271 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:20:39,305 - config - INFO - Epoch [48/200], Train Loss: 0.3737
2024-03-28 22:20:39,310 - config - INFO - Validation Loss: 0.4361
2024-03-28 22:20:39,310 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:20:39,343 - config - INFO - Epoch [49/200], Train Loss: 0.3732
2024-03-28 22:20:39,348 - config - INFO - Validation Loss: 0.4312
2024-03-28 22:20:39,348 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:20:39,390 - config - INFO - Epoch [50/200], Train Loss: 0.3736
2024-03-28 22:20:39,395 - config - INFO - Validation Loss: 0.4308
2024-03-28 22:20:39,396 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:20:39,429 - config - INFO - Epoch [51/200], Train Loss: 0.3727
2024-03-28 22:20:39,434 - config - INFO - Validation Loss: 0.4370
2024-03-28 22:20:39,434 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:20:39,467 - config - INFO - Epoch [52/200], Train Loss: 0.3718
2024-03-28 22:20:39,472 - config - INFO - Validation Loss: 0.4372
2024-03-28 22:20:39,472 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:20:39,506 - config - INFO - Epoch [53/200], Train Loss: 0.3719
2024-03-28 22:20:39,511 - config - INFO - Validation Loss: 0.4345
2024-03-28 22:20:39,511 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:39,544 - config - INFO - Epoch [54/200], Train Loss: 0.3711
2024-03-28 22:20:39,549 - config - INFO - Validation Loss: 0.4349
2024-03-28 22:20:39,549 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:39,582 - config - INFO - Epoch [55/200], Train Loss: 0.3698
2024-03-28 22:20:39,587 - config - INFO - Validation Loss: 0.4380
2024-03-28 22:20:39,587 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:39,620 - config - INFO - Epoch [56/200], Train Loss: 0.3697
2024-03-28 22:20:39,625 - config - INFO - Validation Loss: 0.4364
2024-03-28 22:20:39,626 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:39,659 - config - INFO - Epoch [57/200], Train Loss: 0.3687
2024-03-28 22:20:39,664 - config - INFO - Validation Loss: 0.4435
2024-03-28 22:20:39,664 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:39,697 - config - INFO - Epoch [58/200], Train Loss: 0.3686
2024-03-28 22:20:39,702 - config - INFO - Validation Loss: 0.4400
2024-03-28 22:20:39,702 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:39,736 - config - INFO - Epoch [59/200], Train Loss: 0.3675
2024-03-28 22:20:39,741 - config - INFO - Validation Loss: 0.4391
2024-03-28 22:20:39,741 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:39,773 - config - INFO - Epoch [60/200], Train Loss: 0.3675
2024-03-28 22:20:39,778 - config - INFO - Validation Loss: 0.4413
2024-03-28 22:20:39,778 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:39,808 - config - INFO - Epoch [61/200], Train Loss: 0.3672
2024-03-28 22:20:39,812 - config - INFO - Validation Loss: 0.4397
2024-03-28 22:20:39,812 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:39,841 - config - INFO - Epoch [62/200], Train Loss: 0.3676
2024-03-28 22:20:39,845 - config - INFO - Validation Loss: 0.4397
2024-03-28 22:20:39,845 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:39,874 - config - INFO - Epoch [63/200], Train Loss: 0.3662
2024-03-28 22:20:39,878 - config - INFO - Validation Loss: 0.4375
2024-03-28 22:20:39,878 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:39,906 - config - INFO - Epoch [64/200], Train Loss: 0.3657
2024-03-28 22:20:39,911 - config - INFO - Validation Loss: 0.4385
2024-03-28 22:20:39,911 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:39,939 - config - INFO - Epoch [65/200], Train Loss: 0.3642
2024-03-28 22:20:39,944 - config - INFO - Validation Loss: 0.4423
2024-03-28 22:20:39,944 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:39,972 - config - INFO - Epoch [66/200], Train Loss: 0.3648
2024-03-28 22:20:39,976 - config - INFO - Validation Loss: 0.4424
2024-03-28 22:20:39,976 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:40,005 - config - INFO - Epoch [67/200], Train Loss: 0.3626
2024-03-28 22:20:40,009 - config - INFO - Validation Loss: 0.4402
2024-03-28 22:20:40,009 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:40,038 - config - INFO - Epoch [68/200], Train Loss: 0.3639
2024-03-28 22:20:40,042 - config - INFO - Validation Loss: 0.4374
2024-03-28 22:20:40,042 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:40,070 - config - INFO - Epoch [69/200], Train Loss: 0.3635
2024-03-28 22:20:40,075 - config - INFO - Validation Loss: 0.4386
2024-03-28 22:20:40,075 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:40,103 - config - INFO - Epoch [70/200], Train Loss: 0.3622
2024-03-28 22:20:40,107 - config - INFO - Validation Loss: 0.4413
2024-03-28 22:20:40,108 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:40,136 - config - INFO - Epoch [71/200], Train Loss: 0.3621
2024-03-28 22:20:40,140 - config - INFO - Validation Loss: 0.4416
2024-03-28 22:20:40,140 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:40,169 - config - INFO - Epoch [72/200], Train Loss: 0.3659
2024-03-28 22:20:40,173 - config - INFO - Validation Loss: 0.4428
2024-03-28 22:20:40,173 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:40,202 - config - INFO - Epoch [73/200], Train Loss: 0.3642
2024-03-28 22:20:40,206 - config - INFO - Validation Loss: 0.4477
2024-03-28 22:20:40,206 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:20:40,235 - config - INFO - Epoch [74/200], Train Loss: 0.3619
2024-03-28 22:20:40,240 - config - INFO - Validation Loss: 0.4373
2024-03-28 22:20:40,240 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:40,268 - config - INFO - Epoch [75/200], Train Loss: 0.3607
2024-03-28 22:20:40,273 - config - INFO - Validation Loss: 0.4318
2024-03-28 22:20:40,273 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:40,304 - config - INFO - Epoch [76/200], Train Loss: 0.3609
2024-03-28 22:20:40,309 - config - INFO - Validation Loss: 0.4372
2024-03-28 22:20:40,309 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:40,337 - config - INFO - Epoch [77/200], Train Loss: 0.3596
2024-03-28 22:20:40,342 - config - INFO - Validation Loss: 0.4371
2024-03-28 22:20:40,342 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:40,370 - config - INFO - Epoch [78/200], Train Loss: 0.3630
2024-03-28 22:20:40,383 - config - INFO - Validation Loss: 0.4439
2024-03-28 22:20:40,384 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:20:40,417 - config - INFO - Epoch [79/200], Train Loss: 0.3588
2024-03-28 22:20:40,422 - config - INFO - Validation Loss: 0.4384
2024-03-28 22:20:40,422 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:40,455 - config - INFO - Epoch [80/200], Train Loss: 0.3576
2024-03-28 22:20:40,460 - config - INFO - Validation Loss: 0.4403
2024-03-28 22:20:40,460 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:40,493 - config - INFO - Epoch [81/200], Train Loss: 0.3579
2024-03-28 22:20:40,498 - config - INFO - Validation Loss: 0.4433
2024-03-28 22:20:40,498 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:40,531 - config - INFO - Epoch [82/200], Train Loss: 0.3579
2024-03-28 22:20:40,536 - config - INFO - Validation Loss: 0.4427
2024-03-28 22:20:40,536 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:40,569 - config - INFO - Epoch [83/200], Train Loss: 0.3561
2024-03-28 22:20:40,574 - config - INFO - Validation Loss: 0.4435
2024-03-28 22:20:40,574 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:40,607 - config - INFO - Epoch [84/200], Train Loss: 0.3584
2024-03-28 22:20:40,612 - config - INFO - Validation Loss: 0.4424
2024-03-28 22:20:40,612 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:20:40,645 - config - INFO - Epoch [85/200], Train Loss: 0.3565
2024-03-28 22:20:40,650 - config - INFO - Validation Loss: 0.4371
2024-03-28 22:20:40,650 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:40,683 - config - INFO - Epoch [86/200], Train Loss: 0.3565
2024-03-28 22:20:40,688 - config - INFO - Validation Loss: 0.4390
2024-03-28 22:20:40,688 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:40,721 - config - INFO - Epoch [87/200], Train Loss: 0.3554
2024-03-28 22:20:40,726 - config - INFO - Validation Loss: 0.4419
2024-03-28 22:20:40,726 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:40,759 - config - INFO - Epoch [88/200], Train Loss: 0.3542
2024-03-28 22:20:40,764 - config - INFO - Validation Loss: 0.4443
2024-03-28 22:20:40,764 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:40,797 - config - INFO - Epoch [89/200], Train Loss: 0.3542
2024-03-28 22:20:40,801 - config - INFO - Validation Loss: 0.4418
2024-03-28 22:20:40,802 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:40,834 - config - INFO - Epoch [90/200], Train Loss: 0.3539
2024-03-28 22:20:40,838 - config - INFO - Validation Loss: 0.4372
2024-03-28 22:20:40,838 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:40,866 - config - INFO - Epoch [91/200], Train Loss: 0.3529
2024-03-28 22:20:40,870 - config - INFO - Validation Loss: 0.4350
2024-03-28 22:20:40,870 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:40,898 - config - INFO - Epoch [92/200], Train Loss: 0.3524
2024-03-28 22:20:40,902 - config - INFO - Validation Loss: 0.4397
2024-03-28 22:20:40,903 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:40,931 - config - INFO - Epoch [93/200], Train Loss: 0.3552
2024-03-28 22:20:40,935 - config - INFO - Validation Loss: 0.4432
2024-03-28 22:20:40,935 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:20:40,963 - config - INFO - Epoch [94/200], Train Loss: 0.3504
2024-03-28 22:20:40,967 - config - INFO - Validation Loss: 0.4367
2024-03-28 22:20:40,967 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:40,995 - config - INFO - Epoch [95/200], Train Loss: 0.3522
2024-03-28 22:20:40,999 - config - INFO - Validation Loss: 0.4387
2024-03-28 22:20:40,999 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:41,027 - config - INFO - Epoch [96/200], Train Loss: 0.3522
2024-03-28 22:20:41,031 - config - INFO - Validation Loss: 0.4419
2024-03-28 22:20:41,032 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:41,060 - config - INFO - Epoch [97/200], Train Loss: 0.3538
2024-03-28 22:20:41,064 - config - INFO - Validation Loss: 0.4397
2024-03-28 22:20:41,064 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:41,092 - config - INFO - Epoch [98/200], Train Loss: 0.3492
2024-03-28 22:20:41,096 - config - INFO - Validation Loss: 0.4398
2024-03-28 22:20:41,096 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:41,124 - config - INFO - Epoch [99/200], Train Loss: 0.3492
2024-03-28 22:20:41,128 - config - INFO - Validation Loss: 0.4374
2024-03-28 22:20:41,128 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:41,156 - config - INFO - Epoch [100/200], Train Loss: 0.3482
2024-03-28 22:20:41,160 - config - INFO - Validation Loss: 0.4423
2024-03-28 22:20:41,161 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:41,189 - config - INFO - Epoch [101/200], Train Loss: 0.3485
2024-03-28 22:20:41,193 - config - INFO - Validation Loss: 0.4433
2024-03-28 22:20:41,193 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:41,221 - config - INFO - Epoch [102/200], Train Loss: 0.3471
2024-03-28 22:20:41,225 - config - INFO - Validation Loss: 0.4436
2024-03-28 22:20:41,225 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:41,253 - config - INFO - Epoch [103/200], Train Loss: 0.3461
2024-03-28 22:20:41,257 - config - INFO - Validation Loss: 0.4443
2024-03-28 22:20:41,257 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:41,285 - config - INFO - Epoch [104/200], Train Loss: 0.3469
2024-03-28 22:20:41,289 - config - INFO - Validation Loss: 0.4427
2024-03-28 22:20:41,290 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:41,318 - config - INFO - Epoch [105/200], Train Loss: 0.3465
2024-03-28 22:20:41,322 - config - INFO - Validation Loss: 0.4484
2024-03-28 22:20:41,322 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:41,350 - config - INFO - Epoch [106/200], Train Loss: 0.3451
2024-03-28 22:20:41,354 - config - INFO - Validation Loss: 0.4470
2024-03-28 22:20:41,354 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:41,389 - config - INFO - Epoch [107/200], Train Loss: 0.3483
2024-03-28 22:20:41,394 - config - INFO - Validation Loss: 0.4499
2024-03-28 22:20:41,394 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:41,428 - config - INFO - Epoch [108/200], Train Loss: 0.3529
2024-03-28 22:20:41,433 - config - INFO - Validation Loss: 0.4593
2024-03-28 22:20:41,434 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:20:41,463 - config - INFO - Epoch [109/200], Train Loss: 0.3465
2024-03-28 22:20:41,467 - config - INFO - Validation Loss: 0.4408
2024-03-28 22:20:41,467 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:41,496 - config - INFO - Epoch [110/200], Train Loss: 0.3467
2024-03-28 22:20:41,500 - config - INFO - Validation Loss: 0.4424
2024-03-28 22:20:41,500 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:41,528 - config - INFO - Epoch [111/200], Train Loss: 0.3454
2024-03-28 22:20:41,532 - config - INFO - Validation Loss: 0.4468
2024-03-28 22:20:41,533 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:41,561 - config - INFO - Epoch [112/200], Train Loss: 0.3452
2024-03-28 22:20:41,565 - config - INFO - Validation Loss: 0.4458
2024-03-28 22:20:41,565 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:41,593 - config - INFO - Epoch [113/200], Train Loss: 0.3428
2024-03-28 22:20:41,598 - config - INFO - Validation Loss: 0.4449
2024-03-28 22:20:41,598 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:41,626 - config - INFO - Epoch [114/200], Train Loss: 0.3428
2024-03-28 22:20:41,630 - config - INFO - Validation Loss: 0.4453
2024-03-28 22:20:41,630 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:41,659 - config - INFO - Epoch [115/200], Train Loss: 0.3421
2024-03-28 22:20:41,663 - config - INFO - Validation Loss: 0.4482
2024-03-28 22:20:41,663 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:41,691 - config - INFO - Epoch [116/200], Train Loss: 0.3418
2024-03-28 22:20:41,695 - config - INFO - Validation Loss: 0.4497
2024-03-28 22:20:41,695 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:41,724 - config - INFO - Epoch [117/200], Train Loss: 0.3421
2024-03-28 22:20:41,728 - config - INFO - Validation Loss: 0.4465
2024-03-28 22:20:41,728 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:41,756 - config - INFO - Epoch [118/200], Train Loss: 0.3409
2024-03-28 22:20:41,761 - config - INFO - Validation Loss: 0.4462
2024-03-28 22:20:41,761 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:41,789 - config - INFO - Epoch [119/200], Train Loss: 0.3409
2024-03-28 22:20:41,793 - config - INFO - Validation Loss: 0.4423
2024-03-28 22:20:41,793 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:41,822 - config - INFO - Epoch [120/200], Train Loss: 0.3404
2024-03-28 22:20:41,826 - config - INFO - Validation Loss: 0.4466
2024-03-28 22:20:41,826 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:41,854 - config - INFO - Epoch [121/200], Train Loss: 0.3398
2024-03-28 22:20:41,858 - config - INFO - Validation Loss: 0.4506
2024-03-28 22:20:41,858 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:41,887 - config - INFO - Epoch [122/200], Train Loss: 0.3392
2024-03-28 22:20:41,891 - config - INFO - Validation Loss: 0.4507
2024-03-28 22:20:41,891 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:41,919 - config - INFO - Epoch [123/200], Train Loss: 0.3384
2024-03-28 22:20:41,923 - config - INFO - Validation Loss: 0.4458
2024-03-28 22:20:41,923 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:41,952 - config - INFO - Epoch [124/200], Train Loss: 0.3383
2024-03-28 22:20:41,956 - config - INFO - Validation Loss: 0.4494
2024-03-28 22:20:41,956 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:20:41,985 - config - INFO - Epoch [125/200], Train Loss: 0.3412
2024-03-28 22:20:41,989 - config - INFO - Validation Loss: 0.4414
2024-03-28 22:20:41,989 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:42,017 - config - INFO - Epoch [126/200], Train Loss: 0.3401
2024-03-28 22:20:42,021 - config - INFO - Validation Loss: 0.4455
2024-03-28 22:20:42,021 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:42,050 - config - INFO - Epoch [127/200], Train Loss: 0.3377
2024-03-28 22:20:42,054 - config - INFO - Validation Loss: 0.4445
2024-03-28 22:20:42,054 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:42,082 - config - INFO - Epoch [128/200], Train Loss: 0.3362
2024-03-28 22:20:42,086 - config - INFO - Validation Loss: 0.4490
2024-03-28 22:20:42,087 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:42,115 - config - INFO - Epoch [129/200], Train Loss: 0.3374
2024-03-28 22:20:42,119 - config - INFO - Validation Loss: 0.4516
2024-03-28 22:20:42,119 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:42,147 - config - INFO - Epoch [130/200], Train Loss: 0.3397
2024-03-28 22:20:42,151 - config - INFO - Validation Loss: 0.4484
2024-03-28 22:20:42,152 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:20:42,180 - config - INFO - Epoch [131/200], Train Loss: 0.3364
2024-03-28 22:20:42,184 - config - INFO - Validation Loss: 0.4494
2024-03-28 22:20:42,184 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:20:42,212 - config - INFO - Epoch [132/200], Train Loss: 0.3387
2024-03-28 22:20:42,217 - config - INFO - Validation Loss: 0.4428
2024-03-28 22:20:42,217 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:20:42,245 - config - INFO - Epoch [133/200], Train Loss: 0.3360
2024-03-28 22:20:42,249 - config - INFO - Validation Loss: 0.4433
2024-03-28 22:20:42,249 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:42,278 - config - INFO - Epoch [134/200], Train Loss: 0.3356
2024-03-28 22:20:42,282 - config - INFO - Validation Loss: 0.4514
2024-03-28 22:20:42,282 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:42,310 - config - INFO - Epoch [135/200], Train Loss: 0.3373
2024-03-28 22:20:42,314 - config - INFO - Validation Loss: 0.4553
2024-03-28 22:20:42,314 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:42,343 - config - INFO - Epoch [136/200], Train Loss: 0.3400
2024-03-28 22:20:42,347 - config - INFO - Validation Loss: 0.4568
2024-03-28 22:20:42,347 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:42,375 - config - INFO - Epoch [137/200], Train Loss: 0.3387
2024-03-28 22:20:42,379 - config - INFO - Validation Loss: 0.4562
2024-03-28 22:20:42,380 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:42,411 - config - INFO - Epoch [138/200], Train Loss: 0.3398
2024-03-28 22:20:42,415 - config - INFO - Validation Loss: 0.4513
2024-03-28 22:20:42,415 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:42,443 - config - INFO - Epoch [139/200], Train Loss: 0.3330
2024-03-28 22:20:42,448 - config - INFO - Validation Loss: 0.4455
2024-03-28 22:20:42,448 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:42,476 - config - INFO - Epoch [140/200], Train Loss: 0.3414
2024-03-28 22:20:42,480 - config - INFO - Validation Loss: 0.4483
2024-03-28 22:20:42,480 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:42,509 - config - INFO - Epoch [141/200], Train Loss: 0.3359
2024-03-28 22:20:42,513 - config - INFO - Validation Loss: 0.4542
2024-03-28 22:20:42,513 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:42,541 - config - INFO - Epoch [142/200], Train Loss: 0.3375
2024-03-28 22:20:42,545 - config - INFO - Validation Loss: 0.4495
2024-03-28 22:20:42,545 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:42,573 - config - INFO - Epoch [143/200], Train Loss: 0.3308
2024-03-28 22:20:42,578 - config - INFO - Validation Loss: 0.4503
2024-03-28 22:20:42,578 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:42,606 - config - INFO - Epoch [144/200], Train Loss: 0.3329
2024-03-28 22:20:42,610 - config - INFO - Validation Loss: 0.4535
2024-03-28 22:20:42,610 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:20:42,638 - config - INFO - Epoch [145/200], Train Loss: 0.3331
2024-03-28 22:20:42,643 - config - INFO - Validation Loss: 0.4508
2024-03-28 22:20:42,643 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:42,671 - config - INFO - Epoch [146/200], Train Loss: 0.3339
2024-03-28 22:20:42,675 - config - INFO - Validation Loss: 0.4570
2024-03-28 22:20:42,675 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:42,703 - config - INFO - Epoch [147/200], Train Loss: 0.3328
2024-03-28 22:20:42,708 - config - INFO - Validation Loss: 0.4490
2024-03-28 22:20:42,708 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:42,736 - config - INFO - Epoch [148/200], Train Loss: 0.3316
2024-03-28 22:20:42,740 - config - INFO - Validation Loss: 0.4536
2024-03-28 22:20:42,740 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:42,768 - config - INFO - Epoch [149/200], Train Loss: 0.3293
2024-03-28 22:20:42,773 - config - INFO - Validation Loss: 0.4558
2024-03-28 22:20:42,773 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:42,801 - config - INFO - Epoch [150/200], Train Loss: 0.3296
2024-03-28 22:20:42,805 - config - INFO - Validation Loss: 0.4520
2024-03-28 22:20:42,805 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:42,833 - config - INFO - Epoch [151/200], Train Loss: 0.3296
2024-03-28 22:20:42,838 - config - INFO - Validation Loss: 0.4485
2024-03-28 22:20:42,838 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:42,866 - config - INFO - Epoch [152/200], Train Loss: 0.3339
2024-03-28 22:20:42,870 - config - INFO - Validation Loss: 0.4562
2024-03-28 22:20:42,870 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:20:42,899 - config - INFO - Epoch [153/200], Train Loss: 0.3336
2024-03-28 22:20:42,903 - config - INFO - Validation Loss: 0.4610
2024-03-28 22:20:42,903 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:20:42,903 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 22:22:38,546 - config - INFO - resume: None
2024-03-28 22:22:38,546 - config - INFO - device: cpu
2024-03-28 22:22:38,546 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:22:38,546 - config - INFO - learning_rate: 0.001
2024-03-28 22:22:38,546 - config - INFO - num_epochs: 200
2024-03-28 22:22:38,546 - config - INFO - batch_size: 64
2024-03-28 22:22:38,546 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.03

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:22:38,568 - config - INFO - Dataset size: 891
2024-03-28 22:22:38,591 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=self.config.batch_size)
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs = batch['features']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(test_dataloader)
        self.logger.info(f"test Loss: {val_loss:.4f}")
        predictions = (outputs > threshold).float()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1242)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions})

        # Save DataFrame with no index
        df.to_csv('predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 22:22:38,591 - config - INFO - Training start
2024-03-28 22:22:40,902 - config - INFO - Epoch [1/200], Train Loss: 0.6951
2024-03-28 22:22:40,908 - config - INFO - Validation Loss: 0.6667
2024-03-28 22:22:40,908 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:22:40,945 - config - INFO - Epoch [2/200], Train Loss: 0.6478
2024-03-28 22:22:40,950 - config - INFO - Validation Loss: 0.6212
2024-03-28 22:22:40,950 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:22:40,987 - config - INFO - Epoch [3/200], Train Loss: 0.6031
2024-03-28 22:22:40,992 - config - INFO - Validation Loss: 0.5707
2024-03-28 22:22:40,992 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:22:41,029 - config - INFO - Epoch [4/200], Train Loss: 0.5591
2024-03-28 22:22:41,034 - config - INFO - Validation Loss: 0.5248
2024-03-28 22:22:41,034 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:22:41,069 - config - INFO - Epoch [5/200], Train Loss: 0.5184
2024-03-28 22:22:41,074 - config - INFO - Validation Loss: 0.4779
2024-03-28 22:22:41,074 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:22:41,109 - config - INFO - Epoch [6/200], Train Loss: 0.4817
2024-03-28 22:22:41,114 - config - INFO - Validation Loss: 0.4416
2024-03-28 22:22:41,114 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:41,147 - config - INFO - Epoch [7/200], Train Loss: 0.4605
2024-03-28 22:22:41,153 - config - INFO - Validation Loss: 0.4196
2024-03-28 22:22:41,153 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:41,187 - config - INFO - Epoch [8/200], Train Loss: 0.4509
2024-03-28 22:22:41,192 - config - INFO - Validation Loss: 0.4093
2024-03-28 22:22:41,192 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:41,228 - config - INFO - Epoch [9/200], Train Loss: 0.4432
2024-03-28 22:22:41,233 - config - INFO - Validation Loss: 0.4043
2024-03-28 22:22:41,233 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:41,264 - config - INFO - Epoch [10/200], Train Loss: 0.4370
2024-03-28 22:22:41,268 - config - INFO - Validation Loss: 0.4009
2024-03-28 22:22:41,268 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:41,299 - config - INFO - Epoch [11/200], Train Loss: 0.4318
2024-03-28 22:22:41,303 - config - INFO - Validation Loss: 0.3985
2024-03-28 22:22:41,303 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:41,333 - config - INFO - Epoch [12/200], Train Loss: 0.4296
2024-03-28 22:22:41,337 - config - INFO - Validation Loss: 0.3980
2024-03-28 22:22:41,338 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:41,387 - config - INFO - Epoch [13/200], Train Loss: 0.4269
2024-03-28 22:22:41,391 - config - INFO - Validation Loss: 0.3955
2024-03-28 22:22:41,391 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:22:41,415 - config - INFO - Epoch [14/200], Train Loss: 0.4228
2024-03-28 22:22:41,418 - config - INFO - Validation Loss: 0.3935
2024-03-28 22:22:41,418 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:41,442 - config - INFO - Epoch [15/200], Train Loss: 0.4201
2024-03-28 22:22:41,446 - config - INFO - Validation Loss: 0.3940
2024-03-28 22:22:41,446 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:41,470 - config - INFO - Epoch [16/200], Train Loss: 0.4212
2024-03-28 22:22:41,474 - config - INFO - Validation Loss: 0.3927
2024-03-28 22:22:41,474 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:22:41,498 - config - INFO - Epoch [17/200], Train Loss: 0.4172
2024-03-28 22:22:41,502 - config - INFO - Validation Loss: 0.3962
2024-03-28 22:22:41,502 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:41,526 - config - INFO - Epoch [18/200], Train Loss: 0.4145
2024-03-28 22:22:41,530 - config - INFO - Validation Loss: 0.3935
2024-03-28 22:22:41,530 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:22:41,554 - config - INFO - Epoch [19/200], Train Loss: 0.4123
2024-03-28 22:22:41,557 - config - INFO - Validation Loss: 0.3928
2024-03-28 22:22:41,558 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:41,582 - config - INFO - Epoch [20/200], Train Loss: 0.4114
2024-03-28 22:22:41,585 - config - INFO - Validation Loss: 0.3964
2024-03-28 22:22:41,585 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:41,610 - config - INFO - Epoch [21/200], Train Loss: 0.4091
2024-03-28 22:22:41,613 - config - INFO - Validation Loss: 0.3930
2024-03-28 22:22:41,613 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:41,638 - config - INFO - Epoch [22/200], Train Loss: 0.4073
2024-03-28 22:22:41,641 - config - INFO - Validation Loss: 0.3897
2024-03-28 22:22:41,641 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:22:41,666 - config - INFO - Epoch [23/200], Train Loss: 0.4072
2024-03-28 22:22:41,669 - config - INFO - Validation Loss: 0.3881
2024-03-28 22:22:41,669 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:22:41,693 - config - INFO - Epoch [24/200], Train Loss: 0.4045
2024-03-28 22:22:41,697 - config - INFO - Validation Loss: 0.3873
2024-03-28 22:22:41,697 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:22:41,722 - config - INFO - Epoch [25/200], Train Loss: 0.4027
2024-03-28 22:22:41,726 - config - INFO - Validation Loss: 0.3877
2024-03-28 22:22:41,726 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:22:41,755 - config - INFO - Epoch [26/200], Train Loss: 0.4019
2024-03-28 22:22:41,759 - config - INFO - Validation Loss: 0.3899
2024-03-28 22:22:41,759 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:41,787 - config - INFO - Epoch [27/200], Train Loss: 0.4010
2024-03-28 22:22:41,791 - config - INFO - Validation Loss: 0.3889
2024-03-28 22:22:41,792 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:22:41,819 - config - INFO - Epoch [28/200], Train Loss: 0.3999
2024-03-28 22:22:41,823 - config - INFO - Validation Loss: 0.3877
2024-03-28 22:22:41,824 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:22:41,853 - config - INFO - Epoch [29/200], Train Loss: 0.3994
2024-03-28 22:22:41,857 - config - INFO - Validation Loss: 0.3916
2024-03-28 22:22:41,857 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:41,885 - config - INFO - Epoch [30/200], Train Loss: 0.3996
2024-03-28 22:22:41,890 - config - INFO - Validation Loss: 0.3962
2024-03-28 22:22:41,890 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:41,918 - config - INFO - Epoch [31/200], Train Loss: 0.3965
2024-03-28 22:22:41,922 - config - INFO - Validation Loss: 0.3925
2024-03-28 22:22:41,922 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:41,950 - config - INFO - Epoch [32/200], Train Loss: 0.3970
2024-03-28 22:22:41,954 - config - INFO - Validation Loss: 0.3897
2024-03-28 22:22:41,954 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:41,983 - config - INFO - Epoch [33/200], Train Loss: 0.3954
2024-03-28 22:22:41,987 - config - INFO - Validation Loss: 0.3885
2024-03-28 22:22:41,987 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,015 - config - INFO - Epoch [34/200], Train Loss: 0.3935
2024-03-28 22:22:42,019 - config - INFO - Validation Loss: 0.3899
2024-03-28 22:22:42,019 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,047 - config - INFO - Epoch [35/200], Train Loss: 0.3925
2024-03-28 22:22:42,052 - config - INFO - Validation Loss: 0.3896
2024-03-28 22:22:42,052 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,080 - config - INFO - Epoch [36/200], Train Loss: 0.3925
2024-03-28 22:22:42,084 - config - INFO - Validation Loss: 0.3888
2024-03-28 22:22:42,084 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,112 - config - INFO - Epoch [37/200], Train Loss: 0.3914
2024-03-28 22:22:42,116 - config - INFO - Validation Loss: 0.3934
2024-03-28 22:22:42,116 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,144 - config - INFO - Epoch [38/200], Train Loss: 0.3915
2024-03-28 22:22:42,148 - config - INFO - Validation Loss: 0.3913
2024-03-28 22:22:42,149 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,177 - config - INFO - Epoch [39/200], Train Loss: 0.3899
2024-03-28 22:22:42,181 - config - INFO - Validation Loss: 0.3925
2024-03-28 22:22:42,181 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,209 - config - INFO - Epoch [40/200], Train Loss: 0.3898
2024-03-28 22:22:42,213 - config - INFO - Validation Loss: 0.3949
2024-03-28 22:22:42,213 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,241 - config - INFO - Epoch [41/200], Train Loss: 0.3885
2024-03-28 22:22:42,246 - config - INFO - Validation Loss: 0.3914
2024-03-28 22:22:42,246 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,274 - config - INFO - Epoch [42/200], Train Loss: 0.3867
2024-03-28 22:22:42,278 - config - INFO - Validation Loss: 0.3923
2024-03-28 22:22:42,278 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,306 - config - INFO - Epoch [43/200], Train Loss: 0.3877
2024-03-28 22:22:42,310 - config - INFO - Validation Loss: 0.3971
2024-03-28 22:22:42,310 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,339 - config - INFO - Epoch [44/200], Train Loss: 0.3882
2024-03-28 22:22:42,343 - config - INFO - Validation Loss: 0.3930
2024-03-28 22:22:42,343 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,371 - config - INFO - Epoch [45/200], Train Loss: 0.3881
2024-03-28 22:22:42,375 - config - INFO - Validation Loss: 0.3949
2024-03-28 22:22:42,375 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,403 - config - INFO - Epoch [46/200], Train Loss: 0.3852
2024-03-28 22:22:42,407 - config - INFO - Validation Loss: 0.3950
2024-03-28 22:22:42,408 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,436 - config - INFO - Epoch [47/200], Train Loss: 0.3839
2024-03-28 22:22:42,440 - config - INFO - Validation Loss: 0.3908
2024-03-28 22:22:42,440 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,468 - config - INFO - Epoch [48/200], Train Loss: 0.3827
2024-03-28 22:22:42,472 - config - INFO - Validation Loss: 0.3916
2024-03-28 22:22:42,472 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,500 - config - INFO - Epoch [49/200], Train Loss: 0.3843
2024-03-28 22:22:42,505 - config - INFO - Validation Loss: 0.3954
2024-03-28 22:22:42,505 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,533 - config - INFO - Epoch [50/200], Train Loss: 0.3814
2024-03-28 22:22:42,537 - config - INFO - Validation Loss: 0.3879
2024-03-28 22:22:42,537 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,565 - config - INFO - Epoch [51/200], Train Loss: 0.3836
2024-03-28 22:22:42,569 - config - INFO - Validation Loss: 0.3849
2024-03-28 22:22:42,570 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,598 - config - INFO - Epoch [52/200], Train Loss: 0.3814
2024-03-28 22:22:42,602 - config - INFO - Validation Loss: 0.3875
2024-03-28 22:22:42,602 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,630 - config - INFO - Epoch [53/200], Train Loss: 0.3800
2024-03-28 22:22:42,634 - config - INFO - Validation Loss: 0.3874
2024-03-28 22:22:42,634 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,662 - config - INFO - Epoch [54/200], Train Loss: 0.3798
2024-03-28 22:22:42,666 - config - INFO - Validation Loss: 0.3874
2024-03-28 22:22:42,667 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,695 - config - INFO - Epoch [55/200], Train Loss: 0.3806
2024-03-28 22:22:42,699 - config - INFO - Validation Loss: 0.3890
2024-03-28 22:22:42,699 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,727 - config - INFO - Epoch [56/200], Train Loss: 0.3784
2024-03-28 22:22:42,731 - config - INFO - Validation Loss: 0.3933
2024-03-28 22:22:42,731 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,759 - config - INFO - Epoch [57/200], Train Loss: 0.3785
2024-03-28 22:22:42,763 - config - INFO - Validation Loss: 0.3900
2024-03-28 22:22:42,764 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,791 - config - INFO - Epoch [58/200], Train Loss: 0.3784
2024-03-28 22:22:42,796 - config - INFO - Validation Loss: 0.3880
2024-03-28 22:22:42,796 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,824 - config - INFO - Epoch [59/200], Train Loss: 0.3767
2024-03-28 22:22:42,828 - config - INFO - Validation Loss: 0.3916
2024-03-28 22:22:42,828 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,863 - config - INFO - Epoch [60/200], Train Loss: 0.3759
2024-03-28 22:22:42,868 - config - INFO - Validation Loss: 0.3988
2024-03-28 22:22:42,868 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,896 - config - INFO - Epoch [61/200], Train Loss: 0.3758
2024-03-28 22:22:42,900 - config - INFO - Validation Loss: 0.3929
2024-03-28 22:22:42,900 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,928 - config - INFO - Epoch [62/200], Train Loss: 0.3766
2024-03-28 22:22:42,932 - config - INFO - Validation Loss: 0.3910
2024-03-28 22:22:42,932 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,960 - config - INFO - Epoch [63/200], Train Loss: 0.3763
2024-03-28 22:22:42,964 - config - INFO - Validation Loss: 0.3902
2024-03-28 22:22:42,965 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:42,993 - config - INFO - Epoch [64/200], Train Loss: 0.3737
2024-03-28 22:22:42,997 - config - INFO - Validation Loss: 0.3971
2024-03-28 22:22:42,997 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,025 - config - INFO - Epoch [65/200], Train Loss: 0.3766
2024-03-28 22:22:43,029 - config - INFO - Validation Loss: 0.3970
2024-03-28 22:22:43,029 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,057 - config - INFO - Epoch [66/200], Train Loss: 0.3759
2024-03-28 22:22:43,061 - config - INFO - Validation Loss: 0.3950
2024-03-28 22:22:43,061 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,090 - config - INFO - Epoch [67/200], Train Loss: 0.3733
2024-03-28 22:22:43,094 - config - INFO - Validation Loss: 0.3909
2024-03-28 22:22:43,094 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,122 - config - INFO - Epoch [68/200], Train Loss: 0.3744
2024-03-28 22:22:43,126 - config - INFO - Validation Loss: 0.3911
2024-03-28 22:22:43,126 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,154 - config - INFO - Epoch [69/200], Train Loss: 0.3712
2024-03-28 22:22:43,158 - config - INFO - Validation Loss: 0.3910
2024-03-28 22:22:43,158 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,186 - config - INFO - Epoch [70/200], Train Loss: 0.3725
2024-03-28 22:22:43,190 - config - INFO - Validation Loss: 0.3938
2024-03-28 22:22:43,191 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,218 - config - INFO - Epoch [71/200], Train Loss: 0.3699
2024-03-28 22:22:43,223 - config - INFO - Validation Loss: 0.3961
2024-03-28 22:22:43,223 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,251 - config - INFO - Epoch [72/200], Train Loss: 0.3711
2024-03-28 22:22:43,255 - config - INFO - Validation Loss: 0.4002
2024-03-28 22:22:43,255 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,283 - config - INFO - Epoch [73/200], Train Loss: 0.3701
2024-03-28 22:22:43,287 - config - INFO - Validation Loss: 0.4015
2024-03-28 22:22:43,287 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,315 - config - INFO - Epoch [74/200], Train Loss: 0.3709
2024-03-28 22:22:43,319 - config - INFO - Validation Loss: 0.3936
2024-03-28 22:22:43,319 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,347 - config - INFO - Epoch [75/200], Train Loss: 0.3693
2024-03-28 22:22:43,351 - config - INFO - Validation Loss: 0.3935
2024-03-28 22:22:43,351 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,379 - config - INFO - Epoch [76/200], Train Loss: 0.3677
2024-03-28 22:22:43,384 - config - INFO - Validation Loss: 0.3926
2024-03-28 22:22:43,384 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,411 - config - INFO - Epoch [77/200], Train Loss: 0.3696
2024-03-28 22:22:43,416 - config - INFO - Validation Loss: 0.3919
2024-03-28 22:22:43,416 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,444 - config - INFO - Epoch [78/200], Train Loss: 0.3661
2024-03-28 22:22:43,448 - config - INFO - Validation Loss: 0.3924
2024-03-28 22:22:43,448 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,476 - config - INFO - Epoch [79/200], Train Loss: 0.3674
2024-03-28 22:22:43,480 - config - INFO - Validation Loss: 0.3945
2024-03-28 22:22:43,480 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,508 - config - INFO - Epoch [80/200], Train Loss: 0.3668
2024-03-28 22:22:43,512 - config - INFO - Validation Loss: 0.3954
2024-03-28 22:22:43,512 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,540 - config - INFO - Epoch [81/200], Train Loss: 0.3646
2024-03-28 22:22:43,544 - config - INFO - Validation Loss: 0.3957
2024-03-28 22:22:43,544 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,572 - config - INFO - Epoch [82/200], Train Loss: 0.3652
2024-03-28 22:22:43,576 - config - INFO - Validation Loss: 0.3977
2024-03-28 22:22:43,576 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,604 - config - INFO - Epoch [83/200], Train Loss: 0.3668
2024-03-28 22:22:43,608 - config - INFO - Validation Loss: 0.4002
2024-03-28 22:22:43,609 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,636 - config - INFO - Epoch [84/200], Train Loss: 0.3657
2024-03-28 22:22:43,641 - config - INFO - Validation Loss: 0.4004
2024-03-28 22:22:43,641 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,669 - config - INFO - Epoch [85/200], Train Loss: 0.3640
2024-03-28 22:22:43,673 - config - INFO - Validation Loss: 0.3957
2024-03-28 22:22:43,673 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,701 - config - INFO - Epoch [86/200], Train Loss: 0.3625
2024-03-28 22:22:43,705 - config - INFO - Validation Loss: 0.4016
2024-03-28 22:22:43,705 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,733 - config - INFO - Epoch [87/200], Train Loss: 0.3645
2024-03-28 22:22:43,737 - config - INFO - Validation Loss: 0.4009
2024-03-28 22:22:43,738 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,765 - config - INFO - Epoch [88/200], Train Loss: 0.3617
2024-03-28 22:22:43,769 - config - INFO - Validation Loss: 0.3980
2024-03-28 22:22:43,770 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,797 - config - INFO - Epoch [89/200], Train Loss: 0.3616
2024-03-28 22:22:43,802 - config - INFO - Validation Loss: 0.4022
2024-03-28 22:22:43,802 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,829 - config - INFO - Epoch [90/200], Train Loss: 0.3633
2024-03-28 22:22:43,833 - config - INFO - Validation Loss: 0.3997
2024-03-28 22:22:43,834 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,878 - config - INFO - Epoch [91/200], Train Loss: 0.3605
2024-03-28 22:22:43,884 - config - INFO - Validation Loss: 0.3977
2024-03-28 22:22:43,884 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,916 - config - INFO - Epoch [92/200], Train Loss: 0.3604
2024-03-28 22:22:43,921 - config - INFO - Validation Loss: 0.3957
2024-03-28 22:22:43,921 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,954 - config - INFO - Epoch [93/200], Train Loss: 0.3655
2024-03-28 22:22:43,958 - config - INFO - Validation Loss: 0.3984
2024-03-28 22:22:43,958 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:43,991 - config - INFO - Epoch [94/200], Train Loss: 0.3627
2024-03-28 22:22:43,996 - config - INFO - Validation Loss: 0.3936
2024-03-28 22:22:43,996 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,028 - config - INFO - Epoch [95/200], Train Loss: 0.3613
2024-03-28 22:22:44,032 - config - INFO - Validation Loss: 0.3886
2024-03-28 22:22:44,033 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,065 - config - INFO - Epoch [96/200], Train Loss: 0.3597
2024-03-28 22:22:44,069 - config - INFO - Validation Loss: 0.3894
2024-03-28 22:22:44,070 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,102 - config - INFO - Epoch [97/200], Train Loss: 0.3586
2024-03-28 22:22:44,106 - config - INFO - Validation Loss: 0.3927
2024-03-28 22:22:44,107 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,140 - config - INFO - Epoch [98/200], Train Loss: 0.3584
2024-03-28 22:22:44,145 - config - INFO - Validation Loss: 0.3976
2024-03-28 22:22:44,145 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,177 - config - INFO - Epoch [99/200], Train Loss: 0.3586
2024-03-28 22:22:44,181 - config - INFO - Validation Loss: 0.3951
2024-03-28 22:22:44,181 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,208 - config - INFO - Epoch [100/200], Train Loss: 0.3581
2024-03-28 22:22:44,212 - config - INFO - Validation Loss: 0.3949
2024-03-28 22:22:44,213 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,240 - config - INFO - Epoch [101/200], Train Loss: 0.3592
2024-03-28 22:22:44,244 - config - INFO - Validation Loss: 0.3938
2024-03-28 22:22:44,244 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,272 - config - INFO - Epoch [102/200], Train Loss: 0.3599
2024-03-28 22:22:44,276 - config - INFO - Validation Loss: 0.3974
2024-03-28 22:22:44,276 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,303 - config - INFO - Epoch [103/200], Train Loss: 0.3553
2024-03-28 22:22:44,307 - config - INFO - Validation Loss: 0.3914
2024-03-28 22:22:44,308 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,335 - config - INFO - Epoch [104/200], Train Loss: 0.3593
2024-03-28 22:22:44,339 - config - INFO - Validation Loss: 0.3936
2024-03-28 22:22:44,339 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,367 - config - INFO - Epoch [105/200], Train Loss: 0.3551
2024-03-28 22:22:44,371 - config - INFO - Validation Loss: 0.3946
2024-03-28 22:22:44,371 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,399 - config - INFO - Epoch [106/200], Train Loss: 0.3577
2024-03-28 22:22:44,403 - config - INFO - Validation Loss: 0.4022
2024-03-28 22:22:44,403 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,430 - config - INFO - Epoch [107/200], Train Loss: 0.3567
2024-03-28 22:22:44,434 - config - INFO - Validation Loss: 0.3983
2024-03-28 22:22:44,434 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,462 - config - INFO - Epoch [108/200], Train Loss: 0.3565
2024-03-28 22:22:44,466 - config - INFO - Validation Loss: 0.3955
2024-03-28 22:22:44,466 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,494 - config - INFO - Epoch [109/200], Train Loss: 0.3580
2024-03-28 22:22:44,498 - config - INFO - Validation Loss: 0.3938
2024-03-28 22:22:44,498 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,526 - config - INFO - Epoch [110/200], Train Loss: 0.3555
2024-03-28 22:22:44,530 - config - INFO - Validation Loss: 0.3953
2024-03-28 22:22:44,531 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,558 - config - INFO - Epoch [111/200], Train Loss: 0.3538
2024-03-28 22:22:44,562 - config - INFO - Validation Loss: 0.3941
2024-03-28 22:22:44,562 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,590 - config - INFO - Epoch [112/200], Train Loss: 0.3557
2024-03-28 22:22:44,594 - config - INFO - Validation Loss: 0.3968
2024-03-28 22:22:44,595 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,624 - config - INFO - Epoch [113/200], Train Loss: 0.3540
2024-03-28 22:22:44,628 - config - INFO - Validation Loss: 0.3956
2024-03-28 22:22:44,629 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,660 - config - INFO - Epoch [114/200], Train Loss: 0.3542
2024-03-28 22:22:44,664 - config - INFO - Validation Loss: 0.3968
2024-03-28 22:22:44,664 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,694 - config - INFO - Epoch [115/200], Train Loss: 0.3532
2024-03-28 22:22:44,698 - config - INFO - Validation Loss: 0.3948
2024-03-28 22:22:44,699 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,726 - config - INFO - Epoch [116/200], Train Loss: 0.3532
2024-03-28 22:22:44,730 - config - INFO - Validation Loss: 0.3948
2024-03-28 22:22:44,730 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,758 - config - INFO - Epoch [117/200], Train Loss: 0.3515
2024-03-28 22:22:44,762 - config - INFO - Validation Loss: 0.3956
2024-03-28 22:22:44,762 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,789 - config - INFO - Epoch [118/200], Train Loss: 0.3507
2024-03-28 22:22:44,793 - config - INFO - Validation Loss: 0.4000
2024-03-28 22:22:44,793 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,821 - config - INFO - Epoch [119/200], Train Loss: 0.3505
2024-03-28 22:22:44,825 - config - INFO - Validation Loss: 0.3965
2024-03-28 22:22:44,825 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,853 - config - INFO - Epoch [120/200], Train Loss: 0.3516
2024-03-28 22:22:44,857 - config - INFO - Validation Loss: 0.4019
2024-03-28 22:22:44,857 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,885 - config - INFO - Epoch [121/200], Train Loss: 0.3498
2024-03-28 22:22:44,889 - config - INFO - Validation Loss: 0.3991
2024-03-28 22:22:44,889 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,917 - config - INFO - Epoch [122/200], Train Loss: 0.3504
2024-03-28 22:22:44,921 - config - INFO - Validation Loss: 0.4008
2024-03-28 22:22:44,921 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,948 - config - INFO - Epoch [123/200], Train Loss: 0.3502
2024-03-28 22:22:44,953 - config - INFO - Validation Loss: 0.4072
2024-03-28 22:22:44,953 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:44,980 - config - INFO - Epoch [124/200], Train Loss: 0.3515
2024-03-28 22:22:44,984 - config - INFO - Validation Loss: 0.4050
2024-03-28 22:22:44,985 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:45,013 - config - INFO - Epoch [125/200], Train Loss: 0.3492
2024-03-28 22:22:45,017 - config - INFO - Validation Loss: 0.3989
2024-03-28 22:22:45,017 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:45,045 - config - INFO - Epoch [126/200], Train Loss: 0.3516
2024-03-28 22:22:45,049 - config - INFO - Validation Loss: 0.4007
2024-03-28 22:22:45,050 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:45,077 - config - INFO - Epoch [127/200], Train Loss: 0.3495
2024-03-28 22:22:45,081 - config - INFO - Validation Loss: 0.3947
2024-03-28 22:22:45,082 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:45,110 - config - INFO - Epoch [128/200], Train Loss: 0.3497
2024-03-28 22:22:45,114 - config - INFO - Validation Loss: 0.3973
2024-03-28 22:22:45,115 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:22:45,142 - config - INFO - Epoch [129/200], Train Loss: 0.3484
2024-03-28 22:22:45,146 - config - INFO - Validation Loss: 0.4012
2024-03-28 22:22:45,146 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:45,174 - config - INFO - Epoch [130/200], Train Loss: 0.3469
2024-03-28 22:22:45,178 - config - INFO - Validation Loss: 0.3954
2024-03-28 22:22:45,178 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:45,206 - config - INFO - Epoch [131/200], Train Loss: 0.3492
2024-03-28 22:22:45,210 - config - INFO - Validation Loss: 0.3947
2024-03-28 22:22:45,210 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:45,238 - config - INFO - Epoch [132/200], Train Loss: 0.3487
2024-03-28 22:22:45,242 - config - INFO - Validation Loss: 0.3983
2024-03-28 22:22:45,242 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:22:45,270 - config - INFO - Epoch [133/200], Train Loss: 0.3483
2024-03-28 22:22:45,274 - config - INFO - Validation Loss: 0.4029
2024-03-28 22:22:45,274 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:45,302 - config - INFO - Epoch [134/200], Train Loss: 0.3478
2024-03-28 22:22:45,306 - config - INFO - Validation Loss: 0.3998
2024-03-28 22:22:45,306 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:45,333 - config - INFO - Epoch [135/200], Train Loss: 0.3490
2024-03-28 22:22:45,338 - config - INFO - Validation Loss: 0.4089
2024-03-28 22:22:45,338 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:45,365 - config - INFO - Epoch [136/200], Train Loss: 0.3488
2024-03-28 22:22:45,369 - config - INFO - Validation Loss: 0.4031
2024-03-28 22:22:45,369 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:45,397 - config - INFO - Epoch [137/200], Train Loss: 0.3462
2024-03-28 22:22:45,401 - config - INFO - Validation Loss: 0.4073
2024-03-28 22:22:45,401 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:45,429 - config - INFO - Epoch [138/200], Train Loss: 0.3477
2024-03-28 22:22:45,433 - config - INFO - Validation Loss: 0.4081
2024-03-28 22:22:45,433 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:45,460 - config - INFO - Epoch [139/200], Train Loss: 0.3450
2024-03-28 22:22:45,464 - config - INFO - Validation Loss: 0.4023
2024-03-28 22:22:45,465 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:45,492 - config - INFO - Epoch [140/200], Train Loss: 0.3474
2024-03-28 22:22:45,496 - config - INFO - Validation Loss: 0.4102
2024-03-28 22:22:45,496 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:22:45,524 - config - INFO - Epoch [141/200], Train Loss: 0.3451
2024-03-28 22:22:45,528 - config - INFO - Validation Loss: 0.4115
2024-03-28 22:22:45,528 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:45,556 - config - INFO - Epoch [142/200], Train Loss: 0.3550
2024-03-28 22:22:45,561 - config - INFO - Validation Loss: 0.4177
2024-03-28 22:22:45,561 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:22:45,561 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 22:23:36,254 - config - INFO - resume: None
2024-03-28 22:23:36,254 - config - INFO - device: cpu
2024-03-28 22:23:36,254 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:23:36,254 - config - INFO - learning_rate: 0.001
2024-03-28 22:23:36,254 - config - INFO - num_epochs: 200
2024-03-28 22:23:36,255 - config - INFO - batch_size: 64
2024-03-28 22:23:36,255 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:23:36,276 - config - INFO - Dataset size: 891
2024-03-28 22:23:36,300 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=self.config.batch_size)
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs = batch['features']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(test_dataloader)
        self.logger.info(f"test Loss: {val_loss:.4f}")
        predictions = (outputs > threshold).float()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1242)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions})

        # Save DataFrame with no index
        df.to_csv('predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 22:23:36,300 - config - INFO - Training start
2024-03-28 22:23:38,596 - config - INFO - Epoch [1/200], Train Loss: 0.6751
2024-03-28 22:23:38,600 - config - INFO - Validation Loss: 0.6391
2024-03-28 22:23:38,601 - config - INFO - Validation Acc: 0.7200
2024-03-28 22:23:38,636 - config - INFO - Epoch [2/200], Train Loss: 0.6275
2024-03-28 22:23:38,640 - config - INFO - Validation Loss: 0.5896
2024-03-28 22:23:38,640 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:23:38,678 - config - INFO - Epoch [3/200], Train Loss: 0.5784
2024-03-28 22:23:38,683 - config - INFO - Validation Loss: 0.5405
2024-03-28 22:23:38,683 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:23:38,728 - config - INFO - Epoch [4/200], Train Loss: 0.5326
2024-03-28 22:23:38,733 - config - INFO - Validation Loss: 0.4983
2024-03-28 22:23:38,733 - config - INFO - Validation Acc: 0.7400
2024-03-28 22:23:38,771 - config - INFO - Epoch [5/200], Train Loss: 0.4944
2024-03-28 22:23:38,776 - config - INFO - Validation Loss: 0.4690
2024-03-28 22:23:38,776 - config - INFO - Validation Acc: 0.7600
2024-03-28 22:23:38,815 - config - INFO - Epoch [6/200], Train Loss: 0.4661
2024-03-28 22:23:38,820 - config - INFO - Validation Loss: 0.4462
2024-03-28 22:23:38,820 - config - INFO - Validation Acc: 0.7800
2024-03-28 22:23:38,858 - config - INFO - Epoch [7/200], Train Loss: 0.4481
2024-03-28 22:23:38,863 - config - INFO - Validation Loss: 0.4309
2024-03-28 22:23:38,863 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:23:38,904 - config - INFO - Epoch [8/200], Train Loss: 0.4377
2024-03-28 22:23:38,908 - config - INFO - Validation Loss: 0.4207
2024-03-28 22:23:38,908 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:23:38,938 - config - INFO - Epoch [9/200], Train Loss: 0.4317
2024-03-28 22:23:38,942 - config - INFO - Validation Loss: 0.4126
2024-03-28 22:23:38,942 - config - INFO - Validation Acc: 0.8400
2024-03-28 22:23:38,970 - config - INFO - Epoch [10/200], Train Loss: 0.4275
2024-03-28 22:23:38,974 - config - INFO - Validation Loss: 0.4093
2024-03-28 22:23:38,974 - config - INFO - Validation Acc: 0.8400
2024-03-28 22:23:39,002 - config - INFO - Epoch [11/200], Train Loss: 0.4245
2024-03-28 22:23:39,006 - config - INFO - Validation Loss: 0.4068
2024-03-28 22:23:39,007 - config - INFO - Validation Acc: 0.8400
2024-03-28 22:23:39,035 - config - INFO - Epoch [12/200], Train Loss: 0.4200
2024-03-28 22:23:39,039 - config - INFO - Validation Loss: 0.4023
2024-03-28 22:23:39,039 - config - INFO - Validation Acc: 0.8400
2024-03-28 22:23:39,067 - config - INFO - Epoch [13/200], Train Loss: 0.4187
2024-03-28 22:23:39,071 - config - INFO - Validation Loss: 0.4003
2024-03-28 22:23:39,072 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:23:39,100 - config - INFO - Epoch [14/200], Train Loss: 0.4148
2024-03-28 22:23:39,104 - config - INFO - Validation Loss: 0.3990
2024-03-28 22:23:39,104 - config - INFO - Validation Acc: 0.8400
2024-03-28 22:23:39,132 - config - INFO - Epoch [15/200], Train Loss: 0.4124
2024-03-28 22:23:39,136 - config - INFO - Validation Loss: 0.4012
2024-03-28 22:23:39,136 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:23:39,165 - config - INFO - Epoch [16/200], Train Loss: 0.4091
2024-03-28 22:23:39,169 - config - INFO - Validation Loss: 0.3968
2024-03-28 22:23:39,169 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:23:39,197 - config - INFO - Epoch [17/200], Train Loss: 0.4074
2024-03-28 22:23:39,202 - config - INFO - Validation Loss: 0.3949
2024-03-28 22:23:39,202 - config - INFO - Validation Acc: 0.8200
2024-03-28 22:23:39,230 - config - INFO - Epoch [18/200], Train Loss: 0.4051
2024-03-28 22:23:39,234 - config - INFO - Validation Loss: 0.3989
2024-03-28 22:23:39,234 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:23:39,234 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 22:25:37,173 - config - INFO - resume: None
2024-03-28 22:25:37,173 - config - INFO - device: cpu
2024-03-28 22:25:37,173 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:25:37,173 - config - INFO - learning_rate: 0.001
2024-03-28 22:25:37,173 - config - INFO - num_epochs: 18
2024-03-28 22:25:37,173 - config - INFO - batch_size: 64
2024-03-28 22:25:37,173 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:25:37,195 - config - INFO - Dataset size: 891
2024-03-28 22:25:37,219 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(1 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=self.config.batch_size)
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs = batch['features']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(test_dataloader)
        self.logger.info(f"test Loss: {val_loss:.4f}")
        predictions = (outputs > threshold).float()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1242)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 22:25:37,219 - config - INFO - Training start
2024-03-28 22:25:39,487 - config - INFO - Epoch [1/18], Train Loss: 0.6744
2024-03-28 22:25:53,918 - config - INFO - resume: None
2024-03-28 22:25:53,918 - config - INFO - device: cpu
2024-03-28 22:25:53,918 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:25:53,918 - config - INFO - learning_rate: 0.001
2024-03-28 22:25:53,918 - config - INFO - num_epochs: 18
2024-03-28 22:25:53,918 - config - INFO - batch_size: 64
2024-03-28 22:25:53,918 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:25:53,939 - config - INFO - Dataset size: 891
2024-03-28 22:25:53,963 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.95 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=self.config.batch_size)
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs = batch['features']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(test_dataloader)
        self.logger.info(f"test Loss: {val_loss:.4f}")
        predictions = (outputs > threshold).float()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1242)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 22:25:53,963 - config - INFO - Training start
2024-03-28 22:25:56,457 - config - INFO - Epoch [1/18], Train Loss: 0.6972
2024-03-28 22:25:56,459 - config - INFO - Validation Loss: 0.6694
2024-03-28 22:25:56,459 - config - INFO - Validation Acc: 0.7556
2024-03-28 22:25:56,507 - config - INFO - Epoch [2/18], Train Loss: 0.6456
2024-03-28 22:25:56,508 - config - INFO - Validation Loss: 0.6243
2024-03-28 22:25:56,517 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:25:56,564 - config - INFO - Epoch [3/18], Train Loss: 0.5903
2024-03-28 22:25:56,565 - config - INFO - Validation Loss: 0.5838
2024-03-28 22:25:56,566 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:25:56,613 - config - INFO - Epoch [4/18], Train Loss: 0.5323
2024-03-28 22:25:56,615 - config - INFO - Validation Loss: 0.5556
2024-03-28 22:25:56,615 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:25:56,664 - config - INFO - Epoch [5/18], Train Loss: 0.4799
2024-03-28 22:25:56,665 - config - INFO - Validation Loss: 0.5522
2024-03-28 22:25:56,666 - config - INFO - Validation Acc: 0.7111
2024-03-28 22:25:56,706 - config - INFO - Epoch [6/18], Train Loss: 0.4472
2024-03-28 22:25:56,708 - config - INFO - Validation Loss: 0.5543
2024-03-28 22:25:56,708 - config - INFO - Validation Acc: 0.7111
2024-03-28 22:25:56,758 - config - INFO - Epoch [7/18], Train Loss: 0.4300
2024-03-28 22:25:56,760 - config - INFO - Validation Loss: 0.5629
2024-03-28 22:25:56,760 - config - INFO - Validation Acc: 0.7111
2024-03-28 22:25:56,760 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 22:26:42,225 - config - INFO - resume: None
2024-03-28 22:26:42,225 - config - INFO - device: cpu
2024-03-28 22:26:42,225 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:26:42,225 - config - INFO - learning_rate: 0.001
2024-03-28 22:26:42,225 - config - INFO - num_epochs: 18
2024-03-28 22:26:42,225 - config - INFO - batch_size: 64
2024-03-28 22:26:42,225 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:26:42,247 - config - INFO - Dataset size: 891
2024-03-28 22:26:42,271 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.95 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=self.config.batch_size)
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs = batch['features']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(test_dataloader)
        self.logger.info(f"test Loss: {val_loss:.4f}")
        predictions = (outputs > threshold).float()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1242)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 22:26:42,271 - config - INFO - Training start
2024-03-28 22:26:44,648 - config - INFO - Epoch [1/18], Train Loss: 0.6821
2024-03-28 22:26:44,650 - config - INFO - Validation Loss: 0.6575
2024-03-28 22:26:44,651 - config - INFO - Validation Acc: 0.6444
2024-03-28 22:26:44,690 - config - INFO - Epoch [2/18], Train Loss: 0.6279
2024-03-28 22:26:44,691 - config - INFO - Validation Loss: 0.6119
2024-03-28 22:26:44,691 - config - INFO - Validation Acc: 0.6222
2024-03-28 22:26:44,732 - config - INFO - Epoch [3/18], Train Loss: 0.5769
2024-03-28 22:26:44,733 - config - INFO - Validation Loss: 0.5647
2024-03-28 22:26:44,733 - config - INFO - Validation Acc: 0.6667
2024-03-28 22:26:44,771 - config - INFO - Epoch [4/18], Train Loss: 0.5258
2024-03-28 22:26:44,773 - config - INFO - Validation Loss: 0.5203
2024-03-28 22:26:44,773 - config - INFO - Validation Acc: 0.7333
2024-03-28 22:26:44,809 - config - INFO - Epoch [5/18], Train Loss: 0.4853
2024-03-28 22:26:44,811 - config - INFO - Validation Loss: 0.4800
2024-03-28 22:26:44,811 - config - INFO - Validation Acc: 0.7556
2024-03-28 22:26:44,847 - config - INFO - Epoch [6/18], Train Loss: 0.4552
2024-03-28 22:26:44,849 - config - INFO - Validation Loss: 0.4503
2024-03-28 22:26:44,849 - config - INFO - Validation Acc: 0.8222
2024-03-28 22:26:44,890 - config - INFO - Epoch [7/18], Train Loss: 0.4408
2024-03-28 22:26:44,892 - config - INFO - Validation Loss: 0.4311
2024-03-28 22:26:44,892 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:26:44,937 - config - INFO - Epoch [8/18], Train Loss: 0.4341
2024-03-28 22:26:44,938 - config - INFO - Validation Loss: 0.4128
2024-03-28 22:26:44,939 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:26:44,978 - config - INFO - Epoch [9/18], Train Loss: 0.4274
2024-03-28 22:26:44,979 - config - INFO - Validation Loss: 0.4180
2024-03-28 22:26:44,979 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:26:44,979 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 22:27:05,445 - config - INFO - resume: None
2024-03-28 22:27:05,445 - config - INFO - device: cpu
2024-03-28 22:27:05,445 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:27:05,445 - config - INFO - learning_rate: 0.001
2024-03-28 22:27:05,445 - config - INFO - num_epochs: 18
2024-03-28 22:27:05,445 - config - INFO - batch_size: 64
2024-03-28 22:27:05,445 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:27:05,467 - config - INFO - Dataset size: 891
2024-03-28 22:27:05,491 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.95 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=self.config.batch_size)
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > threshold).float()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1242)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 22:27:05,491 - config - INFO - Training start
2024-03-28 22:27:07,903 - config - INFO - Epoch [1/18], Train Loss: 0.6796
2024-03-28 22:27:07,905 - config - INFO - Validation Loss: 0.6509
2024-03-28 22:27:07,905 - config - INFO - Validation Acc: 0.6444
2024-03-28 22:27:07,949 - config - INFO - Epoch [2/18], Train Loss: 0.6312
2024-03-28 22:27:07,951 - config - INFO - Validation Loss: 0.6053
2024-03-28 22:27:07,951 - config - INFO - Validation Acc: 0.7333
2024-03-28 22:27:07,995 - config - INFO - Epoch [3/18], Train Loss: 0.5826
2024-03-28 22:27:07,997 - config - INFO - Validation Loss: 0.5489
2024-03-28 22:27:07,997 - config - INFO - Validation Acc: 0.7556
2024-03-28 22:27:08,041 - config - INFO - Epoch [4/18], Train Loss: 0.5271
2024-03-28 22:27:08,043 - config - INFO - Validation Loss: 0.4970
2024-03-28 22:27:08,043 - config - INFO - Validation Acc: 0.7778
2024-03-28 22:27:08,085 - config - INFO - Epoch [5/18], Train Loss: 0.4815
2024-03-28 22:27:08,086 - config - INFO - Validation Loss: 0.4560
2024-03-28 22:27:08,087 - config - INFO - Validation Acc: 0.8222
2024-03-28 22:27:08,128 - config - INFO - Epoch [6/18], Train Loss: 0.4526
2024-03-28 22:27:08,130 - config - INFO - Validation Loss: 0.4420
2024-03-28 22:27:08,130 - config - INFO - Validation Acc: 0.8222
2024-03-28 22:27:08,175 - config - INFO - Epoch [7/18], Train Loss: 0.4375
2024-03-28 22:27:08,176 - config - INFO - Validation Loss: 0.4472
2024-03-28 22:27:08,176 - config - INFO - Validation Acc: 0.8222
2024-03-28 22:27:08,177 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 22:27:18,532 - config - INFO - resume: None
2024-03-28 22:27:18,533 - config - INFO - device: cpu
2024-03-28 22:27:18,533 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:27:18,533 - config - INFO - learning_rate: 0.001
2024-03-28 22:27:18,533 - config - INFO - num_epochs: 18
2024-03-28 22:27:18,533 - config - INFO - batch_size: 64
2024-03-28 22:27:18,533 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:27:18,554 - config - INFO - Dataset size: 891
2024-03-28 22:27:18,576 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.95 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=self.config.batch_size)
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).float()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1242)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 22:27:18,576 - config - INFO - Training start
2024-03-28 22:27:20,937 - config - INFO - Epoch [1/18], Train Loss: 0.6957
2024-03-28 22:27:20,939 - config - INFO - Validation Loss: 0.6558
2024-03-28 22:27:20,940 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:27:20,984 - config - INFO - Epoch [2/18], Train Loss: 0.6440
2024-03-28 22:27:20,985 - config - INFO - Validation Loss: 0.5929
2024-03-28 22:27:20,986 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:27:21,030 - config - INFO - Epoch [3/18], Train Loss: 0.5871
2024-03-28 22:27:21,032 - config - INFO - Validation Loss: 0.5195
2024-03-28 22:27:21,032 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:27:21,079 - config - INFO - Epoch [4/18], Train Loss: 0.5275
2024-03-28 22:27:21,080 - config - INFO - Validation Loss: 0.4478
2024-03-28 22:27:21,081 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:27:21,133 - config - INFO - Epoch [5/18], Train Loss: 0.4802
2024-03-28 22:27:21,135 - config - INFO - Validation Loss: 0.4047
2024-03-28 22:27:21,135 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:27:21,179 - config - INFO - Epoch [6/18], Train Loss: 0.4532
2024-03-28 22:27:21,180 - config - INFO - Validation Loss: 0.3718
2024-03-28 22:27:21,180 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:27:21,225 - config - INFO - Epoch [7/18], Train Loss: 0.4405
2024-03-28 22:27:21,226 - config - INFO - Validation Loss: 0.3533
2024-03-28 22:27:21,227 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:27:21,271 - config - INFO - Epoch [8/18], Train Loss: 0.4323
2024-03-28 22:27:21,272 - config - INFO - Validation Loss: 0.3496
2024-03-28 22:27:21,273 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:27:21,313 - config - INFO - Epoch [9/18], Train Loss: 0.4258
2024-03-28 22:27:21,314 - config - INFO - Validation Loss: 0.3400
2024-03-28 22:27:21,314 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:27:21,353 - config - INFO - Epoch [10/18], Train Loss: 0.4226
2024-03-28 22:27:21,355 - config - INFO - Validation Loss: 0.3282
2024-03-28 22:27:21,355 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:27:21,394 - config - INFO - Epoch [11/18], Train Loss: 0.4182
2024-03-28 22:27:21,396 - config - INFO - Validation Loss: 0.3253
2024-03-28 22:27:21,396 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:27:21,435 - config - INFO - Epoch [12/18], Train Loss: 0.4155
2024-03-28 22:27:21,436 - config - INFO - Validation Loss: 0.3195
2024-03-28 22:27:21,437 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:27:21,476 - config - INFO - Epoch [13/18], Train Loss: 0.4128
2024-03-28 22:27:21,477 - config - INFO - Validation Loss: 0.3238
2024-03-28 22:27:21,477 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:27:21,477 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 22:28:08,020 - config - INFO - resume: None
2024-03-28 22:28:08,021 - config - INFO - device: cpu
2024-03-28 22:28:08,021 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:28:08,021 - config - INFO - learning_rate: 0.001
2024-03-28 22:28:08,021 - config - INFO - num_epochs: 18
2024-03-28 22:28:08,021 - config - INFO - batch_size: 64
2024-03-28 22:28:08,021 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:28:08,042 - config - INFO - Dataset size: 891
2024-03-28 22:28:08,064 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.95 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels)
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=self.config.batch_size)
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).float()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1242)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 22:28:08,064 - config - INFO - Training start
2024-03-28 22:28:10,434 - config - INFO - Epoch [1/18], Train Loss: 0.6729
2024-03-28 22:28:10,436 - config - INFO - Validation Loss: 0.6769
2024-03-28 22:28:10,437 - config - INFO - Validation Acc: 0.5333
2024-03-28 22:28:10,484 - config - INFO - Epoch [2/18], Train Loss: 0.6296
2024-03-28 22:28:10,486 - config - INFO - Validation Loss: 0.6533
2024-03-28 22:28:10,486 - config - INFO - Validation Acc: 0.6222
2024-03-28 22:28:10,534 - config - INFO - Epoch [3/18], Train Loss: 0.5838
2024-03-28 22:28:10,535 - config - INFO - Validation Loss: 0.6203
2024-03-28 22:28:10,536 - config - INFO - Validation Acc: 0.6667
2024-03-28 22:28:10,599 - config - INFO - Epoch [4/18], Train Loss: 0.5277
2024-03-28 22:28:10,601 - config - INFO - Validation Loss: 0.5748
2024-03-28 22:28:10,601 - config - INFO - Validation Acc: 0.6667
2024-03-28 22:28:10,647 - config - INFO - Epoch [5/18], Train Loss: 0.4755
2024-03-28 22:28:10,649 - config - INFO - Validation Loss: 0.5510
2024-03-28 22:28:10,649 - config - INFO - Validation Acc: 0.7111
2024-03-28 22:28:10,695 - config - INFO - Epoch [6/18], Train Loss: 0.4435
2024-03-28 22:28:10,697 - config - INFO - Validation Loss: 0.5407
2024-03-28 22:28:10,697 - config - INFO - Validation Acc: 0.7111
2024-03-28 22:28:10,746 - config - INFO - Epoch [7/18], Train Loss: 0.4257
2024-03-28 22:28:10,748 - config - INFO - Validation Loss: 0.5537
2024-03-28 22:28:10,748 - config - INFO - Validation Acc: 0.7111
2024-03-28 22:28:10,748 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 22:31:33,938 - config - INFO - resume: None
2024-03-28 22:31:33,938 - config - INFO - device: cpu
2024-03-28 22:31:33,938 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:31:33,938 - config - INFO - learning_rate: 0.001
2024-03-28 22:31:33,938 - config - INFO - num_epochs: 18
2024-03-28 22:31:33,938 - config - INFO - batch_size: 64
2024-03-28 22:31:33,938 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:31:33,960 - config - INFO - Dataset size: 891
2024-03-28 22:31:33,983 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.95 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(test_dataloader))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).float()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1242)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 22:31:33,983 - config - INFO - Training start
2024-03-28 22:31:36,482 - config - INFO - Epoch [1/18], Train Loss: 0.6774
2024-03-28 22:31:36,488 - config - INFO - Validation Loss: 0.6691
2024-03-28 22:31:36,490 - config - INFO - Validation Acc: 0.6667
2024-03-28 22:31:36,568 - config - INFO - Epoch [2/18], Train Loss: 0.6307
2024-03-28 22:31:36,569 - config - INFO - Validation Loss: 0.6354
2024-03-28 22:31:36,569 - config - INFO - Validation Acc: 0.7333
2024-03-28 22:31:36,609 - config - INFO - Epoch [3/18], Train Loss: 0.5772
2024-03-28 22:31:36,610 - config - INFO - Validation Loss: 0.5964
2024-03-28 22:31:36,611 - config - INFO - Validation Acc: 0.7333
2024-03-28 22:31:36,652 - config - INFO - Epoch [4/18], Train Loss: 0.5200
2024-03-28 22:31:36,653 - config - INFO - Validation Loss: 0.5637
2024-03-28 22:31:36,653 - config - INFO - Validation Acc: 0.7556
2024-03-28 22:31:36,700 - config - INFO - Epoch [5/18], Train Loss: 0.4764
2024-03-28 22:31:36,701 - config - INFO - Validation Loss: 0.5471
2024-03-28 22:31:36,701 - config - INFO - Validation Acc: 0.7111
2024-03-28 22:31:36,735 - config - INFO - Epoch [6/18], Train Loss: 0.4512
2024-03-28 22:31:36,737 - config - INFO - Validation Loss: 0.5467
2024-03-28 22:31:36,737 - config - INFO - Validation Acc: 0.7111
2024-03-28 22:31:36,774 - config - INFO - Epoch [7/18], Train Loss: 0.4394
2024-03-28 22:31:36,776 - config - INFO - Validation Loss: 0.5433
2024-03-28 22:31:36,776 - config - INFO - Validation Acc: 0.7111
2024-03-28 22:31:36,808 - config - INFO - Epoch [8/18], Train Loss: 0.4316
2024-03-28 22:31:36,810 - config - INFO - Validation Loss: 0.5442
2024-03-28 22:31:36,810 - config - INFO - Validation Acc: 0.7111
2024-03-28 22:31:36,845 - config - INFO - Epoch [9/18], Train Loss: 0.4247
2024-03-28 22:31:36,846 - config - INFO - Validation Loss: 0.5477
2024-03-28 22:31:36,846 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:31:36,846 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 22:31:51,653 - config - INFO - resume: None
2024-03-28 22:31:51,654 - config - INFO - device: cpu
2024-03-28 22:31:51,654 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:31:51,654 - config - INFO - learning_rate: 0.001
2024-03-28 22:31:51,654 - config - INFO - num_epochs: 18
2024-03-28 22:31:51,654 - config - INFO - batch_size: 64
2024-03-28 22:31:51,654 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:31:51,675 - config - INFO - Dataset size: 891
2024-03-28 22:31:51,699 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.95 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).float()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1242)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 22:31:51,699 - config - INFO - Training start
2024-03-28 22:31:54,011 - config - INFO - Epoch [1/18], Train Loss: 0.6427
2024-03-28 22:31:54,014 - config - INFO - Validation Loss: 0.6066
2024-03-28 22:31:54,014 - config - INFO - Validation Acc: 0.7111
2024-03-28 22:31:54,067 - config - INFO - Epoch [2/18], Train Loss: 0.5994
2024-03-28 22:31:54,069 - config - INFO - Validation Loss: 0.5433
2024-03-28 22:31:54,069 - config - INFO - Validation Acc: 0.8222
2024-03-28 22:31:54,117 - config - INFO - Epoch [3/18], Train Loss: 0.5481
2024-03-28 22:31:54,118 - config - INFO - Validation Loss: 0.4728
2024-03-28 22:31:54,119 - config - INFO - Validation Acc: 0.8222
2024-03-28 22:31:54,167 - config - INFO - Epoch [4/18], Train Loss: 0.5011
2024-03-28 22:31:54,169 - config - INFO - Validation Loss: 0.4042
2024-03-28 22:31:54,169 - config - INFO - Validation Acc: 0.8222
2024-03-28 22:31:54,216 - config - INFO - Epoch [5/18], Train Loss: 0.4633
2024-03-28 22:31:54,217 - config - INFO - Validation Loss: 0.3603
2024-03-28 22:31:54,218 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:31:54,263 - config - INFO - Epoch [6/18], Train Loss: 0.4449
2024-03-28 22:31:54,264 - config - INFO - Validation Loss: 0.3303
2024-03-28 22:31:54,264 - config - INFO - Validation Acc: 0.8889
2024-03-28 22:31:54,304 - config - INFO - Epoch [7/18], Train Loss: 0.4356
2024-03-28 22:31:54,306 - config - INFO - Validation Loss: 0.3125
2024-03-28 22:31:54,306 - config - INFO - Validation Acc: 0.8889
2024-03-28 22:31:54,345 - config - INFO - Epoch [8/18], Train Loss: 0.4292
2024-03-28 22:31:54,347 - config - INFO - Validation Loss: 0.3081
2024-03-28 22:31:54,347 - config - INFO - Validation Acc: 0.8889
2024-03-28 22:31:54,386 - config - INFO - Epoch [9/18], Train Loss: 0.4254
2024-03-28 22:31:54,387 - config - INFO - Validation Loss: 0.3086
2024-03-28 22:31:54,387 - config - INFO - Validation Acc: 0.8889
2024-03-28 22:31:54,426 - config - INFO - Epoch [10/18], Train Loss: 0.4210
2024-03-28 22:31:54,428 - config - INFO - Validation Loss: 0.3105
2024-03-28 22:31:54,428 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:31:54,466 - config - INFO - Epoch [11/18], Train Loss: 0.4212
2024-03-28 22:31:54,468 - config - INFO - Validation Loss: 0.3084
2024-03-28 22:31:54,468 - config - INFO - Validation Acc: 0.8889
2024-03-28 22:31:54,507 - config - INFO - Epoch [12/18], Train Loss: 0.4162
2024-03-28 22:31:54,508 - config - INFO - Validation Loss: 0.3071
2024-03-28 22:31:54,508 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:31:54,547 - config - INFO - Epoch [13/18], Train Loss: 0.4140
2024-03-28 22:31:54,549 - config - INFO - Validation Loss: 0.3059
2024-03-28 22:31:54,549 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:31:54,588 - config - INFO - Epoch [14/18], Train Loss: 0.4136
2024-03-28 22:31:54,589 - config - INFO - Validation Loss: 0.3062
2024-03-28 22:31:54,589 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:31:54,628 - config - INFO - Epoch [15/18], Train Loss: 0.4100
2024-03-28 22:31:54,630 - config - INFO - Validation Loss: 0.3054
2024-03-28 22:31:54,630 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:31:54,669 - config - INFO - Epoch [16/18], Train Loss: 0.4083
2024-03-28 22:31:54,670 - config - INFO - Validation Loss: 0.3086
2024-03-28 22:31:54,670 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:31:54,670 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 22:32:04,890 - config - INFO - resume: None
2024-03-28 22:32:04,891 - config - INFO - device: cpu
2024-03-28 22:32:04,891 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:32:04,891 - config - INFO - learning_rate: 0.001
2024-03-28 22:32:04,891 - config - INFO - num_epochs: 18
2024-03-28 22:32:04,891 - config - INFO - batch_size: 64
2024-03-28 22:32:04,891 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:32:04,912 - config - INFO - Dataset size: 891
2024-03-28 22:32:04,936 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.95 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).float()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1242)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 22:32:04,936 - config - INFO - Training start
2024-03-28 22:32:07,365 - config - INFO - Epoch [1/18], Train Loss: 0.6721
2024-03-28 22:32:07,367 - config - INFO - Validation Loss: 0.6481
2024-03-28 22:32:07,367 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:32:07,424 - config - INFO - Epoch [2/18], Train Loss: 0.6302
2024-03-28 22:32:07,425 - config - INFO - Validation Loss: 0.6083
2024-03-28 22:32:07,425 - config - INFO - Validation Acc: 0.7778
2024-03-28 22:32:07,473 - config - INFO - Epoch [3/18], Train Loss: 0.5823
2024-03-28 22:32:07,474 - config - INFO - Validation Loss: 0.5692
2024-03-28 22:32:07,474 - config - INFO - Validation Acc: 0.7556
2024-03-28 22:32:07,515 - config - INFO - Epoch [4/18], Train Loss: 0.5316
2024-03-28 22:32:07,517 - config - INFO - Validation Loss: 0.5290
2024-03-28 22:32:07,517 - config - INFO - Validation Acc: 0.7778
2024-03-28 22:32:07,558 - config - INFO - Epoch [5/18], Train Loss: 0.4798
2024-03-28 22:32:07,559 - config - INFO - Validation Loss: 0.5037
2024-03-28 22:32:07,559 - config - INFO - Validation Acc: 0.7556
2024-03-28 22:32:07,599 - config - INFO - Epoch [6/18], Train Loss: 0.4453
2024-03-28 22:32:07,600 - config - INFO - Validation Loss: 0.5058
2024-03-28 22:32:07,601 - config - INFO - Validation Acc: 0.7778
2024-03-28 22:32:07,634 - config - INFO - Epoch [7/18], Train Loss: 0.4269
2024-03-28 22:32:07,635 - config - INFO - Validation Loss: 0.5107
2024-03-28 22:32:07,635 - config - INFO - Validation Acc: 0.7778
2024-03-28 22:32:07,636 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 22:32:55,255 - config - INFO - resume: None
2024-03-28 22:32:55,255 - config - INFO - device: cpu
2024-03-28 22:32:55,255 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:32:55,255 - config - INFO - learning_rate: 0.001
2024-03-28 22:32:55,255 - config - INFO - num_epochs: 18
2024-03-28 22:32:55,255 - config - INFO - batch_size: 64
2024-03-28 22:32:55,255 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:32:55,277 - config - INFO - Dataset size: 891
2024-03-28 22:32:55,300 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.95 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).float()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1242)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 22:32:55,300 - config - INFO - Training start
2024-03-28 22:32:57,554 - config - INFO - Epoch [1/18], Train Loss: 0.6540
2024-03-28 22:32:57,557 - config - INFO - Validation Loss: 0.6265
2024-03-28 22:32:57,557 - config - INFO - Validation Acc: 0.6444
2024-03-28 22:32:57,600 - config - INFO - Epoch [2/18], Train Loss: 0.6057
2024-03-28 22:32:57,602 - config - INFO - Validation Loss: 0.5891
2024-03-28 22:32:57,602 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:32:57,644 - config - INFO - Epoch [3/18], Train Loss: 0.5546
2024-03-28 22:32:57,646 - config - INFO - Validation Loss: 0.5620
2024-03-28 22:32:57,646 - config - INFO - Validation Acc: 0.7333
2024-03-28 22:32:57,687 - config - INFO - Epoch [4/18], Train Loss: 0.5061
2024-03-28 22:32:57,689 - config - INFO - Validation Loss: 0.5497
2024-03-28 22:32:57,689 - config - INFO - Validation Acc: 0.7556
2024-03-28 22:32:57,729 - config - INFO - Epoch [5/18], Train Loss: 0.4667
2024-03-28 22:32:57,730 - config - INFO - Validation Loss: 0.5460
2024-03-28 22:32:57,731 - config - INFO - Validation Acc: 0.7111
2024-03-28 22:32:57,770 - config - INFO - Epoch [6/18], Train Loss: 0.4437
2024-03-28 22:32:57,772 - config - INFO - Validation Loss: 0.5506
2024-03-28 22:32:57,772 - config - INFO - Validation Acc: 0.7111
2024-03-28 22:32:57,772 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 22:34:37,527 - config - INFO - resume: None
2024-03-28 22:34:37,527 - config - INFO - device: cpu
2024-03-28 22:34:37,527 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:34:37,527 - config - INFO - learning_rate: 0.001
2024-03-28 22:34:37,527 - config - INFO - num_epochs: 18
2024-03-28 22:34:37,527 - config - INFO - batch_size: 64
2024-03-28 22:34:37,527 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:34:37,570 - config - INFO - Dataset size: 891
2024-03-28 22:35:21,793 - config - INFO - resume: None
2024-03-28 22:35:21,793 - config - INFO - device: cpu
2024-03-28 22:35:21,793 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:35:21,793 - config - INFO - learning_rate: 0.001
2024-03-28 22:35:21,793 - config - INFO - num_epochs: 18
2024-03-28 22:35:21,793 - config - INFO - batch_size: 64
2024-03-28 22:35:21,794 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:35:21,815 - config - INFO - Dataset size: 891
2024-03-28 22:35:21,836 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.95 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).float()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1242)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 22:35:21,836 - config - INFO - Training start
2024-03-28 22:35:24,246 - config - INFO - Epoch [1/18], Train Loss: 0.6917
2024-03-28 22:35:24,248 - config - INFO - Validation Loss: 0.6693
2024-03-28 22:35:24,248 - config - INFO - Validation Acc: 0.7556
2024-03-28 22:35:24,297 - config - INFO - Epoch [2/18], Train Loss: 0.6353
2024-03-28 22:35:24,298 - config - INFO - Validation Loss: 0.6116
2024-03-28 22:35:24,298 - config - INFO - Validation Acc: 0.8222
2024-03-28 22:35:24,346 - config - INFO - Epoch [3/18], Train Loss: 0.5707
2024-03-28 22:35:24,347 - config - INFO - Validation Loss: 0.5403
2024-03-28 22:35:24,347 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:35:24,392 - config - INFO - Epoch [4/18], Train Loss: 0.5075
2024-03-28 22:35:24,394 - config - INFO - Validation Loss: 0.4784
2024-03-28 22:35:24,394 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:35:24,439 - config - INFO - Epoch [5/18], Train Loss: 0.4633
2024-03-28 22:35:24,441 - config - INFO - Validation Loss: 0.4447
2024-03-28 22:35:24,441 - config - INFO - Validation Acc: 0.8222
2024-03-28 22:35:24,485 - config - INFO - Epoch [6/18], Train Loss: 0.4428
2024-03-28 22:35:24,487 - config - INFO - Validation Loss: 0.4290
2024-03-28 22:35:24,487 - config - INFO - Validation Acc: 0.8222
2024-03-28 22:35:24,535 - config - INFO - Epoch [7/18], Train Loss: 0.4331
2024-03-28 22:35:24,537 - config - INFO - Validation Loss: 0.4284
2024-03-28 22:35:24,537 - config - INFO - Validation Acc: 0.7778
2024-03-28 22:35:24,580 - config - INFO - Epoch [8/18], Train Loss: 0.4262
2024-03-28 22:35:24,582 - config - INFO - Validation Loss: 0.4185
2024-03-28 22:35:24,582 - config - INFO - Validation Acc: 0.8222
2024-03-28 22:35:24,624 - config - INFO - Epoch [9/18], Train Loss: 0.4209
2024-03-28 22:35:24,626 - config - INFO - Validation Loss: 0.4179
2024-03-28 22:35:24,626 - config - INFO - Validation Acc: 0.8222
2024-03-28 22:35:24,667 - config - INFO - Epoch [10/18], Train Loss: 0.4164
2024-03-28 22:35:24,669 - config - INFO - Validation Loss: 0.4155
2024-03-28 22:35:24,670 - config - INFO - Validation Acc: 0.8222
2024-03-28 22:35:24,710 - config - INFO - Epoch [11/18], Train Loss: 0.4133
2024-03-28 22:35:24,712 - config - INFO - Validation Loss: 0.4149
2024-03-28 22:35:24,712 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:35:24,752 - config - INFO - Epoch [12/18], Train Loss: 0.4107
2024-03-28 22:35:24,753 - config - INFO - Validation Loss: 0.4116
2024-03-28 22:35:24,754 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:35:24,793 - config - INFO - Epoch [13/18], Train Loss: 0.4088
2024-03-28 22:35:24,795 - config - INFO - Validation Loss: 0.4054
2024-03-28 22:35:24,795 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:35:24,838 - config - INFO - Epoch [14/18], Train Loss: 0.4060
2024-03-28 22:35:24,840 - config - INFO - Validation Loss: 0.4043
2024-03-28 22:35:24,841 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:35:24,882 - config - INFO - Epoch [15/18], Train Loss: 0.4037
2024-03-28 22:35:24,883 - config - INFO - Validation Loss: 0.4114
2024-03-28 22:35:24,884 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:35:24,884 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 22:36:25,985 - config - INFO - resume: None
2024-03-28 22:36:25,985 - config - INFO - device: cpu
2024-03-28 22:36:25,985 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:36:25,985 - config - INFO - learning_rate: 0.001
2024-03-28 22:36:25,985 - config - INFO - num_epochs: 18
2024-03-28 22:36:25,985 - config - INFO - batch_size: 64
2024-03-28 22:36:25,985 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:36:26,006 - config - INFO - Dataset size: 891
2024-03-28 22:36:26,031 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.95 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).float()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1309)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 22:36:26,031 - config - INFO - Training start
2024-03-28 22:36:28,496 - config - INFO - Epoch [1/18], Train Loss: 0.6728
2024-03-28 22:36:28,498 - config - INFO - Validation Loss: 0.6332
2024-03-28 22:36:28,498 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:36:28,546 - config - INFO - Epoch [2/18], Train Loss: 0.6180
2024-03-28 22:36:28,548 - config - INFO - Validation Loss: 0.5623
2024-03-28 22:36:28,548 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:36:28,595 - config - INFO - Epoch [3/18], Train Loss: 0.5622
2024-03-28 22:36:28,597 - config - INFO - Validation Loss: 0.4881
2024-03-28 22:36:28,597 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:36:28,646 - config - INFO - Epoch [4/18], Train Loss: 0.5077
2024-03-28 22:36:28,648 - config - INFO - Validation Loss: 0.4215
2024-03-28 22:36:28,648 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:36:28,697 - config - INFO - Epoch [5/18], Train Loss: 0.4685
2024-03-28 22:36:28,698 - config - INFO - Validation Loss: 0.3813
2024-03-28 22:36:28,698 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:36:28,748 - config - INFO - Epoch [6/18], Train Loss: 0.4458
2024-03-28 22:36:28,750 - config - INFO - Validation Loss: 0.3547
2024-03-28 22:36:28,750 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:36:28,793 - config - INFO - Epoch [7/18], Train Loss: 0.4358
2024-03-28 22:36:28,795 - config - INFO - Validation Loss: 0.3518
2024-03-28 22:36:28,795 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:36:28,838 - config - INFO - Epoch [8/18], Train Loss: 0.4287
2024-03-28 22:36:28,840 - config - INFO - Validation Loss: 0.3520
2024-03-28 22:36:28,840 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:36:28,883 - config - INFO - Epoch [9/18], Train Loss: 0.4233
2024-03-28 22:36:28,884 - config - INFO - Validation Loss: 0.3441
2024-03-28 22:36:28,885 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:36:28,925 - config - INFO - Epoch [10/18], Train Loss: 0.4211
2024-03-28 22:36:28,926 - config - INFO - Validation Loss: 0.3435
2024-03-28 22:36:28,927 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:36:28,966 - config - INFO - Epoch [11/18], Train Loss: 0.4177
2024-03-28 22:36:28,968 - config - INFO - Validation Loss: 0.3473
2024-03-28 22:36:28,968 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:36:28,969 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 22:36:37,266 - config - INFO - resume: None
2024-03-28 22:36:37,266 - config - INFO - device: cpu
2024-03-28 22:36:37,266 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:36:37,266 - config - INFO - learning_rate: 0.001
2024-03-28 22:36:37,266 - config - INFO - num_epochs: 18
2024-03-28 22:36:37,266 - config - INFO - batch_size: 64
2024-03-28 22:36:37,266 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:36:37,288 - config - INFO - Dataset size: 891
2024-03-28 22:36:37,312 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.95 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).float()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 22:36:37,312 - config - INFO - Training start
2024-03-28 22:36:39,694 - config - INFO - Epoch [1/18], Train Loss: 0.6915
2024-03-28 22:36:39,696 - config - INFO - Validation Loss: 0.6632
2024-03-28 22:36:39,696 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:36:39,744 - config - INFO - Epoch [2/18], Train Loss: 0.6373
2024-03-28 22:36:39,746 - config - INFO - Validation Loss: 0.6164
2024-03-28 22:36:39,746 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:36:39,797 - config - INFO - Epoch [3/18], Train Loss: 0.5768
2024-03-28 22:36:39,799 - config - INFO - Validation Loss: 0.5638
2024-03-28 22:36:39,799 - config - INFO - Validation Acc: 0.7778
2024-03-28 22:36:39,847 - config - INFO - Epoch [4/18], Train Loss: 0.5183
2024-03-28 22:36:39,849 - config - INFO - Validation Loss: 0.5165
2024-03-28 22:36:39,849 - config - INFO - Validation Acc: 0.7778
2024-03-28 22:36:39,898 - config - INFO - Epoch [5/18], Train Loss: 0.4788
2024-03-28 22:36:39,900 - config - INFO - Validation Loss: 0.4818
2024-03-28 22:36:39,900 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:36:39,942 - config - INFO - Epoch [6/18], Train Loss: 0.4556
2024-03-28 22:36:39,943 - config - INFO - Validation Loss: 0.4580
2024-03-28 22:36:39,943 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:36:39,987 - config - INFO - Epoch [7/18], Train Loss: 0.4437
2024-03-28 22:36:39,989 - config - INFO - Validation Loss: 0.4507
2024-03-28 22:36:39,989 - config - INFO - Validation Acc: 0.7778
2024-03-28 22:36:40,031 - config - INFO - Epoch [8/18], Train Loss: 0.4348
2024-03-28 22:36:40,033 - config - INFO - Validation Loss: 0.4441
2024-03-28 22:36:40,033 - config - INFO - Validation Acc: 0.7778
2024-03-28 22:36:40,074 - config - INFO - Epoch [9/18], Train Loss: 0.4296
2024-03-28 22:36:40,076 - config - INFO - Validation Loss: 0.4316
2024-03-28 22:36:40,076 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:36:40,122 - config - INFO - Epoch [10/18], Train Loss: 0.4255
2024-03-28 22:36:40,123 - config - INFO - Validation Loss: 0.4338
2024-03-28 22:36:40,123 - config - INFO - Validation Acc: 0.8222
2024-03-28 22:36:40,159 - config - INFO - Epoch [11/18], Train Loss: 0.4210
2024-03-28 22:36:40,160 - config - INFO - Validation Loss: 0.4235
2024-03-28 22:36:40,161 - config - INFO - Validation Acc: 0.8222
2024-03-28 22:36:40,196 - config - INFO - Epoch [12/18], Train Loss: 0.4186
2024-03-28 22:36:40,197 - config - INFO - Validation Loss: 0.4188
2024-03-28 22:36:40,198 - config - INFO - Validation Acc: 0.8222
2024-03-28 22:36:40,233 - config - INFO - Epoch [13/18], Train Loss: 0.4152
2024-03-28 22:36:40,235 - config - INFO - Validation Loss: 0.4171
2024-03-28 22:36:40,235 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:36:40,270 - config - INFO - Epoch [14/18], Train Loss: 0.4129
2024-03-28 22:36:40,271 - config - INFO - Validation Loss: 0.4124
2024-03-28 22:36:40,272 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:36:40,307 - config - INFO - Epoch [15/18], Train Loss: 0.4120
2024-03-28 22:36:40,308 - config - INFO - Validation Loss: 0.4077
2024-03-28 22:36:40,308 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:36:40,344 - config - INFO - Epoch [16/18], Train Loss: 0.4079
2024-03-28 22:36:40,345 - config - INFO - Validation Loss: 0.4088
2024-03-28 22:36:40,346 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:36:40,381 - config - INFO - Epoch [17/18], Train Loss: 0.4074
2024-03-28 22:36:40,382 - config - INFO - Validation Loss: 0.4067
2024-03-28 22:36:40,382 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:36:40,423 - config - INFO - Epoch [18/18], Train Loss: 0.4058
2024-03-28 22:36:40,426 - config - INFO - Validation Loss: 0.4049
2024-03-28 22:36:40,426 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:37:13,340 - config - INFO - resume: None
2024-03-28 22:37:13,340 - config - INFO - device: cpu
2024-03-28 22:37:13,340 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:37:13,340 - config - INFO - learning_rate: 0.001
2024-03-28 22:37:13,340 - config - INFO - num_epochs: 20
2024-03-28 22:37:13,340 - config - INFO - batch_size: 64
2024-03-28 22:37:13,341 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:37:13,362 - config - INFO - Dataset size: 891
2024-03-28 22:37:13,384 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.95 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 22:37:13,384 - config - INFO - Training start
2024-03-28 22:37:15,513 - config - INFO - Epoch [1/20], Train Loss: 0.6984
2024-03-28 22:37:15,514 - config - INFO - Validation Loss: 0.6648
2024-03-28 22:37:15,515 - config - INFO - Validation Acc: 0.8222
2024-03-28 22:37:15,548 - config - INFO - Epoch [2/20], Train Loss: 0.6455
2024-03-28 22:37:15,550 - config - INFO - Validation Loss: 0.6106
2024-03-28 22:37:15,550 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:37:15,583 - config - INFO - Epoch [3/20], Train Loss: 0.5938
2024-03-28 22:37:15,584 - config - INFO - Validation Loss: 0.5429
2024-03-28 22:37:15,584 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:37:15,616 - config - INFO - Epoch [4/20], Train Loss: 0.5363
2024-03-28 22:37:15,617 - config - INFO - Validation Loss: 0.4719
2024-03-28 22:37:15,617 - config - INFO - Validation Acc: 0.9111
2024-03-28 22:37:15,649 - config - INFO - Epoch [5/20], Train Loss: 0.4894
2024-03-28 22:37:15,650 - config - INFO - Validation Loss: 0.4089
2024-03-28 22:37:15,650 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:37:15,682 - config - INFO - Epoch [6/20], Train Loss: 0.4572
2024-03-28 22:37:15,683 - config - INFO - Validation Loss: 0.3787
2024-03-28 22:37:15,683 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:37:15,715 - config - INFO - Epoch [7/20], Train Loss: 0.4417
2024-03-28 22:37:15,716 - config - INFO - Validation Loss: 0.3629
2024-03-28 22:37:15,716 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:37:15,748 - config - INFO - Epoch [8/20], Train Loss: 0.4335
2024-03-28 22:37:15,750 - config - INFO - Validation Loss: 0.3579
2024-03-28 22:37:15,750 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:37:15,780 - config - INFO - Epoch [9/20], Train Loss: 0.4288
2024-03-28 22:37:15,782 - config - INFO - Validation Loss: 0.3601
2024-03-28 22:37:15,782 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:37:15,813 - config - INFO - Epoch [10/20], Train Loss: 0.4245
2024-03-28 22:37:15,814 - config - INFO - Validation Loss: 0.3560
2024-03-28 22:37:15,823 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:37:15,854 - config - INFO - Epoch [11/20], Train Loss: 0.4199
2024-03-28 22:37:15,855 - config - INFO - Validation Loss: 0.3538
2024-03-28 22:37:15,855 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:37:15,886 - config - INFO - Epoch [12/20], Train Loss: 0.4158
2024-03-28 22:37:15,887 - config - INFO - Validation Loss: 0.3473
2024-03-28 22:37:15,887 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:37:15,918 - config - INFO - Epoch [13/20], Train Loss: 0.4137
2024-03-28 22:37:15,919 - config - INFO - Validation Loss: 0.3513
2024-03-28 22:37:15,919 - config - INFO - Validation Acc: 0.8667
2024-03-28 22:37:15,919 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 22:58:14,314 - config - INFO - resume: None
2024-03-28 22:58:14,314 - config - INFO - device: cpu
2024-03-28 22:58:14,314 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:58:14,314 - config - INFO - learning_rate: 0.001
2024-03-28 22:58:14,314 - config - INFO - num_epochs: 200
2024-03-28 22:58:14,314 - config - INFO - batch_size: 64
2024-03-28 22:58:14,314 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:58:14,336 - config - INFO - Dataset size: 891
2024-03-28 22:58:14,359 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.95 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 22:58:14,359 - config - INFO - Training start
2024-03-28 22:58:16,610 - config - INFO - Epoch [1/200], Train Loss: 0.6868
2024-03-28 22:58:16,612 - config - INFO - Validation Loss: 0.6595
2024-03-28 22:58:16,612 - config - INFO - Validation Acc: 0.8222
2024-03-28 22:58:16,650 - config - INFO - Epoch [2/200], Train Loss: 0.6419
2024-03-28 22:58:16,651 - config - INFO - Validation Loss: 0.6115
2024-03-28 22:58:16,651 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:58:16,695 - config - INFO - Epoch [3/200], Train Loss: 0.5895
2024-03-28 22:58:16,696 - config - INFO - Validation Loss: 0.5522
2024-03-28 22:58:16,696 - config - INFO - Validation Acc: 0.7778
2024-03-28 22:58:16,734 - config - INFO - Epoch [4/200], Train Loss: 0.5335
2024-03-28 22:58:16,736 - config - INFO - Validation Loss: 0.4919
2024-03-28 22:58:16,736 - config - INFO - Validation Acc: 0.7556
2024-03-28 22:58:16,774 - config - INFO - Epoch [5/200], Train Loss: 0.4908
2024-03-28 22:58:16,775 - config - INFO - Validation Loss: 0.4436
2024-03-28 22:58:16,775 - config - INFO - Validation Acc: 0.7556
2024-03-28 22:58:16,813 - config - INFO - Epoch [6/200], Train Loss: 0.4626
2024-03-28 22:58:16,814 - config - INFO - Validation Loss: 0.4088
2024-03-28 22:58:16,814 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:58:16,851 - config - INFO - Epoch [7/200], Train Loss: 0.4490
2024-03-28 22:58:16,852 - config - INFO - Validation Loss: 0.3984
2024-03-28 22:58:16,852 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:58:16,889 - config - INFO - Epoch [8/200], Train Loss: 0.4395
2024-03-28 22:58:16,890 - config - INFO - Validation Loss: 0.4013
2024-03-28 22:58:16,890 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:58:16,925 - config - INFO - Epoch [9/200], Train Loss: 0.4324
2024-03-28 22:58:16,927 - config - INFO - Validation Loss: 0.3936
2024-03-28 22:58:16,927 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:58:16,962 - config - INFO - Epoch [10/200], Train Loss: 0.4270
2024-03-28 22:58:16,963 - config - INFO - Validation Loss: 0.3917
2024-03-28 22:58:16,964 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:58:16,998 - config - INFO - Epoch [11/200], Train Loss: 0.4230
2024-03-28 22:58:16,999 - config - INFO - Validation Loss: 0.3961
2024-03-28 22:58:16,999 - config - INFO - Validation Acc: 0.8222
2024-03-28 22:58:17,000 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 22:58:46,276 - config - INFO - resume: None
2024-03-28 22:58:46,276 - config - INFO - device: cpu
2024-03-28 22:58:46,276 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:58:46,276 - config - INFO - learning_rate: 0.001
2024-03-28 22:58:46,276 - config - INFO - num_epochs: 200
2024-03-28 22:58:46,276 - config - INFO - batch_size: 64
2024-03-28 22:58:46,276 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:58:46,298 - config - INFO - Dataset size: 891
2024-03-28 22:58:46,323 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.95 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 22:58:46,323 - config - INFO - Training start
2024-03-28 22:58:48,589 - config - INFO - Epoch [1/200], Train Loss: 0.6963
2024-03-28 22:58:48,591 - config - INFO - Validation Loss: 0.6560
2024-03-28 22:58:48,591 - config - INFO - Validation Acc: 0.7556
2024-03-28 22:58:48,642 - config - INFO - Epoch [2/200], Train Loss: 0.6461
2024-03-28 22:58:48,644 - config - INFO - Validation Loss: 0.6070
2024-03-28 22:58:48,644 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:58:48,690 - config - INFO - Epoch [3/200], Train Loss: 0.5945
2024-03-28 22:58:48,692 - config - INFO - Validation Loss: 0.5475
2024-03-28 22:58:48,692 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:58:48,738 - config - INFO - Epoch [4/200], Train Loss: 0.5334
2024-03-28 22:58:48,739 - config - INFO - Validation Loss: 0.4887
2024-03-28 22:58:48,740 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:58:48,782 - config - INFO - Epoch [5/200], Train Loss: 0.4787
2024-03-28 22:58:48,783 - config - INFO - Validation Loss: 0.4555
2024-03-28 22:58:48,784 - config - INFO - Validation Acc: 0.8444
2024-03-28 22:58:48,825 - config - INFO - Epoch [6/200], Train Loss: 0.4466
2024-03-28 22:58:48,827 - config - INFO - Validation Loss: 0.4569
2024-03-28 22:58:48,827 - config - INFO - Validation Acc: 0.8222
2024-03-28 22:58:48,868 - config - INFO - Epoch [7/200], Train Loss: 0.4329
2024-03-28 22:58:48,870 - config - INFO - Validation Loss: 0.4565
2024-03-28 22:58:48,870 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:58:48,911 - config - INFO - Epoch [8/200], Train Loss: 0.4247
2024-03-28 22:58:48,913 - config - INFO - Validation Loss: 0.4571
2024-03-28 22:58:48,913 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:58:48,954 - config - INFO - Epoch [9/200], Train Loss: 0.4190
2024-03-28 22:58:48,956 - config - INFO - Validation Loss: 0.4580
2024-03-28 22:58:48,956 - config - INFO - Validation Acc: 0.8000
2024-03-28 22:58:48,997 - config - INFO - Epoch [10/200], Train Loss: 0.4137
2024-03-28 22:58:48,999 - config - INFO - Validation Loss: 0.4658
2024-03-28 22:58:48,999 - config - INFO - Validation Acc: 0.8222
2024-03-28 22:58:48,999 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 22:59:08,802 - config - INFO - resume: None
2024-03-28 22:59:08,803 - config - INFO - device: cpu
2024-03-28 22:59:08,803 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:59:08,803 - config - INFO - learning_rate: 0.0001
2024-03-28 22:59:08,803 - config - INFO - num_epochs: 200
2024-03-28 22:59:08,803 - config - INFO - batch_size: 64
2024-03-28 22:59:08,803 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:59:08,824 - config - INFO - Dataset size: 891
2024-03-28 22:59:08,851 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.95 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 22:59:08,851 - config - INFO - Training start
2024-03-28 22:59:11,031 - config - INFO - Epoch [1/200], Train Loss: 0.6953
2024-03-28 22:59:11,033 - config - INFO - Validation Loss: 0.6956
2024-03-28 22:59:11,033 - config - INFO - Validation Acc: 0.3556
2024-03-28 22:59:11,079 - config - INFO - Epoch [2/200], Train Loss: 0.6883
2024-03-28 22:59:11,080 - config - INFO - Validation Loss: 0.6899
2024-03-28 22:59:11,080 - config - INFO - Validation Acc: 0.5778
2024-03-28 22:59:11,121 - config - INFO - Epoch [3/200], Train Loss: 0.6817
2024-03-28 22:59:11,123 - config - INFO - Validation Loss: 0.6845
2024-03-28 22:59:11,123 - config - INFO - Validation Acc: 0.6667
2024-03-28 22:59:11,160 - config - INFO - Epoch [4/200], Train Loss: 0.6754
2024-03-28 22:59:11,161 - config - INFO - Validation Loss: 0.6793
2024-03-28 22:59:11,162 - config - INFO - Validation Acc: 0.6444
2024-03-28 22:59:11,196 - config - INFO - Epoch [5/200], Train Loss: 0.6693
2024-03-28 22:59:11,197 - config - INFO - Validation Loss: 0.6743
2024-03-28 22:59:11,197 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:11,241 - config - INFO - Epoch [6/200], Train Loss: 0.6632
2024-03-28 22:59:11,242 - config - INFO - Validation Loss: 0.6698
2024-03-28 22:59:11,243 - config - INFO - Validation Acc: 0.6667
2024-03-28 22:59:11,272 - config - INFO - Epoch [7/200], Train Loss: 0.6574
2024-03-28 22:59:11,274 - config - INFO - Validation Loss: 0.6654
2024-03-28 22:59:11,274 - config - INFO - Validation Acc: 0.6667
2024-03-28 22:59:11,304 - config - INFO - Epoch [8/200], Train Loss: 0.6513
2024-03-28 22:59:11,305 - config - INFO - Validation Loss: 0.6613
2024-03-28 22:59:11,306 - config - INFO - Validation Acc: 0.6667
2024-03-28 22:59:11,335 - config - INFO - Epoch [9/200], Train Loss: 0.6453
2024-03-28 22:59:11,337 - config - INFO - Validation Loss: 0.6567
2024-03-28 22:59:11,337 - config - INFO - Validation Acc: 0.6667
2024-03-28 22:59:11,367 - config - INFO - Epoch [10/200], Train Loss: 0.6391
2024-03-28 22:59:11,368 - config - INFO - Validation Loss: 0.6526
2024-03-28 22:59:11,368 - config - INFO - Validation Acc: 0.6667
2024-03-28 22:59:11,398 - config - INFO - Epoch [11/200], Train Loss: 0.6328
2024-03-28 22:59:11,400 - config - INFO - Validation Loss: 0.6486
2024-03-28 22:59:11,400 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:11,430 - config - INFO - Epoch [12/200], Train Loss: 0.6265
2024-03-28 22:59:11,431 - config - INFO - Validation Loss: 0.6447
2024-03-28 22:59:11,431 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:11,461 - config - INFO - Epoch [13/200], Train Loss: 0.6201
2024-03-28 22:59:11,462 - config - INFO - Validation Loss: 0.6399
2024-03-28 22:59:11,463 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:11,498 - config - INFO - Epoch [14/200], Train Loss: 0.6137
2024-03-28 22:59:11,499 - config - INFO - Validation Loss: 0.6354
2024-03-28 22:59:11,499 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:11,534 - config - INFO - Epoch [15/200], Train Loss: 0.6076
2024-03-28 22:59:11,536 - config - INFO - Validation Loss: 0.6312
2024-03-28 22:59:11,536 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:11,584 - config - INFO - Epoch [16/200], Train Loss: 0.6013
2024-03-28 22:59:11,585 - config - INFO - Validation Loss: 0.6279
2024-03-28 22:59:11,585 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:11,620 - config - INFO - Epoch [17/200], Train Loss: 0.5950
2024-03-28 22:59:11,622 - config - INFO - Validation Loss: 0.6232
2024-03-28 22:59:11,622 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:11,656 - config - INFO - Epoch [18/200], Train Loss: 0.5885
2024-03-28 22:59:11,658 - config - INFO - Validation Loss: 0.6187
2024-03-28 22:59:11,658 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:11,693 - config - INFO - Epoch [19/200], Train Loss: 0.5820
2024-03-28 22:59:11,694 - config - INFO - Validation Loss: 0.6147
2024-03-28 22:59:11,694 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:11,729 - config - INFO - Epoch [20/200], Train Loss: 0.5754
2024-03-28 22:59:11,731 - config - INFO - Validation Loss: 0.6097
2024-03-28 22:59:11,731 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:11,766 - config - INFO - Epoch [21/200], Train Loss: 0.5688
2024-03-28 22:59:11,767 - config - INFO - Validation Loss: 0.6051
2024-03-28 22:59:11,767 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:11,802 - config - INFO - Epoch [22/200], Train Loss: 0.5622
2024-03-28 22:59:11,804 - config - INFO - Validation Loss: 0.6014
2024-03-28 22:59:11,804 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:11,838 - config - INFO - Epoch [23/200], Train Loss: 0.5554
2024-03-28 22:59:11,840 - config - INFO - Validation Loss: 0.5967
2024-03-28 22:59:11,840 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:11,875 - config - INFO - Epoch [24/200], Train Loss: 0.5490
2024-03-28 22:59:11,876 - config - INFO - Validation Loss: 0.5917
2024-03-28 22:59:11,877 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:11,911 - config - INFO - Epoch [25/200], Train Loss: 0.5418
2024-03-28 22:59:11,913 - config - INFO - Validation Loss: 0.5869
2024-03-28 22:59:11,913 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:11,948 - config - INFO - Epoch [26/200], Train Loss: 0.5350
2024-03-28 22:59:11,949 - config - INFO - Validation Loss: 0.5819
2024-03-28 22:59:11,949 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:11,984 - config - INFO - Epoch [27/200], Train Loss: 0.5276
2024-03-28 22:59:11,986 - config - INFO - Validation Loss: 0.5781
2024-03-28 22:59:11,986 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,020 - config - INFO - Epoch [28/200], Train Loss: 0.5209
2024-03-28 22:59:12,022 - config - INFO - Validation Loss: 0.5738
2024-03-28 22:59:12,022 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,057 - config - INFO - Epoch [29/200], Train Loss: 0.5142
2024-03-28 22:59:12,059 - config - INFO - Validation Loss: 0.5700
2024-03-28 22:59:12,059 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,094 - config - INFO - Epoch [30/200], Train Loss: 0.5079
2024-03-28 22:59:12,095 - config - INFO - Validation Loss: 0.5674
2024-03-28 22:59:12,095 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,130 - config - INFO - Epoch [31/200], Train Loss: 0.5022
2024-03-28 22:59:12,131 - config - INFO - Validation Loss: 0.5641
2024-03-28 22:59:12,132 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,166 - config - INFO - Epoch [32/200], Train Loss: 0.4966
2024-03-28 22:59:12,168 - config - INFO - Validation Loss: 0.5610
2024-03-28 22:59:12,168 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,203 - config - INFO - Epoch [33/200], Train Loss: 0.4912
2024-03-28 22:59:12,204 - config - INFO - Validation Loss: 0.5595
2024-03-28 22:59:12,204 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,239 - config - INFO - Epoch [34/200], Train Loss: 0.4863
2024-03-28 22:59:12,241 - config - INFO - Validation Loss: 0.5587
2024-03-28 22:59:12,241 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,276 - config - INFO - Epoch [35/200], Train Loss: 0.4816
2024-03-28 22:59:12,277 - config - INFO - Validation Loss: 0.5563
2024-03-28 22:59:12,278 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,312 - config - INFO - Epoch [36/200], Train Loss: 0.4774
2024-03-28 22:59:12,314 - config - INFO - Validation Loss: 0.5537
2024-03-28 22:59:12,314 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,349 - config - INFO - Epoch [37/200], Train Loss: 0.4734
2024-03-28 22:59:12,350 - config - INFO - Validation Loss: 0.5531
2024-03-28 22:59:12,350 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,385 - config - INFO - Epoch [38/200], Train Loss: 0.4697
2024-03-28 22:59:12,387 - config - INFO - Validation Loss: 0.5515
2024-03-28 22:59:12,387 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,421 - config - INFO - Epoch [39/200], Train Loss: 0.4664
2024-03-28 22:59:12,423 - config - INFO - Validation Loss: 0.5516
2024-03-28 22:59:12,423 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,457 - config - INFO - Epoch [40/200], Train Loss: 0.4630
2024-03-28 22:59:12,458 - config - INFO - Validation Loss: 0.5513
2024-03-28 22:59:12,459 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,493 - config - INFO - Epoch [41/200], Train Loss: 0.4601
2024-03-28 22:59:12,494 - config - INFO - Validation Loss: 0.5521
2024-03-28 22:59:12,495 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,529 - config - INFO - Epoch [42/200], Train Loss: 0.4574
2024-03-28 22:59:12,530 - config - INFO - Validation Loss: 0.5526
2024-03-28 22:59:12,531 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,573 - config - INFO - Epoch [43/200], Train Loss: 0.4547
2024-03-28 22:59:12,574 - config - INFO - Validation Loss: 0.5510
2024-03-28 22:59:12,575 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,609 - config - INFO - Epoch [44/200], Train Loss: 0.4522
2024-03-28 22:59:12,610 - config - INFO - Validation Loss: 0.5512
2024-03-28 22:59:12,610 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,645 - config - INFO - Epoch [45/200], Train Loss: 0.4498
2024-03-28 22:59:12,646 - config - INFO - Validation Loss: 0.5504
2024-03-28 22:59:12,646 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,681 - config - INFO - Epoch [46/200], Train Loss: 0.4476
2024-03-28 22:59:12,682 - config - INFO - Validation Loss: 0.5502
2024-03-28 22:59:12,682 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,716 - config - INFO - Epoch [47/200], Train Loss: 0.4456
2024-03-28 22:59:12,718 - config - INFO - Validation Loss: 0.5488
2024-03-28 22:59:12,718 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,752 - config - INFO - Epoch [48/200], Train Loss: 0.4438
2024-03-28 22:59:12,754 - config - INFO - Validation Loss: 0.5488
2024-03-28 22:59:12,754 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,788 - config - INFO - Epoch [49/200], Train Loss: 0.4422
2024-03-28 22:59:12,790 - config - INFO - Validation Loss: 0.5495
2024-03-28 22:59:12,790 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,824 - config - INFO - Epoch [50/200], Train Loss: 0.4406
2024-03-28 22:59:12,826 - config - INFO - Validation Loss: 0.5489
2024-03-28 22:59:12,826 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,860 - config - INFO - Epoch [51/200], Train Loss: 0.4389
2024-03-28 22:59:12,862 - config - INFO - Validation Loss: 0.5490
2024-03-28 22:59:12,862 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,896 - config - INFO - Epoch [52/200], Train Loss: 0.4375
2024-03-28 22:59:12,898 - config - INFO - Validation Loss: 0.5483
2024-03-28 22:59:12,898 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,932 - config - INFO - Epoch [53/200], Train Loss: 0.4361
2024-03-28 22:59:12,933 - config - INFO - Validation Loss: 0.5481
2024-03-28 22:59:12,934 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:12,968 - config - INFO - Epoch [54/200], Train Loss: 0.4350
2024-03-28 22:59:12,969 - config - INFO - Validation Loss: 0.5485
2024-03-28 22:59:12,970 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:13,004 - config - INFO - Epoch [55/200], Train Loss: 0.4336
2024-03-28 22:59:13,005 - config - INFO - Validation Loss: 0.5486
2024-03-28 22:59:13,005 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:13,040 - config - INFO - Epoch [56/200], Train Loss: 0.4326
2024-03-28 22:59:13,041 - config - INFO - Validation Loss: 0.5508
2024-03-28 22:59:13,041 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:13,092 - config - INFO - Epoch [57/200], Train Loss: 0.4313
2024-03-28 22:59:13,094 - config - INFO - Validation Loss: 0.5473
2024-03-28 22:59:13,094 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:13,133 - config - INFO - Epoch [58/200], Train Loss: 0.4304
2024-03-28 22:59:13,134 - config - INFO - Validation Loss: 0.5462
2024-03-28 22:59:13,135 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:13,173 - config - INFO - Epoch [59/200], Train Loss: 0.4295
2024-03-28 22:59:13,175 - config - INFO - Validation Loss: 0.5463
2024-03-28 22:59:13,175 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:13,214 - config - INFO - Epoch [60/200], Train Loss: 0.4285
2024-03-28 22:59:13,215 - config - INFO - Validation Loss: 0.5476
2024-03-28 22:59:13,215 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:13,254 - config - INFO - Epoch [61/200], Train Loss: 0.4278
2024-03-28 22:59:13,255 - config - INFO - Validation Loss: 0.5497
2024-03-28 22:59:13,256 - config - INFO - Validation Acc: 0.6889
2024-03-28 22:59:13,256 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 22:59:31,354 - config - INFO - resume: None
2024-03-28 22:59:31,354 - config - INFO - device: cpu
2024-03-28 22:59:31,354 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:59:31,354 - config - INFO - learning_rate: 0.0001
2024-03-28 22:59:31,354 - config - INFO - num_epochs: 200
2024-03-28 22:59:31,354 - config - INFO - batch_size: 32
2024-03-28 22:59:31,354 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:59:31,376 - config - INFO - Dataset size: 891
2024-03-28 22:59:31,399 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.95 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 22:59:31,399 - config - INFO - Training start
2024-03-28 22:59:33,669 - config - INFO - Epoch [1/200], Train Loss: 0.6691
2024-03-28 22:59:33,671 - config - INFO - Validation Loss: 0.6648
2024-03-28 22:59:33,671 - config - INFO - Validation Acc: 0.4615
2024-03-28 22:59:33,719 - config - INFO - Epoch [2/200], Train Loss: 0.6604
2024-03-28 22:59:33,721 - config - INFO - Validation Loss: 0.6553
2024-03-28 22:59:33,721 - config - INFO - Validation Acc: 0.4615
2024-03-28 22:59:33,766 - config - INFO - Epoch [3/200], Train Loss: 0.6518
2024-03-28 22:59:33,767 - config - INFO - Validation Loss: 0.6455
2024-03-28 22:59:33,768 - config - INFO - Validation Acc: 0.4615
2024-03-28 22:59:33,813 - config - INFO - Epoch [4/200], Train Loss: 0.6431
2024-03-28 22:59:33,814 - config - INFO - Validation Loss: 0.6357
2024-03-28 22:59:33,814 - config - INFO - Validation Acc: 0.4615
2024-03-28 22:59:33,859 - config - INFO - Epoch [5/200], Train Loss: 0.6344
2024-03-28 22:59:33,861 - config - INFO - Validation Loss: 0.6260
2024-03-28 22:59:33,861 - config - INFO - Validation Acc: 0.4615
2024-03-28 22:59:33,906 - config - INFO - Epoch [6/200], Train Loss: 0.6256
2024-03-28 22:59:33,908 - config - INFO - Validation Loss: 0.6163
2024-03-28 22:59:33,908 - config - INFO - Validation Acc: 0.4615
2024-03-28 22:59:33,953 - config - INFO - Epoch [7/200], Train Loss: 0.6163
2024-03-28 22:59:33,954 - config - INFO - Validation Loss: 0.6067
2024-03-28 22:59:33,954 - config - INFO - Validation Acc: 0.4615
2024-03-28 22:59:33,999 - config - INFO - Epoch [8/200], Train Loss: 0.6070
2024-03-28 22:59:34,000 - config - INFO - Validation Loss: 0.5958
2024-03-28 22:59:34,000 - config - INFO - Validation Acc: 0.4615
2024-03-28 22:59:34,045 - config - INFO - Epoch [9/200], Train Loss: 0.5971
2024-03-28 22:59:34,046 - config - INFO - Validation Loss: 0.5866
2024-03-28 22:59:34,046 - config - INFO - Validation Acc: 0.6154
2024-03-28 22:59:34,091 - config - INFO - Epoch [10/200], Train Loss: 0.5872
2024-03-28 22:59:34,092 - config - INFO - Validation Loss: 0.5758
2024-03-28 22:59:34,092 - config - INFO - Validation Acc: 0.6923
2024-03-28 22:59:34,153 - config - INFO - Epoch [11/200], Train Loss: 0.5770
2024-03-28 22:59:34,154 - config - INFO - Validation Loss: 0.5658
2024-03-28 22:59:34,155 - config - INFO - Validation Acc: 0.6923
2024-03-28 22:59:34,199 - config - INFO - Epoch [12/200], Train Loss: 0.5669
2024-03-28 22:59:34,200 - config - INFO - Validation Loss: 0.5565
2024-03-28 22:59:34,201 - config - INFO - Validation Acc: 0.6923
2024-03-28 22:59:34,245 - config - INFO - Epoch [13/200], Train Loss: 0.5566
2024-03-28 22:59:34,247 - config - INFO - Validation Loss: 0.5460
2024-03-28 22:59:34,247 - config - INFO - Validation Acc: 0.6923
2024-03-28 22:59:34,291 - config - INFO - Epoch [14/200], Train Loss: 0.5464
2024-03-28 22:59:34,293 - config - INFO - Validation Loss: 0.5372
2024-03-28 22:59:34,293 - config - INFO - Validation Acc: 0.6923
2024-03-28 22:59:34,338 - config - INFO - Epoch [15/200], Train Loss: 0.5367
2024-03-28 22:59:34,339 - config - INFO - Validation Loss: 0.5284
2024-03-28 22:59:34,339 - config - INFO - Validation Acc: 0.6923
2024-03-28 22:59:34,384 - config - INFO - Epoch [16/200], Train Loss: 0.5272
2024-03-28 22:59:34,385 - config - INFO - Validation Loss: 0.5210
2024-03-28 22:59:34,385 - config - INFO - Validation Acc: 0.6923
2024-03-28 22:59:34,430 - config - INFO - Epoch [17/200], Train Loss: 0.5181
2024-03-28 22:59:34,431 - config - INFO - Validation Loss: 0.5137
2024-03-28 22:59:34,431 - config - INFO - Validation Acc: 0.6923
2024-03-28 22:59:34,476 - config - INFO - Epoch [18/200], Train Loss: 0.5095
2024-03-28 22:59:34,477 - config - INFO - Validation Loss: 0.5075
2024-03-28 22:59:34,477 - config - INFO - Validation Acc: 0.6923
2024-03-28 22:59:34,522 - config - INFO - Epoch [19/200], Train Loss: 0.5013
2024-03-28 22:59:34,523 - config - INFO - Validation Loss: 0.5025
2024-03-28 22:59:34,523 - config - INFO - Validation Acc: 0.6923
2024-03-28 22:59:34,567 - config - INFO - Epoch [20/200], Train Loss: 0.4934
2024-03-28 22:59:34,569 - config - INFO - Validation Loss: 0.4965
2024-03-28 22:59:34,569 - config - INFO - Validation Acc: 0.6923
2024-03-28 22:59:34,615 - config - INFO - Epoch [21/200], Train Loss: 0.4860
2024-03-28 22:59:34,616 - config - INFO - Validation Loss: 0.4917
2024-03-28 22:59:34,616 - config - INFO - Validation Acc: 0.6923
2024-03-28 22:59:34,660 - config - INFO - Epoch [22/200], Train Loss: 0.4793
2024-03-28 22:59:34,662 - config - INFO - Validation Loss: 0.4876
2024-03-28 22:59:34,662 - config - INFO - Validation Acc: 0.6923
2024-03-28 22:59:34,706 - config - INFO - Epoch [23/200], Train Loss: 0.4731
2024-03-28 22:59:34,708 - config - INFO - Validation Loss: 0.4843
2024-03-28 22:59:34,708 - config - INFO - Validation Acc: 0.6923
2024-03-28 22:59:34,752 - config - INFO - Epoch [24/200], Train Loss: 0.4673
2024-03-28 22:59:34,753 - config - INFO - Validation Loss: 0.4820
2024-03-28 22:59:34,754 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:34,798 - config - INFO - Epoch [25/200], Train Loss: 0.4619
2024-03-28 22:59:34,799 - config - INFO - Validation Loss: 0.4792
2024-03-28 22:59:34,800 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:34,844 - config - INFO - Epoch [26/200], Train Loss: 0.4573
2024-03-28 22:59:34,845 - config - INFO - Validation Loss: 0.4781
2024-03-28 22:59:34,846 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:34,890 - config - INFO - Epoch [27/200], Train Loss: 0.4535
2024-03-28 22:59:34,891 - config - INFO - Validation Loss: 0.4749
2024-03-28 22:59:34,892 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:34,936 - config - INFO - Epoch [28/200], Train Loss: 0.4494
2024-03-28 22:59:34,938 - config - INFO - Validation Loss: 0.4748
2024-03-28 22:59:34,938 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:34,982 - config - INFO - Epoch [29/200], Train Loss: 0.4459
2024-03-28 22:59:34,984 - config - INFO - Validation Loss: 0.4746
2024-03-28 22:59:34,984 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:35,028 - config - INFO - Epoch [30/200], Train Loss: 0.4431
2024-03-28 22:59:35,029 - config - INFO - Validation Loss: 0.4729
2024-03-28 22:59:35,030 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:35,074 - config - INFO - Epoch [31/200], Train Loss: 0.4402
2024-03-28 22:59:35,075 - config - INFO - Validation Loss: 0.4735
2024-03-28 22:59:35,075 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:35,129 - config - INFO - Epoch [32/200], Train Loss: 0.4378
2024-03-28 22:59:35,131 - config - INFO - Validation Loss: 0.4729
2024-03-28 22:59:35,131 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:35,175 - config - INFO - Epoch [33/200], Train Loss: 0.4356
2024-03-28 22:59:35,177 - config - INFO - Validation Loss: 0.4741
2024-03-28 22:59:35,177 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:35,221 - config - INFO - Epoch [34/200], Train Loss: 0.4334
2024-03-28 22:59:35,223 - config - INFO - Validation Loss: 0.4725
2024-03-28 22:59:35,223 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:35,274 - config - INFO - Epoch [35/200], Train Loss: 0.4318
2024-03-28 22:59:35,276 - config - INFO - Validation Loss: 0.4721
2024-03-28 22:59:35,276 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:35,320 - config - INFO - Epoch [36/200], Train Loss: 0.4300
2024-03-28 22:59:35,322 - config - INFO - Validation Loss: 0.4715
2024-03-28 22:59:35,322 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:35,367 - config - INFO - Epoch [37/200], Train Loss: 0.4287
2024-03-28 22:59:35,368 - config - INFO - Validation Loss: 0.4710
2024-03-28 22:59:35,368 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:35,413 - config - INFO - Epoch [38/200], Train Loss: 0.4273
2024-03-28 22:59:35,414 - config - INFO - Validation Loss: 0.4720
2024-03-28 22:59:35,414 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:35,458 - config - INFO - Epoch [39/200], Train Loss: 0.4260
2024-03-28 22:59:35,460 - config - INFO - Validation Loss: 0.4723
2024-03-28 22:59:35,460 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:35,504 - config - INFO - Epoch [40/200], Train Loss: 0.4248
2024-03-28 22:59:35,505 - config - INFO - Validation Loss: 0.4713
2024-03-28 22:59:35,506 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:35,550 - config - INFO - Epoch [41/200], Train Loss: 0.4237
2024-03-28 22:59:35,551 - config - INFO - Validation Loss: 0.4706
2024-03-28 22:59:35,551 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:35,595 - config - INFO - Epoch [42/200], Train Loss: 0.4227
2024-03-28 22:59:35,597 - config - INFO - Validation Loss: 0.4700
2024-03-28 22:59:35,597 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:35,655 - config - INFO - Epoch [43/200], Train Loss: 0.4219
2024-03-28 22:59:35,657 - config - INFO - Validation Loss: 0.4709
2024-03-28 22:59:35,657 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:35,701 - config - INFO - Epoch [44/200], Train Loss: 0.4211
2024-03-28 22:59:35,702 - config - INFO - Validation Loss: 0.4695
2024-03-28 22:59:35,703 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:35,747 - config - INFO - Epoch [45/200], Train Loss: 0.4201
2024-03-28 22:59:35,749 - config - INFO - Validation Loss: 0.4691
2024-03-28 22:59:35,749 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:35,793 - config - INFO - Epoch [46/200], Train Loss: 0.4193
2024-03-28 22:59:35,795 - config - INFO - Validation Loss: 0.4697
2024-03-28 22:59:35,795 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:35,839 - config - INFO - Epoch [47/200], Train Loss: 0.4186
2024-03-28 22:59:35,840 - config - INFO - Validation Loss: 0.4686
2024-03-28 22:59:35,841 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:35,885 - config - INFO - Epoch [48/200], Train Loss: 0.4180
2024-03-28 22:59:35,886 - config - INFO - Validation Loss: 0.4680
2024-03-28 22:59:35,886 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:35,930 - config - INFO - Epoch [49/200], Train Loss: 0.4172
2024-03-28 22:59:35,931 - config - INFO - Validation Loss: 0.4693
2024-03-28 22:59:35,932 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:35,976 - config - INFO - Epoch [50/200], Train Loss: 0.4166
2024-03-28 22:59:35,977 - config - INFO - Validation Loss: 0.4675
2024-03-28 22:59:35,977 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:36,021 - config - INFO - Epoch [51/200], Train Loss: 0.4160
2024-03-28 22:59:36,023 - config - INFO - Validation Loss: 0.4676
2024-03-28 22:59:36,023 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:36,069 - config - INFO - Epoch [52/200], Train Loss: 0.4155
2024-03-28 22:59:36,070 - config - INFO - Validation Loss: 0.4669
2024-03-28 22:59:36,071 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:36,121 - config - INFO - Epoch [53/200], Train Loss: 0.4147
2024-03-28 22:59:36,123 - config - INFO - Validation Loss: 0.4662
2024-03-28 22:59:36,123 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:36,174 - config - INFO - Epoch [54/200], Train Loss: 0.4143
2024-03-28 22:59:36,175 - config - INFO - Validation Loss: 0.4654
2024-03-28 22:59:36,175 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:36,226 - config - INFO - Epoch [55/200], Train Loss: 0.4136
2024-03-28 22:59:36,228 - config - INFO - Validation Loss: 0.4650
2024-03-28 22:59:36,228 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:36,279 - config - INFO - Epoch [56/200], Train Loss: 0.4130
2024-03-28 22:59:36,280 - config - INFO - Validation Loss: 0.4648
2024-03-28 22:59:36,281 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:36,331 - config - INFO - Epoch [57/200], Train Loss: 0.4124
2024-03-28 22:59:36,333 - config - INFO - Validation Loss: 0.4642
2024-03-28 22:59:36,333 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:36,384 - config - INFO - Epoch [58/200], Train Loss: 0.4120
2024-03-28 22:59:36,386 - config - INFO - Validation Loss: 0.4630
2024-03-28 22:59:36,395 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:36,449 - config - INFO - Epoch [59/200], Train Loss: 0.4114
2024-03-28 22:59:36,451 - config - INFO - Validation Loss: 0.4624
2024-03-28 22:59:36,451 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:36,502 - config - INFO - Epoch [60/200], Train Loss: 0.4109
2024-03-28 22:59:36,504 - config - INFO - Validation Loss: 0.4619
2024-03-28 22:59:36,504 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:36,555 - config - INFO - Epoch [61/200], Train Loss: 0.4103
2024-03-28 22:59:36,557 - config - INFO - Validation Loss: 0.4618
2024-03-28 22:59:36,557 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:36,608 - config - INFO - Epoch [62/200], Train Loss: 0.4099
2024-03-28 22:59:36,612 - config - INFO - Validation Loss: 0.4623
2024-03-28 22:59:36,613 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:36,665 - config - INFO - Epoch [63/200], Train Loss: 0.4095
2024-03-28 22:59:36,667 - config - INFO - Validation Loss: 0.4616
2024-03-28 22:59:36,667 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:36,718 - config - INFO - Epoch [64/200], Train Loss: 0.4090
2024-03-28 22:59:36,719 - config - INFO - Validation Loss: 0.4603
2024-03-28 22:59:36,720 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:36,771 - config - INFO - Epoch [65/200], Train Loss: 0.4086
2024-03-28 22:59:36,772 - config - INFO - Validation Loss: 0.4609
2024-03-28 22:59:36,772 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:36,823 - config - INFO - Epoch [66/200], Train Loss: 0.4081
2024-03-28 22:59:36,825 - config - INFO - Validation Loss: 0.4594
2024-03-28 22:59:36,825 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:36,876 - config - INFO - Epoch [67/200], Train Loss: 0.4077
2024-03-28 22:59:36,878 - config - INFO - Validation Loss: 0.4592
2024-03-28 22:59:36,878 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:36,929 - config - INFO - Epoch [68/200], Train Loss: 0.4073
2024-03-28 22:59:36,930 - config - INFO - Validation Loss: 0.4575
2024-03-28 22:59:36,931 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:36,982 - config - INFO - Epoch [69/200], Train Loss: 0.4068
2024-03-28 22:59:36,983 - config - INFO - Validation Loss: 0.4589
2024-03-28 22:59:36,984 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:37,034 - config - INFO - Epoch [70/200], Train Loss: 0.4066
2024-03-28 22:59:37,036 - config - INFO - Validation Loss: 0.4571
2024-03-28 22:59:37,036 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:37,087 - config - INFO - Epoch [71/200], Train Loss: 0.4060
2024-03-28 22:59:37,089 - config - INFO - Validation Loss: 0.4570
2024-03-28 22:59:37,089 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:37,141 - config - INFO - Epoch [72/200], Train Loss: 0.4057
2024-03-28 22:59:37,142 - config - INFO - Validation Loss: 0.4560
2024-03-28 22:59:37,143 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:37,194 - config - INFO - Epoch [73/200], Train Loss: 0.4053
2024-03-28 22:59:37,196 - config - INFO - Validation Loss: 0.4569
2024-03-28 22:59:37,196 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:37,247 - config - INFO - Epoch [74/200], Train Loss: 0.4049
2024-03-28 22:59:37,248 - config - INFO - Validation Loss: 0.4551
2024-03-28 22:59:37,249 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:37,300 - config - INFO - Epoch [75/200], Train Loss: 0.4044
2024-03-28 22:59:37,302 - config - INFO - Validation Loss: 0.4549
2024-03-28 22:59:37,302 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:37,353 - config - INFO - Epoch [76/200], Train Loss: 0.4042
2024-03-28 22:59:37,355 - config - INFO - Validation Loss: 0.4548
2024-03-28 22:59:37,355 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:37,406 - config - INFO - Epoch [77/200], Train Loss: 0.4037
2024-03-28 22:59:37,408 - config - INFO - Validation Loss: 0.4543
2024-03-28 22:59:37,408 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:37,459 - config - INFO - Epoch [78/200], Train Loss: 0.4034
2024-03-28 22:59:37,460 - config - INFO - Validation Loss: 0.4548
2024-03-28 22:59:37,460 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:37,511 - config - INFO - Epoch [79/200], Train Loss: 0.4031
2024-03-28 22:59:37,513 - config - INFO - Validation Loss: 0.4533
2024-03-28 22:59:37,513 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:37,564 - config - INFO - Epoch [80/200], Train Loss: 0.4029
2024-03-28 22:59:37,566 - config - INFO - Validation Loss: 0.4519
2024-03-28 22:59:37,566 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:37,617 - config - INFO - Epoch [81/200], Train Loss: 0.4025
2024-03-28 22:59:37,621 - config - INFO - Validation Loss: 0.4526
2024-03-28 22:59:37,621 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:37,672 - config - INFO - Epoch [82/200], Train Loss: 0.4022
2024-03-28 22:59:37,674 - config - INFO - Validation Loss: 0.4534
2024-03-28 22:59:37,674 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:37,725 - config - INFO - Epoch [83/200], Train Loss: 0.4017
2024-03-28 22:59:37,727 - config - INFO - Validation Loss: 0.4516
2024-03-28 22:59:37,727 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:37,778 - config - INFO - Epoch [84/200], Train Loss: 0.4014
2024-03-28 22:59:37,779 - config - INFO - Validation Loss: 0.4519
2024-03-28 22:59:37,779 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:37,830 - config - INFO - Epoch [85/200], Train Loss: 0.4015
2024-03-28 22:59:37,832 - config - INFO - Validation Loss: 0.4507
2024-03-28 22:59:37,832 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:37,883 - config - INFO - Epoch [86/200], Train Loss: 0.4010
2024-03-28 22:59:37,884 - config - INFO - Validation Loss: 0.4526
2024-03-28 22:59:37,884 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:37,935 - config - INFO - Epoch [87/200], Train Loss: 0.4005
2024-03-28 22:59:37,937 - config - INFO - Validation Loss: 0.4516
2024-03-28 22:59:37,937 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:37,988 - config - INFO - Epoch [88/200], Train Loss: 0.4003
2024-03-28 22:59:37,989 - config - INFO - Validation Loss: 0.4507
2024-03-28 22:59:37,990 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:38,040 - config - INFO - Epoch [89/200], Train Loss: 0.4000
2024-03-28 22:59:38,042 - config - INFO - Validation Loss: 0.4508
2024-03-28 22:59:38,042 - config - INFO - Validation Acc: 0.8462
2024-03-28 22:59:38,093 - config - INFO - Epoch [90/200], Train Loss: 0.3997
2024-03-28 22:59:38,094 - config - INFO - Validation Loss: 0.4487
2024-03-28 22:59:38,094 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:38,145 - config - INFO - Epoch [91/200], Train Loss: 0.3994
2024-03-28 22:59:38,147 - config - INFO - Validation Loss: 0.4498
2024-03-28 22:59:38,147 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:38,198 - config - INFO - Epoch [92/200], Train Loss: 0.3991
2024-03-28 22:59:38,199 - config - INFO - Validation Loss: 0.4491
2024-03-28 22:59:38,200 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:38,250 - config - INFO - Epoch [93/200], Train Loss: 0.3987
2024-03-28 22:59:38,252 - config - INFO - Validation Loss: 0.4495
2024-03-28 22:59:38,252 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:38,303 - config - INFO - Epoch [94/200], Train Loss: 0.3985
2024-03-28 22:59:38,305 - config - INFO - Validation Loss: 0.4490
2024-03-28 22:59:38,305 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:38,355 - config - INFO - Epoch [95/200], Train Loss: 0.3981
2024-03-28 22:59:38,357 - config - INFO - Validation Loss: 0.4483
2024-03-28 22:59:38,357 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:38,408 - config - INFO - Epoch [96/200], Train Loss: 0.3979
2024-03-28 22:59:38,409 - config - INFO - Validation Loss: 0.4497
2024-03-28 22:59:38,410 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:38,460 - config - INFO - Epoch [97/200], Train Loss: 0.3977
2024-03-28 22:59:38,462 - config - INFO - Validation Loss: 0.4483
2024-03-28 22:59:38,462 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:38,513 - config - INFO - Epoch [98/200], Train Loss: 0.3975
2024-03-28 22:59:38,514 - config - INFO - Validation Loss: 0.4490
2024-03-28 22:59:38,515 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:38,565 - config - INFO - Epoch [99/200], Train Loss: 0.3973
2024-03-28 22:59:38,567 - config - INFO - Validation Loss: 0.4490
2024-03-28 22:59:38,567 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:38,618 - config - INFO - Epoch [100/200], Train Loss: 0.3968
2024-03-28 22:59:38,619 - config - INFO - Validation Loss: 0.4487
2024-03-28 22:59:38,620 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:38,678 - config - INFO - Epoch [101/200], Train Loss: 0.3967
2024-03-28 22:59:38,680 - config - INFO - Validation Loss: 0.4488
2024-03-28 22:59:38,680 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:38,731 - config - INFO - Epoch [102/200], Train Loss: 0.3964
2024-03-28 22:59:38,733 - config - INFO - Validation Loss: 0.4480
2024-03-28 22:59:38,733 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:38,784 - config - INFO - Epoch [103/200], Train Loss: 0.3962
2024-03-28 22:59:38,785 - config - INFO - Validation Loss: 0.4494
2024-03-28 22:59:38,785 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:38,836 - config - INFO - Epoch [104/200], Train Loss: 0.3958
2024-03-28 22:59:38,838 - config - INFO - Validation Loss: 0.4478
2024-03-28 22:59:38,838 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:38,889 - config - INFO - Epoch [105/200], Train Loss: 0.3956
2024-03-28 22:59:38,891 - config - INFO - Validation Loss: 0.4476
2024-03-28 22:59:38,891 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:38,941 - config - INFO - Epoch [106/200], Train Loss: 0.3954
2024-03-28 22:59:38,943 - config - INFO - Validation Loss: 0.4478
2024-03-28 22:59:38,943 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:38,994 - config - INFO - Epoch [107/200], Train Loss: 0.3951
2024-03-28 22:59:38,996 - config - INFO - Validation Loss: 0.4482
2024-03-28 22:59:38,996 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:39,046 - config - INFO - Epoch [108/200], Train Loss: 0.3952
2024-03-28 22:59:39,048 - config - INFO - Validation Loss: 0.4480
2024-03-28 22:59:39,048 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:39,099 - config - INFO - Epoch [109/200], Train Loss: 0.3948
2024-03-28 22:59:39,101 - config - INFO - Validation Loss: 0.4466
2024-03-28 22:59:39,101 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:39,153 - config - INFO - Epoch [110/200], Train Loss: 0.3946
2024-03-28 22:59:39,155 - config - INFO - Validation Loss: 0.4488
2024-03-28 22:59:39,155 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:39,206 - config - INFO - Epoch [111/200], Train Loss: 0.3943
2024-03-28 22:59:39,208 - config - INFO - Validation Loss: 0.4478
2024-03-28 22:59:39,208 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:39,259 - config - INFO - Epoch [112/200], Train Loss: 0.3946
2024-03-28 22:59:39,260 - config - INFO - Validation Loss: 0.4458
2024-03-28 22:59:39,260 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:39,311 - config - INFO - Epoch [113/200], Train Loss: 0.3939
2024-03-28 22:59:39,313 - config - INFO - Validation Loss: 0.4473
2024-03-28 22:59:39,313 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:39,364 - config - INFO - Epoch [114/200], Train Loss: 0.3937
2024-03-28 22:59:39,366 - config - INFO - Validation Loss: 0.4467
2024-03-28 22:59:39,366 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:39,416 - config - INFO - Epoch [115/200], Train Loss: 0.3933
2024-03-28 22:59:39,418 - config - INFO - Validation Loss: 0.4464
2024-03-28 22:59:39,418 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:39,469 - config - INFO - Epoch [116/200], Train Loss: 0.3932
2024-03-28 22:59:39,471 - config - INFO - Validation Loss: 0.4461
2024-03-28 22:59:39,471 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:39,521 - config - INFO - Epoch [117/200], Train Loss: 0.3929
2024-03-28 22:59:39,523 - config - INFO - Validation Loss: 0.4461
2024-03-28 22:59:39,523 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:39,574 - config - INFO - Epoch [118/200], Train Loss: 0.3928
2024-03-28 22:59:39,576 - config - INFO - Validation Loss: 0.4463
2024-03-28 22:59:39,576 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:39,627 - config - INFO - Epoch [119/200], Train Loss: 0.3926
2024-03-28 22:59:39,628 - config - INFO - Validation Loss: 0.4452
2024-03-28 22:59:39,628 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:39,679 - config - INFO - Epoch [120/200], Train Loss: 0.3922
2024-03-28 22:59:39,681 - config - INFO - Validation Loss: 0.4447
2024-03-28 22:59:39,681 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:39,732 - config - INFO - Epoch [121/200], Train Loss: 0.3921
2024-03-28 22:59:39,734 - config - INFO - Validation Loss: 0.4437
2024-03-28 22:59:39,734 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:39,785 - config - INFO - Epoch [122/200], Train Loss: 0.3921
2024-03-28 22:59:39,787 - config - INFO - Validation Loss: 0.4447
2024-03-28 22:59:39,787 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:39,837 - config - INFO - Epoch [123/200], Train Loss: 0.3917
2024-03-28 22:59:39,839 - config - INFO - Validation Loss: 0.4442
2024-03-28 22:59:39,839 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:39,890 - config - INFO - Epoch [124/200], Train Loss: 0.3916
2024-03-28 22:59:39,892 - config - INFO - Validation Loss: 0.4444
2024-03-28 22:59:39,892 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:39,943 - config - INFO - Epoch [125/200], Train Loss: 0.3913
2024-03-28 22:59:39,944 - config - INFO - Validation Loss: 0.4439
2024-03-28 22:59:39,944 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:39,995 - config - INFO - Epoch [126/200], Train Loss: 0.3915
2024-03-28 22:59:39,997 - config - INFO - Validation Loss: 0.4434
2024-03-28 22:59:39,997 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:40,048 - config - INFO - Epoch [127/200], Train Loss: 0.3909
2024-03-28 22:59:40,049 - config - INFO - Validation Loss: 0.4438
2024-03-28 22:59:40,049 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:40,100 - config - INFO - Epoch [128/200], Train Loss: 0.3908
2024-03-28 22:59:40,102 - config - INFO - Validation Loss: 0.4447
2024-03-28 22:59:40,102 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:40,153 - config - INFO - Epoch [129/200], Train Loss: 0.3906
2024-03-28 22:59:40,154 - config - INFO - Validation Loss: 0.4453
2024-03-28 22:59:40,155 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:40,205 - config - INFO - Epoch [130/200], Train Loss: 0.3904
2024-03-28 22:59:40,207 - config - INFO - Validation Loss: 0.4443
2024-03-28 22:59:40,207 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:40,258 - config - INFO - Epoch [131/200], Train Loss: 0.3902
2024-03-28 22:59:40,260 - config - INFO - Validation Loss: 0.4436
2024-03-28 22:59:40,260 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:40,310 - config - INFO - Epoch [132/200], Train Loss: 0.3901
2024-03-28 22:59:40,312 - config - INFO - Validation Loss: 0.4436
2024-03-28 22:59:40,312 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:40,363 - config - INFO - Epoch [133/200], Train Loss: 0.3898
2024-03-28 22:59:40,364 - config - INFO - Validation Loss: 0.4439
2024-03-28 22:59:40,365 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:40,415 - config - INFO - Epoch [134/200], Train Loss: 0.3897
2024-03-28 22:59:40,417 - config - INFO - Validation Loss: 0.4434
2024-03-28 22:59:40,417 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:40,468 - config - INFO - Epoch [135/200], Train Loss: 0.3896
2024-03-28 22:59:40,469 - config - INFO - Validation Loss: 0.4429
2024-03-28 22:59:40,470 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:40,520 - config - INFO - Epoch [136/200], Train Loss: 0.3894
2024-03-28 22:59:40,522 - config - INFO - Validation Loss: 0.4419
2024-03-28 22:59:40,522 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:40,573 - config - INFO - Epoch [137/200], Train Loss: 0.3892
2024-03-28 22:59:40,574 - config - INFO - Validation Loss: 0.4408
2024-03-28 22:59:40,574 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:40,625 - config - INFO - Epoch [138/200], Train Loss: 0.3892
2024-03-28 22:59:40,627 - config - INFO - Validation Loss: 0.4408
2024-03-28 22:59:40,627 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:40,681 - config - INFO - Epoch [139/200], Train Loss: 0.3889
2024-03-28 22:59:40,683 - config - INFO - Validation Loss: 0.4410
2024-03-28 22:59:40,683 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:40,734 - config - INFO - Epoch [140/200], Train Loss: 0.3887
2024-03-28 22:59:40,735 - config - INFO - Validation Loss: 0.4408
2024-03-28 22:59:40,736 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:40,787 - config - INFO - Epoch [141/200], Train Loss: 0.3887
2024-03-28 22:59:40,788 - config - INFO - Validation Loss: 0.4425
2024-03-28 22:59:40,788 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:40,839 - config - INFO - Epoch [142/200], Train Loss: 0.3885
2024-03-28 22:59:40,841 - config - INFO - Validation Loss: 0.4422
2024-03-28 22:59:40,841 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:40,892 - config - INFO - Epoch [143/200], Train Loss: 0.3885
2024-03-28 22:59:40,894 - config - INFO - Validation Loss: 0.4396
2024-03-28 22:59:40,894 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:40,944 - config - INFO - Epoch [144/200], Train Loss: 0.3883
2024-03-28 22:59:40,946 - config - INFO - Validation Loss: 0.4416
2024-03-28 22:59:40,946 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:40,997 - config - INFO - Epoch [145/200], Train Loss: 0.3882
2024-03-28 22:59:40,998 - config - INFO - Validation Loss: 0.4406
2024-03-28 22:59:40,999 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:41,049 - config - INFO - Epoch [146/200], Train Loss: 0.3879
2024-03-28 22:59:41,051 - config - INFO - Validation Loss: 0.4405
2024-03-28 22:59:41,051 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:41,102 - config - INFO - Epoch [147/200], Train Loss: 0.3876
2024-03-28 22:59:41,103 - config - INFO - Validation Loss: 0.4406
2024-03-28 22:59:41,104 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:41,154 - config - INFO - Epoch [148/200], Train Loss: 0.3876
2024-03-28 22:59:41,156 - config - INFO - Validation Loss: 0.4410
2024-03-28 22:59:41,156 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:41,207 - config - INFO - Epoch [149/200], Train Loss: 0.3873
2024-03-28 22:59:41,209 - config - INFO - Validation Loss: 0.4406
2024-03-28 22:59:41,209 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:41,259 - config - INFO - Epoch [150/200], Train Loss: 0.3875
2024-03-28 22:59:41,261 - config - INFO - Validation Loss: 0.4406
2024-03-28 22:59:41,261 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:41,312 - config - INFO - Epoch [151/200], Train Loss: 0.3870
2024-03-28 22:59:41,314 - config - INFO - Validation Loss: 0.4395
2024-03-28 22:59:41,314 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:41,364 - config - INFO - Epoch [152/200], Train Loss: 0.3869
2024-03-28 22:59:41,366 - config - INFO - Validation Loss: 0.4400
2024-03-28 22:59:41,366 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:41,417 - config - INFO - Epoch [153/200], Train Loss: 0.3868
2024-03-28 22:59:41,419 - config - INFO - Validation Loss: 0.4383
2024-03-28 22:59:41,427 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:41,483 - config - INFO - Epoch [154/200], Train Loss: 0.3866
2024-03-28 22:59:41,485 - config - INFO - Validation Loss: 0.4396
2024-03-28 22:59:41,485 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:41,535 - config - INFO - Epoch [155/200], Train Loss: 0.3864
2024-03-28 22:59:41,537 - config - INFO - Validation Loss: 0.4391
2024-03-28 22:59:41,537 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:41,588 - config - INFO - Epoch [156/200], Train Loss: 0.3864
2024-03-28 22:59:41,590 - config - INFO - Validation Loss: 0.4402
2024-03-28 22:59:41,590 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:41,641 - config - INFO - Epoch [157/200], Train Loss: 0.3862
2024-03-28 22:59:41,642 - config - INFO - Validation Loss: 0.4404
2024-03-28 22:59:41,643 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:41,693 - config - INFO - Epoch [158/200], Train Loss: 0.3861
2024-03-28 22:59:41,695 - config - INFO - Validation Loss: 0.4414
2024-03-28 22:59:41,695 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:41,695 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 22:59:51,906 - config - INFO - resume: None
2024-03-28 22:59:51,906 - config - INFO - device: cpu
2024-03-28 22:59:51,906 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 22:59:51,906 - config - INFO - learning_rate: 0.0001
2024-03-28 22:59:51,907 - config - INFO - num_epochs: 200
2024-03-28 22:59:51,907 - config - INFO - batch_size: 32
2024-03-28 22:59:51,907 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 22:59:51,928 - config - INFO - Dataset size: 891
2024-03-28 22:59:51,951 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.95 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    # trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 22:59:51,951 - config - INFO - Training start
2024-03-28 22:59:54,286 - config - INFO - Epoch [1/200], Train Loss: 0.7013
2024-03-28 22:59:54,289 - config - INFO - Validation Loss: 0.7013
2024-03-28 22:59:54,289 - config - INFO - Validation Acc: 0.3846
2024-03-28 22:59:54,361 - config - INFO - Epoch [2/200], Train Loss: 0.6900
2024-03-28 22:59:54,363 - config - INFO - Validation Loss: 0.6903
2024-03-28 22:59:54,363 - config - INFO - Validation Acc: 0.3846
2024-03-28 22:59:54,436 - config - INFO - Epoch [3/200], Train Loss: 0.6790
2024-03-28 22:59:54,438 - config - INFO - Validation Loss: 0.6790
2024-03-28 22:59:54,438 - config - INFO - Validation Acc: 0.6154
2024-03-28 22:59:54,505 - config - INFO - Epoch [4/200], Train Loss: 0.6681
2024-03-28 22:59:54,507 - config - INFO - Validation Loss: 0.6686
2024-03-28 22:59:54,507 - config - INFO - Validation Acc: 0.6923
2024-03-28 22:59:54,565 - config - INFO - Epoch [5/200], Train Loss: 0.6577
2024-03-28 22:59:54,567 - config - INFO - Validation Loss: 0.6581
2024-03-28 22:59:54,567 - config - INFO - Validation Acc: 0.6923
2024-03-28 22:59:54,627 - config - INFO - Epoch [6/200], Train Loss: 0.6471
2024-03-28 22:59:54,628 - config - INFO - Validation Loss: 0.6476
2024-03-28 22:59:54,628 - config - INFO - Validation Acc: 0.6923
2024-03-28 22:59:54,679 - config - INFO - Epoch [7/200], Train Loss: 0.6362
2024-03-28 22:59:54,681 - config - INFO - Validation Loss: 0.6368
2024-03-28 22:59:54,681 - config - INFO - Validation Acc: 0.6923
2024-03-28 22:59:54,731 - config - INFO - Epoch [8/200], Train Loss: 0.6251
2024-03-28 22:59:54,733 - config - INFO - Validation Loss: 0.6253
2024-03-28 22:59:54,733 - config - INFO - Validation Acc: 0.6923
2024-03-28 22:59:54,783 - config - INFO - Epoch [9/200], Train Loss: 0.6137
2024-03-28 22:59:54,785 - config - INFO - Validation Loss: 0.6142
2024-03-28 22:59:54,785 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:54,836 - config - INFO - Epoch [10/200], Train Loss: 0.6020
2024-03-28 22:59:54,838 - config - INFO - Validation Loss: 0.6023
2024-03-28 22:59:54,838 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:54,888 - config - INFO - Epoch [11/200], Train Loss: 0.5900
2024-03-28 22:59:54,890 - config - INFO - Validation Loss: 0.5910
2024-03-28 22:59:54,890 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:54,941 - config - INFO - Epoch [12/200], Train Loss: 0.5782
2024-03-28 22:59:54,942 - config - INFO - Validation Loss: 0.5793
2024-03-28 22:59:54,943 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:54,993 - config - INFO - Epoch [13/200], Train Loss: 0.5666
2024-03-28 22:59:54,995 - config - INFO - Validation Loss: 0.5675
2024-03-28 22:59:54,995 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:55,045 - config - INFO - Epoch [14/200], Train Loss: 0.5547
2024-03-28 22:59:55,047 - config - INFO - Validation Loss: 0.5558
2024-03-28 22:59:55,047 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:55,097 - config - INFO - Epoch [15/200], Train Loss: 0.5435
2024-03-28 22:59:55,099 - config - INFO - Validation Loss: 0.5443
2024-03-28 22:59:55,099 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:55,163 - config - INFO - Epoch [16/200], Train Loss: 0.5323
2024-03-28 22:59:55,165 - config - INFO - Validation Loss: 0.5340
2024-03-28 22:59:55,165 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:55,215 - config - INFO - Epoch [17/200], Train Loss: 0.5218
2024-03-28 22:59:55,217 - config - INFO - Validation Loss: 0.5242
2024-03-28 22:59:55,217 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:55,268 - config - INFO - Epoch [18/200], Train Loss: 0.5119
2024-03-28 22:59:55,270 - config - INFO - Validation Loss: 0.5156
2024-03-28 22:59:55,270 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:55,320 - config - INFO - Epoch [19/200], Train Loss: 0.5025
2024-03-28 22:59:55,322 - config - INFO - Validation Loss: 0.5065
2024-03-28 22:59:55,322 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:55,373 - config - INFO - Epoch [20/200], Train Loss: 0.4938
2024-03-28 22:59:55,374 - config - INFO - Validation Loss: 0.4985
2024-03-28 22:59:55,375 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:55,425 - config - INFO - Epoch [21/200], Train Loss: 0.4857
2024-03-28 22:59:55,427 - config - INFO - Validation Loss: 0.4911
2024-03-28 22:59:55,427 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:55,477 - config - INFO - Epoch [22/200], Train Loss: 0.4781
2024-03-28 22:59:55,479 - config - INFO - Validation Loss: 0.4838
2024-03-28 22:59:55,479 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:55,530 - config - INFO - Epoch [23/200], Train Loss: 0.4711
2024-03-28 22:59:55,531 - config - INFO - Validation Loss: 0.4781
2024-03-28 22:59:55,532 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:55,582 - config - INFO - Epoch [24/200], Train Loss: 0.4651
2024-03-28 22:59:55,584 - config - INFO - Validation Loss: 0.4727
2024-03-28 22:59:55,584 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:55,635 - config - INFO - Epoch [25/200], Train Loss: 0.4598
2024-03-28 22:59:55,636 - config - INFO - Validation Loss: 0.4672
2024-03-28 22:59:55,636 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:55,688 - config - INFO - Epoch [26/200], Train Loss: 0.4548
2024-03-28 22:59:55,690 - config - INFO - Validation Loss: 0.4630
2024-03-28 22:59:55,690 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:55,740 - config - INFO - Epoch [27/200], Train Loss: 0.4506
2024-03-28 22:59:55,742 - config - INFO - Validation Loss: 0.4591
2024-03-28 22:59:55,742 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:55,793 - config - INFO - Epoch [28/200], Train Loss: 0.4469
2024-03-28 22:59:55,794 - config - INFO - Validation Loss: 0.4555
2024-03-28 22:59:55,795 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:55,845 - config - INFO - Epoch [29/200], Train Loss: 0.4436
2024-03-28 22:59:55,847 - config - INFO - Validation Loss: 0.4525
2024-03-28 22:59:55,847 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:55,897 - config - INFO - Epoch [30/200], Train Loss: 0.4406
2024-03-28 22:59:55,899 - config - INFO - Validation Loss: 0.4495
2024-03-28 22:59:55,899 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:55,950 - config - INFO - Epoch [31/200], Train Loss: 0.4382
2024-03-28 22:59:55,951 - config - INFO - Validation Loss: 0.4467
2024-03-28 22:59:55,952 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:56,002 - config - INFO - Epoch [32/200], Train Loss: 0.4356
2024-03-28 22:59:56,004 - config - INFO - Validation Loss: 0.4449
2024-03-28 22:59:56,004 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:56,054 - config - INFO - Epoch [33/200], Train Loss: 0.4336
2024-03-28 22:59:56,056 - config - INFO - Validation Loss: 0.4424
2024-03-28 22:59:56,056 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:56,107 - config - INFO - Epoch [34/200], Train Loss: 0.4320
2024-03-28 22:59:56,109 - config - INFO - Validation Loss: 0.4403
2024-03-28 22:59:56,109 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:56,164 - config - INFO - Epoch [35/200], Train Loss: 0.4301
2024-03-28 22:59:56,166 - config - INFO - Validation Loss: 0.4382
2024-03-28 22:59:56,166 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:56,216 - config - INFO - Epoch [36/200], Train Loss: 0.4286
2024-03-28 22:59:56,218 - config - INFO - Validation Loss: 0.4369
2024-03-28 22:59:56,218 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:56,268 - config - INFO - Epoch [37/200], Train Loss: 0.4272
2024-03-28 22:59:56,270 - config - INFO - Validation Loss: 0.4356
2024-03-28 22:59:56,270 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:56,321 - config - INFO - Epoch [38/200], Train Loss: 0.4260
2024-03-28 22:59:56,325 - config - INFO - Validation Loss: 0.4338
2024-03-28 22:59:56,326 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:56,380 - config - INFO - Epoch [39/200], Train Loss: 0.4251
2024-03-28 22:59:56,381 - config - INFO - Validation Loss: 0.4322
2024-03-28 22:59:56,382 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:56,433 - config - INFO - Epoch [40/200], Train Loss: 0.4238
2024-03-28 22:59:56,435 - config - INFO - Validation Loss: 0.4318
2024-03-28 22:59:56,435 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:56,487 - config - INFO - Epoch [41/200], Train Loss: 0.4228
2024-03-28 22:59:56,489 - config - INFO - Validation Loss: 0.4303
2024-03-28 22:59:56,489 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:56,541 - config - INFO - Epoch [42/200], Train Loss: 0.4218
2024-03-28 22:59:56,543 - config - INFO - Validation Loss: 0.4290
2024-03-28 22:59:56,543 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:56,595 - config - INFO - Epoch [43/200], Train Loss: 0.4207
2024-03-28 22:59:56,597 - config - INFO - Validation Loss: 0.4283
2024-03-28 22:59:56,597 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:56,649 - config - INFO - Epoch [44/200], Train Loss: 0.4200
2024-03-28 22:59:56,650 - config - INFO - Validation Loss: 0.4275
2024-03-28 22:59:56,651 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:56,702 - config - INFO - Epoch [45/200], Train Loss: 0.4190
2024-03-28 22:59:56,704 - config - INFO - Validation Loss: 0.4264
2024-03-28 22:59:56,704 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:56,755 - config - INFO - Epoch [46/200], Train Loss: 0.4182
2024-03-28 22:59:56,757 - config - INFO - Validation Loss: 0.4256
2024-03-28 22:59:56,757 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:56,809 - config - INFO - Epoch [47/200], Train Loss: 0.4175
2024-03-28 22:59:56,811 - config - INFO - Validation Loss: 0.4239
2024-03-28 22:59:56,811 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:56,862 - config - INFO - Epoch [48/200], Train Loss: 0.4167
2024-03-28 22:59:56,864 - config - INFO - Validation Loss: 0.4231
2024-03-28 22:59:56,864 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:56,916 - config - INFO - Epoch [49/200], Train Loss: 0.4160
2024-03-28 22:59:56,918 - config - INFO - Validation Loss: 0.4224
2024-03-28 22:59:56,926 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:56,983 - config - INFO - Epoch [50/200], Train Loss: 0.4156
2024-03-28 22:59:56,985 - config - INFO - Validation Loss: 0.4209
2024-03-28 22:59:56,985 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:57,037 - config - INFO - Epoch [51/200], Train Loss: 0.4148
2024-03-28 22:59:57,039 - config - INFO - Validation Loss: 0.4211
2024-03-28 22:59:57,039 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:57,090 - config - INFO - Epoch [52/200], Train Loss: 0.4140
2024-03-28 22:59:57,092 - config - INFO - Validation Loss: 0.4194
2024-03-28 22:59:57,092 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:57,143 - config - INFO - Epoch [53/200], Train Loss: 0.4135
2024-03-28 22:59:57,145 - config - INFO - Validation Loss: 0.4191
2024-03-28 22:59:57,145 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:57,209 - config - INFO - Epoch [54/200], Train Loss: 0.4128
2024-03-28 22:59:57,211 - config - INFO - Validation Loss: 0.4176
2024-03-28 22:59:57,211 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:57,261 - config - INFO - Epoch [55/200], Train Loss: 0.4126
2024-03-28 22:59:57,262 - config - INFO - Validation Loss: 0.4158
2024-03-28 22:59:57,263 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:57,313 - config - INFO - Epoch [56/200], Train Loss: 0.4117
2024-03-28 22:59:57,315 - config - INFO - Validation Loss: 0.4161
2024-03-28 22:59:57,315 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:57,365 - config - INFO - Epoch [57/200], Train Loss: 0.4111
2024-03-28 22:59:57,366 - config - INFO - Validation Loss: 0.4148
2024-03-28 22:59:57,367 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:57,416 - config - INFO - Epoch [58/200], Train Loss: 0.4106
2024-03-28 22:59:57,418 - config - INFO - Validation Loss: 0.4142
2024-03-28 22:59:57,418 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:57,468 - config - INFO - Epoch [59/200], Train Loss: 0.4100
2024-03-28 22:59:57,470 - config - INFO - Validation Loss: 0.4131
2024-03-28 22:59:57,470 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:57,520 - config - INFO - Epoch [60/200], Train Loss: 0.4094
2024-03-28 22:59:57,522 - config - INFO - Validation Loss: 0.4128
2024-03-28 22:59:57,522 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:57,572 - config - INFO - Epoch [61/200], Train Loss: 0.4090
2024-03-28 22:59:57,573 - config - INFO - Validation Loss: 0.4117
2024-03-28 22:59:57,574 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:57,623 - config - INFO - Epoch [62/200], Train Loss: 0.4083
2024-03-28 22:59:57,625 - config - INFO - Validation Loss: 0.4115
2024-03-28 22:59:57,625 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:57,675 - config - INFO - Epoch [63/200], Train Loss: 0.4081
2024-03-28 22:59:57,677 - config - INFO - Validation Loss: 0.4107
2024-03-28 22:59:57,677 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:57,727 - config - INFO - Epoch [64/200], Train Loss: 0.4075
2024-03-28 22:59:57,729 - config - INFO - Validation Loss: 0.4103
2024-03-28 22:59:57,729 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:57,779 - config - INFO - Epoch [65/200], Train Loss: 0.4070
2024-03-28 22:59:57,780 - config - INFO - Validation Loss: 0.4089
2024-03-28 22:59:57,781 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:57,831 - config - INFO - Epoch [66/200], Train Loss: 0.4064
2024-03-28 22:59:57,832 - config - INFO - Validation Loss: 0.4085
2024-03-28 22:59:57,833 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:57,883 - config - INFO - Epoch [67/200], Train Loss: 0.4061
2024-03-28 22:59:57,884 - config - INFO - Validation Loss: 0.4087
2024-03-28 22:59:57,884 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:57,935 - config - INFO - Epoch [68/200], Train Loss: 0.4056
2024-03-28 22:59:57,936 - config - INFO - Validation Loss: 0.4077
2024-03-28 22:59:57,936 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:57,987 - config - INFO - Epoch [69/200], Train Loss: 0.4053
2024-03-28 22:59:57,988 - config - INFO - Validation Loss: 0.4065
2024-03-28 22:59:57,988 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:58,039 - config - INFO - Epoch [70/200], Train Loss: 0.4047
2024-03-28 22:59:58,040 - config - INFO - Validation Loss: 0.4064
2024-03-28 22:59:58,040 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:58,090 - config - INFO - Epoch [71/200], Train Loss: 0.4045
2024-03-28 22:59:58,092 - config - INFO - Validation Loss: 0.4049
2024-03-28 22:59:58,092 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:58,142 - config - INFO - Epoch [72/200], Train Loss: 0.4040
2024-03-28 22:59:58,144 - config - INFO - Validation Loss: 0.4048
2024-03-28 22:59:58,144 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:58,197 - config - INFO - Epoch [73/200], Train Loss: 0.4035
2024-03-28 22:59:58,199 - config - INFO - Validation Loss: 0.4043
2024-03-28 22:59:58,199 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:58,250 - config - INFO - Epoch [74/200], Train Loss: 0.4030
2024-03-28 22:59:58,251 - config - INFO - Validation Loss: 0.4041
2024-03-28 22:59:58,252 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:58,302 - config - INFO - Epoch [75/200], Train Loss: 0.4026
2024-03-28 22:59:58,304 - config - INFO - Validation Loss: 0.4036
2024-03-28 22:59:58,304 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:58,354 - config - INFO - Epoch [76/200], Train Loss: 0.4023
2024-03-28 22:59:58,356 - config - INFO - Validation Loss: 0.4027
2024-03-28 22:59:58,356 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:58,406 - config - INFO - Epoch [77/200], Train Loss: 0.4022
2024-03-28 22:59:58,408 - config - INFO - Validation Loss: 0.4029
2024-03-28 22:59:58,408 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:58,458 - config - INFO - Epoch [78/200], Train Loss: 0.4018
2024-03-28 22:59:58,460 - config - INFO - Validation Loss: 0.4018
2024-03-28 22:59:58,460 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:58,510 - config - INFO - Epoch [79/200], Train Loss: 0.4015
2024-03-28 22:59:58,512 - config - INFO - Validation Loss: 0.4009
2024-03-28 22:59:58,512 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:58,562 - config - INFO - Epoch [80/200], Train Loss: 0.4009
2024-03-28 22:59:58,564 - config - INFO - Validation Loss: 0.4007
2024-03-28 22:59:58,564 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:58,614 - config - INFO - Epoch [81/200], Train Loss: 0.4006
2024-03-28 22:59:58,616 - config - INFO - Validation Loss: 0.4008
2024-03-28 22:59:58,616 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:58,666 - config - INFO - Epoch [82/200], Train Loss: 0.4010
2024-03-28 22:59:58,667 - config - INFO - Validation Loss: 0.4000
2024-03-28 22:59:58,668 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:58,718 - config - INFO - Epoch [83/200], Train Loss: 0.4000
2024-03-28 22:59:58,719 - config - INFO - Validation Loss: 0.4007
2024-03-28 22:59:58,720 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:58,770 - config - INFO - Epoch [84/200], Train Loss: 0.3996
2024-03-28 22:59:58,772 - config - INFO - Validation Loss: 0.3997
2024-03-28 22:59:58,772 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:58,822 - config - INFO - Epoch [85/200], Train Loss: 0.3991
2024-03-28 22:59:58,823 - config - INFO - Validation Loss: 0.3991
2024-03-28 22:59:58,824 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:58,874 - config - INFO - Epoch [86/200], Train Loss: 0.3989
2024-03-28 22:59:58,875 - config - INFO - Validation Loss: 0.3991
2024-03-28 22:59:58,875 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:58,925 - config - INFO - Epoch [87/200], Train Loss: 0.3986
2024-03-28 22:59:58,927 - config - INFO - Validation Loss: 0.3980
2024-03-28 22:59:58,927 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:58,977 - config - INFO - Epoch [88/200], Train Loss: 0.3985
2024-03-28 22:59:58,979 - config - INFO - Validation Loss: 0.3973
2024-03-28 22:59:58,979 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:59,029 - config - INFO - Epoch [89/200], Train Loss: 0.3982
2024-03-28 22:59:59,030 - config - INFO - Validation Loss: 0.3969
2024-03-28 22:59:59,031 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:59,081 - config - INFO - Epoch [90/200], Train Loss: 0.3977
2024-03-28 22:59:59,082 - config - INFO - Validation Loss: 0.3977
2024-03-28 22:59:59,082 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:59,132 - config - INFO - Epoch [91/200], Train Loss: 0.3975
2024-03-28 22:59:59,134 - config - INFO - Validation Loss: 0.3977
2024-03-28 22:59:59,134 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:59,188 - config - INFO - Epoch [92/200], Train Loss: 0.3973
2024-03-28 22:59:59,190 - config - INFO - Validation Loss: 0.3969
2024-03-28 22:59:59,190 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:59,249 - config - INFO - Epoch [93/200], Train Loss: 0.3970
2024-03-28 22:59:59,252 - config - INFO - Validation Loss: 0.3973
2024-03-28 22:59:59,252 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:59,318 - config - INFO - Epoch [94/200], Train Loss: 0.3967
2024-03-28 22:59:59,320 - config - INFO - Validation Loss: 0.3959
2024-03-28 22:59:59,320 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:59,374 - config - INFO - Epoch [95/200], Train Loss: 0.3965
2024-03-28 22:59:59,375 - config - INFO - Validation Loss: 0.3961
2024-03-28 22:59:59,376 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:59,426 - config - INFO - Epoch [96/200], Train Loss: 0.3962
2024-03-28 22:59:59,428 - config - INFO - Validation Loss: 0.3959
2024-03-28 22:59:59,428 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:59,478 - config - INFO - Epoch [97/200], Train Loss: 0.3959
2024-03-28 22:59:59,480 - config - INFO - Validation Loss: 0.3954
2024-03-28 22:59:59,480 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:59,530 - config - INFO - Epoch [98/200], Train Loss: 0.3958
2024-03-28 22:59:59,532 - config - INFO - Validation Loss: 0.3948
2024-03-28 22:59:59,532 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:59,582 - config - INFO - Epoch [99/200], Train Loss: 0.3955
2024-03-28 22:59:59,584 - config - INFO - Validation Loss: 0.3943
2024-03-28 22:59:59,584 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:59,634 - config - INFO - Epoch [100/200], Train Loss: 0.3951
2024-03-28 22:59:59,636 - config - INFO - Validation Loss: 0.3940
2024-03-28 22:59:59,636 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:59,687 - config - INFO - Epoch [101/200], Train Loss: 0.3949
2024-03-28 22:59:59,688 - config - INFO - Validation Loss: 0.3934
2024-03-28 22:59:59,688 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:59,739 - config - INFO - Epoch [102/200], Train Loss: 0.3947
2024-03-28 22:59:59,741 - config - INFO - Validation Loss: 0.3942
2024-03-28 22:59:59,741 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:59,791 - config - INFO - Epoch [103/200], Train Loss: 0.3944
2024-03-28 22:59:59,793 - config - INFO - Validation Loss: 0.3934
2024-03-28 22:59:59,793 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:59,843 - config - INFO - Epoch [104/200], Train Loss: 0.3942
2024-03-28 22:59:59,845 - config - INFO - Validation Loss: 0.3937
2024-03-28 22:59:59,845 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:59,895 - config - INFO - Epoch [105/200], Train Loss: 0.3942
2024-03-28 22:59:59,897 - config - INFO - Validation Loss: 0.3928
2024-03-28 22:59:59,897 - config - INFO - Validation Acc: 0.7692
2024-03-28 22:59:59,948 - config - INFO - Epoch [106/200], Train Loss: 0.3937
2024-03-28 22:59:59,949 - config - INFO - Validation Loss: 0.3927
2024-03-28 22:59:59,949 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:00,000 - config - INFO - Epoch [107/200], Train Loss: 0.3934
2024-03-28 23:00:00,002 - config - INFO - Validation Loss: 0.3929
2024-03-28 23:00:00,002 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:00,052 - config - INFO - Epoch [108/200], Train Loss: 0.3931
2024-03-28 23:00:00,054 - config - INFO - Validation Loss: 0.3923
2024-03-28 23:00:00,054 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:00,104 - config - INFO - Epoch [109/200], Train Loss: 0.3929
2024-03-28 23:00:00,106 - config - INFO - Validation Loss: 0.3927
2024-03-28 23:00:00,106 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:00,156 - config - INFO - Epoch [110/200], Train Loss: 0.3928
2024-03-28 23:00:00,158 - config - INFO - Validation Loss: 0.3922
2024-03-28 23:00:00,158 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:00,214 - config - INFO - Epoch [111/200], Train Loss: 0.3925
2024-03-28 23:00:00,216 - config - INFO - Validation Loss: 0.3917
2024-03-28 23:00:00,216 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:00,267 - config - INFO - Epoch [112/200], Train Loss: 0.3924
2024-03-28 23:00:00,269 - config - INFO - Validation Loss: 0.3917
2024-03-28 23:00:00,269 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:00,319 - config - INFO - Epoch [113/200], Train Loss: 0.3923
2024-03-28 23:00:00,321 - config - INFO - Validation Loss: 0.3916
2024-03-28 23:00:00,321 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:00,371 - config - INFO - Epoch [114/200], Train Loss: 0.3924
2024-03-28 23:00:00,373 - config - INFO - Validation Loss: 0.3909
2024-03-28 23:00:00,373 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:00,423 - config - INFO - Epoch [115/200], Train Loss: 0.3917
2024-03-28 23:00:00,425 - config - INFO - Validation Loss: 0.3911
2024-03-28 23:00:00,425 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:00,475 - config - INFO - Epoch [116/200], Train Loss: 0.3917
2024-03-28 23:00:00,477 - config - INFO - Validation Loss: 0.3905
2024-03-28 23:00:00,477 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:00,527 - config - INFO - Epoch [117/200], Train Loss: 0.3914
2024-03-28 23:00:00,529 - config - INFO - Validation Loss: 0.3908
2024-03-28 23:00:00,529 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:00,579 - config - INFO - Epoch [118/200], Train Loss: 0.3912
2024-03-28 23:00:00,581 - config - INFO - Validation Loss: 0.3906
2024-03-28 23:00:00,581 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:00,632 - config - INFO - Epoch [119/200], Train Loss: 0.3909
2024-03-28 23:00:00,633 - config - INFO - Validation Loss: 0.3896
2024-03-28 23:00:00,633 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:00,684 - config - INFO - Epoch [120/200], Train Loss: 0.3909
2024-03-28 23:00:00,685 - config - INFO - Validation Loss: 0.3911
2024-03-28 23:00:00,685 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:00,735 - config - INFO - Epoch [121/200], Train Loss: 0.3907
2024-03-28 23:00:00,737 - config - INFO - Validation Loss: 0.3907
2024-03-28 23:00:00,737 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:00,788 - config - INFO - Epoch [122/200], Train Loss: 0.3904
2024-03-28 23:00:00,789 - config - INFO - Validation Loss: 0.3902
2024-03-28 23:00:00,789 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:00,840 - config - INFO - Epoch [123/200], Train Loss: 0.3902
2024-03-28 23:00:00,841 - config - INFO - Validation Loss: 0.3899
2024-03-28 23:00:00,841 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:00,892 - config - INFO - Epoch [124/200], Train Loss: 0.3900
2024-03-28 23:00:00,893 - config - INFO - Validation Loss: 0.3906
2024-03-28 23:00:00,894 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:00,944 - config - INFO - Epoch [125/200], Train Loss: 0.3900
2024-03-28 23:00:00,945 - config - INFO - Validation Loss: 0.3902
2024-03-28 23:00:00,946 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:00,996 - config - INFO - Epoch [126/200], Train Loss: 0.3896
2024-03-28 23:00:00,998 - config - INFO - Validation Loss: 0.3904
2024-03-28 23:00:00,998 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:01,048 - config - INFO - Epoch [127/200], Train Loss: 0.3896
2024-03-28 23:00:01,050 - config - INFO - Validation Loss: 0.3890
2024-03-28 23:00:01,050 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:01,100 - config - INFO - Epoch [128/200], Train Loss: 0.3892
2024-03-28 23:00:01,102 - config - INFO - Validation Loss: 0.3900
2024-03-28 23:00:01,102 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:01,152 - config - INFO - Epoch [129/200], Train Loss: 0.3892
2024-03-28 23:00:01,154 - config - INFO - Validation Loss: 0.3900
2024-03-28 23:00:01,154 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:01,204 - config - INFO - Epoch [130/200], Train Loss: 0.3889
2024-03-28 23:00:01,206 - config - INFO - Validation Loss: 0.3895
2024-03-28 23:00:01,206 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:01,256 - config - INFO - Epoch [131/200], Train Loss: 0.3889
2024-03-28 23:00:01,258 - config - INFO - Validation Loss: 0.3893
2024-03-28 23:00:01,258 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:01,309 - config - INFO - Epoch [132/200], Train Loss: 0.3886
2024-03-28 23:00:01,310 - config - INFO - Validation Loss: 0.3891
2024-03-28 23:00:01,311 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:01,361 - config - INFO - Epoch [133/200], Train Loss: 0.3885
2024-03-28 23:00:01,362 - config - INFO - Validation Loss: 0.3896
2024-03-28 23:00:01,363 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:01,413 - config - INFO - Epoch [134/200], Train Loss: 0.3883
2024-03-28 23:00:01,414 - config - INFO - Validation Loss: 0.3885
2024-03-28 23:00:01,415 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:01,465 - config - INFO - Epoch [135/200], Train Loss: 0.3882
2024-03-28 23:00:01,467 - config - INFO - Validation Loss: 0.3884
2024-03-28 23:00:01,467 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:01,517 - config - INFO - Epoch [136/200], Train Loss: 0.3879
2024-03-28 23:00:01,519 - config - INFO - Validation Loss: 0.3889
2024-03-28 23:00:01,519 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:01,569 - config - INFO - Epoch [137/200], Train Loss: 0.3880
2024-03-28 23:00:01,571 - config - INFO - Validation Loss: 0.3891
2024-03-28 23:00:01,571 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:01,621 - config - INFO - Epoch [138/200], Train Loss: 0.3878
2024-03-28 23:00:01,623 - config - INFO - Validation Loss: 0.3887
2024-03-28 23:00:01,623 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:01,673 - config - INFO - Epoch [139/200], Train Loss: 0.3877
2024-03-28 23:00:01,675 - config - INFO - Validation Loss: 0.3886
2024-03-28 23:00:01,675 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:01,726 - config - INFO - Epoch [140/200], Train Loss: 0.3874
2024-03-28 23:00:01,727 - config - INFO - Validation Loss: 0.3882
2024-03-28 23:00:01,727 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:01,778 - config - INFO - Epoch [141/200], Train Loss: 0.3874
2024-03-28 23:00:01,779 - config - INFO - Validation Loss: 0.3879
2024-03-28 23:00:01,779 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:01,830 - config - INFO - Epoch [142/200], Train Loss: 0.3872
2024-03-28 23:00:01,831 - config - INFO - Validation Loss: 0.3880
2024-03-28 23:00:01,831 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:01,882 - config - INFO - Epoch [143/200], Train Loss: 0.3871
2024-03-28 23:00:01,883 - config - INFO - Validation Loss: 0.3883
2024-03-28 23:00:01,884 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:01,934 - config - INFO - Epoch [144/200], Train Loss: 0.3870
2024-03-28 23:00:01,935 - config - INFO - Validation Loss: 0.3875
2024-03-28 23:00:01,944 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:01,998 - config - INFO - Epoch [145/200], Train Loss: 0.3866
2024-03-28 23:00:02,000 - config - INFO - Validation Loss: 0.3879
2024-03-28 23:00:02,000 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:02,051 - config - INFO - Epoch [146/200], Train Loss: 0.3866
2024-03-28 23:00:02,052 - config - INFO - Validation Loss: 0.3875
2024-03-28 23:00:02,052 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:02,103 - config - INFO - Epoch [147/200], Train Loss: 0.3864
2024-03-28 23:00:02,104 - config - INFO - Validation Loss: 0.3879
2024-03-28 23:00:02,104 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:02,155 - config - INFO - Epoch [148/200], Train Loss: 0.3862
2024-03-28 23:00:02,156 - config - INFO - Validation Loss: 0.3882
2024-03-28 23:00:02,156 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:02,211 - config - INFO - Epoch [149/200], Train Loss: 0.3860
2024-03-28 23:00:02,212 - config - INFO - Validation Loss: 0.3879
2024-03-28 23:00:02,212 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:02,263 - config - INFO - Epoch [150/200], Train Loss: 0.3861
2024-03-28 23:00:02,265 - config - INFO - Validation Loss: 0.3874
2024-03-28 23:00:02,265 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:02,315 - config - INFO - Epoch [151/200], Train Loss: 0.3860
2024-03-28 23:00:02,317 - config - INFO - Validation Loss: 0.3875
2024-03-28 23:00:02,317 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:02,367 - config - INFO - Epoch [152/200], Train Loss: 0.3857
2024-03-28 23:00:02,369 - config - INFO - Validation Loss: 0.3876
2024-03-28 23:00:02,369 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:02,419 - config - INFO - Epoch [153/200], Train Loss: 0.3855
2024-03-28 23:00:02,421 - config - INFO - Validation Loss: 0.3874
2024-03-28 23:00:02,421 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:02,472 - config - INFO - Epoch [154/200], Train Loss: 0.3854
2024-03-28 23:00:02,473 - config - INFO - Validation Loss: 0.3872
2024-03-28 23:00:02,473 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:02,524 - config - INFO - Epoch [155/200], Train Loss: 0.3853
2024-03-28 23:00:02,525 - config - INFO - Validation Loss: 0.3866
2024-03-28 23:00:02,525 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:02,576 - config - INFO - Epoch [156/200], Train Loss: 0.3854
2024-03-28 23:00:02,577 - config - INFO - Validation Loss: 0.3868
2024-03-28 23:00:02,578 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:02,628 - config - INFO - Epoch [157/200], Train Loss: 0.3852
2024-03-28 23:00:02,629 - config - INFO - Validation Loss: 0.3878
2024-03-28 23:00:02,630 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:02,680 - config - INFO - Epoch [158/200], Train Loss: 0.3851
2024-03-28 23:00:02,682 - config - INFO - Validation Loss: 0.3866
2024-03-28 23:00:02,682 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:02,732 - config - INFO - Epoch [159/200], Train Loss: 0.3848
2024-03-28 23:00:02,734 - config - INFO - Validation Loss: 0.3878
2024-03-28 23:00:02,734 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:02,784 - config - INFO - Epoch [160/200], Train Loss: 0.3846
2024-03-28 23:00:02,786 - config - INFO - Validation Loss: 0.3872
2024-03-28 23:00:02,786 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:02,836 - config - INFO - Epoch [161/200], Train Loss: 0.3847
2024-03-28 23:00:02,838 - config - INFO - Validation Loss: 0.3880
2024-03-28 23:00:02,838 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:02,888 - config - INFO - Epoch [162/200], Train Loss: 0.3842
2024-03-28 23:00:02,890 - config - INFO - Validation Loss: 0.3867
2024-03-28 23:00:02,890 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:02,940 - config - INFO - Epoch [163/200], Train Loss: 0.3844
2024-03-28 23:00:02,942 - config - INFO - Validation Loss: 0.3872
2024-03-28 23:00:02,942 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:02,992 - config - INFO - Epoch [164/200], Train Loss: 0.3842
2024-03-28 23:00:02,994 - config - INFO - Validation Loss: 0.3863
2024-03-28 23:00:02,994 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:03,044 - config - INFO - Epoch [165/200], Train Loss: 0.3838
2024-03-28 23:00:03,046 - config - INFO - Validation Loss: 0.3863
2024-03-28 23:00:03,046 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:03,096 - config - INFO - Epoch [166/200], Train Loss: 0.3839
2024-03-28 23:00:03,098 - config - INFO - Validation Loss: 0.3876
2024-03-28 23:00:03,098 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:03,148 - config - INFO - Epoch [167/200], Train Loss: 0.3836
2024-03-28 23:00:03,150 - config - INFO - Validation Loss: 0.3869
2024-03-28 23:00:03,150 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:03,201 - config - INFO - Epoch [168/200], Train Loss: 0.3838
2024-03-28 23:00:03,202 - config - INFO - Validation Loss: 0.3875
2024-03-28 23:00:03,202 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:03,253 - config - INFO - Epoch [169/200], Train Loss: 0.3836
2024-03-28 23:00:03,254 - config - INFO - Validation Loss: 0.3869
2024-03-28 23:00:03,254 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:03,305 - config - INFO - Epoch [170/200], Train Loss: 0.3834
2024-03-28 23:00:03,307 - config - INFO - Validation Loss: 0.3870
2024-03-28 23:00:03,307 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:03,357 - config - INFO - Epoch [171/200], Train Loss: 0.3831
2024-03-28 23:00:03,359 - config - INFO - Validation Loss: 0.3870
2024-03-28 23:00:03,359 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:03,409 - config - INFO - Epoch [172/200], Train Loss: 0.3831
2024-03-28 23:00:03,411 - config - INFO - Validation Loss: 0.3869
2024-03-28 23:00:03,411 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:03,461 - config - INFO - Epoch [173/200], Train Loss: 0.3830
2024-03-28 23:00:03,463 - config - INFO - Validation Loss: 0.3866
2024-03-28 23:00:03,463 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:03,513 - config - INFO - Epoch [174/200], Train Loss: 0.3830
2024-03-28 23:00:03,515 - config - INFO - Validation Loss: 0.3863
2024-03-28 23:00:03,515 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:03,565 - config - INFO - Epoch [175/200], Train Loss: 0.3827
2024-03-28 23:00:03,567 - config - INFO - Validation Loss: 0.3859
2024-03-28 23:00:03,567 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:03,618 - config - INFO - Epoch [176/200], Train Loss: 0.3825
2024-03-28 23:00:03,619 - config - INFO - Validation Loss: 0.3866
2024-03-28 23:00:03,619 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:03,670 - config - INFO - Epoch [177/200], Train Loss: 0.3823
2024-03-28 23:00:03,671 - config - INFO - Validation Loss: 0.3874
2024-03-28 23:00:03,672 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:03,722 - config - INFO - Epoch [178/200], Train Loss: 0.3824
2024-03-28 23:00:03,723 - config - INFO - Validation Loss: 0.3876
2024-03-28 23:00:03,724 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:03,774 - config - INFO - Epoch [179/200], Train Loss: 0.3824
2024-03-28 23:00:03,776 - config - INFO - Validation Loss: 0.3859
2024-03-28 23:00:03,776 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:03,827 - config - INFO - Epoch [180/200], Train Loss: 0.3822
2024-03-28 23:00:03,829 - config - INFO - Validation Loss: 0.3859
2024-03-28 23:00:03,829 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:03,881 - config - INFO - Epoch [181/200], Train Loss: 0.3819
2024-03-28 23:00:03,883 - config - INFO - Validation Loss: 0.3873
2024-03-28 23:00:03,883 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:03,934 - config - INFO - Epoch [182/200], Train Loss: 0.3819
2024-03-28 23:00:03,935 - config - INFO - Validation Loss: 0.3872
2024-03-28 23:00:03,936 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:03,986 - config - INFO - Epoch [183/200], Train Loss: 0.3818
2024-03-28 23:00:03,987 - config - INFO - Validation Loss: 0.3871
2024-03-28 23:00:03,987 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:04,038 - config - INFO - Epoch [184/200], Train Loss: 0.3815
2024-03-28 23:00:04,039 - config - INFO - Validation Loss: 0.3865
2024-03-28 23:00:04,039 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:04,090 - config - INFO - Epoch [185/200], Train Loss: 0.3818
2024-03-28 23:00:04,091 - config - INFO - Validation Loss: 0.3864
2024-03-28 23:00:04,092 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:04,142 - config - INFO - Epoch [186/200], Train Loss: 0.3815
2024-03-28 23:00:04,143 - config - INFO - Validation Loss: 0.3861
2024-03-28 23:00:04,144 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:04,194 - config - INFO - Epoch [187/200], Train Loss: 0.3812
2024-03-28 23:00:04,195 - config - INFO - Validation Loss: 0.3866
2024-03-28 23:00:04,196 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:04,246 - config - INFO - Epoch [188/200], Train Loss: 0.3812
2024-03-28 23:00:04,248 - config - INFO - Validation Loss: 0.3868
2024-03-28 23:00:04,248 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:04,298 - config - INFO - Epoch [189/200], Train Loss: 0.3812
2024-03-28 23:00:04,299 - config - INFO - Validation Loss: 0.3857
2024-03-28 23:00:04,300 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:04,350 - config - INFO - Epoch [190/200], Train Loss: 0.3812
2024-03-28 23:00:04,351 - config - INFO - Validation Loss: 0.3867
2024-03-28 23:00:04,351 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:04,401 - config - INFO - Epoch [191/200], Train Loss: 0.3808
2024-03-28 23:00:04,403 - config - INFO - Validation Loss: 0.3860
2024-03-28 23:00:04,403 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:04,453 - config - INFO - Epoch [192/200], Train Loss: 0.3808
2024-03-28 23:00:04,455 - config - INFO - Validation Loss: 0.3859
2024-03-28 23:00:04,455 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:04,505 - config - INFO - Epoch [193/200], Train Loss: 0.3808
2024-03-28 23:00:04,507 - config - INFO - Validation Loss: 0.3863
2024-03-28 23:00:04,507 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:04,557 - config - INFO - Epoch [194/200], Train Loss: 0.3807
2024-03-28 23:00:04,559 - config - INFO - Validation Loss: 0.3854
2024-03-28 23:00:04,559 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:04,610 - config - INFO - Epoch [195/200], Train Loss: 0.3805
2024-03-28 23:00:04,611 - config - INFO - Validation Loss: 0.3854
2024-03-28 23:00:04,611 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:04,662 - config - INFO - Epoch [196/200], Train Loss: 0.3803
2024-03-28 23:00:04,663 - config - INFO - Validation Loss: 0.3860
2024-03-28 23:00:04,663 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:04,714 - config - INFO - Epoch [197/200], Train Loss: 0.3803
2024-03-28 23:00:04,715 - config - INFO - Validation Loss: 0.3851
2024-03-28 23:00:04,715 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:04,766 - config - INFO - Epoch [198/200], Train Loss: 0.3802
2024-03-28 23:00:04,767 - config - INFO - Validation Loss: 0.3862
2024-03-28 23:00:04,768 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:04,818 - config - INFO - Epoch [199/200], Train Loss: 0.3800
2024-03-28 23:00:04,820 - config - INFO - Validation Loss: 0.3858
2024-03-28 23:00:04,820 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:04,870 - config - INFO - Epoch [200/200], Train Loss: 0.3801
2024-03-28 23:00:04,872 - config - INFO - Validation Loss: 0.3877
2024-03-28 23:00:04,872 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:45,349 - config - INFO - resume: None
2024-03-28 23:00:45,349 - config - INFO - device: cpu
2024-03-28 23:00:45,349 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 23:00:45,349 - config - INFO - learning_rate: 0.0001
2024-03-28 23:00:45,349 - config - INFO - num_epochs: 200
2024-03-28 23:00:45,349 - config - INFO - batch_size: 32
2024-03-28 23:00:45,349 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 23:00:45,371 - config - INFO - Dataset size: 891
2024-03-28 23:00:45,395 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.95 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 23:00:45,395 - config - INFO - Training start
2024-03-28 23:00:47,764 - config - INFO - Epoch [1/200], Train Loss: 0.6913
2024-03-28 23:00:47,766 - config - INFO - Validation Loss: 0.6858
2024-03-28 23:00:47,767 - config - INFO - Validation Acc: 0.6154
2024-03-28 23:00:47,854 - config - INFO - Epoch [2/200], Train Loss: 0.6837
2024-03-28 23:00:47,856 - config - INFO - Validation Loss: 0.6799
2024-03-28 23:00:47,856 - config - INFO - Validation Acc: 0.6154
2024-03-28 23:00:47,914 - config - INFO - Epoch [3/200], Train Loss: 0.6755
2024-03-28 23:00:47,916 - config - INFO - Validation Loss: 0.6744
2024-03-28 23:00:47,916 - config - INFO - Validation Acc: 0.6923
2024-03-28 23:00:47,985 - config - INFO - Epoch [4/200], Train Loss: 0.6669
2024-03-28 23:00:47,987 - config - INFO - Validation Loss: 0.6691
2024-03-28 23:00:47,987 - config - INFO - Validation Acc: 0.6923
2024-03-28 23:00:48,049 - config - INFO - Epoch [5/200], Train Loss: 0.6579
2024-03-28 23:00:48,051 - config - INFO - Validation Loss: 0.6624
2024-03-28 23:00:48,051 - config - INFO - Validation Acc: 0.6923
2024-03-28 23:00:48,101 - config - INFO - Epoch [6/200], Train Loss: 0.6476
2024-03-28 23:00:48,103 - config - INFO - Validation Loss: 0.6555
2024-03-28 23:00:48,103 - config - INFO - Validation Acc: 0.6923
2024-03-28 23:00:48,153 - config - INFO - Epoch [7/200], Train Loss: 0.6367
2024-03-28 23:00:48,155 - config - INFO - Validation Loss: 0.6483
2024-03-28 23:00:48,155 - config - INFO - Validation Acc: 0.6923
2024-03-28 23:00:48,205 - config - INFO - Epoch [8/200], Train Loss: 0.6250
2024-03-28 23:00:48,206 - config - INFO - Validation Loss: 0.6402
2024-03-28 23:00:48,207 - config - INFO - Validation Acc: 0.6923
2024-03-28 23:00:48,257 - config - INFO - Epoch [9/200], Train Loss: 0.6129
2024-03-28 23:00:48,258 - config - INFO - Validation Loss: 0.6326
2024-03-28 23:00:48,258 - config - INFO - Validation Acc: 0.6923
2024-03-28 23:00:48,308 - config - INFO - Epoch [10/200], Train Loss: 0.6007
2024-03-28 23:00:48,310 - config - INFO - Validation Loss: 0.6254
2024-03-28 23:00:48,310 - config - INFO - Validation Acc: 0.6923
2024-03-28 23:00:48,360 - config - INFO - Epoch [11/200], Train Loss: 0.5886
2024-03-28 23:00:48,362 - config - INFO - Validation Loss: 0.6165
2024-03-28 23:00:48,362 - config - INFO - Validation Acc: 0.6923
2024-03-28 23:00:48,412 - config - INFO - Epoch [12/200], Train Loss: 0.5761
2024-03-28 23:00:48,414 - config - INFO - Validation Loss: 0.6092
2024-03-28 23:00:48,414 - config - INFO - Validation Acc: 0.6923
2024-03-28 23:00:48,464 - config - INFO - Epoch [13/200], Train Loss: 0.5636
2024-03-28 23:00:48,466 - config - INFO - Validation Loss: 0.6017
2024-03-28 23:00:48,466 - config - INFO - Validation Acc: 0.6923
2024-03-28 23:00:48,516 - config - INFO - Epoch [14/200], Train Loss: 0.5515
2024-03-28 23:00:48,518 - config - INFO - Validation Loss: 0.5958
2024-03-28 23:00:48,518 - config - INFO - Validation Acc: 0.6923
2024-03-28 23:00:48,582 - config - INFO - Epoch [15/200], Train Loss: 0.5398
2024-03-28 23:00:48,583 - config - INFO - Validation Loss: 0.5888
2024-03-28 23:00:48,583 - config - INFO - Validation Acc: 0.6923
2024-03-28 23:00:48,634 - config - INFO - Epoch [16/200], Train Loss: 0.5284
2024-03-28 23:00:48,635 - config - INFO - Validation Loss: 0.5838
2024-03-28 23:00:48,635 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:48,685 - config - INFO - Epoch [17/200], Train Loss: 0.5177
2024-03-28 23:00:48,687 - config - INFO - Validation Loss: 0.5792
2024-03-28 23:00:48,687 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:48,737 - config - INFO - Epoch [18/200], Train Loss: 0.5076
2024-03-28 23:00:48,739 - config - INFO - Validation Loss: 0.5747
2024-03-28 23:00:48,739 - config - INFO - Validation Acc: 0.7692
2024-03-28 23:00:48,789 - config - INFO - Epoch [19/200], Train Loss: 0.4981
2024-03-28 23:00:48,791 - config - INFO - Validation Loss: 0.5704
2024-03-28 23:00:48,791 - config - INFO - Validation Acc: 0.6923
2024-03-28 23:00:48,841 - config - INFO - Epoch [20/200], Train Loss: 0.4888
2024-03-28 23:00:48,843 - config - INFO - Validation Loss: 0.5691
2024-03-28 23:00:48,843 - config - INFO - Validation Acc: 0.6923
2024-03-28 23:00:48,893 - config - INFO - Epoch [21/200], Train Loss: 0.4802
2024-03-28 23:00:48,895 - config - INFO - Validation Loss: 0.5677
2024-03-28 23:00:48,895 - config - INFO - Validation Acc: 0.6923
2024-03-28 23:00:48,945 - config - INFO - Epoch [22/200], Train Loss: 0.4726
2024-03-28 23:00:48,946 - config - INFO - Validation Loss: 0.5657
2024-03-28 23:00:48,946 - config - INFO - Validation Acc: 0.6923
2024-03-28 23:00:48,996 - config - INFO - Epoch [23/200], Train Loss: 0.4658
2024-03-28 23:00:48,998 - config - INFO - Validation Loss: 0.5660
2024-03-28 23:00:48,998 - config - INFO - Validation Acc: 0.6923
2024-03-28 23:00:49,048 - config - INFO - Epoch [24/200], Train Loss: 0.4596
2024-03-28 23:00:49,050 - config - INFO - Validation Loss: 0.5673
2024-03-28 23:00:49,050 - config - INFO - Validation Acc: 0.6923
2024-03-28 23:00:49,100 - config - INFO - Epoch [25/200], Train Loss: 0.4544
2024-03-28 23:00:49,102 - config - INFO - Validation Loss: 0.5680
2024-03-28 23:00:49,102 - config - INFO - Validation Acc: 0.6923
2024-03-28 23:00:49,152 - config - INFO - Epoch [26/200], Train Loss: 0.4496
2024-03-28 23:00:49,154 - config - INFO - Validation Loss: 0.5687
2024-03-28 23:00:49,154 - config - INFO - Validation Acc: 0.6923
2024-03-28 23:00:49,206 - config - INFO - Epoch [27/200], Train Loss: 0.4453
2024-03-28 23:00:49,208 - config - INFO - Validation Loss: 0.5707
2024-03-28 23:00:49,208 - config - INFO - Validation Acc: 0.6923
2024-03-28 23:00:49,208 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 23:01:36,917 - config - INFO - resume: None
2024-03-28 23:01:36,918 - config - INFO - device: cpu
2024-03-28 23:01:36,918 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 23:01:36,918 - config - INFO - learning_rate: 0.0001
2024-03-28 23:01:36,918 - config - INFO - num_epochs: 200
2024-03-28 23:01:36,918 - config - INFO - batch_size: 32
2024-03-28 23:01:36,918 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 23:01:36,939 - config - INFO - Dataset size: 891
2024-03-28 23:01:36,963 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 23:01:36,963 - config - INFO - Training start
2024-03-28 23:01:39,130 - config - INFO - Epoch [1/200], Train Loss: 0.7020
2024-03-28 23:01:39,137 - config - INFO - Validation Loss: 0.6995
2024-03-28 23:01:39,137 - config - INFO - Validation Acc: 0.3333
2024-03-28 23:01:39,188 - config - INFO - Epoch [2/200], Train Loss: 0.6944
2024-03-28 23:01:39,193 - config - INFO - Validation Loss: 0.6924
2024-03-28 23:01:39,193 - config - INFO - Validation Acc: 0.5000
2024-03-28 23:01:39,239 - config - INFO - Epoch [3/200], Train Loss: 0.6874
2024-03-28 23:01:39,244 - config - INFO - Validation Loss: 0.6858
2024-03-28 23:01:39,244 - config - INFO - Validation Acc: 0.6111
2024-03-28 23:01:39,291 - config - INFO - Epoch [4/200], Train Loss: 0.6805
2024-03-28 23:01:39,296 - config - INFO - Validation Loss: 0.6793
2024-03-28 23:01:39,296 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:01:39,342 - config - INFO - Epoch [5/200], Train Loss: 0.6734
2024-03-28 23:01:39,347 - config - INFO - Validation Loss: 0.6721
2024-03-28 23:01:39,347 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:01:39,393 - config - INFO - Epoch [6/200], Train Loss: 0.6661
2024-03-28 23:01:39,398 - config - INFO - Validation Loss: 0.6652
2024-03-28 23:01:39,398 - config - INFO - Validation Acc: 0.7778
2024-03-28 23:01:39,444 - config - INFO - Epoch [7/200], Train Loss: 0.6588
2024-03-28 23:01:39,449 - config - INFO - Validation Loss: 0.6583
2024-03-28 23:01:39,450 - config - INFO - Validation Acc: 0.7778
2024-03-28 23:01:39,495 - config - INFO - Epoch [8/200], Train Loss: 0.6513
2024-03-28 23:01:39,500 - config - INFO - Validation Loss: 0.6509
2024-03-28 23:01:39,500 - config - INFO - Validation Acc: 0.7778
2024-03-28 23:01:39,546 - config - INFO - Epoch [9/200], Train Loss: 0.6434
2024-03-28 23:01:39,551 - config - INFO - Validation Loss: 0.6435
2024-03-28 23:01:39,551 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:39,597 - config - INFO - Epoch [10/200], Train Loss: 0.6355
2024-03-28 23:01:39,602 - config - INFO - Validation Loss: 0.6362
2024-03-28 23:01:39,602 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:39,664 - config - INFO - Epoch [11/200], Train Loss: 0.6277
2024-03-28 23:01:39,670 - config - INFO - Validation Loss: 0.6281
2024-03-28 23:01:39,670 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:39,715 - config - INFO - Epoch [12/200], Train Loss: 0.6192
2024-03-28 23:01:39,721 - config - INFO - Validation Loss: 0.6202
2024-03-28 23:01:39,721 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:39,766 - config - INFO - Epoch [13/200], Train Loss: 0.6102
2024-03-28 23:01:39,772 - config - INFO - Validation Loss: 0.6119
2024-03-28 23:01:39,772 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:39,817 - config - INFO - Epoch [14/200], Train Loss: 0.6007
2024-03-28 23:01:39,823 - config - INFO - Validation Loss: 0.6023
2024-03-28 23:01:39,823 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:39,868 - config - INFO - Epoch [15/200], Train Loss: 0.5900
2024-03-28 23:01:39,874 - config - INFO - Validation Loss: 0.5925
2024-03-28 23:01:39,874 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:39,919 - config - INFO - Epoch [16/200], Train Loss: 0.5791
2024-03-28 23:01:39,924 - config - INFO - Validation Loss: 0.5827
2024-03-28 23:01:39,929 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:39,974 - config - INFO - Epoch [17/200], Train Loss: 0.5687
2024-03-28 23:01:39,980 - config - INFO - Validation Loss: 0.5739
2024-03-28 23:01:39,980 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:40,025 - config - INFO - Epoch [18/200], Train Loss: 0.5588
2024-03-28 23:01:40,031 - config - INFO - Validation Loss: 0.5654
2024-03-28 23:01:40,031 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:40,076 - config - INFO - Epoch [19/200], Train Loss: 0.5495
2024-03-28 23:01:40,082 - config - INFO - Validation Loss: 0.5573
2024-03-28 23:01:40,082 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:40,127 - config - INFO - Epoch [20/200], Train Loss: 0.5400
2024-03-28 23:01:40,132 - config - INFO - Validation Loss: 0.5493
2024-03-28 23:01:40,133 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:40,179 - config - INFO - Epoch [21/200], Train Loss: 0.5307
2024-03-28 23:01:40,185 - config - INFO - Validation Loss: 0.5421
2024-03-28 23:01:40,185 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:40,230 - config - INFO - Epoch [22/200], Train Loss: 0.5221
2024-03-28 23:01:40,235 - config - INFO - Validation Loss: 0.5352
2024-03-28 23:01:40,236 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:40,281 - config - INFO - Epoch [23/200], Train Loss: 0.5140
2024-03-28 23:01:40,286 - config - INFO - Validation Loss: 0.5285
2024-03-28 23:01:40,286 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:40,331 - config - INFO - Epoch [24/200], Train Loss: 0.5060
2024-03-28 23:01:40,337 - config - INFO - Validation Loss: 0.5224
2024-03-28 23:01:40,337 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:40,382 - config - INFO - Epoch [25/200], Train Loss: 0.4985
2024-03-28 23:01:40,387 - config - INFO - Validation Loss: 0.5170
2024-03-28 23:01:40,387 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:40,432 - config - INFO - Epoch [26/200], Train Loss: 0.4918
2024-03-28 23:01:40,437 - config - INFO - Validation Loss: 0.5120
2024-03-28 23:01:40,437 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:40,481 - config - INFO - Epoch [27/200], Train Loss: 0.4855
2024-03-28 23:01:40,487 - config - INFO - Validation Loss: 0.5075
2024-03-28 23:01:40,487 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:40,532 - config - INFO - Epoch [28/200], Train Loss: 0.4799
2024-03-28 23:01:40,537 - config - INFO - Validation Loss: 0.5037
2024-03-28 23:01:40,537 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:40,582 - config - INFO - Epoch [29/200], Train Loss: 0.4747
2024-03-28 23:01:40,588 - config - INFO - Validation Loss: 0.5002
2024-03-28 23:01:40,588 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:40,632 - config - INFO - Epoch [30/200], Train Loss: 0.4700
2024-03-28 23:01:40,638 - config - INFO - Validation Loss: 0.4970
2024-03-28 23:01:40,638 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:40,689 - config - INFO - Epoch [31/200], Train Loss: 0.4650
2024-03-28 23:01:40,695 - config - INFO - Validation Loss: 0.4941
2024-03-28 23:01:40,695 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:40,739 - config - INFO - Epoch [32/200], Train Loss: 0.4612
2024-03-28 23:01:40,744 - config - INFO - Validation Loss: 0.4918
2024-03-28 23:01:40,744 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:40,789 - config - INFO - Epoch [33/200], Train Loss: 0.4574
2024-03-28 23:01:40,794 - config - INFO - Validation Loss: 0.4898
2024-03-28 23:01:40,794 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:40,838 - config - INFO - Epoch [34/200], Train Loss: 0.4537
2024-03-28 23:01:40,844 - config - INFO - Validation Loss: 0.4874
2024-03-28 23:01:40,844 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:40,888 - config - INFO - Epoch [35/200], Train Loss: 0.4505
2024-03-28 23:01:40,893 - config - INFO - Validation Loss: 0.4856
2024-03-28 23:01:40,894 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:40,938 - config - INFO - Epoch [36/200], Train Loss: 0.4476
2024-03-28 23:01:40,943 - config - INFO - Validation Loss: 0.4843
2024-03-28 23:01:40,944 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:40,988 - config - INFO - Epoch [37/200], Train Loss: 0.4450
2024-03-28 23:01:40,993 - config - INFO - Validation Loss: 0.4828
2024-03-28 23:01:40,993 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:41,038 - config - INFO - Epoch [38/200], Train Loss: 0.4428
2024-03-28 23:01:41,043 - config - INFO - Validation Loss: 0.4815
2024-03-28 23:01:41,043 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:41,088 - config - INFO - Epoch [39/200], Train Loss: 0.4406
2024-03-28 23:01:41,093 - config - INFO - Validation Loss: 0.4801
2024-03-28 23:01:41,093 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:41,138 - config - INFO - Epoch [40/200], Train Loss: 0.4384
2024-03-28 23:01:41,143 - config - INFO - Validation Loss: 0.4788
2024-03-28 23:01:41,143 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:41,187 - config - INFO - Epoch [41/200], Train Loss: 0.4365
2024-03-28 23:01:41,193 - config - INFO - Validation Loss: 0.4776
2024-03-28 23:01:41,193 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:41,237 - config - INFO - Epoch [42/200], Train Loss: 0.4348
2024-03-28 23:01:41,243 - config - INFO - Validation Loss: 0.4765
2024-03-28 23:01:41,243 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:41,287 - config - INFO - Epoch [43/200], Train Loss: 0.4330
2024-03-28 23:01:41,292 - config - INFO - Validation Loss: 0.4760
2024-03-28 23:01:41,292 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:41,351 - config - INFO - Epoch [44/200], Train Loss: 0.4315
2024-03-28 23:01:41,357 - config - INFO - Validation Loss: 0.4754
2024-03-28 23:01:41,357 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:41,400 - config - INFO - Epoch [45/200], Train Loss: 0.4300
2024-03-28 23:01:41,406 - config - INFO - Validation Loss: 0.4747
2024-03-28 23:01:41,406 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:41,449 - config - INFO - Epoch [46/200], Train Loss: 0.4285
2024-03-28 23:01:41,454 - config - INFO - Validation Loss: 0.4744
2024-03-28 23:01:41,454 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:41,498 - config - INFO - Epoch [47/200], Train Loss: 0.4273
2024-03-28 23:01:41,503 - config - INFO - Validation Loss: 0.4741
2024-03-28 23:01:41,503 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:41,546 - config - INFO - Epoch [48/200], Train Loss: 0.4260
2024-03-28 23:01:41,551 - config - INFO - Validation Loss: 0.4739
2024-03-28 23:01:41,551 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:41,595 - config - INFO - Epoch [49/200], Train Loss: 0.4250
2024-03-28 23:01:41,600 - config - INFO - Validation Loss: 0.4737
2024-03-28 23:01:41,600 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:41,643 - config - INFO - Epoch [50/200], Train Loss: 0.4239
2024-03-28 23:01:41,649 - config - INFO - Validation Loss: 0.4728
2024-03-28 23:01:41,649 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:41,692 - config - INFO - Epoch [51/200], Train Loss: 0.4228
2024-03-28 23:01:41,697 - config - INFO - Validation Loss: 0.4719
2024-03-28 23:01:41,697 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:41,741 - config - INFO - Epoch [52/200], Train Loss: 0.4217
2024-03-28 23:01:41,746 - config - INFO - Validation Loss: 0.4719
2024-03-28 23:01:41,746 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:41,789 - config - INFO - Epoch [53/200], Train Loss: 0.4207
2024-03-28 23:01:41,795 - config - INFO - Validation Loss: 0.4718
2024-03-28 23:01:41,795 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:41,838 - config - INFO - Epoch [54/200], Train Loss: 0.4198
2024-03-28 23:01:41,843 - config - INFO - Validation Loss: 0.4711
2024-03-28 23:01:41,843 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:41,887 - config - INFO - Epoch [55/200], Train Loss: 0.4189
2024-03-28 23:01:41,892 - config - INFO - Validation Loss: 0.4709
2024-03-28 23:01:41,892 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:41,935 - config - INFO - Epoch [56/200], Train Loss: 0.4180
2024-03-28 23:01:41,940 - config - INFO - Validation Loss: 0.4703
2024-03-28 23:01:41,940 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:41,984 - config - INFO - Epoch [57/200], Train Loss: 0.4171
2024-03-28 23:01:41,989 - config - INFO - Validation Loss: 0.4701
2024-03-28 23:01:41,989 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:42,032 - config - INFO - Epoch [58/200], Train Loss: 0.4164
2024-03-28 23:01:42,037 - config - INFO - Validation Loss: 0.4701
2024-03-28 23:01:42,038 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:42,081 - config - INFO - Epoch [59/200], Train Loss: 0.4159
2024-03-28 23:01:42,086 - config - INFO - Validation Loss: 0.4692
2024-03-28 23:01:42,086 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:42,129 - config - INFO - Epoch [60/200], Train Loss: 0.4149
2024-03-28 23:01:42,135 - config - INFO - Validation Loss: 0.4691
2024-03-28 23:01:42,135 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:42,178 - config - INFO - Epoch [61/200], Train Loss: 0.4142
2024-03-28 23:01:42,183 - config - INFO - Validation Loss: 0.4687
2024-03-28 23:01:42,183 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:42,227 - config - INFO - Epoch [62/200], Train Loss: 0.4139
2024-03-28 23:01:42,232 - config - INFO - Validation Loss: 0.4686
2024-03-28 23:01:42,232 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:42,275 - config - INFO - Epoch [63/200], Train Loss: 0.4129
2024-03-28 23:01:42,280 - config - INFO - Validation Loss: 0.4678
2024-03-28 23:01:42,280 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:42,324 - config - INFO - Epoch [64/200], Train Loss: 0.4122
2024-03-28 23:01:42,329 - config - INFO - Validation Loss: 0.4677
2024-03-28 23:01:42,329 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:42,372 - config - INFO - Epoch [65/200], Train Loss: 0.4116
2024-03-28 23:01:42,377 - config - INFO - Validation Loss: 0.4676
2024-03-28 23:01:42,378 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:42,421 - config - INFO - Epoch [66/200], Train Loss: 0.4109
2024-03-28 23:01:42,426 - config - INFO - Validation Loss: 0.4671
2024-03-28 23:01:42,426 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:42,469 - config - INFO - Epoch [67/200], Train Loss: 0.4103
2024-03-28 23:01:42,475 - config - INFO - Validation Loss: 0.4668
2024-03-28 23:01:42,475 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:42,518 - config - INFO - Epoch [68/200], Train Loss: 0.4098
2024-03-28 23:01:42,523 - config - INFO - Validation Loss: 0.4666
2024-03-28 23:01:42,523 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:42,566 - config - INFO - Epoch [69/200], Train Loss: 0.4092
2024-03-28 23:01:42,572 - config - INFO - Validation Loss: 0.4660
2024-03-28 23:01:42,572 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:42,615 - config - INFO - Epoch [70/200], Train Loss: 0.4086
2024-03-28 23:01:42,620 - config - INFO - Validation Loss: 0.4656
2024-03-28 23:01:42,620 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:42,664 - config - INFO - Epoch [71/200], Train Loss: 0.4083
2024-03-28 23:01:42,669 - config - INFO - Validation Loss: 0.4654
2024-03-28 23:01:42,669 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:42,712 - config - INFO - Epoch [72/200], Train Loss: 0.4078
2024-03-28 23:01:42,717 - config - INFO - Validation Loss: 0.4649
2024-03-28 23:01:42,717 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:42,760 - config - INFO - Epoch [73/200], Train Loss: 0.4072
2024-03-28 23:01:42,766 - config - INFO - Validation Loss: 0.4650
2024-03-28 23:01:42,766 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:42,809 - config - INFO - Epoch [74/200], Train Loss: 0.4065
2024-03-28 23:01:42,814 - config - INFO - Validation Loss: 0.4646
2024-03-28 23:01:42,814 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:42,858 - config - INFO - Epoch [75/200], Train Loss: 0.4060
2024-03-28 23:01:42,863 - config - INFO - Validation Loss: 0.4644
2024-03-28 23:01:42,863 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:42,906 - config - INFO - Epoch [76/200], Train Loss: 0.4055
2024-03-28 23:01:42,911 - config - INFO - Validation Loss: 0.4641
2024-03-28 23:01:42,911 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:42,955 - config - INFO - Epoch [77/200], Train Loss: 0.4050
2024-03-28 23:01:42,960 - config - INFO - Validation Loss: 0.4638
2024-03-28 23:01:42,960 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:43,003 - config - INFO - Epoch [78/200], Train Loss: 0.4047
2024-03-28 23:01:43,008 - config - INFO - Validation Loss: 0.4634
2024-03-28 23:01:43,009 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:43,052 - config - INFO - Epoch [79/200], Train Loss: 0.4042
2024-03-28 23:01:43,057 - config - INFO - Validation Loss: 0.4625
2024-03-28 23:01:43,057 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:43,100 - config - INFO - Epoch [80/200], Train Loss: 0.4036
2024-03-28 23:01:43,106 - config - INFO - Validation Loss: 0.4628
2024-03-28 23:01:43,106 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:43,149 - config - INFO - Epoch [81/200], Train Loss: 0.4032
2024-03-28 23:01:43,154 - config - INFO - Validation Loss: 0.4621
2024-03-28 23:01:43,154 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:43,197 - config - INFO - Epoch [82/200], Train Loss: 0.4027
2024-03-28 23:01:43,203 - config - INFO - Validation Loss: 0.4620
2024-03-28 23:01:43,203 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:43,246 - config - INFO - Epoch [83/200], Train Loss: 0.4024
2024-03-28 23:01:43,251 - config - INFO - Validation Loss: 0.4616
2024-03-28 23:01:43,251 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:43,295 - config - INFO - Epoch [84/200], Train Loss: 0.4020
2024-03-28 23:01:43,300 - config - INFO - Validation Loss: 0.4615
2024-03-28 23:01:43,300 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:43,343 - config - INFO - Epoch [85/200], Train Loss: 0.4016
2024-03-28 23:01:43,351 - config - INFO - Validation Loss: 0.4619
2024-03-28 23:01:43,351 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:43,396 - config - INFO - Epoch [86/200], Train Loss: 0.4012
2024-03-28 23:01:43,401 - config - INFO - Validation Loss: 0.4616
2024-03-28 23:01:43,401 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:43,448 - config - INFO - Epoch [87/200], Train Loss: 0.4006
2024-03-28 23:01:43,454 - config - INFO - Validation Loss: 0.4614
2024-03-28 23:01:43,454 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:43,504 - config - INFO - Epoch [88/200], Train Loss: 0.4006
2024-03-28 23:01:43,510 - config - INFO - Validation Loss: 0.4611
2024-03-28 23:01:43,510 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:43,561 - config - INFO - Epoch [89/200], Train Loss: 0.4001
2024-03-28 23:01:43,567 - config - INFO - Validation Loss: 0.4612
2024-03-28 23:01:43,567 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:43,617 - config - INFO - Epoch [90/200], Train Loss: 0.3996
2024-03-28 23:01:43,623 - config - INFO - Validation Loss: 0.4606
2024-03-28 23:01:43,623 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:43,673 - config - INFO - Epoch [91/200], Train Loss: 0.3993
2024-03-28 23:01:43,679 - config - INFO - Validation Loss: 0.4603
2024-03-28 23:01:43,679 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:43,733 - config - INFO - Epoch [92/200], Train Loss: 0.3989
2024-03-28 23:01:43,739 - config - INFO - Validation Loss: 0.4602
2024-03-28 23:01:43,739 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:43,785 - config - INFO - Epoch [93/200], Train Loss: 0.3987
2024-03-28 23:01:43,791 - config - INFO - Validation Loss: 0.4597
2024-03-28 23:01:43,791 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:43,835 - config - INFO - Epoch [94/200], Train Loss: 0.3983
2024-03-28 23:01:43,840 - config - INFO - Validation Loss: 0.4598
2024-03-28 23:01:43,840 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:43,883 - config - INFO - Epoch [95/200], Train Loss: 0.3979
2024-03-28 23:01:43,889 - config - INFO - Validation Loss: 0.4593
2024-03-28 23:01:43,889 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:43,932 - config - INFO - Epoch [96/200], Train Loss: 0.3977
2024-03-28 23:01:43,937 - config - INFO - Validation Loss: 0.4593
2024-03-28 23:01:43,938 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:43,981 - config - INFO - Epoch [97/200], Train Loss: 0.3974
2024-03-28 23:01:43,986 - config - INFO - Validation Loss: 0.4591
2024-03-28 23:01:43,987 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:44,030 - config - INFO - Epoch [98/200], Train Loss: 0.3970
2024-03-28 23:01:44,035 - config - INFO - Validation Loss: 0.4591
2024-03-28 23:01:44,035 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:44,079 - config - INFO - Epoch [99/200], Train Loss: 0.3967
2024-03-28 23:01:44,084 - config - INFO - Validation Loss: 0.4590
2024-03-28 23:01:44,084 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:44,128 - config - INFO - Epoch [100/200], Train Loss: 0.3963
2024-03-28 23:01:44,133 - config - INFO - Validation Loss: 0.4588
2024-03-28 23:01:44,133 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:44,177 - config - INFO - Epoch [101/200], Train Loss: 0.3961
2024-03-28 23:01:44,182 - config - INFO - Validation Loss: 0.4590
2024-03-28 23:01:44,182 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:44,225 - config - INFO - Epoch [102/200], Train Loss: 0.3957
2024-03-28 23:01:44,231 - config - INFO - Validation Loss: 0.4587
2024-03-28 23:01:44,231 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:44,274 - config - INFO - Epoch [103/200], Train Loss: 0.3956
2024-03-28 23:01:44,280 - config - INFO - Validation Loss: 0.4588
2024-03-28 23:01:44,280 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:44,323 - config - INFO - Epoch [104/200], Train Loss: 0.3951
2024-03-28 23:01:44,328 - config - INFO - Validation Loss: 0.4589
2024-03-28 23:01:44,329 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:44,376 - config - INFO - Epoch [105/200], Train Loss: 0.3950
2024-03-28 23:01:44,381 - config - INFO - Validation Loss: 0.4586
2024-03-28 23:01:44,381 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:44,425 - config - INFO - Epoch [106/200], Train Loss: 0.3945
2024-03-28 23:01:44,430 - config - INFO - Validation Loss: 0.4581
2024-03-28 23:01:44,430 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:44,473 - config - INFO - Epoch [107/200], Train Loss: 0.3944
2024-03-28 23:01:44,479 - config - INFO - Validation Loss: 0.4574
2024-03-28 23:01:44,479 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:44,522 - config - INFO - Epoch [108/200], Train Loss: 0.3940
2024-03-28 23:01:44,527 - config - INFO - Validation Loss: 0.4573
2024-03-28 23:01:44,528 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:44,571 - config - INFO - Epoch [109/200], Train Loss: 0.3937
2024-03-28 23:01:44,576 - config - INFO - Validation Loss: 0.4571
2024-03-28 23:01:44,576 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:44,620 - config - INFO - Epoch [110/200], Train Loss: 0.3933
2024-03-28 23:01:44,625 - config - INFO - Validation Loss: 0.4571
2024-03-28 23:01:44,625 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:44,669 - config - INFO - Epoch [111/200], Train Loss: 0.3932
2024-03-28 23:01:44,674 - config - INFO - Validation Loss: 0.4574
2024-03-28 23:01:44,674 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:44,718 - config - INFO - Epoch [112/200], Train Loss: 0.3928
2024-03-28 23:01:44,723 - config - INFO - Validation Loss: 0.4564
2024-03-28 23:01:44,723 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:44,766 - config - INFO - Epoch [113/200], Train Loss: 0.3926
2024-03-28 23:01:44,772 - config - INFO - Validation Loss: 0.4562
2024-03-28 23:01:44,772 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:44,815 - config - INFO - Epoch [114/200], Train Loss: 0.3922
2024-03-28 23:01:44,820 - config - INFO - Validation Loss: 0.4563
2024-03-28 23:01:44,821 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:44,864 - config - INFO - Epoch [115/200], Train Loss: 0.3920
2024-03-28 23:01:44,869 - config - INFO - Validation Loss: 0.4560
2024-03-28 23:01:44,869 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:44,913 - config - INFO - Epoch [116/200], Train Loss: 0.3918
2024-03-28 23:01:44,918 - config - INFO - Validation Loss: 0.4556
2024-03-28 23:01:44,918 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:44,962 - config - INFO - Epoch [117/200], Train Loss: 0.3915
2024-03-28 23:01:44,967 - config - INFO - Validation Loss: 0.4556
2024-03-28 23:01:44,967 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:45,010 - config - INFO - Epoch [118/200], Train Loss: 0.3914
2024-03-28 23:01:45,016 - config - INFO - Validation Loss: 0.4553
2024-03-28 23:01:45,016 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:45,059 - config - INFO - Epoch [119/200], Train Loss: 0.3914
2024-03-28 23:01:45,064 - config - INFO - Validation Loss: 0.4550
2024-03-28 23:01:45,065 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:45,108 - config - INFO - Epoch [120/200], Train Loss: 0.3910
2024-03-28 23:01:45,113 - config - INFO - Validation Loss: 0.4545
2024-03-28 23:01:45,113 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:45,157 - config - INFO - Epoch [121/200], Train Loss: 0.3907
2024-03-28 23:01:45,162 - config - INFO - Validation Loss: 0.4544
2024-03-28 23:01:45,162 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:45,206 - config - INFO - Epoch [122/200], Train Loss: 0.3904
2024-03-28 23:01:45,211 - config - INFO - Validation Loss: 0.4544
2024-03-28 23:01:45,211 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:45,254 - config - INFO - Epoch [123/200], Train Loss: 0.3901
2024-03-28 23:01:45,259 - config - INFO - Validation Loss: 0.4537
2024-03-28 23:01:45,260 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:45,303 - config - INFO - Epoch [124/200], Train Loss: 0.3900
2024-03-28 23:01:45,309 - config - INFO - Validation Loss: 0.4537
2024-03-28 23:01:45,309 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:45,359 - config - INFO - Epoch [125/200], Train Loss: 0.3898
2024-03-28 23:01:45,364 - config - INFO - Validation Loss: 0.4530
2024-03-28 23:01:45,364 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:45,408 - config - INFO - Epoch [126/200], Train Loss: 0.3894
2024-03-28 23:01:45,413 - config - INFO - Validation Loss: 0.4531
2024-03-28 23:01:45,413 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:45,457 - config - INFO - Epoch [127/200], Train Loss: 0.3894
2024-03-28 23:01:45,462 - config - INFO - Validation Loss: 0.4532
2024-03-28 23:01:45,462 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:45,506 - config - INFO - Epoch [128/200], Train Loss: 0.3890
2024-03-28 23:01:45,511 - config - INFO - Validation Loss: 0.4534
2024-03-28 23:01:45,511 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:45,555 - config - INFO - Epoch [129/200], Train Loss: 0.3888
2024-03-28 23:01:45,560 - config - INFO - Validation Loss: 0.4531
2024-03-28 23:01:45,560 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:45,604 - config - INFO - Epoch [130/200], Train Loss: 0.3886
2024-03-28 23:01:45,609 - config - INFO - Validation Loss: 0.4528
2024-03-28 23:01:45,609 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:45,652 - config - INFO - Epoch [131/200], Train Loss: 0.3885
2024-03-28 23:01:45,658 - config - INFO - Validation Loss: 0.4529
2024-03-28 23:01:45,658 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:45,701 - config - INFO - Epoch [132/200], Train Loss: 0.3882
2024-03-28 23:01:45,706 - config - INFO - Validation Loss: 0.4528
2024-03-28 23:01:45,707 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:45,750 - config - INFO - Epoch [133/200], Train Loss: 0.3880
2024-03-28 23:01:45,756 - config - INFO - Validation Loss: 0.4527
2024-03-28 23:01:45,756 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:45,799 - config - INFO - Epoch [134/200], Train Loss: 0.3877
2024-03-28 23:01:45,804 - config - INFO - Validation Loss: 0.4530
2024-03-28 23:01:45,805 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:45,848 - config - INFO - Epoch [135/200], Train Loss: 0.3875
2024-03-28 23:01:45,853 - config - INFO - Validation Loss: 0.4530
2024-03-28 23:01:45,853 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:45,897 - config - INFO - Epoch [136/200], Train Loss: 0.3873
2024-03-28 23:01:45,902 - config - INFO - Validation Loss: 0.4527
2024-03-28 23:01:45,902 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:45,946 - config - INFO - Epoch [137/200], Train Loss: 0.3871
2024-03-28 23:01:45,951 - config - INFO - Validation Loss: 0.4522
2024-03-28 23:01:45,951 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:45,995 - config - INFO - Epoch [138/200], Train Loss: 0.3868
2024-03-28 23:01:46,000 - config - INFO - Validation Loss: 0.4522
2024-03-28 23:01:46,000 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:46,044 - config - INFO - Epoch [139/200], Train Loss: 0.3867
2024-03-28 23:01:46,049 - config - INFO - Validation Loss: 0.4517
2024-03-28 23:01:46,049 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:46,092 - config - INFO - Epoch [140/200], Train Loss: 0.3865
2024-03-28 23:01:46,098 - config - INFO - Validation Loss: 0.4516
2024-03-28 23:01:46,098 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:46,141 - config - INFO - Epoch [141/200], Train Loss: 0.3866
2024-03-28 23:01:46,147 - config - INFO - Validation Loss: 0.4519
2024-03-28 23:01:46,147 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:46,190 - config - INFO - Epoch [142/200], Train Loss: 0.3861
2024-03-28 23:01:46,195 - config - INFO - Validation Loss: 0.4510
2024-03-28 23:01:46,196 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:46,239 - config - INFO - Epoch [143/200], Train Loss: 0.3859
2024-03-28 23:01:46,244 - config - INFO - Validation Loss: 0.4513
2024-03-28 23:01:46,244 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:46,288 - config - INFO - Epoch [144/200], Train Loss: 0.3858
2024-03-28 23:01:46,293 - config - INFO - Validation Loss: 0.4513
2024-03-28 23:01:46,293 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:46,337 - config - INFO - Epoch [145/200], Train Loss: 0.3857
2024-03-28 23:01:46,342 - config - INFO - Validation Loss: 0.4513
2024-03-28 23:01:46,342 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:46,386 - config - INFO - Epoch [146/200], Train Loss: 0.3854
2024-03-28 23:01:46,391 - config - INFO - Validation Loss: 0.4516
2024-03-28 23:01:46,391 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:46,435 - config - INFO - Epoch [147/200], Train Loss: 0.3851
2024-03-28 23:01:46,440 - config - INFO - Validation Loss: 0.4512
2024-03-28 23:01:46,440 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:46,487 - config - INFO - Epoch [148/200], Train Loss: 0.3851
2024-03-28 23:01:46,492 - config - INFO - Validation Loss: 0.4510
2024-03-28 23:01:46,492 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:46,536 - config - INFO - Epoch [149/200], Train Loss: 0.3849
2024-03-28 23:01:46,542 - config - INFO - Validation Loss: 0.4509
2024-03-28 23:01:46,542 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:46,586 - config - INFO - Epoch [150/200], Train Loss: 0.3848
2024-03-28 23:01:46,591 - config - INFO - Validation Loss: 0.4503
2024-03-28 23:01:46,591 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:46,635 - config - INFO - Epoch [151/200], Train Loss: 0.3845
2024-03-28 23:01:46,640 - config - INFO - Validation Loss: 0.4501
2024-03-28 23:01:46,640 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:46,684 - config - INFO - Epoch [152/200], Train Loss: 0.3844
2024-03-28 23:01:46,689 - config - INFO - Validation Loss: 0.4502
2024-03-28 23:01:46,689 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:46,733 - config - INFO - Epoch [153/200], Train Loss: 0.3843
2024-03-28 23:01:46,738 - config - INFO - Validation Loss: 0.4503
2024-03-28 23:01:46,738 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:46,782 - config - INFO - Epoch [154/200], Train Loss: 0.3840
2024-03-28 23:01:46,787 - config - INFO - Validation Loss: 0.4494
2024-03-28 23:01:46,787 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:46,831 - config - INFO - Epoch [155/200], Train Loss: 0.3838
2024-03-28 23:01:46,836 - config - INFO - Validation Loss: 0.4491
2024-03-28 23:01:46,836 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:46,880 - config - INFO - Epoch [156/200], Train Loss: 0.3836
2024-03-28 23:01:46,885 - config - INFO - Validation Loss: 0.4493
2024-03-28 23:01:46,885 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:46,928 - config - INFO - Epoch [157/200], Train Loss: 0.3837
2024-03-28 23:01:46,934 - config - INFO - Validation Loss: 0.4494
2024-03-28 23:01:46,934 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:46,977 - config - INFO - Epoch [158/200], Train Loss: 0.3833
2024-03-28 23:01:46,983 - config - INFO - Validation Loss: 0.4493
2024-03-28 23:01:46,983 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:47,026 - config - INFO - Epoch [159/200], Train Loss: 0.3830
2024-03-28 23:01:47,032 - config - INFO - Validation Loss: 0.4497
2024-03-28 23:01:47,032 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:47,075 - config - INFO - Epoch [160/200], Train Loss: 0.3829
2024-03-28 23:01:47,081 - config - INFO - Validation Loss: 0.4496
2024-03-28 23:01:47,081 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:47,124 - config - INFO - Epoch [161/200], Train Loss: 0.3827
2024-03-28 23:01:47,130 - config - INFO - Validation Loss: 0.4496
2024-03-28 23:01:47,130 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:47,173 - config - INFO - Epoch [162/200], Train Loss: 0.3825
2024-03-28 23:01:47,178 - config - INFO - Validation Loss: 0.4497
2024-03-28 23:01:47,179 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:47,222 - config - INFO - Epoch [163/200], Train Loss: 0.3829
2024-03-28 23:01:47,227 - config - INFO - Validation Loss: 0.4498
2024-03-28 23:01:47,228 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:47,271 - config - INFO - Epoch [164/200], Train Loss: 0.3824
2024-03-28 23:01:47,276 - config - INFO - Validation Loss: 0.4496
2024-03-28 23:01:47,276 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:47,320 - config - INFO - Epoch [165/200], Train Loss: 0.3820
2024-03-28 23:01:47,325 - config - INFO - Validation Loss: 0.4495
2024-03-28 23:01:47,326 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:47,369 - config - INFO - Epoch [166/200], Train Loss: 0.3820
2024-03-28 23:01:47,374 - config - INFO - Validation Loss: 0.4494
2024-03-28 23:01:47,374 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:47,418 - config - INFO - Epoch [167/200], Train Loss: 0.3819
2024-03-28 23:01:47,423 - config - INFO - Validation Loss: 0.4491
2024-03-28 23:01:47,423 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:47,467 - config - INFO - Epoch [168/200], Train Loss: 0.3815
2024-03-28 23:01:47,472 - config - INFO - Validation Loss: 0.4488
2024-03-28 23:01:47,472 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:47,516 - config - INFO - Epoch [169/200], Train Loss: 0.3814
2024-03-28 23:01:47,521 - config - INFO - Validation Loss: 0.4485
2024-03-28 23:01:47,521 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:47,565 - config - INFO - Epoch [170/200], Train Loss: 0.3812
2024-03-28 23:01:47,570 - config - INFO - Validation Loss: 0.4486
2024-03-28 23:01:47,570 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:47,614 - config - INFO - Epoch [171/200], Train Loss: 0.3809
2024-03-28 23:01:47,619 - config - INFO - Validation Loss: 0.4486
2024-03-28 23:01:47,619 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:47,663 - config - INFO - Epoch [172/200], Train Loss: 0.3808
2024-03-28 23:01:47,668 - config - INFO - Validation Loss: 0.4487
2024-03-28 23:01:47,668 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:47,712 - config - INFO - Epoch [173/200], Train Loss: 0.3806
2024-03-28 23:01:47,717 - config - INFO - Validation Loss: 0.4487
2024-03-28 23:01:47,717 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:01:47,762 - config - INFO - Epoch [174/200], Train Loss: 0.3805
2024-03-28 23:01:47,767 - config - INFO - Validation Loss: 0.4486
2024-03-28 23:01:47,768 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:47,811 - config - INFO - Epoch [175/200], Train Loss: 0.3804
2024-03-28 23:01:47,816 - config - INFO - Validation Loss: 0.4490
2024-03-28 23:01:47,817 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:47,860 - config - INFO - Epoch [176/200], Train Loss: 0.3802
2024-03-28 23:01:47,865 - config - INFO - Validation Loss: 0.4489
2024-03-28 23:01:47,865 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:47,909 - config - INFO - Epoch [177/200], Train Loss: 0.3801
2024-03-28 23:01:47,914 - config - INFO - Validation Loss: 0.4487
2024-03-28 23:01:47,914 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:47,958 - config - INFO - Epoch [178/200], Train Loss: 0.3799
2024-03-28 23:01:47,963 - config - INFO - Validation Loss: 0.4491
2024-03-28 23:01:47,963 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:48,007 - config - INFO - Epoch [179/200], Train Loss: 0.3799
2024-03-28 23:01:48,012 - config - INFO - Validation Loss: 0.4484
2024-03-28 23:01:48,012 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:48,056 - config - INFO - Epoch [180/200], Train Loss: 0.3795
2024-03-28 23:01:48,061 - config - INFO - Validation Loss: 0.4488
2024-03-28 23:01:48,061 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:48,104 - config - INFO - Epoch [181/200], Train Loss: 0.3794
2024-03-28 23:01:48,110 - config - INFO - Validation Loss: 0.4483
2024-03-28 23:01:48,110 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:48,153 - config - INFO - Epoch [182/200], Train Loss: 0.3792
2024-03-28 23:01:48,159 - config - INFO - Validation Loss: 0.4481
2024-03-28 23:01:48,159 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:48,202 - config - INFO - Epoch [183/200], Train Loss: 0.3791
2024-03-28 23:01:48,208 - config - INFO - Validation Loss: 0.4477
2024-03-28 23:01:48,208 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:48,251 - config - INFO - Epoch [184/200], Train Loss: 0.3790
2024-03-28 23:01:48,257 - config - INFO - Validation Loss: 0.4480
2024-03-28 23:01:48,257 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:48,300 - config - INFO - Epoch [185/200], Train Loss: 0.3789
2024-03-28 23:01:48,305 - config - INFO - Validation Loss: 0.4477
2024-03-28 23:01:48,306 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:48,349 - config - INFO - Epoch [186/200], Train Loss: 0.3786
2024-03-28 23:01:48,354 - config - INFO - Validation Loss: 0.4478
2024-03-28 23:01:48,355 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:48,398 - config - INFO - Epoch [187/200], Train Loss: 0.3785
2024-03-28 23:01:48,403 - config - INFO - Validation Loss: 0.4477
2024-03-28 23:01:48,403 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:48,447 - config - INFO - Epoch [188/200], Train Loss: 0.3783
2024-03-28 23:01:48,452 - config - INFO - Validation Loss: 0.4476
2024-03-28 23:01:48,452 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:48,499 - config - INFO - Epoch [189/200], Train Loss: 0.3784
2024-03-28 23:01:48,505 - config - INFO - Validation Loss: 0.4476
2024-03-28 23:01:48,505 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:48,548 - config - INFO - Epoch [190/200], Train Loss: 0.3780
2024-03-28 23:01:48,553 - config - INFO - Validation Loss: 0.4473
2024-03-28 23:01:48,554 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:48,597 - config - INFO - Epoch [191/200], Train Loss: 0.3780
2024-03-28 23:01:48,602 - config - INFO - Validation Loss: 0.4468
2024-03-28 23:01:48,602 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:48,646 - config - INFO - Epoch [192/200], Train Loss: 0.3780
2024-03-28 23:01:48,651 - config - INFO - Validation Loss: 0.4477
2024-03-28 23:01:48,651 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:48,695 - config - INFO - Epoch [193/200], Train Loss: 0.3777
2024-03-28 23:01:48,700 - config - INFO - Validation Loss: 0.4471
2024-03-28 23:01:48,700 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:48,744 - config - INFO - Epoch [194/200], Train Loss: 0.3775
2024-03-28 23:01:48,749 - config - INFO - Validation Loss: 0.4470
2024-03-28 23:01:48,749 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:48,793 - config - INFO - Epoch [195/200], Train Loss: 0.3774
2024-03-28 23:01:48,798 - config - INFO - Validation Loss: 0.4468
2024-03-28 23:01:48,798 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:48,842 - config - INFO - Epoch [196/200], Train Loss: 0.3772
2024-03-28 23:01:48,847 - config - INFO - Validation Loss: 0.4467
2024-03-28 23:01:48,847 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:48,891 - config - INFO - Epoch [197/200], Train Loss: 0.3770
2024-03-28 23:01:48,896 - config - INFO - Validation Loss: 0.4471
2024-03-28 23:01:48,896 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:48,940 - config - INFO - Epoch [198/200], Train Loss: 0.3769
2024-03-28 23:01:48,945 - config - INFO - Validation Loss: 0.4469
2024-03-28 23:01:48,945 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:48,989 - config - INFO - Epoch [199/200], Train Loss: 0.3769
2024-03-28 23:01:48,994 - config - INFO - Validation Loss: 0.4470
2024-03-28 23:01:48,994 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:01:49,038 - config - INFO - Epoch [200/200], Train Loss: 0.3766
2024-03-28 23:01:49,043 - config - INFO - Validation Loss: 0.4465
2024-03-28 23:01:49,043 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:05,706 - config - INFO - resume: None
2024-03-28 23:02:05,706 - config - INFO - device: cpu
2024-03-28 23:02:05,706 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 23:02:05,706 - config - INFO - learning_rate: 0.0001
2024-03-28 23:02:05,706 - config - INFO - num_epochs: 600
2024-03-28 23:02:05,706 - config - INFO - batch_size: 32
2024-03-28 23:02:05,706 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 23:02:05,727 - config - INFO - Dataset size: 891
2024-03-28 23:02:05,751 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 23:02:05,751 - config - INFO - Training start
2024-03-28 23:02:08,058 - config - INFO - Epoch [1/600], Train Loss: 0.7105
2024-03-28 23:02:08,064 - config - INFO - Validation Loss: 0.7075
2024-03-28 23:02:08,064 - config - INFO - Validation Acc: 0.2778
2024-03-28 23:02:08,121 - config - INFO - Epoch [2/600], Train Loss: 0.7007
2024-03-28 23:02:08,127 - config - INFO - Validation Loss: 0.6987
2024-03-28 23:02:08,127 - config - INFO - Validation Acc: 0.2778
2024-03-28 23:02:08,184 - config - INFO - Epoch [3/600], Train Loss: 0.6911
2024-03-28 23:02:08,190 - config - INFO - Validation Loss: 0.6900
2024-03-28 23:02:08,191 - config - INFO - Validation Acc: 0.3889
2024-03-28 23:02:08,247 - config - INFO - Epoch [4/600], Train Loss: 0.6821
2024-03-28 23:02:08,253 - config - INFO - Validation Loss: 0.6814
2024-03-28 23:02:08,253 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:02:08,308 - config - INFO - Epoch [5/600], Train Loss: 0.6731
2024-03-28 23:02:08,314 - config - INFO - Validation Loss: 0.6731
2024-03-28 23:02:08,315 - config - INFO - Validation Acc: 0.5556
2024-03-28 23:02:08,369 - config - INFO - Epoch [6/600], Train Loss: 0.6640
2024-03-28 23:02:08,376 - config - INFO - Validation Loss: 0.6648
2024-03-28 23:02:08,376 - config - INFO - Validation Acc: 0.5556
2024-03-28 23:02:08,426 - config - INFO - Epoch [7/600], Train Loss: 0.6548
2024-03-28 23:02:08,432 - config - INFO - Validation Loss: 0.6555
2024-03-28 23:02:08,432 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:02:08,496 - config - INFO - Epoch [8/600], Train Loss: 0.6448
2024-03-28 23:02:08,502 - config - INFO - Validation Loss: 0.6468
2024-03-28 23:02:08,502 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:08,550 - config - INFO - Epoch [9/600], Train Loss: 0.6349
2024-03-28 23:02:08,556 - config - INFO - Validation Loss: 0.6374
2024-03-28 23:02:08,556 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:08,605 - config - INFO - Epoch [10/600], Train Loss: 0.6244
2024-03-28 23:02:08,611 - config - INFO - Validation Loss: 0.6280
2024-03-28 23:02:08,611 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:08,660 - config - INFO - Epoch [11/600], Train Loss: 0.6136
2024-03-28 23:02:08,665 - config - INFO - Validation Loss: 0.6180
2024-03-28 23:02:08,666 - config - INFO - Validation Acc: 0.7778
2024-03-28 23:02:08,714 - config - INFO - Epoch [12/600], Train Loss: 0.6021
2024-03-28 23:02:08,720 - config - INFO - Validation Loss: 0.6074
2024-03-28 23:02:08,720 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:08,769 - config - INFO - Epoch [13/600], Train Loss: 0.5899
2024-03-28 23:02:08,775 - config - INFO - Validation Loss: 0.5962
2024-03-28 23:02:08,775 - config - INFO - Validation Acc: 0.7778
2024-03-28 23:02:08,824 - config - INFO - Epoch [14/600], Train Loss: 0.5768
2024-03-28 23:02:08,830 - config - INFO - Validation Loss: 0.5849
2024-03-28 23:02:08,830 - config - INFO - Validation Acc: 0.7778
2024-03-28 23:02:08,878 - config - INFO - Epoch [15/600], Train Loss: 0.5639
2024-03-28 23:02:08,884 - config - INFO - Validation Loss: 0.5743
2024-03-28 23:02:08,884 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:08,933 - config - INFO - Epoch [16/600], Train Loss: 0.5519
2024-03-28 23:02:08,939 - config - INFO - Validation Loss: 0.5635
2024-03-28 23:02:08,939 - config - INFO - Validation Acc: 0.7778
2024-03-28 23:02:08,988 - config - INFO - Epoch [17/600], Train Loss: 0.5395
2024-03-28 23:02:08,994 - config - INFO - Validation Loss: 0.5536
2024-03-28 23:02:08,994 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:09,043 - config - INFO - Epoch [18/600], Train Loss: 0.5281
2024-03-28 23:02:09,049 - config - INFO - Validation Loss: 0.5447
2024-03-28 23:02:09,049 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:09,098 - config - INFO - Epoch [19/600], Train Loss: 0.5176
2024-03-28 23:02:09,104 - config - INFO - Validation Loss: 0.5358
2024-03-28 23:02:09,104 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:09,168 - config - INFO - Epoch [20/600], Train Loss: 0.5069
2024-03-28 23:02:09,174 - config - INFO - Validation Loss: 0.5288
2024-03-28 23:02:09,174 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:09,223 - config - INFO - Epoch [21/600], Train Loss: 0.4979
2024-03-28 23:02:09,229 - config - INFO - Validation Loss: 0.5218
2024-03-28 23:02:09,229 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:09,279 - config - INFO - Epoch [22/600], Train Loss: 0.4891
2024-03-28 23:02:09,285 - config - INFO - Validation Loss: 0.5154
2024-03-28 23:02:09,285 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:09,335 - config - INFO - Epoch [23/600], Train Loss: 0.4813
2024-03-28 23:02:09,340 - config - INFO - Validation Loss: 0.5103
2024-03-28 23:02:09,341 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:09,380 - config - INFO - Epoch [24/600], Train Loss: 0.4746
2024-03-28 23:02:09,385 - config - INFO - Validation Loss: 0.5060
2024-03-28 23:02:09,385 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:09,424 - config - INFO - Epoch [25/600], Train Loss: 0.4685
2024-03-28 23:02:09,429 - config - INFO - Validation Loss: 0.5022
2024-03-28 23:02:09,429 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:09,483 - config - INFO - Epoch [26/600], Train Loss: 0.4625
2024-03-28 23:02:09,488 - config - INFO - Validation Loss: 0.4979
2024-03-28 23:02:09,488 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:09,528 - config - INFO - Epoch [27/600], Train Loss: 0.4576
2024-03-28 23:02:09,533 - config - INFO - Validation Loss: 0.4946
2024-03-28 23:02:09,533 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:09,571 - config - INFO - Epoch [28/600], Train Loss: 0.4529
2024-03-28 23:02:09,576 - config - INFO - Validation Loss: 0.4923
2024-03-28 23:02:09,576 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:09,617 - config - INFO - Epoch [29/600], Train Loss: 0.4492
2024-03-28 23:02:09,622 - config - INFO - Validation Loss: 0.4901
2024-03-28 23:02:09,622 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:09,663 - config - INFO - Epoch [30/600], Train Loss: 0.4454
2024-03-28 23:02:09,668 - config - INFO - Validation Loss: 0.4877
2024-03-28 23:02:09,669 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:09,710 - config - INFO - Epoch [31/600], Train Loss: 0.4423
2024-03-28 23:02:09,715 - config - INFO - Validation Loss: 0.4860
2024-03-28 23:02:09,715 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:09,757 - config - INFO - Epoch [32/600], Train Loss: 0.4392
2024-03-28 23:02:09,762 - config - INFO - Validation Loss: 0.4848
2024-03-28 23:02:09,762 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:09,803 - config - INFO - Epoch [33/600], Train Loss: 0.4367
2024-03-28 23:02:09,807 - config - INFO - Validation Loss: 0.4834
2024-03-28 23:02:09,808 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:09,848 - config - INFO - Epoch [34/600], Train Loss: 0.4342
2024-03-28 23:02:09,853 - config - INFO - Validation Loss: 0.4818
2024-03-28 23:02:09,854 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:09,894 - config - INFO - Epoch [35/600], Train Loss: 0.4320
2024-03-28 23:02:09,899 - config - INFO - Validation Loss: 0.4806
2024-03-28 23:02:09,899 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:09,940 - config - INFO - Epoch [36/600], Train Loss: 0.4300
2024-03-28 23:02:09,945 - config - INFO - Validation Loss: 0.4798
2024-03-28 23:02:09,945 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:10,002 - config - INFO - Epoch [37/600], Train Loss: 0.4281
2024-03-28 23:02:10,007 - config - INFO - Validation Loss: 0.4788
2024-03-28 23:02:10,007 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:10,050 - config - INFO - Epoch [38/600], Train Loss: 0.4262
2024-03-28 23:02:10,056 - config - INFO - Validation Loss: 0.4779
2024-03-28 23:02:10,056 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:10,102 - config - INFO - Epoch [39/600], Train Loss: 0.4246
2024-03-28 23:02:10,109 - config - INFO - Validation Loss: 0.4771
2024-03-28 23:02:10,109 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:10,162 - config - INFO - Epoch [40/600], Train Loss: 0.4232
2024-03-28 23:02:10,167 - config - INFO - Validation Loss: 0.4764
2024-03-28 23:02:10,168 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:10,216 - config - INFO - Epoch [41/600], Train Loss: 0.4219
2024-03-28 23:02:10,222 - config - INFO - Validation Loss: 0.4755
2024-03-28 23:02:10,222 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:10,270 - config - INFO - Epoch [42/600], Train Loss: 0.4207
2024-03-28 23:02:10,276 - config - INFO - Validation Loss: 0.4755
2024-03-28 23:02:10,276 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:10,325 - config - INFO - Epoch [43/600], Train Loss: 0.4195
2024-03-28 23:02:10,331 - config - INFO - Validation Loss: 0.4749
2024-03-28 23:02:10,331 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:10,379 - config - INFO - Epoch [44/600], Train Loss: 0.4182
2024-03-28 23:02:10,385 - config - INFO - Validation Loss: 0.4743
2024-03-28 23:02:10,385 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:10,434 - config - INFO - Epoch [45/600], Train Loss: 0.4173
2024-03-28 23:02:10,440 - config - INFO - Validation Loss: 0.4742
2024-03-28 23:02:10,440 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:10,488 - config - INFO - Epoch [46/600], Train Loss: 0.4163
2024-03-28 23:02:10,494 - config - INFO - Validation Loss: 0.4738
2024-03-28 23:02:10,494 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:10,542 - config - INFO - Epoch [47/600], Train Loss: 0.4154
2024-03-28 23:02:10,548 - config - INFO - Validation Loss: 0.4735
2024-03-28 23:02:10,548 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:10,597 - config - INFO - Epoch [48/600], Train Loss: 0.4145
2024-03-28 23:02:10,602 - config - INFO - Validation Loss: 0.4736
2024-03-28 23:02:10,603 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:10,651 - config - INFO - Epoch [49/600], Train Loss: 0.4138
2024-03-28 23:02:10,657 - config - INFO - Validation Loss: 0.4737
2024-03-28 23:02:10,657 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:10,705 - config - INFO - Epoch [50/600], Train Loss: 0.4128
2024-03-28 23:02:10,711 - config - INFO - Validation Loss: 0.4731
2024-03-28 23:02:10,715 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:10,764 - config - INFO - Epoch [51/600], Train Loss: 0.4121
2024-03-28 23:02:10,769 - config - INFO - Validation Loss: 0.4723
2024-03-28 23:02:10,770 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:10,818 - config - INFO - Epoch [52/600], Train Loss: 0.4113
2024-03-28 23:02:10,824 - config - INFO - Validation Loss: 0.4722
2024-03-28 23:02:10,824 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:10,872 - config - INFO - Epoch [53/600], Train Loss: 0.4107
2024-03-28 23:02:10,878 - config - INFO - Validation Loss: 0.4721
2024-03-28 23:02:10,878 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:10,927 - config - INFO - Epoch [54/600], Train Loss: 0.4101
2024-03-28 23:02:10,932 - config - INFO - Validation Loss: 0.4723
2024-03-28 23:02:10,933 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:10,981 - config - INFO - Epoch [55/600], Train Loss: 0.4092
2024-03-28 23:02:10,991 - config - INFO - Validation Loss: 0.4720
2024-03-28 23:02:10,992 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:11,039 - config - INFO - Epoch [56/600], Train Loss: 0.4088
2024-03-28 23:02:11,044 - config - INFO - Validation Loss: 0.4719
2024-03-28 23:02:11,045 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:11,087 - config - INFO - Epoch [57/600], Train Loss: 0.4081
2024-03-28 23:02:11,092 - config - INFO - Validation Loss: 0.4718
2024-03-28 23:02:11,092 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:11,135 - config - INFO - Epoch [58/600], Train Loss: 0.4075
2024-03-28 23:02:11,140 - config - INFO - Validation Loss: 0.4716
2024-03-28 23:02:11,140 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:11,182 - config - INFO - Epoch [59/600], Train Loss: 0.4071
2024-03-28 23:02:11,187 - config - INFO - Validation Loss: 0.4711
2024-03-28 23:02:11,187 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:11,230 - config - INFO - Epoch [60/600], Train Loss: 0.4066
2024-03-28 23:02:11,235 - config - INFO - Validation Loss: 0.4715
2024-03-28 23:02:11,235 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:11,278 - config - INFO - Epoch [61/600], Train Loss: 0.4060
2024-03-28 23:02:11,284 - config - INFO - Validation Loss: 0.4715
2024-03-28 23:02:11,284 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:11,326 - config - INFO - Epoch [62/600], Train Loss: 0.4056
2024-03-28 23:02:11,331 - config - INFO - Validation Loss: 0.4717
2024-03-28 23:02:11,331 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:11,374 - config - INFO - Epoch [63/600], Train Loss: 0.4053
2024-03-28 23:02:11,379 - config - INFO - Validation Loss: 0.4718
2024-03-28 23:02:11,379 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:11,421 - config - INFO - Epoch [64/600], Train Loss: 0.4044
2024-03-28 23:02:11,426 - config - INFO - Validation Loss: 0.4712
2024-03-28 23:02:11,426 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:11,469 - config - INFO - Epoch [65/600], Train Loss: 0.4041
2024-03-28 23:02:11,474 - config - INFO - Validation Loss: 0.4713
2024-03-28 23:02:11,474 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:11,516 - config - INFO - Epoch [66/600], Train Loss: 0.4037
2024-03-28 23:02:11,521 - config - INFO - Validation Loss: 0.4710
2024-03-28 23:02:11,522 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:11,564 - config - INFO - Epoch [67/600], Train Loss: 0.4032
2024-03-28 23:02:11,569 - config - INFO - Validation Loss: 0.4712
2024-03-28 23:02:11,569 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:11,611 - config - INFO - Epoch [68/600], Train Loss: 0.4028
2024-03-28 23:02:11,616 - config - INFO - Validation Loss: 0.4719
2024-03-28 23:02:11,617 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:11,659 - config - INFO - Epoch [69/600], Train Loss: 0.4024
2024-03-28 23:02:11,664 - config - INFO - Validation Loss: 0.4707
2024-03-28 23:02:11,664 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:11,706 - config - INFO - Epoch [70/600], Train Loss: 0.4018
2024-03-28 23:02:11,711 - config - INFO - Validation Loss: 0.4714
2024-03-28 23:02:11,712 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:11,754 - config - INFO - Epoch [71/600], Train Loss: 0.4016
2024-03-28 23:02:11,759 - config - INFO - Validation Loss: 0.4709
2024-03-28 23:02:11,759 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:11,801 - config - INFO - Epoch [72/600], Train Loss: 0.4011
2024-03-28 23:02:11,806 - config - INFO - Validation Loss: 0.4704
2024-03-28 23:02:11,806 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:11,849 - config - INFO - Epoch [73/600], Train Loss: 0.4006
2024-03-28 23:02:11,854 - config - INFO - Validation Loss: 0.4703
2024-03-28 23:02:11,854 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:11,896 - config - INFO - Epoch [74/600], Train Loss: 0.4003
2024-03-28 23:02:11,901 - config - INFO - Validation Loss: 0.4704
2024-03-28 23:02:11,901 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:11,944 - config - INFO - Epoch [75/600], Train Loss: 0.3999
2024-03-28 23:02:11,949 - config - INFO - Validation Loss: 0.4713
2024-03-28 23:02:11,949 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:12,002 - config - INFO - Epoch [76/600], Train Loss: 0.3997
2024-03-28 23:02:12,011 - config - INFO - Validation Loss: 0.4710
2024-03-28 23:02:12,011 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:12,055 - config - INFO - Epoch [77/600], Train Loss: 0.3990
2024-03-28 23:02:12,060 - config - INFO - Validation Loss: 0.4713
2024-03-28 23:02:12,060 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:12,103 - config - INFO - Epoch [78/600], Train Loss: 0.3991
2024-03-28 23:02:12,108 - config - INFO - Validation Loss: 0.4704
2024-03-28 23:02:12,108 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:12,151 - config - INFO - Epoch [79/600], Train Loss: 0.3983
2024-03-28 23:02:12,156 - config - INFO - Validation Loss: 0.4718
2024-03-28 23:02:12,156 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:12,199 - config - INFO - Epoch [80/600], Train Loss: 0.3980
2024-03-28 23:02:12,204 - config - INFO - Validation Loss: 0.4720
2024-03-28 23:02:12,204 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:12,246 - config - INFO - Epoch [81/600], Train Loss: 0.3980
2024-03-28 23:02:12,251 - config - INFO - Validation Loss: 0.4708
2024-03-28 23:02:12,252 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:12,294 - config - INFO - Epoch [82/600], Train Loss: 0.3973
2024-03-28 23:02:12,299 - config - INFO - Validation Loss: 0.4715
2024-03-28 23:02:12,300 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:12,342 - config - INFO - Epoch [83/600], Train Loss: 0.3969
2024-03-28 23:02:12,347 - config - INFO - Validation Loss: 0.4708
2024-03-28 23:02:12,347 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:12,390 - config - INFO - Epoch [84/600], Train Loss: 0.3967
2024-03-28 23:02:12,395 - config - INFO - Validation Loss: 0.4706
2024-03-28 23:02:12,395 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:12,438 - config - INFO - Epoch [85/600], Train Loss: 0.3962
2024-03-28 23:02:12,443 - config - INFO - Validation Loss: 0.4707
2024-03-28 23:02:12,443 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:12,485 - config - INFO - Epoch [86/600], Train Loss: 0.3958
2024-03-28 23:02:12,490 - config - INFO - Validation Loss: 0.4707
2024-03-28 23:02:12,491 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:12,533 - config - INFO - Epoch [87/600], Train Loss: 0.3955
2024-03-28 23:02:12,538 - config - INFO - Validation Loss: 0.4711
2024-03-28 23:02:12,538 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:12,581 - config - INFO - Epoch [88/600], Train Loss: 0.3956
2024-03-28 23:02:12,586 - config - INFO - Validation Loss: 0.4701
2024-03-28 23:02:12,586 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:12,629 - config - INFO - Epoch [89/600], Train Loss: 0.3950
2024-03-28 23:02:12,634 - config - INFO - Validation Loss: 0.4702
2024-03-28 23:02:12,634 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:12,677 - config - INFO - Epoch [90/600], Train Loss: 0.3946
2024-03-28 23:02:12,682 - config - INFO - Validation Loss: 0.4714
2024-03-28 23:02:12,682 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:12,725 - config - INFO - Epoch [91/600], Train Loss: 0.3941
2024-03-28 23:02:12,730 - config - INFO - Validation Loss: 0.4713
2024-03-28 23:02:12,730 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:12,772 - config - INFO - Epoch [92/600], Train Loss: 0.3939
2024-03-28 23:02:12,777 - config - INFO - Validation Loss: 0.4714
2024-03-28 23:02:12,777 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:12,820 - config - INFO - Epoch [93/600], Train Loss: 0.3937
2024-03-28 23:02:12,825 - config - INFO - Validation Loss: 0.4715
2024-03-28 23:02:12,825 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:12,868 - config - INFO - Epoch [94/600], Train Loss: 0.3933
2024-03-28 23:02:12,873 - config - INFO - Validation Loss: 0.4717
2024-03-28 23:02:12,873 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:12,916 - config - INFO - Epoch [95/600], Train Loss: 0.3934
2024-03-28 23:02:12,921 - config - INFO - Validation Loss: 0.4714
2024-03-28 23:02:12,921 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:12,963 - config - INFO - Epoch [96/600], Train Loss: 0.3928
2024-03-28 23:02:12,968 - config - INFO - Validation Loss: 0.4719
2024-03-28 23:02:12,969 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:13,021 - config - INFO - Epoch [97/600], Train Loss: 0.3924
2024-03-28 23:02:13,026 - config - INFO - Validation Loss: 0.4717
2024-03-28 23:02:13,026 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:13,069 - config - INFO - Epoch [98/600], Train Loss: 0.3923
2024-03-28 23:02:13,074 - config - INFO - Validation Loss: 0.4724
2024-03-28 23:02:13,074 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:13,116 - config - INFO - Epoch [99/600], Train Loss: 0.3919
2024-03-28 23:02:13,121 - config - INFO - Validation Loss: 0.4726
2024-03-28 23:02:13,122 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:13,164 - config - INFO - Epoch [100/600], Train Loss: 0.3917
2024-03-28 23:02:13,169 - config - INFO - Validation Loss: 0.4728
2024-03-28 23:02:13,169 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:13,211 - config - INFO - Epoch [101/600], Train Loss: 0.3916
2024-03-28 23:02:13,216 - config - INFO - Validation Loss: 0.4731
2024-03-28 23:02:13,217 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:13,217 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 23:02:26,621 - config - INFO - resume: None
2024-03-28 23:02:26,622 - config - INFO - device: cpu
2024-03-28 23:02:26,622 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 23:02:26,622 - config - INFO - learning_rate: 0.0001
2024-03-28 23:02:26,622 - config - INFO - num_epochs: 600
2024-03-28 23:02:26,622 - config - INFO - batch_size: 32
2024-03-28 23:02:26,622 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 23:02:26,643 - config - INFO - Dataset size: 891
2024-03-28 23:02:26,667 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 23:02:26,667 - config - INFO - Training start
2024-03-28 23:02:29,035 - config - INFO - Epoch [1/600], Train Loss: 0.6888
2024-03-28 23:02:29,041 - config - INFO - Validation Loss: 0.6865
2024-03-28 23:02:29,042 - config - INFO - Validation Acc: 0.6111
2024-03-28 23:02:29,099 - config - INFO - Epoch [2/600], Train Loss: 0.6814
2024-03-28 23:02:29,105 - config - INFO - Validation Loss: 0.6793
2024-03-28 23:02:29,106 - config - INFO - Validation Acc: 0.6111
2024-03-28 23:02:29,156 - config - INFO - Epoch [3/600], Train Loss: 0.6741
2024-03-28 23:02:29,161 - config - INFO - Validation Loss: 0.6722
2024-03-28 23:02:29,162 - config - INFO - Validation Acc: 0.6111
2024-03-28 23:02:29,212 - config - INFO - Epoch [4/600], Train Loss: 0.6668
2024-03-28 23:02:29,218 - config - INFO - Validation Loss: 0.6649
2024-03-28 23:02:29,218 - config - INFO - Validation Acc: 0.5556
2024-03-28 23:02:29,268 - config - INFO - Epoch [5/600], Train Loss: 0.6591
2024-03-28 23:02:29,274 - config - INFO - Validation Loss: 0.6582
2024-03-28 23:02:29,275 - config - INFO - Validation Acc: 0.6111
2024-03-28 23:02:29,324 - config - INFO - Epoch [6/600], Train Loss: 0.6515
2024-03-28 23:02:29,330 - config - INFO - Validation Loss: 0.6502
2024-03-28 23:02:29,331 - config - INFO - Validation Acc: 0.6111
2024-03-28 23:02:29,380 - config - INFO - Epoch [7/600], Train Loss: 0.6432
2024-03-28 23:02:29,386 - config - INFO - Validation Loss: 0.6426
2024-03-28 23:02:29,386 - config - INFO - Validation Acc: 0.6111
2024-03-28 23:02:29,454 - config - INFO - Epoch [8/600], Train Loss: 0.6350
2024-03-28 23:02:29,460 - config - INFO - Validation Loss: 0.6349
2024-03-28 23:02:29,460 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:02:29,510 - config - INFO - Epoch [9/600], Train Loss: 0.6260
2024-03-28 23:02:29,516 - config - INFO - Validation Loss: 0.6270
2024-03-28 23:02:29,516 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:02:29,566 - config - INFO - Epoch [10/600], Train Loss: 0.6167
2024-03-28 23:02:29,572 - config - INFO - Validation Loss: 0.6187
2024-03-28 23:02:29,572 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:29,622 - config - INFO - Epoch [11/600], Train Loss: 0.6069
2024-03-28 23:02:29,628 - config - INFO - Validation Loss: 0.6101
2024-03-28 23:02:29,628 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:29,678 - config - INFO - Epoch [12/600], Train Loss: 0.5968
2024-03-28 23:02:29,689 - config - INFO - Validation Loss: 0.6014
2024-03-28 23:02:29,689 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:29,734 - config - INFO - Epoch [13/600], Train Loss: 0.5866
2024-03-28 23:02:29,739 - config - INFO - Validation Loss: 0.5926
2024-03-28 23:02:29,739 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:29,782 - config - INFO - Epoch [14/600], Train Loss: 0.5762
2024-03-28 23:02:29,787 - config - INFO - Validation Loss: 0.5839
2024-03-28 23:02:29,788 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:29,831 - config - INFO - Epoch [15/600], Train Loss: 0.5656
2024-03-28 23:02:29,836 - config - INFO - Validation Loss: 0.5755
2024-03-28 23:02:29,836 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:29,880 - config - INFO - Epoch [16/600], Train Loss: 0.5550
2024-03-28 23:02:29,885 - config - INFO - Validation Loss: 0.5676
2024-03-28 23:02:29,885 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:29,930 - config - INFO - Epoch [17/600], Train Loss: 0.5444
2024-03-28 23:02:29,935 - config - INFO - Validation Loss: 0.5595
2024-03-28 23:02:29,935 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:29,979 - config - INFO - Epoch [18/600], Train Loss: 0.5340
2024-03-28 23:02:29,984 - config - INFO - Validation Loss: 0.5517
2024-03-28 23:02:29,984 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:30,030 - config - INFO - Epoch [19/600], Train Loss: 0.5242
2024-03-28 23:02:30,035 - config - INFO - Validation Loss: 0.5445
2024-03-28 23:02:30,035 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:30,079 - config - INFO - Epoch [20/600], Train Loss: 0.5140
2024-03-28 23:02:30,084 - config - INFO - Validation Loss: 0.5380
2024-03-28 23:02:30,084 - config - INFO - Validation Acc: 0.7778
2024-03-28 23:02:30,128 - config - INFO - Epoch [21/600], Train Loss: 0.5046
2024-03-28 23:02:30,133 - config - INFO - Validation Loss: 0.5321
2024-03-28 23:02:30,133 - config - INFO - Validation Acc: 0.7778
2024-03-28 23:02:30,177 - config - INFO - Epoch [22/600], Train Loss: 0.4956
2024-03-28 23:02:30,182 - config - INFO - Validation Loss: 0.5266
2024-03-28 23:02:30,182 - config - INFO - Validation Acc: 0.7778
2024-03-28 23:02:30,225 - config - INFO - Epoch [23/600], Train Loss: 0.4871
2024-03-28 23:02:30,230 - config - INFO - Validation Loss: 0.5224
2024-03-28 23:02:30,230 - config - INFO - Validation Acc: 0.7778
2024-03-28 23:02:30,274 - config - INFO - Epoch [24/600], Train Loss: 0.4797
2024-03-28 23:02:30,279 - config - INFO - Validation Loss: 0.5182
2024-03-28 23:02:30,279 - config - INFO - Validation Acc: 0.7778
2024-03-28 23:02:30,322 - config - INFO - Epoch [25/600], Train Loss: 0.4724
2024-03-28 23:02:30,328 - config - INFO - Validation Loss: 0.5151
2024-03-28 23:02:30,328 - config - INFO - Validation Acc: 0.7778
2024-03-28 23:02:30,371 - config - INFO - Epoch [26/600], Train Loss: 0.4660
2024-03-28 23:02:30,376 - config - INFO - Validation Loss: 0.5129
2024-03-28 23:02:30,376 - config - INFO - Validation Acc: 0.7778
2024-03-28 23:02:30,420 - config - INFO - Epoch [27/600], Train Loss: 0.4600
2024-03-28 23:02:30,425 - config - INFO - Validation Loss: 0.5103
2024-03-28 23:02:30,425 - config - INFO - Validation Acc: 0.7778
2024-03-28 23:02:30,468 - config - INFO - Epoch [28/600], Train Loss: 0.4544
2024-03-28 23:02:30,473 - config - INFO - Validation Loss: 0.5080
2024-03-28 23:02:30,473 - config - INFO - Validation Acc: 0.7778
2024-03-28 23:02:30,517 - config - INFO - Epoch [29/600], Train Loss: 0.4496
2024-03-28 23:02:30,522 - config - INFO - Validation Loss: 0.5071
2024-03-28 23:02:30,522 - config - INFO - Validation Acc: 0.7778
2024-03-28 23:02:30,565 - config - INFO - Epoch [30/600], Train Loss: 0.4449
2024-03-28 23:02:30,570 - config - INFO - Validation Loss: 0.5051
2024-03-28 23:02:30,571 - config - INFO - Validation Acc: 0.7778
2024-03-28 23:02:30,614 - config - INFO - Epoch [31/600], Train Loss: 0.4406
2024-03-28 23:02:30,619 - config - INFO - Validation Loss: 0.5044
2024-03-28 23:02:30,619 - config - INFO - Validation Acc: 0.7778
2024-03-28 23:02:30,663 - config - INFO - Epoch [32/600], Train Loss: 0.4367
2024-03-28 23:02:30,668 - config - INFO - Validation Loss: 0.5028
2024-03-28 23:02:30,668 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:30,711 - config - INFO - Epoch [33/600], Train Loss: 0.4331
2024-03-28 23:02:30,716 - config - INFO - Validation Loss: 0.5027
2024-03-28 23:02:30,716 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:30,760 - config - INFO - Epoch [34/600], Train Loss: 0.4299
2024-03-28 23:02:30,765 - config - INFO - Validation Loss: 0.5025
2024-03-28 23:02:30,765 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:30,808 - config - INFO - Epoch [35/600], Train Loss: 0.4271
2024-03-28 23:02:30,814 - config - INFO - Validation Loss: 0.5021
2024-03-28 23:02:30,814 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:30,857 - config - INFO - Epoch [36/600], Train Loss: 0.4244
2024-03-28 23:02:30,862 - config - INFO - Validation Loss: 0.5026
2024-03-28 23:02:30,862 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:30,906 - config - INFO - Epoch [37/600], Train Loss: 0.4221
2024-03-28 23:02:30,911 - config - INFO - Validation Loss: 0.5024
2024-03-28 23:02:30,911 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:30,959 - config - INFO - Epoch [38/600], Train Loss: 0.4198
2024-03-28 23:02:30,964 - config - INFO - Validation Loss: 0.5032
2024-03-28 23:02:30,965 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:31,008 - config - INFO - Epoch [39/600], Train Loss: 0.4177
2024-03-28 23:02:31,013 - config - INFO - Validation Loss: 0.5033
2024-03-28 23:02:31,013 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:31,056 - config - INFO - Epoch [40/600], Train Loss: 0.4159
2024-03-28 23:02:31,061 - config - INFO - Validation Loss: 0.5040
2024-03-28 23:02:31,061 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:31,105 - config - INFO - Epoch [41/600], Train Loss: 0.4142
2024-03-28 23:02:31,110 - config - INFO - Validation Loss: 0.5043
2024-03-28 23:02:31,110 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:31,154 - config - INFO - Epoch [42/600], Train Loss: 0.4127
2024-03-28 23:02:31,159 - config - INFO - Validation Loss: 0.5044
2024-03-28 23:02:31,159 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:31,202 - config - INFO - Epoch [43/600], Train Loss: 0.4111
2024-03-28 23:02:31,207 - config - INFO - Validation Loss: 0.5051
2024-03-28 23:02:31,208 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:31,208 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 23:02:46,859 - config - INFO - resume: None
2024-03-28 23:02:46,859 - config - INFO - device: cpu
2024-03-28 23:02:46,859 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 23:02:46,859 - config - INFO - learning_rate: 0.0001
2024-03-28 23:02:46,859 - config - INFO - num_epochs: 600
2024-03-28 23:02:46,859 - config - INFO - batch_size: 32
2024-03-28 23:02:46,859 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.003

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 23:02:46,881 - config - INFO - Dataset size: 891
2024-03-28 23:02:46,907 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.8 * len(self.train_dataset))
        val_size = int(0.2 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 23:02:46,907 - config - INFO - Training start
2024-03-28 23:02:49,253 - config - INFO - Epoch [1/600], Train Loss: 0.6980
2024-03-28 23:02:49,260 - config - INFO - Validation Loss: 0.6905
2024-03-28 23:02:49,260 - config - INFO - Validation Acc: 0.3889
2024-03-28 23:02:49,318 - config - INFO - Epoch [2/600], Train Loss: 0.6904
2024-03-28 23:02:49,324 - config - INFO - Validation Loss: 0.6825
2024-03-28 23:02:49,325 - config - INFO - Validation Acc: 0.3889
2024-03-28 23:02:49,378 - config - INFO - Epoch [3/600], Train Loss: 0.6830
2024-03-28 23:02:49,390 - config - INFO - Validation Loss: 0.6749
2024-03-28 23:02:49,390 - config - INFO - Validation Acc: 0.5000
2024-03-28 23:02:49,435 - config - INFO - Epoch [4/600], Train Loss: 0.6763
2024-03-28 23:02:49,441 - config - INFO - Validation Loss: 0.6674
2024-03-28 23:02:49,441 - config - INFO - Validation Acc: 0.7222
2024-03-28 23:02:49,488 - config - INFO - Epoch [5/600], Train Loss: 0.6699
2024-03-28 23:02:49,493 - config - INFO - Validation Loss: 0.6600
2024-03-28 23:02:49,493 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:49,536 - config - INFO - Epoch [6/600], Train Loss: 0.6632
2024-03-28 23:02:49,541 - config - INFO - Validation Loss: 0.6524
2024-03-28 23:02:49,541 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:49,584 - config - INFO - Epoch [7/600], Train Loss: 0.6564
2024-03-28 23:02:49,590 - config - INFO - Validation Loss: 0.6441
2024-03-28 23:02:49,590 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:49,649 - config - INFO - Epoch [8/600], Train Loss: 0.6488
2024-03-28 23:02:49,655 - config - INFO - Validation Loss: 0.6356
2024-03-28 23:02:49,655 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:49,697 - config - INFO - Epoch [9/600], Train Loss: 0.6412
2024-03-28 23:02:49,703 - config - INFO - Validation Loss: 0.6268
2024-03-28 23:02:49,703 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:49,745 - config - INFO - Epoch [10/600], Train Loss: 0.6331
2024-03-28 23:02:49,750 - config - INFO - Validation Loss: 0.6175
2024-03-28 23:02:49,751 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:49,793 - config - INFO - Epoch [11/600], Train Loss: 0.6249
2024-03-28 23:02:49,798 - config - INFO - Validation Loss: 0.6082
2024-03-28 23:02:49,799 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:49,843 - config - INFO - Epoch [12/600], Train Loss: 0.6164
2024-03-28 23:02:49,848 - config - INFO - Validation Loss: 0.5986
2024-03-28 23:02:49,848 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:49,891 - config - INFO - Epoch [13/600], Train Loss: 0.6078
2024-03-28 23:02:49,896 - config - INFO - Validation Loss: 0.5885
2024-03-28 23:02:49,896 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:49,939 - config - INFO - Epoch [14/600], Train Loss: 0.5994
2024-03-28 23:02:49,944 - config - INFO - Validation Loss: 0.5784
2024-03-28 23:02:49,944 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:49,986 - config - INFO - Epoch [15/600], Train Loss: 0.5906
2024-03-28 23:02:49,991 - config - INFO - Validation Loss: 0.5683
2024-03-28 23:02:49,992 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:50,034 - config - INFO - Epoch [16/600], Train Loss: 0.5821
2024-03-28 23:02:50,039 - config - INFO - Validation Loss: 0.5578
2024-03-28 23:02:50,039 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:50,082 - config - INFO - Epoch [17/600], Train Loss: 0.5730
2024-03-28 23:02:50,087 - config - INFO - Validation Loss: 0.5474
2024-03-28 23:02:50,087 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:50,129 - config - INFO - Epoch [18/600], Train Loss: 0.5643
2024-03-28 23:02:50,135 - config - INFO - Validation Loss: 0.5363
2024-03-28 23:02:50,135 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:50,177 - config - INFO - Epoch [19/600], Train Loss: 0.5550
2024-03-28 23:02:50,182 - config - INFO - Validation Loss: 0.5255
2024-03-28 23:02:50,182 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:50,225 - config - INFO - Epoch [20/600], Train Loss: 0.5463
2024-03-28 23:02:50,230 - config - INFO - Validation Loss: 0.5152
2024-03-28 23:02:50,230 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:50,272 - config - INFO - Epoch [21/600], Train Loss: 0.5377
2024-03-28 23:02:50,278 - config - INFO - Validation Loss: 0.5047
2024-03-28 23:02:50,278 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:50,320 - config - INFO - Epoch [22/600], Train Loss: 0.5296
2024-03-28 23:02:50,325 - config - INFO - Validation Loss: 0.4952
2024-03-28 23:02:50,325 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:50,368 - config - INFO - Epoch [23/600], Train Loss: 0.5219
2024-03-28 23:02:50,373 - config - INFO - Validation Loss: 0.4860
2024-03-28 23:02:50,373 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:50,415 - config - INFO - Epoch [24/600], Train Loss: 0.5147
2024-03-28 23:02:50,420 - config - INFO - Validation Loss: 0.4770
2024-03-28 23:02:50,420 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:50,463 - config - INFO - Epoch [25/600], Train Loss: 0.5077
2024-03-28 23:02:50,468 - config - INFO - Validation Loss: 0.4687
2024-03-28 23:02:50,468 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:50,511 - config - INFO - Epoch [26/600], Train Loss: 0.5015
2024-03-28 23:02:50,516 - config - INFO - Validation Loss: 0.4607
2024-03-28 23:02:50,516 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:50,558 - config - INFO - Epoch [27/600], Train Loss: 0.4960
2024-03-28 23:02:50,564 - config - INFO - Validation Loss: 0.4532
2024-03-28 23:02:50,564 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:50,606 - config - INFO - Epoch [28/600], Train Loss: 0.4907
2024-03-28 23:02:50,611 - config - INFO - Validation Loss: 0.4462
2024-03-28 23:02:50,611 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:50,661 - config - INFO - Epoch [29/600], Train Loss: 0.4858
2024-03-28 23:02:50,666 - config - INFO - Validation Loss: 0.4402
2024-03-28 23:02:50,667 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:50,709 - config - INFO - Epoch [30/600], Train Loss: 0.4817
2024-03-28 23:02:50,714 - config - INFO - Validation Loss: 0.4349
2024-03-28 23:02:50,714 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:50,756 - config - INFO - Epoch [31/600], Train Loss: 0.4776
2024-03-28 23:02:50,761 - config - INFO - Validation Loss: 0.4301
2024-03-28 23:02:50,762 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:50,804 - config - INFO - Epoch [32/600], Train Loss: 0.4741
2024-03-28 23:02:50,809 - config - INFO - Validation Loss: 0.4251
2024-03-28 23:02:50,809 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:50,851 - config - INFO - Epoch [33/600], Train Loss: 0.4710
2024-03-28 23:02:50,856 - config - INFO - Validation Loss: 0.4215
2024-03-28 23:02:50,857 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:50,899 - config - INFO - Epoch [34/600], Train Loss: 0.4680
2024-03-28 23:02:50,904 - config - INFO - Validation Loss: 0.4170
2024-03-28 23:02:50,904 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:50,946 - config - INFO - Epoch [35/600], Train Loss: 0.4650
2024-03-28 23:02:50,951 - config - INFO - Validation Loss: 0.4136
2024-03-28 23:02:50,951 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:50,994 - config - INFO - Epoch [36/600], Train Loss: 0.4626
2024-03-28 23:02:50,999 - config - INFO - Validation Loss: 0.4102
2024-03-28 23:02:50,999 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:51,041 - config - INFO - Epoch [37/600], Train Loss: 0.4602
2024-03-28 23:02:51,046 - config - INFO - Validation Loss: 0.4065
2024-03-28 23:02:51,046 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:51,088 - config - INFO - Epoch [38/600], Train Loss: 0.4580
2024-03-28 23:02:51,094 - config - INFO - Validation Loss: 0.4032
2024-03-28 23:02:51,094 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:51,136 - config - INFO - Epoch [39/600], Train Loss: 0.4559
2024-03-28 23:02:51,157 - config - INFO - Validation Loss: 0.4015
2024-03-28 23:02:51,157 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:51,200 - config - INFO - Epoch [40/600], Train Loss: 0.4544
2024-03-28 23:02:51,205 - config - INFO - Validation Loss: 0.3989
2024-03-28 23:02:51,205 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:51,247 - config - INFO - Epoch [41/600], Train Loss: 0.4525
2024-03-28 23:02:51,252 - config - INFO - Validation Loss: 0.3962
2024-03-28 23:02:51,252 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:51,294 - config - INFO - Epoch [42/600], Train Loss: 0.4508
2024-03-28 23:02:51,299 - config - INFO - Validation Loss: 0.3945
2024-03-28 23:02:51,299 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:51,340 - config - INFO - Epoch [43/600], Train Loss: 0.4494
2024-03-28 23:02:51,345 - config - INFO - Validation Loss: 0.3922
2024-03-28 23:02:51,346 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:51,387 - config - INFO - Epoch [44/600], Train Loss: 0.4480
2024-03-28 23:02:51,392 - config - INFO - Validation Loss: 0.3907
2024-03-28 23:02:51,393 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:51,434 - config - INFO - Epoch [45/600], Train Loss: 0.4466
2024-03-28 23:02:51,439 - config - INFO - Validation Loss: 0.3884
2024-03-28 23:02:51,439 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:51,481 - config - INFO - Epoch [46/600], Train Loss: 0.4454
2024-03-28 23:02:51,486 - config - INFO - Validation Loss: 0.3874
2024-03-28 23:02:51,486 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:51,528 - config - INFO - Epoch [47/600], Train Loss: 0.4442
2024-03-28 23:02:51,533 - config - INFO - Validation Loss: 0.3859
2024-03-28 23:02:51,533 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:51,575 - config - INFO - Epoch [48/600], Train Loss: 0.4431
2024-03-28 23:02:51,580 - config - INFO - Validation Loss: 0.3848
2024-03-28 23:02:51,580 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:51,621 - config - INFO - Epoch [49/600], Train Loss: 0.4419
2024-03-28 23:02:51,626 - config - INFO - Validation Loss: 0.3837
2024-03-28 23:02:51,626 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:51,668 - config - INFO - Epoch [50/600], Train Loss: 0.4409
2024-03-28 23:02:51,673 - config - INFO - Validation Loss: 0.3826
2024-03-28 23:02:51,673 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:51,715 - config - INFO - Epoch [51/600], Train Loss: 0.4400
2024-03-28 23:02:51,720 - config - INFO - Validation Loss: 0.3817
2024-03-28 23:02:51,720 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:51,762 - config - INFO - Epoch [52/600], Train Loss: 0.4390
2024-03-28 23:02:51,767 - config - INFO - Validation Loss: 0.3811
2024-03-28 23:02:51,767 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:51,809 - config - INFO - Epoch [53/600], Train Loss: 0.4382
2024-03-28 23:02:51,814 - config - INFO - Validation Loss: 0.3797
2024-03-28 23:02:51,814 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:51,856 - config - INFO - Epoch [54/600], Train Loss: 0.4373
2024-03-28 23:02:51,861 - config - INFO - Validation Loss: 0.3786
2024-03-28 23:02:51,861 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:51,916 - config - INFO - Epoch [55/600], Train Loss: 0.4366
2024-03-28 23:02:51,921 - config - INFO - Validation Loss: 0.3776
2024-03-28 23:02:51,921 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:51,963 - config - INFO - Epoch [56/600], Train Loss: 0.4358
2024-03-28 23:02:51,968 - config - INFO - Validation Loss: 0.3772
2024-03-28 23:02:51,968 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:52,010 - config - INFO - Epoch [57/600], Train Loss: 0.4350
2024-03-28 23:02:52,015 - config - INFO - Validation Loss: 0.3765
2024-03-28 23:02:52,015 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:52,056 - config - INFO - Epoch [58/600], Train Loss: 0.4344
2024-03-28 23:02:52,061 - config - INFO - Validation Loss: 0.3760
2024-03-28 23:02:52,062 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:52,103 - config - INFO - Epoch [59/600], Train Loss: 0.4337
2024-03-28 23:02:52,108 - config - INFO - Validation Loss: 0.3753
2024-03-28 23:02:52,108 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:52,154 - config - INFO - Epoch [60/600], Train Loss: 0.4331
2024-03-28 23:02:52,159 - config - INFO - Validation Loss: 0.3749
2024-03-28 23:02:52,159 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:52,202 - config - INFO - Epoch [61/600], Train Loss: 0.4324
2024-03-28 23:02:52,207 - config - INFO - Validation Loss: 0.3743
2024-03-28 23:02:52,207 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:52,249 - config - INFO - Epoch [62/600], Train Loss: 0.4319
2024-03-28 23:02:52,254 - config - INFO - Validation Loss: 0.3744
2024-03-28 23:02:52,254 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:52,296 - config - INFO - Epoch [63/600], Train Loss: 0.4315
2024-03-28 23:02:52,301 - config - INFO - Validation Loss: 0.3728
2024-03-28 23:02:52,302 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:52,348 - config - INFO - Epoch [64/600], Train Loss: 0.4305
2024-03-28 23:02:52,353 - config - INFO - Validation Loss: 0.3724
2024-03-28 23:02:52,353 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:52,395 - config - INFO - Epoch [65/600], Train Loss: 0.4301
2024-03-28 23:02:52,400 - config - INFO - Validation Loss: 0.3719
2024-03-28 23:02:52,400 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:52,442 - config - INFO - Epoch [66/600], Train Loss: 0.4295
2024-03-28 23:02:52,447 - config - INFO - Validation Loss: 0.3720
2024-03-28 23:02:52,447 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:52,489 - config - INFO - Epoch [67/600], Train Loss: 0.4290
2024-03-28 23:02:52,494 - config - INFO - Validation Loss: 0.3716
2024-03-28 23:02:52,494 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:52,536 - config - INFO - Epoch [68/600], Train Loss: 0.4288
2024-03-28 23:02:52,541 - config - INFO - Validation Loss: 0.3701
2024-03-28 23:02:52,541 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:52,583 - config - INFO - Epoch [69/600], Train Loss: 0.4279
2024-03-28 23:02:52,588 - config - INFO - Validation Loss: 0.3700
2024-03-28 23:02:52,588 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:52,630 - config - INFO - Epoch [70/600], Train Loss: 0.4279
2024-03-28 23:02:52,635 - config - INFO - Validation Loss: 0.3699
2024-03-28 23:02:52,635 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:52,677 - config - INFO - Epoch [71/600], Train Loss: 0.4271
2024-03-28 23:02:52,682 - config - INFO - Validation Loss: 0.3697
2024-03-28 23:02:52,682 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:52,724 - config - INFO - Epoch [72/600], Train Loss: 0.4268
2024-03-28 23:02:52,729 - config - INFO - Validation Loss: 0.3695
2024-03-28 23:02:52,730 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:52,771 - config - INFO - Epoch [73/600], Train Loss: 0.4263
2024-03-28 23:02:52,776 - config - INFO - Validation Loss: 0.3692
2024-03-28 23:02:52,777 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:52,818 - config - INFO - Epoch [74/600], Train Loss: 0.4256
2024-03-28 23:02:52,823 - config - INFO - Validation Loss: 0.3685
2024-03-28 23:02:52,824 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:52,865 - config - INFO - Epoch [75/600], Train Loss: 0.4252
2024-03-28 23:02:52,870 - config - INFO - Validation Loss: 0.3684
2024-03-28 23:02:52,871 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:52,913 - config - INFO - Epoch [76/600], Train Loss: 0.4247
2024-03-28 23:02:52,918 - config - INFO - Validation Loss: 0.3676
2024-03-28 23:02:52,918 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:52,960 - config - INFO - Epoch [77/600], Train Loss: 0.4245
2024-03-28 23:02:52,965 - config - INFO - Validation Loss: 0.3677
2024-03-28 23:02:52,965 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:53,007 - config - INFO - Epoch [78/600], Train Loss: 0.4239
2024-03-28 23:02:53,012 - config - INFO - Validation Loss: 0.3672
2024-03-28 23:02:53,012 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:53,053 - config - INFO - Epoch [79/600], Train Loss: 0.4234
2024-03-28 23:02:53,058 - config - INFO - Validation Loss: 0.3673
2024-03-28 23:02:53,059 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:53,100 - config - INFO - Epoch [80/600], Train Loss: 0.4231
2024-03-28 23:02:53,106 - config - INFO - Validation Loss: 0.3673
2024-03-28 23:02:53,106 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:53,148 - config - INFO - Epoch [81/600], Train Loss: 0.4227
2024-03-28 23:02:53,153 - config - INFO - Validation Loss: 0.3669
2024-03-28 23:02:53,153 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:53,198 - config - INFO - Epoch [82/600], Train Loss: 0.4224
2024-03-28 23:02:53,203 - config - INFO - Validation Loss: 0.3667
2024-03-28 23:02:53,203 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:53,245 - config - INFO - Epoch [83/600], Train Loss: 0.4221
2024-03-28 23:02:53,250 - config - INFO - Validation Loss: 0.3665
2024-03-28 23:02:53,250 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:53,292 - config - INFO - Epoch [84/600], Train Loss: 0.4216
2024-03-28 23:02:53,297 - config - INFO - Validation Loss: 0.3662
2024-03-28 23:02:53,297 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:53,339 - config - INFO - Epoch [85/600], Train Loss: 0.4212
2024-03-28 23:02:53,344 - config - INFO - Validation Loss: 0.3657
2024-03-28 23:02:53,344 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:53,386 - config - INFO - Epoch [86/600], Train Loss: 0.4210
2024-03-28 23:02:53,391 - config - INFO - Validation Loss: 0.3657
2024-03-28 23:02:53,391 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:53,433 - config - INFO - Epoch [87/600], Train Loss: 0.4205
2024-03-28 23:02:53,438 - config - INFO - Validation Loss: 0.3652
2024-03-28 23:02:53,438 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:53,480 - config - INFO - Epoch [88/600], Train Loss: 0.4202
2024-03-28 23:02:53,485 - config - INFO - Validation Loss: 0.3644
2024-03-28 23:02:53,485 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:53,527 - config - INFO - Epoch [89/600], Train Loss: 0.4199
2024-03-28 23:02:53,532 - config - INFO - Validation Loss: 0.3643
2024-03-28 23:02:53,532 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:53,573 - config - INFO - Epoch [90/600], Train Loss: 0.4194
2024-03-28 23:02:53,578 - config - INFO - Validation Loss: 0.3642
2024-03-28 23:02:53,579 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:53,620 - config - INFO - Epoch [91/600], Train Loss: 0.4193
2024-03-28 23:02:53,625 - config - INFO - Validation Loss: 0.3643
2024-03-28 23:02:53,626 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:53,667 - config - INFO - Epoch [92/600], Train Loss: 0.4190
2024-03-28 23:02:53,672 - config - INFO - Validation Loss: 0.3641
2024-03-28 23:02:53,673 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:53,715 - config - INFO - Epoch [93/600], Train Loss: 0.4188
2024-03-28 23:02:53,720 - config - INFO - Validation Loss: 0.3645
2024-03-28 23:02:53,720 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:53,762 - config - INFO - Epoch [94/600], Train Loss: 0.4183
2024-03-28 23:02:53,767 - config - INFO - Validation Loss: 0.3637
2024-03-28 23:02:53,767 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:53,809 - config - INFO - Epoch [95/600], Train Loss: 0.4179
2024-03-28 23:02:53,814 - config - INFO - Validation Loss: 0.3637
2024-03-28 23:02:53,814 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:53,856 - config - INFO - Epoch [96/600], Train Loss: 0.4177
2024-03-28 23:02:53,861 - config - INFO - Validation Loss: 0.3633
2024-03-28 23:02:53,861 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:53,903 - config - INFO - Epoch [97/600], Train Loss: 0.4174
2024-03-28 23:02:53,908 - config - INFO - Validation Loss: 0.3630
2024-03-28 23:02:53,908 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:53,950 - config - INFO - Epoch [98/600], Train Loss: 0.4171
2024-03-28 23:02:53,955 - config - INFO - Validation Loss: 0.3637
2024-03-28 23:02:53,955 - config - INFO - Validation Acc: 0.9444
2024-03-28 23:02:53,997 - config - INFO - Epoch [99/600], Train Loss: 0.4167
2024-03-28 23:02:54,002 - config - INFO - Validation Loss: 0.3640
2024-03-28 23:02:54,002 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:54,044 - config - INFO - Epoch [100/600], Train Loss: 0.4164
2024-03-28 23:02:54,049 - config - INFO - Validation Loss: 0.3636
2024-03-28 23:02:54,049 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:54,091 - config - INFO - Epoch [101/600], Train Loss: 0.4162
2024-03-28 23:02:54,096 - config - INFO - Validation Loss: 0.3631
2024-03-28 23:02:54,096 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:54,138 - config - INFO - Epoch [102/600], Train Loss: 0.4158
2024-03-28 23:02:54,143 - config - INFO - Validation Loss: 0.3630
2024-03-28 23:02:54,143 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:54,192 - config - INFO - Epoch [103/600], Train Loss: 0.4157
2024-03-28 23:02:54,197 - config - INFO - Validation Loss: 0.3626
2024-03-28 23:02:54,198 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:54,239 - config - INFO - Epoch [104/600], Train Loss: 0.4153
2024-03-28 23:02:54,244 - config - INFO - Validation Loss: 0.3625
2024-03-28 23:02:54,245 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:54,286 - config - INFO - Epoch [105/600], Train Loss: 0.4151
2024-03-28 23:02:54,291 - config - INFO - Validation Loss: 0.3623
2024-03-28 23:02:54,291 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:54,333 - config - INFO - Epoch [106/600], Train Loss: 0.4148
2024-03-28 23:02:54,338 - config - INFO - Validation Loss: 0.3622
2024-03-28 23:02:54,338 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:54,380 - config - INFO - Epoch [107/600], Train Loss: 0.4145
2024-03-28 23:02:54,385 - config - INFO - Validation Loss: 0.3618
2024-03-28 23:02:54,385 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:54,427 - config - INFO - Epoch [108/600], Train Loss: 0.4144
2024-03-28 23:02:54,432 - config - INFO - Validation Loss: 0.3619
2024-03-28 23:02:54,432 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:54,474 - config - INFO - Epoch [109/600], Train Loss: 0.4142
2024-03-28 23:02:54,479 - config - INFO - Validation Loss: 0.3615
2024-03-28 23:02:54,479 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:54,521 - config - INFO - Epoch [110/600], Train Loss: 0.4139
2024-03-28 23:02:54,526 - config - INFO - Validation Loss: 0.3618
2024-03-28 23:02:54,526 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:54,568 - config - INFO - Epoch [111/600], Train Loss: 0.4137
2024-03-28 23:02:54,573 - config - INFO - Validation Loss: 0.3619
2024-03-28 23:02:54,573 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:54,615 - config - INFO - Epoch [112/600], Train Loss: 0.4135
2024-03-28 23:02:54,620 - config - INFO - Validation Loss: 0.3621
2024-03-28 23:02:54,620 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:54,662 - config - INFO - Epoch [113/600], Train Loss: 0.4134
2024-03-28 23:02:54,667 - config - INFO - Validation Loss: 0.3615
2024-03-28 23:02:54,667 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:54,709 - config - INFO - Epoch [114/600], Train Loss: 0.4130
2024-03-28 23:02:54,714 - config - INFO - Validation Loss: 0.3614
2024-03-28 23:02:54,714 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:54,756 - config - INFO - Epoch [115/600], Train Loss: 0.4127
2024-03-28 23:02:54,761 - config - INFO - Validation Loss: 0.3614
2024-03-28 23:02:54,761 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:54,803 - config - INFO - Epoch [116/600], Train Loss: 0.4125
2024-03-28 23:02:54,808 - config - INFO - Validation Loss: 0.3611
2024-03-28 23:02:54,808 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:54,849 - config - INFO - Epoch [117/600], Train Loss: 0.4123
2024-03-28 23:02:54,854 - config - INFO - Validation Loss: 0.3604
2024-03-28 23:02:54,855 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:54,896 - config - INFO - Epoch [118/600], Train Loss: 0.4121
2024-03-28 23:02:54,901 - config - INFO - Validation Loss: 0.3604
2024-03-28 23:02:54,902 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:54,943 - config - INFO - Epoch [119/600], Train Loss: 0.4118
2024-03-28 23:02:54,948 - config - INFO - Validation Loss: 0.3607
2024-03-28 23:02:54,948 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:54,990 - config - INFO - Epoch [120/600], Train Loss: 0.4116
2024-03-28 23:02:54,995 - config - INFO - Validation Loss: 0.3601
2024-03-28 23:02:54,995 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:55,037 - config - INFO - Epoch [121/600], Train Loss: 0.4114
2024-03-28 23:02:55,042 - config - INFO - Validation Loss: 0.3605
2024-03-28 23:02:55,042 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:55,084 - config - INFO - Epoch [122/600], Train Loss: 0.4111
2024-03-28 23:02:55,089 - config - INFO - Validation Loss: 0.3605
2024-03-28 23:02:55,089 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:55,131 - config - INFO - Epoch [123/600], Train Loss: 0.4110
2024-03-28 23:02:55,136 - config - INFO - Validation Loss: 0.3609
2024-03-28 23:02:55,136 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:55,178 - config - INFO - Epoch [124/600], Train Loss: 0.4108
2024-03-28 23:02:55,183 - config - INFO - Validation Loss: 0.3612
2024-03-28 23:02:55,183 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:55,225 - config - INFO - Epoch [125/600], Train Loss: 0.4105
2024-03-28 23:02:55,230 - config - INFO - Validation Loss: 0.3615
2024-03-28 23:02:55,230 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:55,272 - config - INFO - Epoch [126/600], Train Loss: 0.4103
2024-03-28 23:02:55,277 - config - INFO - Validation Loss: 0.3610
2024-03-28 23:02:55,277 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:55,319 - config - INFO - Epoch [127/600], Train Loss: 0.4101
2024-03-28 23:02:55,324 - config - INFO - Validation Loss: 0.3612
2024-03-28 23:02:55,324 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:55,366 - config - INFO - Epoch [128/600], Train Loss: 0.4099
2024-03-28 23:02:55,371 - config - INFO - Validation Loss: 0.3616
2024-03-28 23:02:55,371 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:55,412 - config - INFO - Epoch [129/600], Train Loss: 0.4097
2024-03-28 23:02:55,417 - config - INFO - Validation Loss: 0.3610
2024-03-28 23:02:55,418 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:55,459 - config - INFO - Epoch [130/600], Train Loss: 0.4097
2024-03-28 23:02:55,464 - config - INFO - Validation Loss: 0.3616
2024-03-28 23:02:55,464 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:55,506 - config - INFO - Epoch [131/600], Train Loss: 0.4092
2024-03-28 23:02:55,511 - config - INFO - Validation Loss: 0.3616
2024-03-28 23:02:55,511 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:55,554 - config - INFO - Epoch [132/600], Train Loss: 0.4090
2024-03-28 23:02:55,559 - config - INFO - Validation Loss: 0.3616
2024-03-28 23:02:55,560 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:55,601 - config - INFO - Epoch [133/600], Train Loss: 0.4088
2024-03-28 23:02:55,606 - config - INFO - Validation Loss: 0.3611
2024-03-28 23:02:55,607 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:55,648 - config - INFO - Epoch [134/600], Train Loss: 0.4085
2024-03-28 23:02:55,653 - config - INFO - Validation Loss: 0.3616
2024-03-28 23:02:55,653 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:55,695 - config - INFO - Epoch [135/600], Train Loss: 0.4085
2024-03-28 23:02:55,700 - config - INFO - Validation Loss: 0.3617
2024-03-28 23:02:55,701 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:55,743 - config - INFO - Epoch [136/600], Train Loss: 0.4082
2024-03-28 23:02:55,748 - config - INFO - Validation Loss: 0.3608
2024-03-28 23:02:55,748 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:55,790 - config - INFO - Epoch [137/600], Train Loss: 0.4081
2024-03-28 23:02:55,795 - config - INFO - Validation Loss: 0.3607
2024-03-28 23:02:55,795 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:55,836 - config - INFO - Epoch [138/600], Train Loss: 0.4079
2024-03-28 23:02:55,841 - config - INFO - Validation Loss: 0.3609
2024-03-28 23:02:55,842 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:55,883 - config - INFO - Epoch [139/600], Train Loss: 0.4077
2024-03-28 23:02:55,888 - config - INFO - Validation Loss: 0.3608
2024-03-28 23:02:55,889 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:55,931 - config - INFO - Epoch [140/600], Train Loss: 0.4075
2024-03-28 23:02:55,936 - config - INFO - Validation Loss: 0.3603
2024-03-28 23:02:55,936 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:55,977 - config - INFO - Epoch [141/600], Train Loss: 0.4073
2024-03-28 23:02:55,982 - config - INFO - Validation Loss: 0.3612
2024-03-28 23:02:55,983 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:56,024 - config - INFO - Epoch [142/600], Train Loss: 0.4070
2024-03-28 23:02:56,029 - config - INFO - Validation Loss: 0.3612
2024-03-28 23:02:56,030 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:56,071 - config - INFO - Epoch [143/600], Train Loss: 0.4070
2024-03-28 23:02:56,076 - config - INFO - Validation Loss: 0.3611
2024-03-28 23:02:56,077 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:56,119 - config - INFO - Epoch [144/600], Train Loss: 0.4066
2024-03-28 23:02:56,124 - config - INFO - Validation Loss: 0.3610
2024-03-28 23:02:56,124 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:56,166 - config - INFO - Epoch [145/600], Train Loss: 0.4064
2024-03-28 23:02:56,171 - config - INFO - Validation Loss: 0.3611
2024-03-28 23:02:56,171 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:56,213 - config - INFO - Epoch [146/600], Train Loss: 0.4065
2024-03-28 23:02:56,218 - config - INFO - Validation Loss: 0.3604
2024-03-28 23:02:56,218 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:56,260 - config - INFO - Epoch [147/600], Train Loss: 0.4063
2024-03-28 23:02:56,265 - config - INFO - Validation Loss: 0.3604
2024-03-28 23:02:56,265 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:56,310 - config - INFO - Epoch [148/600], Train Loss: 0.4059
2024-03-28 23:02:56,315 - config - INFO - Validation Loss: 0.3599
2024-03-28 23:02:56,315 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:56,357 - config - INFO - Epoch [149/600], Train Loss: 0.4059
2024-03-28 23:02:56,362 - config - INFO - Validation Loss: 0.3600
2024-03-28 23:02:56,363 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:56,404 - config - INFO - Epoch [150/600], Train Loss: 0.4057
2024-03-28 23:02:56,410 - config - INFO - Validation Loss: 0.3604
2024-03-28 23:02:56,410 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:56,452 - config - INFO - Epoch [151/600], Train Loss: 0.4055
2024-03-28 23:02:56,457 - config - INFO - Validation Loss: 0.3604
2024-03-28 23:02:56,457 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:56,499 - config - INFO - Epoch [152/600], Train Loss: 0.4053
2024-03-28 23:02:56,504 - config - INFO - Validation Loss: 0.3600
2024-03-28 23:02:56,504 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:56,546 - config - INFO - Epoch [153/600], Train Loss: 0.4051
2024-03-28 23:02:56,551 - config - INFO - Validation Loss: 0.3599
2024-03-28 23:02:56,551 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:56,593 - config - INFO - Epoch [154/600], Train Loss: 0.4052
2024-03-28 23:02:56,598 - config - INFO - Validation Loss: 0.3603
2024-03-28 23:02:56,598 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:56,640 - config - INFO - Epoch [155/600], Train Loss: 0.4047
2024-03-28 23:02:56,645 - config - INFO - Validation Loss: 0.3600
2024-03-28 23:02:56,645 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:56,688 - config - INFO - Epoch [156/600], Train Loss: 0.4044
2024-03-28 23:02:56,693 - config - INFO - Validation Loss: 0.3598
2024-03-28 23:02:56,693 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:56,735 - config - INFO - Epoch [157/600], Train Loss: 0.4045
2024-03-28 23:02:56,740 - config - INFO - Validation Loss: 0.3602
2024-03-28 23:02:56,740 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:56,782 - config - INFO - Epoch [158/600], Train Loss: 0.4043
2024-03-28 23:02:56,787 - config - INFO - Validation Loss: 0.3599
2024-03-28 23:02:56,787 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:56,829 - config - INFO - Epoch [159/600], Train Loss: 0.4042
2024-03-28 23:02:56,834 - config - INFO - Validation Loss: 0.3602
2024-03-28 23:02:56,834 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:56,876 - config - INFO - Epoch [160/600], Train Loss: 0.4039
2024-03-28 23:02:56,881 - config - INFO - Validation Loss: 0.3599
2024-03-28 23:02:56,886 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:56,932 - config - INFO - Epoch [161/600], Train Loss: 0.4038
2024-03-28 23:02:56,937 - config - INFO - Validation Loss: 0.3598
2024-03-28 23:02:56,937 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:56,979 - config - INFO - Epoch [162/600], Train Loss: 0.4039
2024-03-28 23:02:56,984 - config - INFO - Validation Loss: 0.3602
2024-03-28 23:02:56,984 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:57,026 - config - INFO - Epoch [163/600], Train Loss: 0.4035
2024-03-28 23:02:57,031 - config - INFO - Validation Loss: 0.3599
2024-03-28 23:02:57,031 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:57,073 - config - INFO - Epoch [164/600], Train Loss: 0.4033
2024-03-28 23:02:57,078 - config - INFO - Validation Loss: 0.3604
2024-03-28 23:02:57,078 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:57,120 - config - INFO - Epoch [165/600], Train Loss: 0.4032
2024-03-28 23:02:57,125 - config - INFO - Validation Loss: 0.3599
2024-03-28 23:02:57,125 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:57,167 - config - INFO - Epoch [166/600], Train Loss: 0.4031
2024-03-28 23:02:57,172 - config - INFO - Validation Loss: 0.3597
2024-03-28 23:02:57,172 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:57,214 - config - INFO - Epoch [167/600], Train Loss: 0.4029
2024-03-28 23:02:57,219 - config - INFO - Validation Loss: 0.3596
2024-03-28 23:02:57,219 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:57,261 - config - INFO - Epoch [168/600], Train Loss: 0.4028
2024-03-28 23:02:57,266 - config - INFO - Validation Loss: 0.3599
2024-03-28 23:02:57,266 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:57,309 - config - INFO - Epoch [169/600], Train Loss: 0.4026
2024-03-28 23:02:57,314 - config - INFO - Validation Loss: 0.3596
2024-03-28 23:02:57,314 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:57,356 - config - INFO - Epoch [170/600], Train Loss: 0.4026
2024-03-28 23:02:57,361 - config - INFO - Validation Loss: 0.3603
2024-03-28 23:02:57,361 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:57,403 - config - INFO - Epoch [171/600], Train Loss: 0.4024
2024-03-28 23:02:57,408 - config - INFO - Validation Loss: 0.3596
2024-03-28 23:02:57,408 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:57,450 - config - INFO - Epoch [172/600], Train Loss: 0.4026
2024-03-28 23:02:57,455 - config - INFO - Validation Loss: 0.3603
2024-03-28 23:02:57,455 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:57,497 - config - INFO - Epoch [173/600], Train Loss: 0.4021
2024-03-28 23:02:57,502 - config - INFO - Validation Loss: 0.3600
2024-03-28 23:02:57,502 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:57,544 - config - INFO - Epoch [174/600], Train Loss: 0.4019
2024-03-28 23:02:57,549 - config - INFO - Validation Loss: 0.3596
2024-03-28 23:02:57,549 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:57,591 - config - INFO - Epoch [175/600], Train Loss: 0.4016
2024-03-28 23:02:57,596 - config - INFO - Validation Loss: 0.3596
2024-03-28 23:02:57,596 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:57,638 - config - INFO - Epoch [176/600], Train Loss: 0.4018
2024-03-28 23:02:57,643 - config - INFO - Validation Loss: 0.3597
2024-03-28 23:02:57,643 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:57,685 - config - INFO - Epoch [177/600], Train Loss: 0.4013
2024-03-28 23:02:57,691 - config - INFO - Validation Loss: 0.3593
2024-03-28 23:02:57,691 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:57,733 - config - INFO - Epoch [178/600], Train Loss: 0.4013
2024-03-28 23:02:57,738 - config - INFO - Validation Loss: 0.3593
2024-03-28 23:02:57,738 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:57,780 - config - INFO - Epoch [179/600], Train Loss: 0.4012
2024-03-28 23:02:57,785 - config - INFO - Validation Loss: 0.3597
2024-03-28 23:02:57,785 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:57,827 - config - INFO - Epoch [180/600], Train Loss: 0.4010
2024-03-28 23:02:57,832 - config - INFO - Validation Loss: 0.3597
2024-03-28 23:02:57,832 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:57,874 - config - INFO - Epoch [181/600], Train Loss: 0.4009
2024-03-28 23:02:57,879 - config - INFO - Validation Loss: 0.3596
2024-03-28 23:02:57,880 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:57,922 - config - INFO - Epoch [182/600], Train Loss: 0.4007
2024-03-28 23:02:57,927 - config - INFO - Validation Loss: 0.3597
2024-03-28 23:02:57,927 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:57,969 - config - INFO - Epoch [183/600], Train Loss: 0.4005
2024-03-28 23:02:57,974 - config - INFO - Validation Loss: 0.3593
2024-03-28 23:02:57,974 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:58,016 - config - INFO - Epoch [184/600], Train Loss: 0.4004
2024-03-28 23:02:58,021 - config - INFO - Validation Loss: 0.3598
2024-03-28 23:02:58,021 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:58,063 - config - INFO - Epoch [185/600], Train Loss: 0.4004
2024-03-28 23:02:58,068 - config - INFO - Validation Loss: 0.3606
2024-03-28 23:02:58,068 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:58,110 - config - INFO - Epoch [186/600], Train Loss: 0.4001
2024-03-28 23:02:58,115 - config - INFO - Validation Loss: 0.3598
2024-03-28 23:02:58,115 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:58,157 - config - INFO - Epoch [187/600], Train Loss: 0.4001
2024-03-28 23:02:58,163 - config - INFO - Validation Loss: 0.3602
2024-03-28 23:02:58,163 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:58,205 - config - INFO - Epoch [188/600], Train Loss: 0.4000
2024-03-28 23:02:58,210 - config - INFO - Validation Loss: 0.3605
2024-03-28 23:02:58,210 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:58,252 - config - INFO - Epoch [189/600], Train Loss: 0.4000
2024-03-28 23:02:58,257 - config - INFO - Validation Loss: 0.3599
2024-03-28 23:02:58,257 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:58,299 - config - INFO - Epoch [190/600], Train Loss: 0.3997
2024-03-28 23:02:58,304 - config - INFO - Validation Loss: 0.3602
2024-03-28 23:02:58,304 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:58,349 - config - INFO - Epoch [191/600], Train Loss: 0.3996
2024-03-28 23:02:58,354 - config - INFO - Validation Loss: 0.3598
2024-03-28 23:02:58,354 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:58,396 - config - INFO - Epoch [192/600], Train Loss: 0.3993
2024-03-28 23:02:58,401 - config - INFO - Validation Loss: 0.3604
2024-03-28 23:02:58,401 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:58,443 - config - INFO - Epoch [193/600], Train Loss: 0.3994
2024-03-28 23:02:58,448 - config - INFO - Validation Loss: 0.3612
2024-03-28 23:02:58,448 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:58,490 - config - INFO - Epoch [194/600], Train Loss: 0.3993
2024-03-28 23:02:58,495 - config - INFO - Validation Loss: 0.3614
2024-03-28 23:02:58,495 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:58,537 - config - INFO - Epoch [195/600], Train Loss: 0.3991
2024-03-28 23:02:58,542 - config - INFO - Validation Loss: 0.3610
2024-03-28 23:02:58,542 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:58,584 - config - INFO - Epoch [196/600], Train Loss: 0.3989
2024-03-28 23:02:58,589 - config - INFO - Validation Loss: 0.3613
2024-03-28 23:02:58,589 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:58,631 - config - INFO - Epoch [197/600], Train Loss: 0.3988
2024-03-28 23:02:58,636 - config - INFO - Validation Loss: 0.3610
2024-03-28 23:02:58,636 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:58,678 - config - INFO - Epoch [198/600], Train Loss: 0.3987
2024-03-28 23:02:58,683 - config - INFO - Validation Loss: 0.3601
2024-03-28 23:02:58,684 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:58,726 - config - INFO - Epoch [199/600], Train Loss: 0.3985
2024-03-28 23:02:58,731 - config - INFO - Validation Loss: 0.3605
2024-03-28 23:02:58,731 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:58,772 - config - INFO - Epoch [200/600], Train Loss: 0.3985
2024-03-28 23:02:58,777 - config - INFO - Validation Loss: 0.3610
2024-03-28 23:02:58,778 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:58,819 - config - INFO - Epoch [201/600], Train Loss: 0.3982
2024-03-28 23:02:58,824 - config - INFO - Validation Loss: 0.3605
2024-03-28 23:02:58,825 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:58,867 - config - INFO - Epoch [202/600], Train Loss: 0.3981
2024-03-28 23:02:58,872 - config - INFO - Validation Loss: 0.3602
2024-03-28 23:02:58,872 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:58,914 - config - INFO - Epoch [203/600], Train Loss: 0.3982
2024-03-28 23:02:58,919 - config - INFO - Validation Loss: 0.3610
2024-03-28 23:02:58,919 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:58,961 - config - INFO - Epoch [204/600], Train Loss: 0.3978
2024-03-28 23:02:58,966 - config - INFO - Validation Loss: 0.3606
2024-03-28 23:02:58,966 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:59,008 - config - INFO - Epoch [205/600], Train Loss: 0.3977
2024-03-28 23:02:59,013 - config - INFO - Validation Loss: 0.3599
2024-03-28 23:02:59,013 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:59,055 - config - INFO - Epoch [206/600], Train Loss: 0.3977
2024-03-28 23:02:59,060 - config - INFO - Validation Loss: 0.3604
2024-03-28 23:02:59,060 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:59,102 - config - INFO - Epoch [207/600], Train Loss: 0.3974
2024-03-28 23:02:59,107 - config - INFO - Validation Loss: 0.3601
2024-03-28 23:02:59,107 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:59,149 - config - INFO - Epoch [208/600], Train Loss: 0.3973
2024-03-28 23:02:59,154 - config - INFO - Validation Loss: 0.3601
2024-03-28 23:02:59,155 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:59,196 - config - INFO - Epoch [209/600], Train Loss: 0.3972
2024-03-28 23:02:59,202 - config - INFO - Validation Loss: 0.3600
2024-03-28 23:02:59,202 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:59,244 - config - INFO - Epoch [210/600], Train Loss: 0.3972
2024-03-28 23:02:59,249 - config - INFO - Validation Loss: 0.3604
2024-03-28 23:02:59,249 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:59,291 - config - INFO - Epoch [211/600], Train Loss: 0.3969
2024-03-28 23:02:59,296 - config - INFO - Validation Loss: 0.3599
2024-03-28 23:02:59,296 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:59,338 - config - INFO - Epoch [212/600], Train Loss: 0.3969
2024-03-28 23:02:59,343 - config - INFO - Validation Loss: 0.3598
2024-03-28 23:02:59,343 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:59,385 - config - INFO - Epoch [213/600], Train Loss: 0.3966
2024-03-28 23:02:59,390 - config - INFO - Validation Loss: 0.3594
2024-03-28 23:02:59,390 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:59,432 - config - INFO - Epoch [214/600], Train Loss: 0.3966
2024-03-28 23:02:59,437 - config - INFO - Validation Loss: 0.3593
2024-03-28 23:02:59,437 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:59,479 - config - INFO - Epoch [215/600], Train Loss: 0.3965
2024-03-28 23:02:59,484 - config - INFO - Validation Loss: 0.3593
2024-03-28 23:02:59,485 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:59,527 - config - INFO - Epoch [216/600], Train Loss: 0.3965
2024-03-28 23:02:59,532 - config - INFO - Validation Loss: 0.3594
2024-03-28 23:02:59,532 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:59,574 - config - INFO - Epoch [217/600], Train Loss: 0.3964
2024-03-28 23:02:59,579 - config - INFO - Validation Loss: 0.3597
2024-03-28 23:02:59,579 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:02:59,621 - config - INFO - Epoch [218/600], Train Loss: 0.3960
2024-03-28 23:02:59,626 - config - INFO - Validation Loss: 0.3598
2024-03-28 23:02:59,626 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:59,668 - config - INFO - Epoch [219/600], Train Loss: 0.3960
2024-03-28 23:02:59,673 - config - INFO - Validation Loss: 0.3602
2024-03-28 23:02:59,673 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:59,715 - config - INFO - Epoch [220/600], Train Loss: 0.3960
2024-03-28 23:02:59,720 - config - INFO - Validation Loss: 0.3600
2024-03-28 23:02:59,720 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:59,763 - config - INFO - Epoch [221/600], Train Loss: 0.3957
2024-03-28 23:02:59,768 - config - INFO - Validation Loss: 0.3601
2024-03-28 23:02:59,768 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:59,810 - config - INFO - Epoch [222/600], Train Loss: 0.3957
2024-03-28 23:02:59,815 - config - INFO - Validation Loss: 0.3603
2024-03-28 23:02:59,815 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:59,857 - config - INFO - Epoch [223/600], Train Loss: 0.3957
2024-03-28 23:02:59,862 - config - INFO - Validation Loss: 0.3596
2024-03-28 23:02:59,862 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:59,904 - config - INFO - Epoch [224/600], Train Loss: 0.3954
2024-03-28 23:02:59,909 - config - INFO - Validation Loss: 0.3595
2024-03-28 23:02:59,909 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:59,951 - config - INFO - Epoch [225/600], Train Loss: 0.3953
2024-03-28 23:02:59,956 - config - INFO - Validation Loss: 0.3595
2024-03-28 23:02:59,956 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:02:59,998 - config - INFO - Epoch [226/600], Train Loss: 0.3951
2024-03-28 23:03:00,003 - config - INFO - Validation Loss: 0.3590
2024-03-28 23:03:00,003 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:00,045 - config - INFO - Epoch [227/600], Train Loss: 0.3951
2024-03-28 23:03:00,051 - config - INFO - Validation Loss: 0.3596
2024-03-28 23:03:00,051 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:00,093 - config - INFO - Epoch [228/600], Train Loss: 0.3951
2024-03-28 23:03:00,098 - config - INFO - Validation Loss: 0.3589
2024-03-28 23:03:00,098 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:00,140 - config - INFO - Epoch [229/600], Train Loss: 0.3949
2024-03-28 23:03:00,145 - config - INFO - Validation Loss: 0.3594
2024-03-28 23:03:00,145 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:03:00,187 - config - INFO - Epoch [230/600], Train Loss: 0.3947
2024-03-28 23:03:00,192 - config - INFO - Validation Loss: 0.3593
2024-03-28 23:03:00,192 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:00,234 - config - INFO - Epoch [231/600], Train Loss: 0.3947
2024-03-28 23:03:00,239 - config - INFO - Validation Loss: 0.3597
2024-03-28 23:03:00,239 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:00,282 - config - INFO - Epoch [232/600], Train Loss: 0.3945
2024-03-28 23:03:00,287 - config - INFO - Validation Loss: 0.3591
2024-03-28 23:03:00,287 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:03:00,334 - config - INFO - Epoch [233/600], Train Loss: 0.3943
2024-03-28 23:03:00,339 - config - INFO - Validation Loss: 0.3593
2024-03-28 23:03:00,340 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:03:00,382 - config - INFO - Epoch [234/600], Train Loss: 0.3943
2024-03-28 23:03:00,387 - config - INFO - Validation Loss: 0.3592
2024-03-28 23:03:00,387 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:00,429 - config - INFO - Epoch [235/600], Train Loss: 0.3942
2024-03-28 23:03:00,434 - config - INFO - Validation Loss: 0.3591
2024-03-28 23:03:00,434 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:00,476 - config - INFO - Epoch [236/600], Train Loss: 0.3940
2024-03-28 23:03:00,481 - config - INFO - Validation Loss: 0.3592
2024-03-28 23:03:00,481 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:00,523 - config - INFO - Epoch [237/600], Train Loss: 0.3940
2024-03-28 23:03:00,528 - config - INFO - Validation Loss: 0.3593
2024-03-28 23:03:00,528 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:00,570 - config - INFO - Epoch [238/600], Train Loss: 0.3939
2024-03-28 23:03:00,575 - config - INFO - Validation Loss: 0.3594
2024-03-28 23:03:00,575 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:00,617 - config - INFO - Epoch [239/600], Train Loss: 0.3938
2024-03-28 23:03:00,622 - config - INFO - Validation Loss: 0.3597
2024-03-28 23:03:00,622 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:00,664 - config - INFO - Epoch [240/600], Train Loss: 0.3937
2024-03-28 23:03:00,669 - config - INFO - Validation Loss: 0.3596
2024-03-28 23:03:00,669 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:03:00,714 - config - INFO - Epoch [241/600], Train Loss: 0.3934
2024-03-28 23:03:00,719 - config - INFO - Validation Loss: 0.3589
2024-03-28 23:03:00,719 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:00,761 - config - INFO - Epoch [242/600], Train Loss: 0.3937
2024-03-28 23:03:00,766 - config - INFO - Validation Loss: 0.3592
2024-03-28 23:03:00,766 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:03:00,808 - config - INFO - Epoch [243/600], Train Loss: 0.3933
2024-03-28 23:03:00,813 - config - INFO - Validation Loss: 0.3595
2024-03-28 23:03:00,813 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:03:00,855 - config - INFO - Epoch [244/600], Train Loss: 0.3932
2024-03-28 23:03:00,860 - config - INFO - Validation Loss: 0.3596
2024-03-28 23:03:00,860 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:00,904 - config - INFO - Epoch [245/600], Train Loss: 0.3930
2024-03-28 23:03:00,909 - config - INFO - Validation Loss: 0.3596
2024-03-28 23:03:00,910 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:03:00,951 - config - INFO - Epoch [246/600], Train Loss: 0.3928
2024-03-28 23:03:00,956 - config - INFO - Validation Loss: 0.3604
2024-03-28 23:03:00,957 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:03:00,998 - config - INFO - Epoch [247/600], Train Loss: 0.3933
2024-03-28 23:03:01,003 - config - INFO - Validation Loss: 0.3611
2024-03-28 23:03:01,004 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:03:01,045 - config - INFO - Epoch [248/600], Train Loss: 0.3927
2024-03-28 23:03:01,050 - config - INFO - Validation Loss: 0.3604
2024-03-28 23:03:01,050 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:03:01,094 - config - INFO - Epoch [249/600], Train Loss: 0.3926
2024-03-28 23:03:01,100 - config - INFO - Validation Loss: 0.3606
2024-03-28 23:03:01,100 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:01,142 - config - INFO - Epoch [250/600], Train Loss: 0.3924
2024-03-28 23:03:01,147 - config - INFO - Validation Loss: 0.3605
2024-03-28 23:03:01,147 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:03:01,189 - config - INFO - Epoch [251/600], Train Loss: 0.3922
2024-03-28 23:03:01,194 - config - INFO - Validation Loss: 0.3603
2024-03-28 23:03:01,194 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:01,236 - config - INFO - Epoch [252/600], Train Loss: 0.3922
2024-03-28 23:03:01,241 - config - INFO - Validation Loss: 0.3602
2024-03-28 23:03:01,241 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:01,284 - config - INFO - Epoch [253/600], Train Loss: 0.3922
2024-03-28 23:03:01,290 - config - INFO - Validation Loss: 0.3603
2024-03-28 23:03:01,290 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:01,332 - config - INFO - Epoch [254/600], Train Loss: 0.3920
2024-03-28 23:03:01,337 - config - INFO - Validation Loss: 0.3608
2024-03-28 23:03:01,338 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:01,379 - config - INFO - Epoch [255/600], Train Loss: 0.3922
2024-03-28 23:03:01,384 - config - INFO - Validation Loss: 0.3610
2024-03-28 23:03:01,385 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:03:01,426 - config - INFO - Epoch [256/600], Train Loss: 0.3917
2024-03-28 23:03:01,431 - config - INFO - Validation Loss: 0.3603
2024-03-28 23:03:01,431 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:01,474 - config - INFO - Epoch [257/600], Train Loss: 0.3916
2024-03-28 23:03:01,479 - config - INFO - Validation Loss: 0.3607
2024-03-28 23:03:01,479 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:01,523 - config - INFO - Epoch [258/600], Train Loss: 0.3915
2024-03-28 23:03:01,528 - config - INFO - Validation Loss: 0.3604
2024-03-28 23:03:01,528 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:01,570 - config - INFO - Epoch [259/600], Train Loss: 0.3914
2024-03-28 23:03:01,575 - config - INFO - Validation Loss: 0.3605
2024-03-28 23:03:01,575 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:01,617 - config - INFO - Epoch [260/600], Train Loss: 0.3912
2024-03-28 23:03:01,622 - config - INFO - Validation Loss: 0.3611
2024-03-28 23:03:01,622 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:03:01,664 - config - INFO - Epoch [261/600], Train Loss: 0.3912
2024-03-28 23:03:01,669 - config - INFO - Validation Loss: 0.3613
2024-03-28 23:03:01,669 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:01,714 - config - INFO - Epoch [262/600], Train Loss: 0.3911
2024-03-28 23:03:01,719 - config - INFO - Validation Loss: 0.3608
2024-03-28 23:03:01,720 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:01,761 - config - INFO - Epoch [263/600], Train Loss: 0.3912
2024-03-28 23:03:01,766 - config - INFO - Validation Loss: 0.3603
2024-03-28 23:03:01,766 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:03:01,809 - config - INFO - Epoch [264/600], Train Loss: 0.3909
2024-03-28 23:03:01,814 - config - INFO - Validation Loss: 0.3608
2024-03-28 23:03:01,814 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:01,857 - config - INFO - Epoch [265/600], Train Loss: 0.3909
2024-03-28 23:03:01,862 - config - INFO - Validation Loss: 0.3601
2024-03-28 23:03:01,862 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:01,907 - config - INFO - Epoch [266/600], Train Loss: 0.3907
2024-03-28 23:03:01,912 - config - INFO - Validation Loss: 0.3602
2024-03-28 23:03:01,917 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:01,964 - config - INFO - Epoch [267/600], Train Loss: 0.3905
2024-03-28 23:03:01,969 - config - INFO - Validation Loss: 0.3595
2024-03-28 23:03:01,969 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:02,011 - config - INFO - Epoch [268/600], Train Loss: 0.3906
2024-03-28 23:03:02,016 - config - INFO - Validation Loss: 0.3597
2024-03-28 23:03:02,016 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:02,058 - config - INFO - Epoch [269/600], Train Loss: 0.3903
2024-03-28 23:03:02,063 - config - INFO - Validation Loss: 0.3597
2024-03-28 23:03:02,063 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:02,107 - config - INFO - Epoch [270/600], Train Loss: 0.3903
2024-03-28 23:03:02,113 - config - INFO - Validation Loss: 0.3597
2024-03-28 23:03:02,113 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:02,154 - config - INFO - Epoch [271/600], Train Loss: 0.3901
2024-03-28 23:03:02,160 - config - INFO - Validation Loss: 0.3599
2024-03-28 23:03:02,160 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:03:02,201 - config - INFO - Epoch [272/600], Train Loss: 0.3901
2024-03-28 23:03:02,206 - config - INFO - Validation Loss: 0.3605
2024-03-28 23:03:02,207 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:03:02,248 - config - INFO - Epoch [273/600], Train Loss: 0.3898
2024-03-28 23:03:02,253 - config - INFO - Validation Loss: 0.3602
2024-03-28 23:03:02,254 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:03:02,298 - config - INFO - Epoch [274/600], Train Loss: 0.3897
2024-03-28 23:03:02,303 - config - INFO - Validation Loss: 0.3604
2024-03-28 23:03:02,303 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:03:02,347 - config - INFO - Epoch [275/600], Train Loss: 0.3899
2024-03-28 23:03:02,352 - config - INFO - Validation Loss: 0.3596
2024-03-28 23:03:02,352 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:03:02,394 - config - INFO - Epoch [276/600], Train Loss: 0.3894
2024-03-28 23:03:02,399 - config - INFO - Validation Loss: 0.3600
2024-03-28 23:03:02,399 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:03:02,441 - config - INFO - Epoch [277/600], Train Loss: 0.3893
2024-03-28 23:03:02,446 - config - INFO - Validation Loss: 0.3604
2024-03-28 23:03:02,446 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:03:02,490 - config - INFO - Epoch [278/600], Train Loss: 0.3893
2024-03-28 23:03:02,495 - config - INFO - Validation Loss: 0.3603
2024-03-28 23:03:02,496 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:03:02,538 - config - INFO - Epoch [279/600], Train Loss: 0.3891
2024-03-28 23:03:02,543 - config - INFO - Validation Loss: 0.3606
2024-03-28 23:03:02,543 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:03:02,585 - config - INFO - Epoch [280/600], Train Loss: 0.3891
2024-03-28 23:03:02,590 - config - INFO - Validation Loss: 0.3611
2024-03-28 23:03:02,590 - config - INFO - Validation Acc: 0.8889
2024-03-28 23:03:02,632 - config - INFO - Epoch [281/600], Train Loss: 0.3890
2024-03-28 23:03:02,637 - config - INFO - Validation Loss: 0.3612
2024-03-28 23:03:02,637 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:02,680 - config - INFO - Epoch [282/600], Train Loss: 0.3891
2024-03-28 23:03:02,685 - config - INFO - Validation Loss: 0.3620
2024-03-28 23:03:02,686 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:03:02,686 - config - INFO - Validation loss increased. Early stopping.
2024-03-28 23:04:02,827 - config - INFO - resume: None
2024-03-28 23:04:02,827 - config - INFO - device: cpu
2024-03-28 23:04:02,827 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 23:04:02,827 - config - INFO - learning_rate: 0.0001
2024-03-28 23:04:02,827 - config - INFO - num_epochs: 260
2024-03-28 23:04:02,827 - config - INFO - batch_size: 32
2024-03-28 23:04:02,827 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.3

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 23:04:02,848 - config - INFO - Dataset size: 891
2024-03-28 23:04:02,875 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.95 * len(self.train_dataset))
        val_size = int(0.05 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 23:04:02,875 - config - INFO - Training start
2024-03-28 23:04:05,209 - config - INFO - Epoch [1/260], Train Loss: 0.6965
2024-03-28 23:04:05,211 - config - INFO - Validation Loss: 0.6870
2024-03-28 23:04:05,211 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:05,285 - config - INFO - Epoch [2/260], Train Loss: 0.6859
2024-03-28 23:04:05,287 - config - INFO - Validation Loss: 0.6746
2024-03-28 23:04:05,287 - config - INFO - Validation Acc: 0.5833
2024-03-28 23:04:05,355 - config - INFO - Epoch [3/260], Train Loss: 0.6754
2024-03-28 23:04:05,357 - config - INFO - Validation Loss: 0.6629
2024-03-28 23:04:05,357 - config - INFO - Validation Acc: 0.5833
2024-03-28 23:04:05,418 - config - INFO - Epoch [4/260], Train Loss: 0.6649
2024-03-28 23:04:05,420 - config - INFO - Validation Loss: 0.6515
2024-03-28 23:04:05,420 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:04:05,485 - config - INFO - Epoch [5/260], Train Loss: 0.6541
2024-03-28 23:04:05,487 - config - INFO - Validation Loss: 0.6395
2024-03-28 23:04:05,488 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:05,560 - config - INFO - Epoch [6/260], Train Loss: 0.6430
2024-03-28 23:04:05,562 - config - INFO - Validation Loss: 0.6274
2024-03-28 23:04:05,562 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:05,633 - config - INFO - Epoch [7/260], Train Loss: 0.6311
2024-03-28 23:04:05,635 - config - INFO - Validation Loss: 0.6150
2024-03-28 23:04:05,635 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:05,691 - config - INFO - Epoch [8/260], Train Loss: 0.6185
2024-03-28 23:04:05,693 - config - INFO - Validation Loss: 0.6009
2024-03-28 23:04:05,693 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:05,750 - config - INFO - Epoch [9/260], Train Loss: 0.6054
2024-03-28 23:04:05,751 - config - INFO - Validation Loss: 0.5873
2024-03-28 23:04:05,752 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:05,808 - config - INFO - Epoch [10/260], Train Loss: 0.5921
2024-03-28 23:04:05,810 - config - INFO - Validation Loss: 0.5736
2024-03-28 23:04:05,811 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:05,867 - config - INFO - Epoch [11/260], Train Loss: 0.5791
2024-03-28 23:04:05,869 - config - INFO - Validation Loss: 0.5598
2024-03-28 23:04:05,869 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:05,926 - config - INFO - Epoch [12/260], Train Loss: 0.5663
2024-03-28 23:04:05,928 - config - INFO - Validation Loss: 0.5469
2024-03-28 23:04:05,928 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:05,985 - config - INFO - Epoch [13/260], Train Loss: 0.5539
2024-03-28 23:04:05,987 - config - INFO - Validation Loss: 0.5353
2024-03-28 23:04:05,987 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:06,059 - config - INFO - Epoch [14/260], Train Loss: 0.5424
2024-03-28 23:04:06,061 - config - INFO - Validation Loss: 0.5240
2024-03-28 23:04:06,061 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:06,118 - config - INFO - Epoch [15/260], Train Loss: 0.5315
2024-03-28 23:04:06,120 - config - INFO - Validation Loss: 0.5139
2024-03-28 23:04:06,120 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:06,177 - config - INFO - Epoch [16/260], Train Loss: 0.5213
2024-03-28 23:04:06,179 - config - INFO - Validation Loss: 0.5046
2024-03-28 23:04:06,179 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:06,235 - config - INFO - Epoch [17/260], Train Loss: 0.5116
2024-03-28 23:04:06,237 - config - INFO - Validation Loss: 0.4963
2024-03-28 23:04:06,237 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:06,296 - config - INFO - Epoch [18/260], Train Loss: 0.5030
2024-03-28 23:04:06,298 - config - INFO - Validation Loss: 0.4883
2024-03-28 23:04:06,298 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:06,349 - config - INFO - Epoch [19/260], Train Loss: 0.4948
2024-03-28 23:04:06,351 - config - INFO - Validation Loss: 0.4825
2024-03-28 23:04:06,351 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:06,402 - config - INFO - Epoch [20/260], Train Loss: 0.4875
2024-03-28 23:04:06,404 - config - INFO - Validation Loss: 0.4765
2024-03-28 23:04:06,404 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:06,458 - config - INFO - Epoch [21/260], Train Loss: 0.4812
2024-03-28 23:04:06,460 - config - INFO - Validation Loss: 0.4705
2024-03-28 23:04:06,460 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:06,513 - config - INFO - Epoch [22/260], Train Loss: 0.4749
2024-03-28 23:04:06,515 - config - INFO - Validation Loss: 0.4662
2024-03-28 23:04:06,515 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:06,565 - config - INFO - Epoch [23/260], Train Loss: 0.4696
2024-03-28 23:04:06,567 - config - INFO - Validation Loss: 0.4622
2024-03-28 23:04:06,567 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:06,618 - config - INFO - Epoch [24/260], Train Loss: 0.4646
2024-03-28 23:04:06,620 - config - INFO - Validation Loss: 0.4583
2024-03-28 23:04:06,620 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:06,670 - config - INFO - Epoch [25/260], Train Loss: 0.4603
2024-03-28 23:04:06,672 - config - INFO - Validation Loss: 0.4551
2024-03-28 23:04:06,672 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:06,723 - config - INFO - Epoch [26/260], Train Loss: 0.4561
2024-03-28 23:04:06,724 - config - INFO - Validation Loss: 0.4522
2024-03-28 23:04:06,724 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:06,775 - config - INFO - Epoch [27/260], Train Loss: 0.4528
2024-03-28 23:04:06,777 - config - INFO - Validation Loss: 0.4499
2024-03-28 23:04:06,777 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:06,828 - config - INFO - Epoch [28/260], Train Loss: 0.4494
2024-03-28 23:04:06,830 - config - INFO - Validation Loss: 0.4482
2024-03-28 23:04:06,830 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:06,881 - config - INFO - Epoch [29/260], Train Loss: 0.4469
2024-03-28 23:04:06,883 - config - INFO - Validation Loss: 0.4458
2024-03-28 23:04:06,883 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:06,933 - config - INFO - Epoch [30/260], Train Loss: 0.4445
2024-03-28 23:04:06,935 - config - INFO - Validation Loss: 0.4443
2024-03-28 23:04:06,935 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:06,986 - config - INFO - Epoch [31/260], Train Loss: 0.4421
2024-03-28 23:04:06,988 - config - INFO - Validation Loss: 0.4437
2024-03-28 23:04:06,988 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:07,038 - config - INFO - Epoch [32/260], Train Loss: 0.4402
2024-03-28 23:04:07,040 - config - INFO - Validation Loss: 0.4430
2024-03-28 23:04:07,040 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:07,096 - config - INFO - Epoch [33/260], Train Loss: 0.4383
2024-03-28 23:04:07,098 - config - INFO - Validation Loss: 0.4424
2024-03-28 23:04:07,098 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:07,149 - config - INFO - Epoch [34/260], Train Loss: 0.4368
2024-03-28 23:04:07,150 - config - INFO - Validation Loss: 0.4405
2024-03-28 23:04:07,151 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:07,201 - config - INFO - Epoch [35/260], Train Loss: 0.4353
2024-03-28 23:04:07,202 - config - INFO - Validation Loss: 0.4396
2024-03-28 23:04:07,203 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:07,253 - config - INFO - Epoch [36/260], Train Loss: 0.4337
2024-03-28 23:04:07,255 - config - INFO - Validation Loss: 0.4390
2024-03-28 23:04:07,255 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:07,305 - config - INFO - Epoch [37/260], Train Loss: 0.4325
2024-03-28 23:04:07,307 - config - INFO - Validation Loss: 0.4388
2024-03-28 23:04:07,307 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:07,358 - config - INFO - Epoch [38/260], Train Loss: 0.4314
2024-03-28 23:04:07,359 - config - INFO - Validation Loss: 0.4380
2024-03-28 23:04:07,359 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:07,410 - config - INFO - Epoch [39/260], Train Loss: 0.4302
2024-03-28 23:04:07,411 - config - INFO - Validation Loss: 0.4371
2024-03-28 23:04:07,411 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:07,461 - config - INFO - Epoch [40/260], Train Loss: 0.4292
2024-03-28 23:04:07,463 - config - INFO - Validation Loss: 0.4361
2024-03-28 23:04:07,463 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:07,513 - config - INFO - Epoch [41/260], Train Loss: 0.4282
2024-03-28 23:04:07,515 - config - INFO - Validation Loss: 0.4350
2024-03-28 23:04:07,515 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:07,565 - config - INFO - Epoch [42/260], Train Loss: 0.4272
2024-03-28 23:04:07,566 - config - INFO - Validation Loss: 0.4351
2024-03-28 23:04:07,567 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:07,617 - config - INFO - Epoch [43/260], Train Loss: 0.4262
2024-03-28 23:04:07,618 - config - INFO - Validation Loss: 0.4347
2024-03-28 23:04:07,618 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:07,669 - config - INFO - Epoch [44/260], Train Loss: 0.4254
2024-03-28 23:04:07,670 - config - INFO - Validation Loss: 0.4362
2024-03-28 23:04:07,670 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:07,720 - config - INFO - Epoch [45/260], Train Loss: 0.4247
2024-03-28 23:04:07,722 - config - INFO - Validation Loss: 0.4349
2024-03-28 23:04:07,722 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:07,773 - config - INFO - Epoch [46/260], Train Loss: 0.4236
2024-03-28 23:04:07,774 - config - INFO - Validation Loss: 0.4336
2024-03-28 23:04:07,775 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:07,824 - config - INFO - Epoch [47/260], Train Loss: 0.4228
2024-03-28 23:04:07,826 - config - INFO - Validation Loss: 0.4329
2024-03-28 23:04:07,826 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:07,876 - config - INFO - Epoch [48/260], Train Loss: 0.4220
2024-03-28 23:04:07,878 - config - INFO - Validation Loss: 0.4336
2024-03-28 23:04:07,878 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:07,928 - config - INFO - Epoch [49/260], Train Loss: 0.4214
2024-03-28 23:04:07,930 - config - INFO - Validation Loss: 0.4334
2024-03-28 23:04:07,930 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:07,980 - config - INFO - Epoch [50/260], Train Loss: 0.4207
2024-03-28 23:04:07,981 - config - INFO - Validation Loss: 0.4332
2024-03-28 23:04:07,982 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:08,032 - config - INFO - Epoch [51/260], Train Loss: 0.4201
2024-03-28 23:04:08,033 - config - INFO - Validation Loss: 0.4327
2024-03-28 23:04:08,033 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:08,100 - config - INFO - Epoch [52/260], Train Loss: 0.4194
2024-03-28 23:04:08,102 - config - INFO - Validation Loss: 0.4321
2024-03-28 23:04:08,102 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:08,159 - config - INFO - Epoch [53/260], Train Loss: 0.4189
2024-03-28 23:04:08,161 - config - INFO - Validation Loss: 0.4318
2024-03-28 23:04:08,161 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:08,218 - config - INFO - Epoch [54/260], Train Loss: 0.4182
2024-03-28 23:04:08,220 - config - INFO - Validation Loss: 0.4312
2024-03-28 23:04:08,220 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:08,276 - config - INFO - Epoch [55/260], Train Loss: 0.4176
2024-03-28 23:04:08,278 - config - INFO - Validation Loss: 0.4316
2024-03-28 23:04:08,278 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:08,335 - config - INFO - Epoch [56/260], Train Loss: 0.4170
2024-03-28 23:04:08,337 - config - INFO - Validation Loss: 0.4303
2024-03-28 23:04:08,337 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:08,393 - config - INFO - Epoch [57/260], Train Loss: 0.4168
2024-03-28 23:04:08,395 - config - INFO - Validation Loss: 0.4311
2024-03-28 23:04:08,395 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:08,452 - config - INFO - Epoch [58/260], Train Loss: 0.4158
2024-03-28 23:04:08,454 - config - INFO - Validation Loss: 0.4296
2024-03-28 23:04:08,454 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:08,511 - config - INFO - Epoch [59/260], Train Loss: 0.4153
2024-03-28 23:04:08,512 - config - INFO - Validation Loss: 0.4293
2024-03-28 23:04:08,513 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:08,569 - config - INFO - Epoch [60/260], Train Loss: 0.4149
2024-03-28 23:04:08,571 - config - INFO - Validation Loss: 0.4283
2024-03-28 23:04:08,571 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:08,627 - config - INFO - Epoch [61/260], Train Loss: 0.4143
2024-03-28 23:04:08,629 - config - INFO - Validation Loss: 0.4279
2024-03-28 23:04:08,630 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:08,686 - config - INFO - Epoch [62/260], Train Loss: 0.4141
2024-03-28 23:04:08,688 - config - INFO - Validation Loss: 0.4290
2024-03-28 23:04:08,688 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:08,745 - config - INFO - Epoch [63/260], Train Loss: 0.4136
2024-03-28 23:04:08,746 - config - INFO - Validation Loss: 0.4266
2024-03-28 23:04:08,747 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:08,803 - config - INFO - Epoch [64/260], Train Loss: 0.4129
2024-03-28 23:04:08,805 - config - INFO - Validation Loss: 0.4272
2024-03-28 23:04:08,805 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:08,862 - config - INFO - Epoch [65/260], Train Loss: 0.4124
2024-03-28 23:04:08,864 - config - INFO - Validation Loss: 0.4272
2024-03-28 23:04:08,864 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:08,920 - config - INFO - Epoch [66/260], Train Loss: 0.4119
2024-03-28 23:04:08,922 - config - INFO - Validation Loss: 0.4268
2024-03-28 23:04:08,922 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:08,979 - config - INFO - Epoch [67/260], Train Loss: 0.4116
2024-03-28 23:04:08,981 - config - INFO - Validation Loss: 0.4264
2024-03-28 23:04:08,981 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:09,037 - config - INFO - Epoch [68/260], Train Loss: 0.4112
2024-03-28 23:04:09,039 - config - INFO - Validation Loss: 0.4255
2024-03-28 23:04:09,039 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:09,101 - config - INFO - Epoch [69/260], Train Loss: 0.4108
2024-03-28 23:04:09,103 - config - INFO - Validation Loss: 0.4252
2024-03-28 23:04:09,103 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:09,160 - config - INFO - Epoch [70/260], Train Loss: 0.4103
2024-03-28 23:04:09,162 - config - INFO - Validation Loss: 0.4254
2024-03-28 23:04:09,162 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:09,219 - config - INFO - Epoch [71/260], Train Loss: 0.4098
2024-03-28 23:04:09,221 - config - INFO - Validation Loss: 0.4246
2024-03-28 23:04:09,221 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:09,278 - config - INFO - Epoch [72/260], Train Loss: 0.4095
2024-03-28 23:04:09,280 - config - INFO - Validation Loss: 0.4238
2024-03-28 23:04:09,280 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:09,339 - config - INFO - Epoch [73/260], Train Loss: 0.4093
2024-03-28 23:04:09,341 - config - INFO - Validation Loss: 0.4248
2024-03-28 23:04:09,341 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:09,398 - config - INFO - Epoch [74/260], Train Loss: 0.4087
2024-03-28 23:04:09,400 - config - INFO - Validation Loss: 0.4234
2024-03-28 23:04:09,400 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:09,458 - config - INFO - Epoch [75/260], Train Loss: 0.4085
2024-03-28 23:04:09,460 - config - INFO - Validation Loss: 0.4226
2024-03-28 23:04:09,460 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:09,517 - config - INFO - Epoch [76/260], Train Loss: 0.4080
2024-03-28 23:04:09,519 - config - INFO - Validation Loss: 0.4231
2024-03-28 23:04:09,519 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:09,576 - config - INFO - Epoch [77/260], Train Loss: 0.4076
2024-03-28 23:04:09,578 - config - INFO - Validation Loss: 0.4230
2024-03-28 23:04:09,578 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:09,635 - config - INFO - Epoch [78/260], Train Loss: 0.4072
2024-03-28 23:04:09,637 - config - INFO - Validation Loss: 0.4226
2024-03-28 23:04:09,637 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:09,694 - config - INFO - Epoch [79/260], Train Loss: 0.4069
2024-03-28 23:04:09,696 - config - INFO - Validation Loss: 0.4213
2024-03-28 23:04:09,696 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:09,754 - config - INFO - Epoch [80/260], Train Loss: 0.4065
2024-03-28 23:04:09,756 - config - INFO - Validation Loss: 0.4215
2024-03-28 23:04:09,756 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:09,813 - config - INFO - Epoch [81/260], Train Loss: 0.4062
2024-03-28 23:04:09,815 - config - INFO - Validation Loss: 0.4225
2024-03-28 23:04:09,815 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:09,872 - config - INFO - Epoch [82/260], Train Loss: 0.4064
2024-03-28 23:04:09,873 - config - INFO - Validation Loss: 0.4227
2024-03-28 23:04:09,874 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:09,931 - config - INFO - Epoch [83/260], Train Loss: 0.4057
2024-03-28 23:04:09,932 - config - INFO - Validation Loss: 0.4201
2024-03-28 23:04:09,933 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:09,989 - config - INFO - Epoch [84/260], Train Loss: 0.4053
2024-03-28 23:04:09,991 - config - INFO - Validation Loss: 0.4205
2024-03-28 23:04:09,991 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:10,048 - config - INFO - Epoch [85/260], Train Loss: 0.4049
2024-03-28 23:04:10,050 - config - INFO - Validation Loss: 0.4192
2024-03-28 23:04:10,050 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:10,099 - config - INFO - Epoch [86/260], Train Loss: 0.4045
2024-03-28 23:04:10,101 - config - INFO - Validation Loss: 0.4202
2024-03-28 23:04:10,101 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:10,153 - config - INFO - Epoch [87/260], Train Loss: 0.4044
2024-03-28 23:04:10,155 - config - INFO - Validation Loss: 0.4201
2024-03-28 23:04:10,155 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:10,204 - config - INFO - Epoch [88/260], Train Loss: 0.4040
2024-03-28 23:04:10,206 - config - INFO - Validation Loss: 0.4203
2024-03-28 23:04:10,206 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:10,255 - config - INFO - Epoch [89/260], Train Loss: 0.4035
2024-03-28 23:04:10,256 - config - INFO - Validation Loss: 0.4198
2024-03-28 23:04:10,265 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:10,314 - config - INFO - Epoch [90/260], Train Loss: 0.4036
2024-03-28 23:04:10,316 - config - INFO - Validation Loss: 0.4210
2024-03-28 23:04:10,316 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:10,365 - config - INFO - Epoch [91/260], Train Loss: 0.4029
2024-03-28 23:04:10,366 - config - INFO - Validation Loss: 0.4204
2024-03-28 23:04:10,366 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:10,415 - config - INFO - Epoch [92/260], Train Loss: 0.4026
2024-03-28 23:04:10,417 - config - INFO - Validation Loss: 0.4200
2024-03-28 23:04:10,417 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:10,466 - config - INFO - Epoch [93/260], Train Loss: 0.4024
2024-03-28 23:04:10,468 - config - INFO - Validation Loss: 0.4194
2024-03-28 23:04:10,468 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:10,517 - config - INFO - Epoch [94/260], Train Loss: 0.4024
2024-03-28 23:04:10,519 - config - INFO - Validation Loss: 0.4182
2024-03-28 23:04:10,519 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:10,568 - config - INFO - Epoch [95/260], Train Loss: 0.4019
2024-03-28 23:04:10,570 - config - INFO - Validation Loss: 0.4194
2024-03-28 23:04:10,570 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:10,619 - config - INFO - Epoch [96/260], Train Loss: 0.4015
2024-03-28 23:04:10,621 - config - INFO - Validation Loss: 0.4188
2024-03-28 23:04:10,621 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:10,670 - config - INFO - Epoch [97/260], Train Loss: 0.4016
2024-03-28 23:04:10,671 - config - INFO - Validation Loss: 0.4183
2024-03-28 23:04:10,672 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:10,721 - config - INFO - Epoch [98/260], Train Loss: 0.4011
2024-03-28 23:04:10,722 - config - INFO - Validation Loss: 0.4177
2024-03-28 23:04:10,722 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:10,771 - config - INFO - Epoch [99/260], Train Loss: 0.4007
2024-03-28 23:04:10,773 - config - INFO - Validation Loss: 0.4180
2024-03-28 23:04:10,773 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:10,822 - config - INFO - Epoch [100/260], Train Loss: 0.4003
2024-03-28 23:04:10,824 - config - INFO - Validation Loss: 0.4185
2024-03-28 23:04:10,824 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:10,873 - config - INFO - Epoch [101/260], Train Loss: 0.4002
2024-03-28 23:04:10,875 - config - INFO - Validation Loss: 0.4176
2024-03-28 23:04:10,875 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:10,924 - config - INFO - Epoch [102/260], Train Loss: 0.3998
2024-03-28 23:04:10,925 - config - INFO - Validation Loss: 0.4172
2024-03-28 23:04:10,926 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:10,975 - config - INFO - Epoch [103/260], Train Loss: 0.3995
2024-03-28 23:04:10,976 - config - INFO - Validation Loss: 0.4177
2024-03-28 23:04:10,976 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:11,025 - config - INFO - Epoch [104/260], Train Loss: 0.3993
2024-03-28 23:04:11,027 - config - INFO - Validation Loss: 0.4171
2024-03-28 23:04:11,027 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:11,076 - config - INFO - Epoch [105/260], Train Loss: 0.3991
2024-03-28 23:04:11,077 - config - INFO - Validation Loss: 0.4159
2024-03-28 23:04:11,078 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:11,134 - config - INFO - Epoch [106/260], Train Loss: 0.3988
2024-03-28 23:04:11,136 - config - INFO - Validation Loss: 0.4164
2024-03-28 23:04:11,136 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:11,185 - config - INFO - Epoch [107/260], Train Loss: 0.3986
2024-03-28 23:04:11,187 - config - INFO - Validation Loss: 0.4151
2024-03-28 23:04:11,187 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:11,236 - config - INFO - Epoch [108/260], Train Loss: 0.3983
2024-03-28 23:04:11,237 - config - INFO - Validation Loss: 0.4156
2024-03-28 23:04:11,237 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:11,286 - config - INFO - Epoch [109/260], Train Loss: 0.3983
2024-03-28 23:04:11,288 - config - INFO - Validation Loss: 0.4161
2024-03-28 23:04:11,288 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:11,337 - config - INFO - Epoch [110/260], Train Loss: 0.3979
2024-03-28 23:04:11,339 - config - INFO - Validation Loss: 0.4159
2024-03-28 23:04:11,339 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:11,388 - config - INFO - Epoch [111/260], Train Loss: 0.3978
2024-03-28 23:04:11,390 - config - INFO - Validation Loss: 0.4163
2024-03-28 23:04:11,390 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:11,439 - config - INFO - Epoch [112/260], Train Loss: 0.3973
2024-03-28 23:04:11,440 - config - INFO - Validation Loss: 0.4159
2024-03-28 23:04:11,440 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:11,489 - config - INFO - Epoch [113/260], Train Loss: 0.3972
2024-03-28 23:04:11,491 - config - INFO - Validation Loss: 0.4145
2024-03-28 23:04:11,491 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:11,540 - config - INFO - Epoch [114/260], Train Loss: 0.3971
2024-03-28 23:04:11,542 - config - INFO - Validation Loss: 0.4154
2024-03-28 23:04:11,542 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:11,591 - config - INFO - Epoch [115/260], Train Loss: 0.3967
2024-03-28 23:04:11,592 - config - INFO - Validation Loss: 0.4145
2024-03-28 23:04:11,592 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:11,641 - config - INFO - Epoch [116/260], Train Loss: 0.3966
2024-03-28 23:04:11,643 - config - INFO - Validation Loss: 0.4158
2024-03-28 23:04:11,643 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:11,692 - config - INFO - Epoch [117/260], Train Loss: 0.3965
2024-03-28 23:04:11,693 - config - INFO - Validation Loss: 0.4133
2024-03-28 23:04:11,694 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:11,743 - config - INFO - Epoch [118/260], Train Loss: 0.3962
2024-03-28 23:04:11,744 - config - INFO - Validation Loss: 0.4137
2024-03-28 23:04:11,745 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:11,794 - config - INFO - Epoch [119/260], Train Loss: 0.3958
2024-03-28 23:04:11,795 - config - INFO - Validation Loss: 0.4137
2024-03-28 23:04:11,795 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:11,844 - config - INFO - Epoch [120/260], Train Loss: 0.3958
2024-03-28 23:04:11,846 - config - INFO - Validation Loss: 0.4139
2024-03-28 23:04:11,846 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:11,895 - config - INFO - Epoch [121/260], Train Loss: 0.3956
2024-03-28 23:04:11,897 - config - INFO - Validation Loss: 0.4139
2024-03-28 23:04:11,897 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:11,946 - config - INFO - Epoch [122/260], Train Loss: 0.3953
2024-03-28 23:04:11,947 - config - INFO - Validation Loss: 0.4143
2024-03-28 23:04:11,948 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:11,997 - config - INFO - Epoch [123/260], Train Loss: 0.3950
2024-03-28 23:04:11,998 - config - INFO - Validation Loss: 0.4135
2024-03-28 23:04:11,998 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:12,047 - config - INFO - Epoch [124/260], Train Loss: 0.3948
2024-03-28 23:04:12,049 - config - INFO - Validation Loss: 0.4121
2024-03-28 23:04:12,049 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:12,098 - config - INFO - Epoch [125/260], Train Loss: 0.3947
2024-03-28 23:04:12,100 - config - INFO - Validation Loss: 0.4124
2024-03-28 23:04:12,100 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:12,149 - config - INFO - Epoch [126/260], Train Loss: 0.3945
2024-03-28 23:04:12,150 - config - INFO - Validation Loss: 0.4141
2024-03-28 23:04:12,151 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:12,202 - config - INFO - Epoch [127/260], Train Loss: 0.3942
2024-03-28 23:04:12,204 - config - INFO - Validation Loss: 0.4129
2024-03-28 23:04:12,204 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:12,253 - config - INFO - Epoch [128/260], Train Loss: 0.3941
2024-03-28 23:04:12,255 - config - INFO - Validation Loss: 0.4138
2024-03-28 23:04:12,255 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:12,304 - config - INFO - Epoch [129/260], Train Loss: 0.3938
2024-03-28 23:04:12,306 - config - INFO - Validation Loss: 0.4119
2024-03-28 23:04:12,306 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:12,355 - config - INFO - Epoch [130/260], Train Loss: 0.3937
2024-03-28 23:04:12,356 - config - INFO - Validation Loss: 0.4114
2024-03-28 23:04:12,357 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:12,406 - config - INFO - Epoch [131/260], Train Loss: 0.3935
2024-03-28 23:04:12,407 - config - INFO - Validation Loss: 0.4117
2024-03-28 23:04:12,407 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:12,456 - config - INFO - Epoch [132/260], Train Loss: 0.3933
2024-03-28 23:04:12,458 - config - INFO - Validation Loss: 0.4130
2024-03-28 23:04:12,458 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:12,507 - config - INFO - Epoch [133/260], Train Loss: 0.3934
2024-03-28 23:04:12,509 - config - INFO - Validation Loss: 0.4105
2024-03-28 23:04:12,509 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:12,558 - config - INFO - Epoch [134/260], Train Loss: 0.3932
2024-03-28 23:04:12,559 - config - INFO - Validation Loss: 0.4119
2024-03-28 23:04:12,559 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:12,608 - config - INFO - Epoch [135/260], Train Loss: 0.3929
2024-03-28 23:04:12,610 - config - INFO - Validation Loss: 0.4109
2024-03-28 23:04:12,610 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:12,659 - config - INFO - Epoch [136/260], Train Loss: 0.3926
2024-03-28 23:04:12,661 - config - INFO - Validation Loss: 0.4116
2024-03-28 23:04:12,661 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:12,710 - config - INFO - Epoch [137/260], Train Loss: 0.3925
2024-03-28 23:04:12,711 - config - INFO - Validation Loss: 0.4116
2024-03-28 23:04:12,712 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:12,761 - config - INFO - Epoch [138/260], Train Loss: 0.3925
2024-03-28 23:04:12,762 - config - INFO - Validation Loss: 0.4119
2024-03-28 23:04:12,762 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:12,811 - config - INFO - Epoch [139/260], Train Loss: 0.3921
2024-03-28 23:04:12,813 - config - INFO - Validation Loss: 0.4114
2024-03-28 23:04:12,813 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:12,862 - config - INFO - Epoch [140/260], Train Loss: 0.3921
2024-03-28 23:04:12,864 - config - INFO - Validation Loss: 0.4119
2024-03-28 23:04:12,864 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:12,912 - config - INFO - Epoch [141/260], Train Loss: 0.3916
2024-03-28 23:04:12,914 - config - INFO - Validation Loss: 0.4112
2024-03-28 23:04:12,914 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:12,963 - config - INFO - Epoch [142/260], Train Loss: 0.3916
2024-03-28 23:04:12,965 - config - INFO - Validation Loss: 0.4106
2024-03-28 23:04:12,965 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:13,014 - config - INFO - Epoch [143/260], Train Loss: 0.3918
2024-03-28 23:04:13,015 - config - INFO - Validation Loss: 0.4124
2024-03-28 23:04:13,015 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:13,064 - config - INFO - Epoch [144/260], Train Loss: 0.3918
2024-03-28 23:04:13,066 - config - INFO - Validation Loss: 0.4085
2024-03-28 23:04:13,066 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:13,115 - config - INFO - Epoch [145/260], Train Loss: 0.3913
2024-03-28 23:04:13,117 - config - INFO - Validation Loss: 0.4110
2024-03-28 23:04:13,117 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:13,165 - config - INFO - Epoch [146/260], Train Loss: 0.3908
2024-03-28 23:04:13,167 - config - INFO - Validation Loss: 0.4095
2024-03-28 23:04:13,167 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:13,216 - config - INFO - Epoch [147/260], Train Loss: 0.3907
2024-03-28 23:04:13,218 - config - INFO - Validation Loss: 0.4100
2024-03-28 23:04:13,218 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:13,267 - config - INFO - Epoch [148/260], Train Loss: 0.3907
2024-03-28 23:04:13,269 - config - INFO - Validation Loss: 0.4099
2024-03-28 23:04:13,269 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:13,318 - config - INFO - Epoch [149/260], Train Loss: 0.3906
2024-03-28 23:04:13,320 - config - INFO - Validation Loss: 0.4110
2024-03-28 23:04:13,320 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:13,368 - config - INFO - Epoch [150/260], Train Loss: 0.3903
2024-03-28 23:04:13,370 - config - INFO - Validation Loss: 0.4111
2024-03-28 23:04:13,370 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:13,419 - config - INFO - Epoch [151/260], Train Loss: 0.3902
2024-03-28 23:04:13,421 - config - INFO - Validation Loss: 0.4108
2024-03-28 23:04:13,421 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:13,470 - config - INFO - Epoch [152/260], Train Loss: 0.3899
2024-03-28 23:04:13,471 - config - INFO - Validation Loss: 0.4109
2024-03-28 23:04:13,472 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:13,520 - config - INFO - Epoch [153/260], Train Loss: 0.3898
2024-03-28 23:04:13,522 - config - INFO - Validation Loss: 0.4109
2024-03-28 23:04:13,522 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:13,571 - config - INFO - Epoch [154/260], Train Loss: 0.3898
2024-03-28 23:04:13,573 - config - INFO - Validation Loss: 0.4094
2024-03-28 23:04:13,573 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:13,622 - config - INFO - Epoch [155/260], Train Loss: 0.3898
2024-03-28 23:04:13,623 - config - INFO - Validation Loss: 0.4102
2024-03-28 23:04:13,624 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:13,672 - config - INFO - Epoch [156/260], Train Loss: 0.3894
2024-03-28 23:04:13,674 - config - INFO - Validation Loss: 0.4098
2024-03-28 23:04:13,674 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:13,724 - config - INFO - Epoch [157/260], Train Loss: 0.3891
2024-03-28 23:04:13,725 - config - INFO - Validation Loss: 0.4103
2024-03-28 23:04:13,725 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:13,774 - config - INFO - Epoch [158/260], Train Loss: 0.3891
2024-03-28 23:04:13,776 - config - INFO - Validation Loss: 0.4107
2024-03-28 23:04:13,776 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:13,825 - config - INFO - Epoch [159/260], Train Loss: 0.3889
2024-03-28 23:04:13,826 - config - INFO - Validation Loss: 0.4099
2024-03-28 23:04:13,827 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:13,875 - config - INFO - Epoch [160/260], Train Loss: 0.3889
2024-03-28 23:04:13,877 - config - INFO - Validation Loss: 0.4106
2024-03-28 23:04:13,877 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:13,926 - config - INFO - Epoch [161/260], Train Loss: 0.3888
2024-03-28 23:04:13,928 - config - INFO - Validation Loss: 0.4107
2024-03-28 23:04:13,928 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:13,977 - config - INFO - Epoch [162/260], Train Loss: 0.3887
2024-03-28 23:04:13,978 - config - INFO - Validation Loss: 0.4094
2024-03-28 23:04:13,978 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:14,027 - config - INFO - Epoch [163/260], Train Loss: 0.3885
2024-03-28 23:04:14,029 - config - INFO - Validation Loss: 0.4105
2024-03-28 23:04:14,029 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:14,078 - config - INFO - Epoch [164/260], Train Loss: 0.3882
2024-03-28 23:04:14,079 - config - INFO - Validation Loss: 0.4101
2024-03-28 23:04:14,080 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:14,128 - config - INFO - Epoch [165/260], Train Loss: 0.3884
2024-03-28 23:04:14,130 - config - INFO - Validation Loss: 0.4118
2024-03-28 23:04:14,130 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:14,179 - config - INFO - Epoch [166/260], Train Loss: 0.3878
2024-03-28 23:04:14,180 - config - INFO - Validation Loss: 0.4094
2024-03-28 23:04:14,181 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:14,231 - config - INFO - Epoch [167/260], Train Loss: 0.3879
2024-03-28 23:04:14,233 - config - INFO - Validation Loss: 0.4095
2024-03-28 23:04:14,233 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:14,282 - config - INFO - Epoch [168/260], Train Loss: 0.3878
2024-03-28 23:04:14,284 - config - INFO - Validation Loss: 0.4104
2024-03-28 23:04:14,284 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:14,333 - config - INFO - Epoch [169/260], Train Loss: 0.3876
2024-03-28 23:04:14,334 - config - INFO - Validation Loss: 0.4089
2024-03-28 23:04:14,335 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:14,388 - config - INFO - Epoch [170/260], Train Loss: 0.3874
2024-03-28 23:04:14,390 - config - INFO - Validation Loss: 0.4095
2024-03-28 23:04:14,390 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:14,438 - config - INFO - Epoch [171/260], Train Loss: 0.3873
2024-03-28 23:04:14,440 - config - INFO - Validation Loss: 0.4091
2024-03-28 23:04:14,440 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:14,489 - config - INFO - Epoch [172/260], Train Loss: 0.3873
2024-03-28 23:04:14,490 - config - INFO - Validation Loss: 0.4100
2024-03-28 23:04:14,490 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:14,539 - config - INFO - Epoch [173/260], Train Loss: 0.3875
2024-03-28 23:04:14,541 - config - INFO - Validation Loss: 0.4068
2024-03-28 23:04:14,541 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:14,590 - config - INFO - Epoch [174/260], Train Loss: 0.3869
2024-03-28 23:04:14,592 - config - INFO - Validation Loss: 0.4093
2024-03-28 23:04:14,592 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:14,640 - config - INFO - Epoch [175/260], Train Loss: 0.3866
2024-03-28 23:04:14,642 - config - INFO - Validation Loss: 0.4077
2024-03-28 23:04:14,642 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:14,691 - config - INFO - Epoch [176/260], Train Loss: 0.3864
2024-03-28 23:04:14,693 - config - INFO - Validation Loss: 0.4085
2024-03-28 23:04:14,693 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:14,742 - config - INFO - Epoch [177/260], Train Loss: 0.3864
2024-03-28 23:04:14,743 - config - INFO - Validation Loss: 0.4099
2024-03-28 23:04:14,744 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:14,793 - config - INFO - Epoch [178/260], Train Loss: 0.3865
2024-03-28 23:04:14,794 - config - INFO - Validation Loss: 0.4073
2024-03-28 23:04:14,794 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:14,843 - config - INFO - Epoch [179/260], Train Loss: 0.3865
2024-03-28 23:04:14,845 - config - INFO - Validation Loss: 0.4094
2024-03-28 23:04:14,845 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:14,894 - config - INFO - Epoch [180/260], Train Loss: 0.3861
2024-03-28 23:04:14,896 - config - INFO - Validation Loss: 0.4072
2024-03-28 23:04:14,896 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:14,945 - config - INFO - Epoch [181/260], Train Loss: 0.3860
2024-03-28 23:04:14,946 - config - INFO - Validation Loss: 0.4078
2024-03-28 23:04:14,946 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:14,995 - config - INFO - Epoch [182/260], Train Loss: 0.3859
2024-03-28 23:04:14,997 - config - INFO - Validation Loss: 0.4076
2024-03-28 23:04:14,997 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:15,046 - config - INFO - Epoch [183/260], Train Loss: 0.3857
2024-03-28 23:04:15,048 - config - INFO - Validation Loss: 0.4082
2024-03-28 23:04:15,048 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:15,096 - config - INFO - Epoch [184/260], Train Loss: 0.3855
2024-03-28 23:04:15,098 - config - INFO - Validation Loss: 0.4082
2024-03-28 23:04:15,098 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:15,147 - config - INFO - Epoch [185/260], Train Loss: 0.3854
2024-03-28 23:04:15,149 - config - INFO - Validation Loss: 0.4078
2024-03-28 23:04:15,149 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:15,201 - config - INFO - Epoch [186/260], Train Loss: 0.3853
2024-03-28 23:04:15,202 - config - INFO - Validation Loss: 0.4082
2024-03-28 23:04:15,203 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:15,251 - config - INFO - Epoch [187/260], Train Loss: 0.3852
2024-03-28 23:04:15,253 - config - INFO - Validation Loss: 0.4067
2024-03-28 23:04:15,253 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:15,312 - config - INFO - Epoch [188/260], Train Loss: 0.3849
2024-03-28 23:04:15,314 - config - INFO - Validation Loss: 0.4077
2024-03-28 23:04:15,314 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:15,363 - config - INFO - Epoch [189/260], Train Loss: 0.3850
2024-03-28 23:04:15,364 - config - INFO - Validation Loss: 0.4092
2024-03-28 23:04:15,365 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:15,413 - config - INFO - Epoch [190/260], Train Loss: 0.3849
2024-03-28 23:04:15,415 - config - INFO - Validation Loss: 0.4081
2024-03-28 23:04:15,415 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:15,464 - config - INFO - Epoch [191/260], Train Loss: 0.3848
2024-03-28 23:04:15,466 - config - INFO - Validation Loss: 0.4092
2024-03-28 23:04:15,466 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:15,515 - config - INFO - Epoch [192/260], Train Loss: 0.3849
2024-03-28 23:04:15,517 - config - INFO - Validation Loss: 0.4099
2024-03-28 23:04:15,517 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:15,566 - config - INFO - Epoch [193/260], Train Loss: 0.3845
2024-03-28 23:04:15,567 - config - INFO - Validation Loss: 0.4076
2024-03-28 23:04:15,567 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:15,616 - config - INFO - Epoch [194/260], Train Loss: 0.3846
2024-03-28 23:04:15,618 - config - INFO - Validation Loss: 0.4072
2024-03-28 23:04:15,618 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:15,667 - config - INFO - Epoch [195/260], Train Loss: 0.3841
2024-03-28 23:04:15,669 - config - INFO - Validation Loss: 0.4072
2024-03-28 23:04:15,669 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:15,718 - config - INFO - Epoch [196/260], Train Loss: 0.3841
2024-03-28 23:04:15,719 - config - INFO - Validation Loss: 0.4080
2024-03-28 23:04:15,719 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:15,769 - config - INFO - Epoch [197/260], Train Loss: 0.3839
2024-03-28 23:04:15,770 - config - INFO - Validation Loss: 0.4075
2024-03-28 23:04:15,771 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:15,819 - config - INFO - Epoch [198/260], Train Loss: 0.3838
2024-03-28 23:04:15,821 - config - INFO - Validation Loss: 0.4080
2024-03-28 23:04:15,821 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:15,870 - config - INFO - Epoch [199/260], Train Loss: 0.3841
2024-03-28 23:04:15,872 - config - INFO - Validation Loss: 0.4079
2024-03-28 23:04:15,872 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:15,921 - config - INFO - Epoch [200/260], Train Loss: 0.3837
2024-03-28 23:04:15,923 - config - INFO - Validation Loss: 0.4069
2024-03-28 23:04:15,923 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:15,972 - config - INFO - Epoch [201/260], Train Loss: 0.3837
2024-03-28 23:04:15,973 - config - INFO - Validation Loss: 0.4061
2024-03-28 23:04:15,973 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:16,022 - config - INFO - Epoch [202/260], Train Loss: 0.3834
2024-03-28 23:04:16,024 - config - INFO - Validation Loss: 0.4070
2024-03-28 23:04:16,024 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:16,073 - config - INFO - Epoch [203/260], Train Loss: 0.3833
2024-03-28 23:04:16,074 - config - INFO - Validation Loss: 0.4076
2024-03-28 23:04:16,074 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:16,123 - config - INFO - Epoch [204/260], Train Loss: 0.3832
2024-03-28 23:04:16,125 - config - INFO - Validation Loss: 0.4071
2024-03-28 23:04:16,125 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:16,174 - config - INFO - Epoch [205/260], Train Loss: 0.3830
2024-03-28 23:04:16,176 - config - INFO - Validation Loss: 0.4064
2024-03-28 23:04:16,176 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:16,230 - config - INFO - Epoch [206/260], Train Loss: 0.3829
2024-03-28 23:04:16,232 - config - INFO - Validation Loss: 0.4066
2024-03-28 23:04:16,232 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:16,281 - config - INFO - Epoch [207/260], Train Loss: 0.3828
2024-03-28 23:04:16,283 - config - INFO - Validation Loss: 0.4045
2024-03-28 23:04:16,283 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:16,331 - config - INFO - Epoch [208/260], Train Loss: 0.3826
2024-03-28 23:04:16,333 - config - INFO - Validation Loss: 0.4053
2024-03-28 23:04:16,333 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:16,382 - config - INFO - Epoch [209/260], Train Loss: 0.3828
2024-03-28 23:04:16,383 - config - INFO - Validation Loss: 0.4056
2024-03-28 23:04:16,384 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:16,432 - config - INFO - Epoch [210/260], Train Loss: 0.3828
2024-03-28 23:04:16,434 - config - INFO - Validation Loss: 0.4059
2024-03-28 23:04:16,434 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:16,483 - config - INFO - Epoch [211/260], Train Loss: 0.3824
2024-03-28 23:04:16,484 - config - INFO - Validation Loss: 0.4047
2024-03-28 23:04:16,484 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:16,533 - config - INFO - Epoch [212/260], Train Loss: 0.3823
2024-03-28 23:04:16,534 - config - INFO - Validation Loss: 0.4053
2024-03-28 23:04:16,535 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:16,583 - config - INFO - Epoch [213/260], Train Loss: 0.3821
2024-03-28 23:04:16,585 - config - INFO - Validation Loss: 0.4053
2024-03-28 23:04:16,585 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:16,634 - config - INFO - Epoch [214/260], Train Loss: 0.3821
2024-03-28 23:04:16,635 - config - INFO - Validation Loss: 0.4050
2024-03-28 23:04:16,635 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:16,684 - config - INFO - Epoch [215/260], Train Loss: 0.3820
2024-03-28 23:04:16,686 - config - INFO - Validation Loss: 0.4073
2024-03-28 23:04:16,686 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:16,734 - config - INFO - Epoch [216/260], Train Loss: 0.3819
2024-03-28 23:04:16,736 - config - INFO - Validation Loss: 0.4051
2024-03-28 23:04:16,736 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:16,784 - config - INFO - Epoch [217/260], Train Loss: 0.3819
2024-03-28 23:04:16,786 - config - INFO - Validation Loss: 0.4058
2024-03-28 23:04:16,786 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:16,835 - config - INFO - Epoch [218/260], Train Loss: 0.3814
2024-03-28 23:04:16,836 - config - INFO - Validation Loss: 0.4064
2024-03-28 23:04:16,836 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:16,885 - config - INFO - Epoch [219/260], Train Loss: 0.3815
2024-03-28 23:04:16,887 - config - INFO - Validation Loss: 0.4071
2024-03-28 23:04:16,887 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:16,935 - config - INFO - Epoch [220/260], Train Loss: 0.3814
2024-03-28 23:04:16,937 - config - INFO - Validation Loss: 0.4062
2024-03-28 23:04:16,937 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:16,986 - config - INFO - Epoch [221/260], Train Loss: 0.3813
2024-03-28 23:04:16,987 - config - INFO - Validation Loss: 0.4064
2024-03-28 23:04:16,987 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:17,036 - config - INFO - Epoch [222/260], Train Loss: 0.3811
2024-03-28 23:04:17,038 - config - INFO - Validation Loss: 0.4050
2024-03-28 23:04:17,038 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:17,086 - config - INFO - Epoch [223/260], Train Loss: 0.3812
2024-03-28 23:04:17,088 - config - INFO - Validation Loss: 0.4067
2024-03-28 23:04:17,088 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:17,137 - config - INFO - Epoch [224/260], Train Loss: 0.3809
2024-03-28 23:04:17,138 - config - INFO - Validation Loss: 0.4059
2024-03-28 23:04:17,138 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:17,187 - config - INFO - Epoch [225/260], Train Loss: 0.3810
2024-03-28 23:04:17,188 - config - INFO - Validation Loss: 0.4056
2024-03-28 23:04:17,188 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:17,237 - config - INFO - Epoch [226/260], Train Loss: 0.3806
2024-03-28 23:04:17,239 - config - INFO - Validation Loss: 0.4062
2024-03-28 23:04:17,239 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:17,287 - config - INFO - Epoch [227/260], Train Loss: 0.3806
2024-03-28 23:04:17,289 - config - INFO - Validation Loss: 0.4061
2024-03-28 23:04:17,289 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:17,338 - config - INFO - Epoch [228/260], Train Loss: 0.3805
2024-03-28 23:04:17,340 - config - INFO - Validation Loss: 0.4059
2024-03-28 23:04:17,340 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:17,389 - config - INFO - Epoch [229/260], Train Loss: 0.3807
2024-03-28 23:04:17,390 - config - INFO - Validation Loss: 0.4045
2024-03-28 23:04:17,390 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:17,439 - config - INFO - Epoch [230/260], Train Loss: 0.3806
2024-03-28 23:04:17,441 - config - INFO - Validation Loss: 0.4058
2024-03-28 23:04:17,441 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:17,489 - config - INFO - Epoch [231/260], Train Loss: 0.3804
2024-03-28 23:04:17,491 - config - INFO - Validation Loss: 0.4047
2024-03-28 23:04:17,491 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:17,539 - config - INFO - Epoch [232/260], Train Loss: 0.3804
2024-03-28 23:04:17,541 - config - INFO - Validation Loss: 0.4066
2024-03-28 23:04:17,541 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:17,590 - config - INFO - Epoch [233/260], Train Loss: 0.3800
2024-03-28 23:04:17,591 - config - INFO - Validation Loss: 0.4061
2024-03-28 23:04:17,591 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:17,640 - config - INFO - Epoch [234/260], Train Loss: 0.3800
2024-03-28 23:04:17,642 - config - INFO - Validation Loss: 0.4056
2024-03-28 23:04:17,642 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:17,690 - config - INFO - Epoch [235/260], Train Loss: 0.3798
2024-03-28 23:04:17,692 - config - INFO - Validation Loss: 0.4048
2024-03-28 23:04:17,692 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:17,741 - config - INFO - Epoch [236/260], Train Loss: 0.3801
2024-03-28 23:04:17,742 - config - INFO - Validation Loss: 0.4076
2024-03-28 23:04:17,743 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:17,791 - config - INFO - Epoch [237/260], Train Loss: 0.3796
2024-03-28 23:04:17,793 - config - INFO - Validation Loss: 0.4047
2024-03-28 23:04:17,793 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:17,841 - config - INFO - Epoch [238/260], Train Loss: 0.3794
2024-03-28 23:04:17,843 - config - INFO - Validation Loss: 0.4049
2024-03-28 23:04:17,843 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:17,892 - config - INFO - Epoch [239/260], Train Loss: 0.3794
2024-03-28 23:04:17,893 - config - INFO - Validation Loss: 0.4048
2024-03-28 23:04:17,893 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:17,942 - config - INFO - Epoch [240/260], Train Loss: 0.3792
2024-03-28 23:04:17,944 - config - INFO - Validation Loss: 0.4060
2024-03-28 23:04:17,944 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:17,992 - config - INFO - Epoch [241/260], Train Loss: 0.3793
2024-03-28 23:04:17,994 - config - INFO - Validation Loss: 0.4054
2024-03-28 23:04:17,994 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:18,043 - config - INFO - Epoch [242/260], Train Loss: 0.3791
2024-03-28 23:04:18,044 - config - INFO - Validation Loss: 0.4055
2024-03-28 23:04:18,044 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:18,093 - config - INFO - Epoch [243/260], Train Loss: 0.3789
2024-03-28 23:04:18,094 - config - INFO - Validation Loss: 0.4034
2024-03-28 23:04:18,095 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:18,143 - config - INFO - Epoch [244/260], Train Loss: 0.3790
2024-03-28 23:04:18,145 - config - INFO - Validation Loss: 0.4044
2024-03-28 23:04:18,145 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:18,193 - config - INFO - Epoch [245/260], Train Loss: 0.3787
2024-03-28 23:04:18,195 - config - INFO - Validation Loss: 0.4040
2024-03-28 23:04:18,195 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:18,247 - config - INFO - Epoch [246/260], Train Loss: 0.3787
2024-03-28 23:04:18,249 - config - INFO - Validation Loss: 0.4043
2024-03-28 23:04:18,249 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:18,298 - config - INFO - Epoch [247/260], Train Loss: 0.3787
2024-03-28 23:04:18,299 - config - INFO - Validation Loss: 0.4028
2024-03-28 23:04:18,300 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:18,348 - config - INFO - Epoch [248/260], Train Loss: 0.3790
2024-03-28 23:04:18,350 - config - INFO - Validation Loss: 0.4045
2024-03-28 23:04:18,350 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:18,398 - config - INFO - Epoch [249/260], Train Loss: 0.3784
2024-03-28 23:04:18,400 - config - INFO - Validation Loss: 0.4030
2024-03-28 23:04:18,400 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:18,449 - config - INFO - Epoch [250/260], Train Loss: 0.3784
2024-03-28 23:04:18,451 - config - INFO - Validation Loss: 0.4037
2024-03-28 23:04:18,451 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:18,499 - config - INFO - Epoch [251/260], Train Loss: 0.3781
2024-03-28 23:04:18,501 - config - INFO - Validation Loss: 0.4037
2024-03-28 23:04:18,501 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:18,549 - config - INFO - Epoch [252/260], Train Loss: 0.3782
2024-03-28 23:04:18,551 - config - INFO - Validation Loss: 0.4029
2024-03-28 23:04:18,551 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:18,600 - config - INFO - Epoch [253/260], Train Loss: 0.3780
2024-03-28 23:04:18,601 - config - INFO - Validation Loss: 0.4039
2024-03-28 23:04:18,601 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:18,650 - config - INFO - Epoch [254/260], Train Loss: 0.3782
2024-03-28 23:04:18,651 - config - INFO - Validation Loss: 0.4042
2024-03-28 23:04:18,651 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:18,700 - config - INFO - Epoch [255/260], Train Loss: 0.3780
2024-03-28 23:04:18,701 - config - INFO - Validation Loss: 0.4043
2024-03-28 23:04:18,702 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:18,750 - config - INFO - Epoch [256/260], Train Loss: 0.3776
2024-03-28 23:04:18,752 - config - INFO - Validation Loss: 0.4050
2024-03-28 23:04:18,752 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:18,800 - config - INFO - Epoch [257/260], Train Loss: 0.3777
2024-03-28 23:04:18,802 - config - INFO - Validation Loss: 0.4047
2024-03-28 23:04:18,802 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:18,850 - config - INFO - Epoch [258/260], Train Loss: 0.3774
2024-03-28 23:04:18,852 - config - INFO - Validation Loss: 0.4039
2024-03-28 23:04:18,852 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:18,900 - config - INFO - Epoch [259/260], Train Loss: 0.3775
2024-03-28 23:04:18,902 - config - INFO - Validation Loss: 0.4037
2024-03-28 23:04:18,902 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:04:18,951 - config - INFO - Epoch [260/260], Train Loss: 0.3776
2024-03-28 23:04:18,952 - config - INFO - Validation Loss: 0.4024
2024-03-28 23:04:18,952 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:33,533 - config - INFO - resume: None
2024-03-28 23:05:33,533 - config - INFO - device: cpu
2024-03-28 23:05:33,533 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 23:05:33,534 - config - INFO - learning_rate: 0.0001
2024-03-28 23:05:33,534 - config - INFO - num_epochs: 260
2024-03-28 23:05:33,534 - config - INFO - batch_size: 32
2024-03-28 23:05:33,534 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.3

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 23:05:33,555 - config - INFO - Dataset size: 891
2024-03-28 23:05:33,579 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.95 * len(self.train_dataset))
        val_size = int(0.05 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 23:05:33,579 - config - INFO - Training start
2024-03-28 23:05:35,795 - config - INFO - Epoch [1/260], Train Loss: 0.7093
2024-03-28 23:05:35,797 - config - INFO - Validation Loss: 0.6991
2024-03-28 23:05:35,798 - config - INFO - Validation Acc: 0.3333
2024-03-28 23:05:35,853 - config - INFO - Epoch [2/260], Train Loss: 0.6993
2024-03-28 23:05:35,855 - config - INFO - Validation Loss: 0.6901
2024-03-28 23:05:35,855 - config - INFO - Validation Acc: 0.4167
2024-03-28 23:05:35,909 - config - INFO - Epoch [3/260], Train Loss: 0.6897
2024-03-28 23:05:35,911 - config - INFO - Validation Loss: 0.6813
2024-03-28 23:05:35,911 - config - INFO - Validation Acc: 0.5000
2024-03-28 23:05:35,962 - config - INFO - Epoch [4/260], Train Loss: 0.6802
2024-03-28 23:05:35,964 - config - INFO - Validation Loss: 0.6725
2024-03-28 23:05:35,964 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:36,016 - config - INFO - Epoch [5/260], Train Loss: 0.6708
2024-03-28 23:05:36,018 - config - INFO - Validation Loss: 0.6640
2024-03-28 23:05:36,018 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:36,069 - config - INFO - Epoch [6/260], Train Loss: 0.6612
2024-03-28 23:05:36,071 - config - INFO - Validation Loss: 0.6544
2024-03-28 23:05:36,071 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:36,122 - config - INFO - Epoch [7/260], Train Loss: 0.6510
2024-03-28 23:05:36,124 - config - INFO - Validation Loss: 0.6444
2024-03-28 23:05:36,124 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:36,175 - config - INFO - Epoch [8/260], Train Loss: 0.6400
2024-03-28 23:05:36,177 - config - INFO - Validation Loss: 0.6335
2024-03-28 23:05:36,177 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:05:36,228 - config - INFO - Epoch [9/260], Train Loss: 0.6283
2024-03-28 23:05:36,230 - config - INFO - Validation Loss: 0.6218
2024-03-28 23:05:36,230 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:36,297 - config - INFO - Epoch [10/260], Train Loss: 0.6159
2024-03-28 23:05:36,299 - config - INFO - Validation Loss: 0.6099
2024-03-28 23:05:36,299 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:36,350 - config - INFO - Epoch [11/260], Train Loss: 0.6033
2024-03-28 23:05:36,352 - config - INFO - Validation Loss: 0.5977
2024-03-28 23:05:36,352 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:36,403 - config - INFO - Epoch [12/260], Train Loss: 0.5902
2024-03-28 23:05:36,405 - config - INFO - Validation Loss: 0.5854
2024-03-28 23:05:36,405 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:36,456 - config - INFO - Epoch [13/260], Train Loss: 0.5774
2024-03-28 23:05:36,458 - config - INFO - Validation Loss: 0.5732
2024-03-28 23:05:36,458 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:36,510 - config - INFO - Epoch [14/260], Train Loss: 0.5640
2024-03-28 23:05:36,512 - config - INFO - Validation Loss: 0.5617
2024-03-28 23:05:36,512 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:36,563 - config - INFO - Epoch [15/260], Train Loss: 0.5516
2024-03-28 23:05:36,565 - config - INFO - Validation Loss: 0.5502
2024-03-28 23:05:36,565 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:36,616 - config - INFO - Epoch [16/260], Train Loss: 0.5395
2024-03-28 23:05:36,618 - config - INFO - Validation Loss: 0.5392
2024-03-28 23:05:36,618 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:36,670 - config - INFO - Epoch [17/260], Train Loss: 0.5279
2024-03-28 23:05:36,671 - config - INFO - Validation Loss: 0.5288
2024-03-28 23:05:36,672 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:36,731 - config - INFO - Epoch [18/260], Train Loss: 0.5168
2024-03-28 23:05:36,732 - config - INFO - Validation Loss: 0.5185
2024-03-28 23:05:36,733 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:36,784 - config - INFO - Epoch [19/260], Train Loss: 0.5065
2024-03-28 23:05:36,785 - config - INFO - Validation Loss: 0.5097
2024-03-28 23:05:36,786 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:36,837 - config - INFO - Epoch [20/260], Train Loss: 0.4971
2024-03-28 23:05:36,838 - config - INFO - Validation Loss: 0.5008
2024-03-28 23:05:36,839 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:36,890 - config - INFO - Epoch [21/260], Train Loss: 0.4881
2024-03-28 23:05:36,892 - config - INFO - Validation Loss: 0.4930
2024-03-28 23:05:36,892 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:36,943 - config - INFO - Epoch [22/260], Train Loss: 0.4802
2024-03-28 23:05:36,945 - config - INFO - Validation Loss: 0.4850
2024-03-28 23:05:36,945 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:36,997 - config - INFO - Epoch [23/260], Train Loss: 0.4728
2024-03-28 23:05:36,999 - config - INFO - Validation Loss: 0.4786
2024-03-28 23:05:36,999 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:37,049 - config - INFO - Epoch [24/260], Train Loss: 0.4663
2024-03-28 23:05:37,051 - config - INFO - Validation Loss: 0.4722
2024-03-28 23:05:37,051 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:37,102 - config - INFO - Epoch [25/260], Train Loss: 0.4604
2024-03-28 23:05:37,103 - config - INFO - Validation Loss: 0.4668
2024-03-28 23:05:37,104 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:37,154 - config - INFO - Epoch [26/260], Train Loss: 0.4551
2024-03-28 23:05:37,156 - config - INFO - Validation Loss: 0.4616
2024-03-28 23:05:37,156 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:37,206 - config - INFO - Epoch [27/260], Train Loss: 0.4506
2024-03-28 23:05:37,208 - config - INFO - Validation Loss: 0.4572
2024-03-28 23:05:37,208 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:37,258 - config - INFO - Epoch [28/260], Train Loss: 0.4467
2024-03-28 23:05:37,260 - config - INFO - Validation Loss: 0.4537
2024-03-28 23:05:37,260 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:37,311 - config - INFO - Epoch [29/260], Train Loss: 0.4428
2024-03-28 23:05:37,313 - config - INFO - Validation Loss: 0.4499
2024-03-28 23:05:37,313 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:37,363 - config - INFO - Epoch [30/260], Train Loss: 0.4400
2024-03-28 23:05:37,365 - config - INFO - Validation Loss: 0.4472
2024-03-28 23:05:37,365 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:37,415 - config - INFO - Epoch [31/260], Train Loss: 0.4373
2024-03-28 23:05:37,417 - config - INFO - Validation Loss: 0.4447
2024-03-28 23:05:37,417 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:37,467 - config - INFO - Epoch [32/260], Train Loss: 0.4351
2024-03-28 23:05:37,469 - config - INFO - Validation Loss: 0.4427
2024-03-28 23:05:37,469 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:37,527 - config - INFO - Epoch [33/260], Train Loss: 0.4330
2024-03-28 23:05:37,529 - config - INFO - Validation Loss: 0.4405
2024-03-28 23:05:37,529 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:37,579 - config - INFO - Epoch [34/260], Train Loss: 0.4313
2024-03-28 23:05:37,581 - config - INFO - Validation Loss: 0.4380
2024-03-28 23:05:37,581 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:37,631 - config - INFO - Epoch [35/260], Train Loss: 0.4296
2024-03-28 23:05:37,633 - config - INFO - Validation Loss: 0.4366
2024-03-28 23:05:37,633 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:37,683 - config - INFO - Epoch [36/260], Train Loss: 0.4282
2024-03-28 23:05:37,685 - config - INFO - Validation Loss: 0.4348
2024-03-28 23:05:37,685 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:37,735 - config - INFO - Epoch [37/260], Train Loss: 0.4270
2024-03-28 23:05:37,736 - config - INFO - Validation Loss: 0.4331
2024-03-28 23:05:37,737 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:37,787 - config - INFO - Epoch [38/260], Train Loss: 0.4257
2024-03-28 23:05:37,789 - config - INFO - Validation Loss: 0.4318
2024-03-28 23:05:37,789 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:37,839 - config - INFO - Epoch [39/260], Train Loss: 0.4248
2024-03-28 23:05:37,840 - config - INFO - Validation Loss: 0.4303
2024-03-28 23:05:37,840 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:37,890 - config - INFO - Epoch [40/260], Train Loss: 0.4238
2024-03-28 23:05:37,892 - config - INFO - Validation Loss: 0.4293
2024-03-28 23:05:37,892 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:37,942 - config - INFO - Epoch [41/260], Train Loss: 0.4230
2024-03-28 23:05:37,944 - config - INFO - Validation Loss: 0.4284
2024-03-28 23:05:37,944 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:37,994 - config - INFO - Epoch [42/260], Train Loss: 0.4225
2024-03-28 23:05:37,996 - config - INFO - Validation Loss: 0.4271
2024-03-28 23:05:37,996 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:38,046 - config - INFO - Epoch [43/260], Train Loss: 0.4216
2024-03-28 23:05:38,047 - config - INFO - Validation Loss: 0.4261
2024-03-28 23:05:38,047 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:38,097 - config - INFO - Epoch [44/260], Train Loss: 0.4210
2024-03-28 23:05:38,099 - config - INFO - Validation Loss: 0.4245
2024-03-28 23:05:38,099 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:38,149 - config - INFO - Epoch [45/260], Train Loss: 0.4203
2024-03-28 23:05:38,151 - config - INFO - Validation Loss: 0.4239
2024-03-28 23:05:38,151 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:38,201 - config - INFO - Epoch [46/260], Train Loss: 0.4196
2024-03-28 23:05:38,203 - config - INFO - Validation Loss: 0.4233
2024-03-28 23:05:38,203 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:38,253 - config - INFO - Epoch [47/260], Train Loss: 0.4190
2024-03-28 23:05:38,254 - config - INFO - Validation Loss: 0.4223
2024-03-28 23:05:38,255 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:38,304 - config - INFO - Epoch [48/260], Train Loss: 0.4185
2024-03-28 23:05:38,306 - config - INFO - Validation Loss: 0.4216
2024-03-28 23:05:38,306 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:38,356 - config - INFO - Epoch [49/260], Train Loss: 0.4179
2024-03-28 23:05:38,358 - config - INFO - Validation Loss: 0.4209
2024-03-28 23:05:38,358 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:38,408 - config - INFO - Epoch [50/260], Train Loss: 0.4175
2024-03-28 23:05:38,410 - config - INFO - Validation Loss: 0.4204
2024-03-28 23:05:38,410 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:38,460 - config - INFO - Epoch [51/260], Train Loss: 0.4169
2024-03-28 23:05:38,461 - config - INFO - Validation Loss: 0.4195
2024-03-28 23:05:38,462 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:38,525 - config - INFO - Epoch [52/260], Train Loss: 0.4166
2024-03-28 23:05:38,527 - config - INFO - Validation Loss: 0.4190
2024-03-28 23:05:38,527 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:38,577 - config - INFO - Epoch [53/260], Train Loss: 0.4159
2024-03-28 23:05:38,579 - config - INFO - Validation Loss: 0.4187
2024-03-28 23:05:38,579 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:38,628 - config - INFO - Epoch [54/260], Train Loss: 0.4156
2024-03-28 23:05:38,630 - config - INFO - Validation Loss: 0.4176
2024-03-28 23:05:38,630 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:38,679 - config - INFO - Epoch [55/260], Train Loss: 0.4150
2024-03-28 23:05:38,681 - config - INFO - Validation Loss: 0.4175
2024-03-28 23:05:38,681 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:38,730 - config - INFO - Epoch [56/260], Train Loss: 0.4148
2024-03-28 23:05:38,732 - config - INFO - Validation Loss: 0.4173
2024-03-28 23:05:38,732 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:38,781 - config - INFO - Epoch [57/260], Train Loss: 0.4142
2024-03-28 23:05:38,783 - config - INFO - Validation Loss: 0.4163
2024-03-28 23:05:38,783 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:38,832 - config - INFO - Epoch [58/260], Train Loss: 0.4138
2024-03-28 23:05:38,834 - config - INFO - Validation Loss: 0.4157
2024-03-28 23:05:38,834 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:38,883 - config - INFO - Epoch [59/260], Train Loss: 0.4133
2024-03-28 23:05:38,885 - config - INFO - Validation Loss: 0.4153
2024-03-28 23:05:38,885 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:38,934 - config - INFO - Epoch [60/260], Train Loss: 0.4130
2024-03-28 23:05:38,936 - config - INFO - Validation Loss: 0.4151
2024-03-28 23:05:38,936 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:38,986 - config - INFO - Epoch [61/260], Train Loss: 0.4126
2024-03-28 23:05:38,987 - config - INFO - Validation Loss: 0.4143
2024-03-28 23:05:38,987 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:39,037 - config - INFO - Epoch [62/260], Train Loss: 0.4124
2024-03-28 23:05:39,038 - config - INFO - Validation Loss: 0.4141
2024-03-28 23:05:39,039 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:39,088 - config - INFO - Epoch [63/260], Train Loss: 0.4118
2024-03-28 23:05:39,090 - config - INFO - Validation Loss: 0.4132
2024-03-28 23:05:39,090 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:39,139 - config - INFO - Epoch [64/260], Train Loss: 0.4114
2024-03-28 23:05:39,141 - config - INFO - Validation Loss: 0.4126
2024-03-28 23:05:39,141 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:39,190 - config - INFO - Epoch [65/260], Train Loss: 0.4111
2024-03-28 23:05:39,192 - config - INFO - Validation Loss: 0.4122
2024-03-28 23:05:39,192 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:39,241 - config - INFO - Epoch [66/260], Train Loss: 0.4108
2024-03-28 23:05:39,243 - config - INFO - Validation Loss: 0.4117
2024-03-28 23:05:39,243 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:39,294 - config - INFO - Epoch [67/260], Train Loss: 0.4104
2024-03-28 23:05:39,296 - config - INFO - Validation Loss: 0.4112
2024-03-28 23:05:39,296 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:39,345 - config - INFO - Epoch [68/260], Train Loss: 0.4102
2024-03-28 23:05:39,347 - config - INFO - Validation Loss: 0.4101
2024-03-28 23:05:39,347 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:39,396 - config - INFO - Epoch [69/260], Train Loss: 0.4097
2024-03-28 23:05:39,398 - config - INFO - Validation Loss: 0.4104
2024-03-28 23:05:39,398 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:39,447 - config - INFO - Epoch [70/260], Train Loss: 0.4095
2024-03-28 23:05:39,449 - config - INFO - Validation Loss: 0.4107
2024-03-28 23:05:39,449 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:39,499 - config - INFO - Epoch [71/260], Train Loss: 0.4092
2024-03-28 23:05:39,500 - config - INFO - Validation Loss: 0.4103
2024-03-28 23:05:39,500 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:39,553 - config - INFO - Epoch [72/260], Train Loss: 0.4087
2024-03-28 23:05:39,555 - config - INFO - Validation Loss: 0.4101
2024-03-28 23:05:39,555 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:39,605 - config - INFO - Epoch [73/260], Train Loss: 0.4085
2024-03-28 23:05:39,607 - config - INFO - Validation Loss: 0.4101
2024-03-28 23:05:39,607 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:39,656 - config - INFO - Epoch [74/260], Train Loss: 0.4081
2024-03-28 23:05:39,658 - config - INFO - Validation Loss: 0.4088
2024-03-28 23:05:39,658 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:39,708 - config - INFO - Epoch [75/260], Train Loss: 0.4079
2024-03-28 23:05:39,709 - config - INFO - Validation Loss: 0.4086
2024-03-28 23:05:39,709 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:39,759 - config - INFO - Epoch [76/260], Train Loss: 0.4074
2024-03-28 23:05:39,761 - config - INFO - Validation Loss: 0.4091
2024-03-28 23:05:39,761 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:39,811 - config - INFO - Epoch [77/260], Train Loss: 0.4071
2024-03-28 23:05:39,812 - config - INFO - Validation Loss: 0.4091
2024-03-28 23:05:39,812 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:39,862 - config - INFO - Epoch [78/260], Train Loss: 0.4070
2024-03-28 23:05:39,863 - config - INFO - Validation Loss: 0.4082
2024-03-28 23:05:39,864 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:39,913 - config - INFO - Epoch [79/260], Train Loss: 0.4070
2024-03-28 23:05:39,915 - config - INFO - Validation Loss: 0.4074
2024-03-28 23:05:39,915 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:39,965 - config - INFO - Epoch [80/260], Train Loss: 0.4063
2024-03-28 23:05:39,966 - config - INFO - Validation Loss: 0.4072
2024-03-28 23:05:39,966 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:40,016 - config - INFO - Epoch [81/260], Train Loss: 0.4060
2024-03-28 23:05:40,018 - config - INFO - Validation Loss: 0.4072
2024-03-28 23:05:40,018 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:40,067 - config - INFO - Epoch [82/260], Train Loss: 0.4059
2024-03-28 23:05:40,069 - config - INFO - Validation Loss: 0.4068
2024-03-28 23:05:40,069 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:40,119 - config - INFO - Epoch [83/260], Train Loss: 0.4053
2024-03-28 23:05:40,120 - config - INFO - Validation Loss: 0.4074
2024-03-28 23:05:40,120 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:40,170 - config - INFO - Epoch [84/260], Train Loss: 0.4052
2024-03-28 23:05:40,172 - config - INFO - Validation Loss: 0.4068
2024-03-28 23:05:40,172 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:40,221 - config - INFO - Epoch [85/260], Train Loss: 0.4048
2024-03-28 23:05:40,223 - config - INFO - Validation Loss: 0.4066
2024-03-28 23:05:40,223 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:40,273 - config - INFO - Epoch [86/260], Train Loss: 0.4046
2024-03-28 23:05:40,274 - config - INFO - Validation Loss: 0.4056
2024-03-28 23:05:40,274 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:40,324 - config - INFO - Epoch [87/260], Train Loss: 0.4045
2024-03-28 23:05:40,326 - config - INFO - Validation Loss: 0.4062
2024-03-28 23:05:40,326 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:40,375 - config - INFO - Epoch [88/260], Train Loss: 0.4042
2024-03-28 23:05:40,377 - config - INFO - Validation Loss: 0.4053
2024-03-28 23:05:40,377 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:40,426 - config - INFO - Epoch [89/260], Train Loss: 0.4038
2024-03-28 23:05:40,428 - config - INFO - Validation Loss: 0.4050
2024-03-28 23:05:40,428 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:05:40,478 - config - INFO - Epoch [90/260], Train Loss: 0.4035
2024-03-28 23:05:40,479 - config - INFO - Validation Loss: 0.4042
2024-03-28 23:05:40,479 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:40,532 - config - INFO - Epoch [91/260], Train Loss: 0.4032
2024-03-28 23:05:40,534 - config - INFO - Validation Loss: 0.4042
2024-03-28 23:05:40,534 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:40,584 - config - INFO - Epoch [92/260], Train Loss: 0.4030
2024-03-28 23:05:40,585 - config - INFO - Validation Loss: 0.4049
2024-03-28 23:05:40,585 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:40,635 - config - INFO - Epoch [93/260], Train Loss: 0.4029
2024-03-28 23:05:40,636 - config - INFO - Validation Loss: 0.4038
2024-03-28 23:05:40,637 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:40,686 - config - INFO - Epoch [94/260], Train Loss: 0.4025
2024-03-28 23:05:40,688 - config - INFO - Validation Loss: 0.4043
2024-03-28 23:05:40,688 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:40,737 - config - INFO - Epoch [95/260], Train Loss: 0.4024
2024-03-28 23:05:40,739 - config - INFO - Validation Loss: 0.4037
2024-03-28 23:05:40,739 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:40,788 - config - INFO - Epoch [96/260], Train Loss: 0.4020
2024-03-28 23:05:40,790 - config - INFO - Validation Loss: 0.4036
2024-03-28 23:05:40,790 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:40,840 - config - INFO - Epoch [97/260], Train Loss: 0.4021
2024-03-28 23:05:40,841 - config - INFO - Validation Loss: 0.4041
2024-03-28 23:05:40,841 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:40,891 - config - INFO - Epoch [98/260], Train Loss: 0.4017
2024-03-28 23:05:40,892 - config - INFO - Validation Loss: 0.4035
2024-03-28 23:05:40,893 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:40,942 - config - INFO - Epoch [99/260], Train Loss: 0.4014
2024-03-28 23:05:40,944 - config - INFO - Validation Loss: 0.4036
2024-03-28 23:05:40,944 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:40,993 - config - INFO - Epoch [100/260], Train Loss: 0.4011
2024-03-28 23:05:40,995 - config - INFO - Validation Loss: 0.4037
2024-03-28 23:05:40,995 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:41,044 - config - INFO - Epoch [101/260], Train Loss: 0.4010
2024-03-28 23:05:41,046 - config - INFO - Validation Loss: 0.4033
2024-03-28 23:05:41,046 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:41,096 - config - INFO - Epoch [102/260], Train Loss: 0.4008
2024-03-28 23:05:41,097 - config - INFO - Validation Loss: 0.4019
2024-03-28 23:05:41,097 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:41,147 - config - INFO - Epoch [103/260], Train Loss: 0.4004
2024-03-28 23:05:41,148 - config - INFO - Validation Loss: 0.4024
2024-03-28 23:05:41,149 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:41,198 - config - INFO - Epoch [104/260], Train Loss: 0.4001
2024-03-28 23:05:41,200 - config - INFO - Validation Loss: 0.4024
2024-03-28 23:05:41,200 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:41,249 - config - INFO - Epoch [105/260], Train Loss: 0.4000
2024-03-28 23:05:41,251 - config - INFO - Validation Loss: 0.4018
2024-03-28 23:05:41,251 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:41,301 - config - INFO - Epoch [106/260], Train Loss: 0.3998
2024-03-28 23:05:41,302 - config - INFO - Validation Loss: 0.4020
2024-03-28 23:05:41,302 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:41,352 - config - INFO - Epoch [107/260], Train Loss: 0.3995
2024-03-28 23:05:41,353 - config - INFO - Validation Loss: 0.4019
2024-03-28 23:05:41,354 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:41,403 - config - INFO - Epoch [108/260], Train Loss: 0.3992
2024-03-28 23:05:41,405 - config - INFO - Validation Loss: 0.4022
2024-03-28 23:05:41,405 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:41,454 - config - INFO - Epoch [109/260], Train Loss: 0.3992
2024-03-28 23:05:41,456 - config - INFO - Validation Loss: 0.4020
2024-03-28 23:05:41,456 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:41,512 - config - INFO - Epoch [110/260], Train Loss: 0.3991
2024-03-28 23:05:41,514 - config - INFO - Validation Loss: 0.4013
2024-03-28 23:05:41,514 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:41,564 - config - INFO - Epoch [111/260], Train Loss: 0.3986
2024-03-28 23:05:41,566 - config - INFO - Validation Loss: 0.4013
2024-03-28 23:05:41,566 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:41,615 - config - INFO - Epoch [112/260], Train Loss: 0.3985
2024-03-28 23:05:41,617 - config - INFO - Validation Loss: 0.4011
2024-03-28 23:05:41,617 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:41,667 - config - INFO - Epoch [113/260], Train Loss: 0.3982
2024-03-28 23:05:41,668 - config - INFO - Validation Loss: 0.4011
2024-03-28 23:05:41,668 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:41,718 - config - INFO - Epoch [114/260], Train Loss: 0.3981
2024-03-28 23:05:41,720 - config - INFO - Validation Loss: 0.4014
2024-03-28 23:05:41,720 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:41,769 - config - INFO - Epoch [115/260], Train Loss: 0.3977
2024-03-28 23:05:41,771 - config - INFO - Validation Loss: 0.4003
2024-03-28 23:05:41,771 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:41,821 - config - INFO - Epoch [116/260], Train Loss: 0.3976
2024-03-28 23:05:41,822 - config - INFO - Validation Loss: 0.4001
2024-03-28 23:05:41,822 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:41,872 - config - INFO - Epoch [117/260], Train Loss: 0.3974
2024-03-28 23:05:41,873 - config - INFO - Validation Loss: 0.3997
2024-03-28 23:05:41,874 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:41,923 - config - INFO - Epoch [118/260], Train Loss: 0.3972
2024-03-28 23:05:41,925 - config - INFO - Validation Loss: 0.4001
2024-03-28 23:05:41,925 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:41,974 - config - INFO - Epoch [119/260], Train Loss: 0.3973
2024-03-28 23:05:41,976 - config - INFO - Validation Loss: 0.4003
2024-03-28 23:05:41,976 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:42,025 - config - INFO - Epoch [120/260], Train Loss: 0.3968
2024-03-28 23:05:42,027 - config - INFO - Validation Loss: 0.4008
2024-03-28 23:05:42,027 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:42,076 - config - INFO - Epoch [121/260], Train Loss: 0.3969
2024-03-28 23:05:42,078 - config - INFO - Validation Loss: 0.4001
2024-03-28 23:05:42,078 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:42,128 - config - INFO - Epoch [122/260], Train Loss: 0.3965
2024-03-28 23:05:42,129 - config - INFO - Validation Loss: 0.3999
2024-03-28 23:05:42,129 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:42,179 - config - INFO - Epoch [123/260], Train Loss: 0.3962
2024-03-28 23:05:42,180 - config - INFO - Validation Loss: 0.4010
2024-03-28 23:05:42,181 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:42,230 - config - INFO - Epoch [124/260], Train Loss: 0.3962
2024-03-28 23:05:42,232 - config - INFO - Validation Loss: 0.4001
2024-03-28 23:05:42,232 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:42,281 - config - INFO - Epoch [125/260], Train Loss: 0.3957
2024-03-28 23:05:42,283 - config - INFO - Validation Loss: 0.4001
2024-03-28 23:05:42,283 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:42,332 - config - INFO - Epoch [126/260], Train Loss: 0.3956
2024-03-28 23:05:42,334 - config - INFO - Validation Loss: 0.3996
2024-03-28 23:05:42,334 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:42,384 - config - INFO - Epoch [127/260], Train Loss: 0.3953
2024-03-28 23:05:42,385 - config - INFO - Validation Loss: 0.4000
2024-03-28 23:05:42,385 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:42,435 - config - INFO - Epoch [128/260], Train Loss: 0.3952
2024-03-28 23:05:42,436 - config - INFO - Validation Loss: 0.3999
2024-03-28 23:05:42,437 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:42,486 - config - INFO - Epoch [129/260], Train Loss: 0.3950
2024-03-28 23:05:42,488 - config - INFO - Validation Loss: 0.3999
2024-03-28 23:05:42,488 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:42,537 - config - INFO - Epoch [130/260], Train Loss: 0.3952
2024-03-28 23:05:42,539 - config - INFO - Validation Loss: 0.3988
2024-03-28 23:05:42,539 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:42,588 - config - INFO - Epoch [131/260], Train Loss: 0.3947
2024-03-28 23:05:42,590 - config - INFO - Validation Loss: 0.4000
2024-03-28 23:05:42,590 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:42,640 - config - INFO - Epoch [132/260], Train Loss: 0.3944
2024-03-28 23:05:42,641 - config - INFO - Validation Loss: 0.3994
2024-03-28 23:05:42,641 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:42,691 - config - INFO - Epoch [133/260], Train Loss: 0.3942
2024-03-28 23:05:42,692 - config - INFO - Validation Loss: 0.3987
2024-03-28 23:05:42,693 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:42,742 - config - INFO - Epoch [134/260], Train Loss: 0.3941
2024-03-28 23:05:42,744 - config - INFO - Validation Loss: 0.3988
2024-03-28 23:05:42,744 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:42,793 - config - INFO - Epoch [135/260], Train Loss: 0.3940
2024-03-28 23:05:42,795 - config - INFO - Validation Loss: 0.3989
2024-03-28 23:05:42,795 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:42,844 - config - INFO - Epoch [136/260], Train Loss: 0.3939
2024-03-28 23:05:42,846 - config - INFO - Validation Loss: 0.3991
2024-03-28 23:05:42,846 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:42,896 - config - INFO - Epoch [137/260], Train Loss: 0.3936
2024-03-28 23:05:42,897 - config - INFO - Validation Loss: 0.3994
2024-03-28 23:05:42,897 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:42,947 - config - INFO - Epoch [138/260], Train Loss: 0.3935
2024-03-28 23:05:42,949 - config - INFO - Validation Loss: 0.3985
2024-03-28 23:05:42,949 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:42,998 - config - INFO - Epoch [139/260], Train Loss: 0.3933
2024-03-28 23:05:43,000 - config - INFO - Validation Loss: 0.3988
2024-03-28 23:05:43,000 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:43,049 - config - INFO - Epoch [140/260], Train Loss: 0.3930
2024-03-28 23:05:43,051 - config - INFO - Validation Loss: 0.3989
2024-03-28 23:05:43,051 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:43,100 - config - INFO - Epoch [141/260], Train Loss: 0.3927
2024-03-28 23:05:43,102 - config - INFO - Validation Loss: 0.3988
2024-03-28 23:05:43,102 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:43,151 - config - INFO - Epoch [142/260], Train Loss: 0.3926
2024-03-28 23:05:43,153 - config - INFO - Validation Loss: 0.3986
2024-03-28 23:05:43,153 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:43,203 - config - INFO - Epoch [143/260], Train Loss: 0.3924
2024-03-28 23:05:43,204 - config - INFO - Validation Loss: 0.3978
2024-03-28 23:05:43,204 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:43,254 - config - INFO - Epoch [144/260], Train Loss: 0.3923
2024-03-28 23:05:43,255 - config - INFO - Validation Loss: 0.3988
2024-03-28 23:05:43,256 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:43,305 - config - INFO - Epoch [145/260], Train Loss: 0.3921
2024-03-28 23:05:43,307 - config - INFO - Validation Loss: 0.3982
2024-03-28 23:05:43,307 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:43,356 - config - INFO - Epoch [146/260], Train Loss: 0.3920
2024-03-28 23:05:43,358 - config - INFO - Validation Loss: 0.3983
2024-03-28 23:05:43,358 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:43,407 - config - INFO - Epoch [147/260], Train Loss: 0.3918
2024-03-28 23:05:43,409 - config - INFO - Validation Loss: 0.3980
2024-03-28 23:05:43,409 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:43,459 - config - INFO - Epoch [148/260], Train Loss: 0.3919
2024-03-28 23:05:43,460 - config - INFO - Validation Loss: 0.3981
2024-03-28 23:05:43,460 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:43,510 - config - INFO - Epoch [149/260], Train Loss: 0.3916
2024-03-28 23:05:43,512 - config - INFO - Validation Loss: 0.3976
2024-03-28 23:05:43,512 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:43,566 - config - INFO - Epoch [150/260], Train Loss: 0.3914
2024-03-28 23:05:43,568 - config - INFO - Validation Loss: 0.3980
2024-03-28 23:05:43,568 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:43,628 - config - INFO - Epoch [151/260], Train Loss: 0.3911
2024-03-28 23:05:43,630 - config - INFO - Validation Loss: 0.3971
2024-03-28 23:05:43,630 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:43,679 - config - INFO - Epoch [152/260], Train Loss: 0.3912
2024-03-28 23:05:43,681 - config - INFO - Validation Loss: 0.3967
2024-03-28 23:05:43,681 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:43,732 - config - INFO - Epoch [153/260], Train Loss: 0.3908
2024-03-28 23:05:43,733 - config - INFO - Validation Loss: 0.3970
2024-03-28 23:05:43,734 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:43,783 - config - INFO - Epoch [154/260], Train Loss: 0.3907
2024-03-28 23:05:43,785 - config - INFO - Validation Loss: 0.3970
2024-03-28 23:05:43,785 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:43,835 - config - INFO - Epoch [155/260], Train Loss: 0.3906
2024-03-28 23:05:43,837 - config - INFO - Validation Loss: 0.3963
2024-03-28 23:05:43,837 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:43,887 - config - INFO - Epoch [156/260], Train Loss: 0.3903
2024-03-28 23:05:43,888 - config - INFO - Validation Loss: 0.3970
2024-03-28 23:05:43,888 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:43,938 - config - INFO - Epoch [157/260], Train Loss: 0.3902
2024-03-28 23:05:43,940 - config - INFO - Validation Loss: 0.3968
2024-03-28 23:05:43,940 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:43,990 - config - INFO - Epoch [158/260], Train Loss: 0.3901
2024-03-28 23:05:43,991 - config - INFO - Validation Loss: 0.3967
2024-03-28 23:05:43,992 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:44,041 - config - INFO - Epoch [159/260], Train Loss: 0.3899
2024-03-28 23:05:44,043 - config - INFO - Validation Loss: 0.3972
2024-03-28 23:05:44,043 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:44,092 - config - INFO - Epoch [160/260], Train Loss: 0.3899
2024-03-28 23:05:44,094 - config - INFO - Validation Loss: 0.3978
2024-03-28 23:05:44,094 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:44,144 - config - INFO - Epoch [161/260], Train Loss: 0.3895
2024-03-28 23:05:44,146 - config - INFO - Validation Loss: 0.3974
2024-03-28 23:05:44,146 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:44,195 - config - INFO - Epoch [162/260], Train Loss: 0.3895
2024-03-28 23:05:44,197 - config - INFO - Validation Loss: 0.3961
2024-03-28 23:05:44,197 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:44,247 - config - INFO - Epoch [163/260], Train Loss: 0.3892
2024-03-28 23:05:44,248 - config - INFO - Validation Loss: 0.3965
2024-03-28 23:05:44,249 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:44,298 - config - INFO - Epoch [164/260], Train Loss: 0.3891
2024-03-28 23:05:44,300 - config - INFO - Validation Loss: 0.3970
2024-03-28 23:05:44,300 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:44,349 - config - INFO - Epoch [165/260], Train Loss: 0.3890
2024-03-28 23:05:44,351 - config - INFO - Validation Loss: 0.3965
2024-03-28 23:05:44,351 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:44,401 - config - INFO - Epoch [166/260], Train Loss: 0.3890
2024-03-28 23:05:44,403 - config - INFO - Validation Loss: 0.3962
2024-03-28 23:05:44,403 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:44,452 - config - INFO - Epoch [167/260], Train Loss: 0.3887
2024-03-28 23:05:44,454 - config - INFO - Validation Loss: 0.3971
2024-03-28 23:05:44,454 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:44,504 - config - INFO - Epoch [168/260], Train Loss: 0.3886
2024-03-28 23:05:44,505 - config - INFO - Validation Loss: 0.3970
2024-03-28 23:05:44,506 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:44,555 - config - INFO - Epoch [169/260], Train Loss: 0.3885
2024-03-28 23:05:44,557 - config - INFO - Validation Loss: 0.3958
2024-03-28 23:05:44,557 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:44,607 - config - INFO - Epoch [170/260], Train Loss: 0.3882
2024-03-28 23:05:44,608 - config - INFO - Validation Loss: 0.3961
2024-03-28 23:05:44,608 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:44,658 - config - INFO - Epoch [171/260], Train Loss: 0.3881
2024-03-28 23:05:44,660 - config - INFO - Validation Loss: 0.3965
2024-03-28 23:05:44,660 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:44,709 - config - INFO - Epoch [172/260], Train Loss: 0.3880
2024-03-28 23:05:44,711 - config - INFO - Validation Loss: 0.3960
2024-03-28 23:05:44,711 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:44,761 - config - INFO - Epoch [173/260], Train Loss: 0.3878
2024-03-28 23:05:44,763 - config - INFO - Validation Loss: 0.3959
2024-03-28 23:05:44,763 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:44,812 - config - INFO - Epoch [174/260], Train Loss: 0.3878
2024-03-28 23:05:44,814 - config - INFO - Validation Loss: 0.3956
2024-03-28 23:05:44,814 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:44,864 - config - INFO - Epoch [175/260], Train Loss: 0.3876
2024-03-28 23:05:44,866 - config - INFO - Validation Loss: 0.3953
2024-03-28 23:05:44,866 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:44,915 - config - INFO - Epoch [176/260], Train Loss: 0.3877
2024-03-28 23:05:44,917 - config - INFO - Validation Loss: 0.3962
2024-03-28 23:05:44,917 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:44,967 - config - INFO - Epoch [177/260], Train Loss: 0.3872
2024-03-28 23:05:44,968 - config - INFO - Validation Loss: 0.3966
2024-03-28 23:05:44,969 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:45,018 - config - INFO - Epoch [178/260], Train Loss: 0.3873
2024-03-28 23:05:45,020 - config - INFO - Validation Loss: 0.3961
2024-03-28 23:05:45,020 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:45,070 - config - INFO - Epoch [179/260], Train Loss: 0.3870
2024-03-28 23:05:45,071 - config - INFO - Validation Loss: 0.3958
2024-03-28 23:05:45,071 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:45,121 - config - INFO - Epoch [180/260], Train Loss: 0.3870
2024-03-28 23:05:45,123 - config - INFO - Validation Loss: 0.3961
2024-03-28 23:05:45,123 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:45,172 - config - INFO - Epoch [181/260], Train Loss: 0.3869
2024-03-28 23:05:45,174 - config - INFO - Validation Loss: 0.3957
2024-03-28 23:05:45,174 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:45,224 - config - INFO - Epoch [182/260], Train Loss: 0.3866
2024-03-28 23:05:45,225 - config - INFO - Validation Loss: 0.3956
2024-03-28 23:05:45,226 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:45,275 - config - INFO - Epoch [183/260], Train Loss: 0.3867
2024-03-28 23:05:45,277 - config - INFO - Validation Loss: 0.3955
2024-03-28 23:05:45,277 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:45,327 - config - INFO - Epoch [184/260], Train Loss: 0.3864
2024-03-28 23:05:45,329 - config - INFO - Validation Loss: 0.3953
2024-03-28 23:05:45,329 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:45,379 - config - INFO - Epoch [185/260], Train Loss: 0.3861
2024-03-28 23:05:45,380 - config - INFO - Validation Loss: 0.3953
2024-03-28 23:05:45,381 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:45,430 - config - INFO - Epoch [186/260], Train Loss: 0.3863
2024-03-28 23:05:45,432 - config - INFO - Validation Loss: 0.3966
2024-03-28 23:05:45,432 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:45,481 - config - INFO - Epoch [187/260], Train Loss: 0.3858
2024-03-28 23:05:45,483 - config - INFO - Validation Loss: 0.3953
2024-03-28 23:05:45,483 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:45,533 - config - INFO - Epoch [188/260], Train Loss: 0.3859
2024-03-28 23:05:45,534 - config - INFO - Validation Loss: 0.3947
2024-03-28 23:05:45,535 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:45,584 - config - INFO - Epoch [189/260], Train Loss: 0.3859
2024-03-28 23:05:45,586 - config - INFO - Validation Loss: 0.3957
2024-03-28 23:05:45,586 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:45,636 - config - INFO - Epoch [190/260], Train Loss: 0.3855
2024-03-28 23:05:45,637 - config - INFO - Validation Loss: 0.3963
2024-03-28 23:05:45,638 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:45,687 - config - INFO - Epoch [191/260], Train Loss: 0.3855
2024-03-28 23:05:45,689 - config - INFO - Validation Loss: 0.3962
2024-03-28 23:05:45,689 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:45,739 - config - INFO - Epoch [192/260], Train Loss: 0.3853
2024-03-28 23:05:45,741 - config - INFO - Validation Loss: 0.3948
2024-03-28 23:05:45,741 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:45,790 - config - INFO - Epoch [193/260], Train Loss: 0.3852
2024-03-28 23:05:45,792 - config - INFO - Validation Loss: 0.3950
2024-03-28 23:05:45,792 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:45,842 - config - INFO - Epoch [194/260], Train Loss: 0.3851
2024-03-28 23:05:45,843 - config - INFO - Validation Loss: 0.3955
2024-03-28 23:05:45,844 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:45,893 - config - INFO - Epoch [195/260], Train Loss: 0.3848
2024-03-28 23:05:45,895 - config - INFO - Validation Loss: 0.3955
2024-03-28 23:05:45,895 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:45,945 - config - INFO - Epoch [196/260], Train Loss: 0.3848
2024-03-28 23:05:45,946 - config - INFO - Validation Loss: 0.3950
2024-03-28 23:05:45,946 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:45,996 - config - INFO - Epoch [197/260], Train Loss: 0.3847
2024-03-28 23:05:45,998 - config - INFO - Validation Loss: 0.3964
2024-03-28 23:05:45,998 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:46,047 - config - INFO - Epoch [198/260], Train Loss: 0.3844
2024-03-28 23:05:46,049 - config - INFO - Validation Loss: 0.3963
2024-03-28 23:05:46,049 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:46,098 - config - INFO - Epoch [199/260], Train Loss: 0.3847
2024-03-28 23:05:46,100 - config - INFO - Validation Loss: 0.3959
2024-03-28 23:05:46,100 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:46,150 - config - INFO - Epoch [200/260], Train Loss: 0.3843
2024-03-28 23:05:46,152 - config - INFO - Validation Loss: 0.3950
2024-03-28 23:05:46,152 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:46,201 - config - INFO - Epoch [201/260], Train Loss: 0.3842
2024-03-28 23:05:46,203 - config - INFO - Validation Loss: 0.3956
2024-03-28 23:05:46,203 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:46,252 - config - INFO - Epoch [202/260], Train Loss: 0.3842
2024-03-28 23:05:46,254 - config - INFO - Validation Loss: 0.3947
2024-03-28 23:05:46,254 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:46,304 - config - INFO - Epoch [203/260], Train Loss: 0.3838
2024-03-28 23:05:46,306 - config - INFO - Validation Loss: 0.3956
2024-03-28 23:05:46,306 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:46,355 - config - INFO - Epoch [204/260], Train Loss: 0.3836
2024-03-28 23:05:46,357 - config - INFO - Validation Loss: 0.3955
2024-03-28 23:05:46,357 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:46,407 - config - INFO - Epoch [205/260], Train Loss: 0.3839
2024-03-28 23:05:46,408 - config - INFO - Validation Loss: 0.3946
2024-03-28 23:05:46,408 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:46,458 - config - INFO - Epoch [206/260], Train Loss: 0.3834
2024-03-28 23:05:46,460 - config - INFO - Validation Loss: 0.3961
2024-03-28 23:05:46,460 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:46,510 - config - INFO - Epoch [207/260], Train Loss: 0.3834
2024-03-28 23:05:46,511 - config - INFO - Validation Loss: 0.3967
2024-03-28 23:05:46,512 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:46,561 - config - INFO - Epoch [208/260], Train Loss: 0.3833
2024-03-28 23:05:46,563 - config - INFO - Validation Loss: 0.3957
2024-03-28 23:05:46,563 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:46,613 - config - INFO - Epoch [209/260], Train Loss: 0.3832
2024-03-28 23:05:46,614 - config - INFO - Validation Loss: 0.3965
2024-03-28 23:05:46,614 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:46,664 - config - INFO - Epoch [210/260], Train Loss: 0.3832
2024-03-28 23:05:46,666 - config - INFO - Validation Loss: 0.3956
2024-03-28 23:05:46,666 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:46,715 - config - INFO - Epoch [211/260], Train Loss: 0.3830
2024-03-28 23:05:46,717 - config - INFO - Validation Loss: 0.3959
2024-03-28 23:05:46,717 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:46,767 - config - INFO - Epoch [212/260], Train Loss: 0.3829
2024-03-28 23:05:46,768 - config - INFO - Validation Loss: 0.3954
2024-03-28 23:05:46,769 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:46,818 - config - INFO - Epoch [213/260], Train Loss: 0.3828
2024-03-28 23:05:46,820 - config - INFO - Validation Loss: 0.3957
2024-03-28 23:05:46,820 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:46,870 - config - INFO - Epoch [214/260], Train Loss: 0.3825
2024-03-28 23:05:46,871 - config - INFO - Validation Loss: 0.3960
2024-03-28 23:05:46,871 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:46,921 - config - INFO - Epoch [215/260], Train Loss: 0.3826
2024-03-28 23:05:46,923 - config - INFO - Validation Loss: 0.3958
2024-03-28 23:05:46,923 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:46,972 - config - INFO - Epoch [216/260], Train Loss: 0.3823
2024-03-28 23:05:46,974 - config - INFO - Validation Loss: 0.3957
2024-03-28 23:05:46,974 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:47,024 - config - INFO - Epoch [217/260], Train Loss: 0.3823
2024-03-28 23:05:47,025 - config - INFO - Validation Loss: 0.3951
2024-03-28 23:05:47,026 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:47,075 - config - INFO - Epoch [218/260], Train Loss: 0.3820
2024-03-28 23:05:47,077 - config - INFO - Validation Loss: 0.3951
2024-03-28 23:05:47,077 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:47,127 - config - INFO - Epoch [219/260], Train Loss: 0.3821
2024-03-28 23:05:47,128 - config - INFO - Validation Loss: 0.3946
2024-03-28 23:05:47,129 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:47,178 - config - INFO - Epoch [220/260], Train Loss: 0.3819
2024-03-28 23:05:47,180 - config - INFO - Validation Loss: 0.3944
2024-03-28 23:05:47,180 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:47,229 - config - INFO - Epoch [221/260], Train Loss: 0.3817
2024-03-28 23:05:47,231 - config - INFO - Validation Loss: 0.3952
2024-03-28 23:05:47,231 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:47,281 - config - INFO - Epoch [222/260], Train Loss: 0.3816
2024-03-28 23:05:47,282 - config - INFO - Validation Loss: 0.3962
2024-03-28 23:05:47,283 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:47,332 - config - INFO - Epoch [223/260], Train Loss: 0.3817
2024-03-28 23:05:47,334 - config - INFO - Validation Loss: 0.3955
2024-03-28 23:05:47,334 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:47,383 - config - INFO - Epoch [224/260], Train Loss: 0.3814
2024-03-28 23:05:47,385 - config - INFO - Validation Loss: 0.3957
2024-03-28 23:05:47,385 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:47,434 - config - INFO - Epoch [225/260], Train Loss: 0.3811
2024-03-28 23:05:47,436 - config - INFO - Validation Loss: 0.3949
2024-03-28 23:05:47,436 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:47,486 - config - INFO - Epoch [226/260], Train Loss: 0.3812
2024-03-28 23:05:47,487 - config - INFO - Validation Loss: 0.3954
2024-03-28 23:05:47,487 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:47,537 - config - INFO - Epoch [227/260], Train Loss: 0.3811
2024-03-28 23:05:47,539 - config - INFO - Validation Loss: 0.3949
2024-03-28 23:05:47,539 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:47,592 - config - INFO - Epoch [228/260], Train Loss: 0.3808
2024-03-28 23:05:47,594 - config - INFO - Validation Loss: 0.3952
2024-03-28 23:05:47,594 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:47,643 - config - INFO - Epoch [229/260], Train Loss: 0.3808
2024-03-28 23:05:47,645 - config - INFO - Validation Loss: 0.3950
2024-03-28 23:05:47,645 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:47,695 - config - INFO - Epoch [230/260], Train Loss: 0.3806
2024-03-28 23:05:47,696 - config - INFO - Validation Loss: 0.3951
2024-03-28 23:05:47,696 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:47,748 - config - INFO - Epoch [231/260], Train Loss: 0.3806
2024-03-28 23:05:47,750 - config - INFO - Validation Loss: 0.3957
2024-03-28 23:05:47,750 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:47,799 - config - INFO - Epoch [232/260], Train Loss: 0.3804
2024-03-28 23:05:47,801 - config - INFO - Validation Loss: 0.3954
2024-03-28 23:05:47,801 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:47,851 - config - INFO - Epoch [233/260], Train Loss: 0.3805
2024-03-28 23:05:47,852 - config - INFO - Validation Loss: 0.3952
2024-03-28 23:05:47,852 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:47,902 - config - INFO - Epoch [234/260], Train Loss: 0.3802
2024-03-28 23:05:47,904 - config - INFO - Validation Loss: 0.3947
2024-03-28 23:05:47,904 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:47,953 - config - INFO - Epoch [235/260], Train Loss: 0.3801
2024-03-28 23:05:47,955 - config - INFO - Validation Loss: 0.3947
2024-03-28 23:05:47,955 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:48,004 - config - INFO - Epoch [236/260], Train Loss: 0.3800
2024-03-28 23:05:48,006 - config - INFO - Validation Loss: 0.3950
2024-03-28 23:05:48,006 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:48,056 - config - INFO - Epoch [237/260], Train Loss: 0.3800
2024-03-28 23:05:48,057 - config - INFO - Validation Loss: 0.3957
2024-03-28 23:05:48,058 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:48,107 - config - INFO - Epoch [238/260], Train Loss: 0.3798
2024-03-28 23:05:48,109 - config - INFO - Validation Loss: 0.3958
2024-03-28 23:05:48,109 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:48,158 - config - INFO - Epoch [239/260], Train Loss: 0.3796
2024-03-28 23:05:48,160 - config - INFO - Validation Loss: 0.3959
2024-03-28 23:05:48,160 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:48,210 - config - INFO - Epoch [240/260], Train Loss: 0.3796
2024-03-28 23:05:48,211 - config - INFO - Validation Loss: 0.3953
2024-03-28 23:05:48,211 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:48,261 - config - INFO - Epoch [241/260], Train Loss: 0.3795
2024-03-28 23:05:48,263 - config - INFO - Validation Loss: 0.3956
2024-03-28 23:05:48,263 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:48,312 - config - INFO - Epoch [242/260], Train Loss: 0.3795
2024-03-28 23:05:48,314 - config - INFO - Validation Loss: 0.3952
2024-03-28 23:05:48,314 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:48,364 - config - INFO - Epoch [243/260], Train Loss: 0.3792
2024-03-28 23:05:48,365 - config - INFO - Validation Loss: 0.3954
2024-03-28 23:05:48,366 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:48,415 - config - INFO - Epoch [244/260], Train Loss: 0.3791
2024-03-28 23:05:48,417 - config - INFO - Validation Loss: 0.3953
2024-03-28 23:05:48,417 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:48,466 - config - INFO - Epoch [245/260], Train Loss: 0.3791
2024-03-28 23:05:48,468 - config - INFO - Validation Loss: 0.3956
2024-03-28 23:05:48,468 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:48,518 - config - INFO - Epoch [246/260], Train Loss: 0.3790
2024-03-28 23:05:48,519 - config - INFO - Validation Loss: 0.3956
2024-03-28 23:05:48,519 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:48,569 - config - INFO - Epoch [247/260], Train Loss: 0.3789
2024-03-28 23:05:48,571 - config - INFO - Validation Loss: 0.3965
2024-03-28 23:05:48,571 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:48,620 - config - INFO - Epoch [248/260], Train Loss: 0.3788
2024-03-28 23:05:48,622 - config - INFO - Validation Loss: 0.3968
2024-03-28 23:05:48,622 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:48,671 - config - INFO - Epoch [249/260], Train Loss: 0.3787
2024-03-28 23:05:48,673 - config - INFO - Validation Loss: 0.3965
2024-03-28 23:05:48,673 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:48,723 - config - INFO - Epoch [250/260], Train Loss: 0.3786
2024-03-28 23:05:48,725 - config - INFO - Validation Loss: 0.3956
2024-03-28 23:05:48,725 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:48,774 - config - INFO - Epoch [251/260], Train Loss: 0.3784
2024-03-28 23:05:48,776 - config - INFO - Validation Loss: 0.3964
2024-03-28 23:05:48,776 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:48,826 - config - INFO - Epoch [252/260], Train Loss: 0.3787
2024-03-28 23:05:48,827 - config - INFO - Validation Loss: 0.3948
2024-03-28 23:05:48,827 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:48,877 - config - INFO - Epoch [253/260], Train Loss: 0.3781
2024-03-28 23:05:48,879 - config - INFO - Validation Loss: 0.3956
2024-03-28 23:05:48,879 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:48,928 - config - INFO - Epoch [254/260], Train Loss: 0.3780
2024-03-28 23:05:48,930 - config - INFO - Validation Loss: 0.3963
2024-03-28 23:05:48,930 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:48,980 - config - INFO - Epoch [255/260], Train Loss: 0.3779
2024-03-28 23:05:48,981 - config - INFO - Validation Loss: 0.3964
2024-03-28 23:05:48,982 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:49,031 - config - INFO - Epoch [256/260], Train Loss: 0.3780
2024-03-28 23:05:49,033 - config - INFO - Validation Loss: 0.3972
2024-03-28 23:05:49,033 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:49,082 - config - INFO - Epoch [257/260], Train Loss: 0.3776
2024-03-28 23:05:49,084 - config - INFO - Validation Loss: 0.3964
2024-03-28 23:05:49,084 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:49,134 - config - INFO - Epoch [258/260], Train Loss: 0.3776
2024-03-28 23:05:49,135 - config - INFO - Validation Loss: 0.3964
2024-03-28 23:05:49,136 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:49,185 - config - INFO - Epoch [259/260], Train Loss: 0.3776
2024-03-28 23:05:49,187 - config - INFO - Validation Loss: 0.3956
2024-03-28 23:05:49,187 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:05:49,236 - config - INFO - Epoch [260/260], Train Loss: 0.3774
2024-03-28 23:05:49,238 - config - INFO - Validation Loss: 0.3965
2024-03-28 23:05:49,238 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:24,482 - config - INFO - resume: None
2024-03-28 23:07:24,482 - config - INFO - device: cpu
2024-03-28 23:07:24,482 - config - INFO - log_path: /mnt/disk1/AI_Lab/to3_titanic/log_simplenn.txt
2024-03-28 23:07:24,483 - config - INFO - learning_rate: 0.0001
2024-03-28 23:07:24,483 - config - INFO - num_epochs: 260
2024-03-28 23:07:24,483 - config - INFO - batch_size: 32
2024-03-28 23:07:24,483 - config - INFO - 
 <<< Config Content <<<
import argparse
import os
import logging

class Config:
    def __init__(self):
        ...
        self.logger = self._load_logger_n_parse_args()
        
        self.logger.info('\n <<< Config Content <<<\n'+self._read_module_content())
        
        # titanic part
        self.train_data_path = "/mnt/disk1/AI_Lab/to3_titanic/train_titnic.csv"
        self.test_data_path = "/mnt/disk1/AI_Lab/to3_titanic/test_titnic.csv"

        self.prev_val_loss = float('inf')
        self.tolerance = 0.3

 
    def _read_module_content(self):
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None


    def _load_logger_n_parse_args(self):
        logger = logging.getLogger(__name__)
        logger.setLevel(level = logging.INFO)
        
        parser = argparse.ArgumentParser(description='Your program description')
        parser.add_argument('-r', '--resume', default=None, type=str,
                            help='path to latest checkpoint (default: None)')
        parser.add_argument('-d', '--device', default=None, type=str,
                            help='indices of GPUs to enable (default: all)')
        parser.add_argument('-l', '--log_path', default=None, type=str,
                            help='Just log path')
        parser.add_argument('-lr', '--learning_rate', default=None, type=float,
                            help='')
        parser.add_argument('-e', '--num_epochs', default=None, type=int,
                            help='')
        parser.add_argument('-b', '--batch_size', default=None, type=int,
                            help='')
        args = parser.parse_args()
        
        if args.log_path:
            self.log_path = args.log_path
        else:
            print("Log path is not specified. Please provide a log path using the '-l' or '--log_path' argument.")
            raise NotImplementedError
        
        handler = logging.FileHandler(self.log_path)
        handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        # logger.info('resume_checkpoint: ' + str(args.resume))
        # logger.info('device_indices: '+ str(args.device))
        # logger.info('log_path: ' + str(args.log_path))
        for arg in vars(args):
            setattr(self, arg, getattr(args, arg))
            logger.info(f'{arg}: {getattr(args, arg)}')
        return logger
        
2024-03-28 23:07:24,504 - config - INFO - Dataset size: 891
2024-03-28 23:07:24,531 - config - INFO - 
 <<< Train Content <<<
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, Dataset
from abc import abstractmethod
from sklearn.utils import shuffle
from base_trainer import Base_trainer
from config import Config

# Model Class
class SimpleNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class DropoutNN(nn.Module):
    def __init__(self, input_size):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.sigmoid(x)
        return x

class MaNN(nn.Module):
    def __init__(self, input_size):
        super(MaNN, self).__init__()
        self.fc1 = nn.Linear(input_size, 128000)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128000, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.fc1(x)
        x = self.sigmoid(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

# Dataset Class
class TitanicDataset(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.drop('Survived', axis=1).values.astype(np.float32)
        self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx]), 'label': torch.tensor(self.y[idx])}

class TitanicDatasetTest(Dataset):
    def __init__(self, csv_file):
        self.data = pd.read_csv(csv_file)
        self.scaler = StandardScaler()
        self.process_data()

    def process_data(self):
        self.data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)
        self.data['Age'].fillna(self.data['Age'].median(), inplace=True)
        self.data['Embarked'].fillna(self.data['Embarked'].mode()[0], inplace=True)
        self.data = pd.get_dummies(self.data, columns=['Sex', 'Embarked'], drop_first=True)
        self.data = self.data.astype('float32')
        self.data.iloc[:, 1:] = self.scaler.fit_transform(self.data.iloc[:, 1:])
        self.X = self.data.values.astype(np.float32)
        # self.y = self.data['Survived'].values.astype(np.float32).reshape(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return {'features': torch.tensor(self.X[idx])}

# Trainer Class
class TitanicTrainer(Base_trainer):
    def __init__(self, config):
        super().__init__(config)
        self.logger = config.logger
        self.train_dataset = TitanicDataset(config.train_data_path)
        self.test_dataset = TitanicDatasetTest(config.test_data_path)
        self.logger.info("Dataset size: " + str(len(self.train_dataset)))
        # self.test_dataset = TitanicDataset(config.test_data_path)
        self.model = SimpleNN(input_size=self.train_dataset.X.shape[1])
        self.train_loader, self.val_loader, self.test_loader = self.create_data_loaders()

    def create_data_loaders(self):
        train_size = int(0.95 * len(self.train_dataset))
        val_size = int(0.05 * len(self.train_dataset))
        test_size = len(self.train_dataset) - train_size - val_size
        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
            self.train_dataset, [train_size, val_size, test_size])

        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size)
        return train_loader, val_loader, test_loader

    def train(self):
        criterion = nn.BCELoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.config.learning_rate)

        for epoch in range(self.config.num_epochs):
            self.train_one_epoch(epoch, criterion, optimizer)
            
            early_stopping = self.eval()
            if early_stopping:
                break
            else:
                continue

    def train_one_epoch(self, epoch, criterion, optimizer):
        self.model.train()
        train_loss = 0.0
        for batch in self.train_loader:
            inputs, labels = batch['features'], batch['label']
            optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * inputs.size(0)
        train_loss /= len(self.train_loader.dataset)
        self.logger.info(f"Epoch [{epoch + 1}/{self.config.num_epochs}], Train Loss: {train_loss:.4f}")

    def eval(self):
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in self.val_loader:
                inputs, labels = batch['features'], batch['label']
                outputs = self.model(inputs)
                loss = nn.BCELoss()(outputs, labels)
                val_loss += loss.item() * inputs.size(0)
        val_loss /= len(self.val_loader.dataset)
        self.logger.info(f"Validation Loss: {val_loss:.4f}")
        
        # Function to calculate accuracy
        def calculate_accuracy(outputs, labels, threshold=0.5):
            # Convert outputs to binary predictions
            predictions = (outputs > threshold).float()

            # Compare predictions with labels
            correct = (predictions == labels).float().sum()

            # Calculate accuracy
            accuracy = correct / labels.size(0)
            
            return accuracy.item()
        val_acc = calculate_accuracy(outputs, labels) # PROBLEM
        self.logger.info(f"Validation Acc: {val_acc:.4f}")

        # Early stopping
        if val_loss >= self.config.prev_val_loss+self.config.tolerance:
            self.logger.info("Validation loss increased. Early stopping.")
            return True
        else:
            self.config.prev_val_loss = min(val_loss, self.config.prev_val_loss)
            return False
    def test(self):
        test_dataloader = DataLoader(self.test_dataset, batch_size=len(self.test_dataset))
        self.model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for batch in test_dataloader:
                inputs = batch['features']
                outputs = self.model(inputs)
                
        predictions = (outputs > 0.5).int()
        import pandas as pd

        # Define the range of PassengerId
        passenger_ids = range(892, 1310)
        print(predictions.squeeze().shape)
        df = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions.squeeze()})

        # Save DataFrame with no index
        df.to_csv('/mnt/disk1/AI_Lab/to3_titanic/predictions.csv', index=False)


def main(config):
    trainer = TitanicTrainer(config)
    def read_module_content():
        try:
            module_path = __import__(__name__).__file__
            with open(module_path, 'r', encoding='utf-8') as file:
                module_content = file.read()
            return module_content
        except Exception as e:
            print(f"Error occurred while reading module '{module_name}': {e}")
            return None
    
    config.logger.info('\n <<< Train Content <<<\n'+read_module_content())
    
    config.logger.info('Training start')
    trainer.train()
    trainer.test()


    

if __name__ == '__main__':
    config = Config()
    
    main(config)
2024-03-28 23:07:24,531 - config - INFO - Training start
2024-03-28 23:07:26,697 - config - INFO - Epoch [1/260], Train Loss: 0.6913
2024-03-28 23:07:26,699 - config - INFO - Validation Loss: 0.6837
2024-03-28 23:07:26,699 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:07:26,768 - config - INFO - Epoch [2/260], Train Loss: 0.6828
2024-03-28 23:07:26,770 - config - INFO - Validation Loss: 0.6771
2024-03-28 23:07:26,771 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:26,829 - config - INFO - Epoch [3/260], Train Loss: 0.6742
2024-03-28 23:07:26,831 - config - INFO - Validation Loss: 0.6703
2024-03-28 23:07:26,831 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:26,886 - config - INFO - Epoch [4/260], Train Loss: 0.6652
2024-03-28 23:07:26,888 - config - INFO - Validation Loss: 0.6630
2024-03-28 23:07:26,888 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:26,940 - config - INFO - Epoch [5/260], Train Loss: 0.6553
2024-03-28 23:07:26,942 - config - INFO - Validation Loss: 0.6553
2024-03-28 23:07:26,942 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:26,994 - config - INFO - Epoch [6/260], Train Loss: 0.6449
2024-03-28 23:07:26,996 - config - INFO - Validation Loss: 0.6469
2024-03-28 23:07:26,996 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:27,048 - config - INFO - Epoch [7/260], Train Loss: 0.6334
2024-03-28 23:07:27,050 - config - INFO - Validation Loss: 0.6381
2024-03-28 23:07:27,050 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:27,102 - config - INFO - Epoch [8/260], Train Loss: 0.6214
2024-03-28 23:07:27,104 - config - INFO - Validation Loss: 0.6285
2024-03-28 23:07:27,104 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:27,156 - config - INFO - Epoch [9/260], Train Loss: 0.6086
2024-03-28 23:07:27,158 - config - INFO - Validation Loss: 0.6202
2024-03-28 23:07:27,158 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:27,210 - config - INFO - Epoch [10/260], Train Loss: 0.5958
2024-03-28 23:07:27,212 - config - INFO - Validation Loss: 0.6110
2024-03-28 23:07:27,212 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:27,264 - config - INFO - Epoch [11/260], Train Loss: 0.5821
2024-03-28 23:07:27,266 - config - INFO - Validation Loss: 0.6019
2024-03-28 23:07:27,267 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:27,319 - config - INFO - Epoch [12/260], Train Loss: 0.5685
2024-03-28 23:07:27,321 - config - INFO - Validation Loss: 0.5930
2024-03-28 23:07:27,321 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:27,389 - config - INFO - Epoch [13/260], Train Loss: 0.5549
2024-03-28 23:07:27,391 - config - INFO - Validation Loss: 0.5843
2024-03-28 23:07:27,391 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:27,443 - config - INFO - Epoch [14/260], Train Loss: 0.5415
2024-03-28 23:07:27,445 - config - INFO - Validation Loss: 0.5766
2024-03-28 23:07:27,445 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:27,498 - config - INFO - Epoch [15/260], Train Loss: 0.5287
2024-03-28 23:07:27,500 - config - INFO - Validation Loss: 0.5685
2024-03-28 23:07:27,500 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:27,552 - config - INFO - Epoch [16/260], Train Loss: 0.5169
2024-03-28 23:07:27,554 - config - INFO - Validation Loss: 0.5617
2024-03-28 23:07:27,554 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:27,606 - config - INFO - Epoch [17/260], Train Loss: 0.5062
2024-03-28 23:07:27,608 - config - INFO - Validation Loss: 0.5547
2024-03-28 23:07:27,608 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:27,660 - config - INFO - Epoch [18/260], Train Loss: 0.4959
2024-03-28 23:07:27,662 - config - INFO - Validation Loss: 0.5495
2024-03-28 23:07:27,662 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:27,714 - config - INFO - Epoch [19/260], Train Loss: 0.4869
2024-03-28 23:07:27,716 - config - INFO - Validation Loss: 0.5443
2024-03-28 23:07:27,716 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:27,768 - config - INFO - Epoch [20/260], Train Loss: 0.4788
2024-03-28 23:07:27,770 - config - INFO - Validation Loss: 0.5402
2024-03-28 23:07:27,770 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:27,821 - config - INFO - Epoch [21/260], Train Loss: 0.4714
2024-03-28 23:07:27,823 - config - INFO - Validation Loss: 0.5375
2024-03-28 23:07:27,823 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:27,874 - config - INFO - Epoch [22/260], Train Loss: 0.4651
2024-03-28 23:07:27,876 - config - INFO - Validation Loss: 0.5339
2024-03-28 23:07:27,876 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:07:27,927 - config - INFO - Epoch [23/260], Train Loss: 0.4591
2024-03-28 23:07:27,931 - config - INFO - Validation Loss: 0.5315
2024-03-28 23:07:27,931 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:07:27,982 - config - INFO - Epoch [24/260], Train Loss: 0.4544
2024-03-28 23:07:27,984 - config - INFO - Validation Loss: 0.5312
2024-03-28 23:07:27,984 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:07:28,037 - config - INFO - Epoch [25/260], Train Loss: 0.4497
2024-03-28 23:07:28,039 - config - INFO - Validation Loss: 0.5297
2024-03-28 23:07:28,039 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:07:28,093 - config - INFO - Epoch [26/260], Train Loss: 0.4461
2024-03-28 23:07:28,095 - config - INFO - Validation Loss: 0.5273
2024-03-28 23:07:28,095 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:07:28,147 - config - INFO - Epoch [27/260], Train Loss: 0.4423
2024-03-28 23:07:28,149 - config - INFO - Validation Loss: 0.5273
2024-03-28 23:07:28,149 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:07:28,201 - config - INFO - Epoch [28/260], Train Loss: 0.4396
2024-03-28 23:07:28,203 - config - INFO - Validation Loss: 0.5257
2024-03-28 23:07:28,203 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:07:28,258 - config - INFO - Epoch [29/260], Train Loss: 0.4368
2024-03-28 23:07:28,260 - config - INFO - Validation Loss: 0.5263
2024-03-28 23:07:28,260 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:07:28,311 - config - INFO - Epoch [30/260], Train Loss: 0.4345
2024-03-28 23:07:28,313 - config - INFO - Validation Loss: 0.5274
2024-03-28 23:07:28,313 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:07:28,364 - config - INFO - Epoch [31/260], Train Loss: 0.4322
2024-03-28 23:07:28,366 - config - INFO - Validation Loss: 0.5271
2024-03-28 23:07:28,366 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:07:28,417 - config - INFO - Epoch [32/260], Train Loss: 0.4305
2024-03-28 23:07:28,419 - config - INFO - Validation Loss: 0.5277
2024-03-28 23:07:28,419 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:07:28,479 - config - INFO - Epoch [33/260], Train Loss: 0.4289
2024-03-28 23:07:28,481 - config - INFO - Validation Loss: 0.5267
2024-03-28 23:07:28,481 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:07:28,533 - config - INFO - Epoch [34/260], Train Loss: 0.4273
2024-03-28 23:07:28,535 - config - INFO - Validation Loss: 0.5287
2024-03-28 23:07:28,535 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:07:28,587 - config - INFO - Epoch [35/260], Train Loss: 0.4259
2024-03-28 23:07:28,588 - config - INFO - Validation Loss: 0.5279
2024-03-28 23:07:28,589 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:07:28,640 - config - INFO - Epoch [36/260], Train Loss: 0.4244
2024-03-28 23:07:28,641 - config - INFO - Validation Loss: 0.5291
2024-03-28 23:07:28,642 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:07:28,692 - config - INFO - Epoch [37/260], Train Loss: 0.4233
2024-03-28 23:07:28,694 - config - INFO - Validation Loss: 0.5302
2024-03-28 23:07:28,694 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:07:28,746 - config - INFO - Epoch [38/260], Train Loss: 0.4221
2024-03-28 23:07:28,748 - config - INFO - Validation Loss: 0.5304
2024-03-28 23:07:28,748 - config - INFO - Validation Acc: 0.6667
2024-03-28 23:07:28,800 - config - INFO - Epoch [39/260], Train Loss: 0.4210
2024-03-28 23:07:28,802 - config - INFO - Validation Loss: 0.5307
2024-03-28 23:07:28,802 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:28,853 - config - INFO - Epoch [40/260], Train Loss: 0.4202
2024-03-28 23:07:28,855 - config - INFO - Validation Loss: 0.5301
2024-03-28 23:07:28,855 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:28,905 - config - INFO - Epoch [41/260], Train Loss: 0.4193
2024-03-28 23:07:28,907 - config - INFO - Validation Loss: 0.5311
2024-03-28 23:07:28,907 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:28,958 - config - INFO - Epoch [42/260], Train Loss: 0.4185
2024-03-28 23:07:28,960 - config - INFO - Validation Loss: 0.5306
2024-03-28 23:07:28,960 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:29,011 - config - INFO - Epoch [43/260], Train Loss: 0.4178
2024-03-28 23:07:29,013 - config - INFO - Validation Loss: 0.5314
2024-03-28 23:07:29,013 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:29,064 - config - INFO - Epoch [44/260], Train Loss: 0.4171
2024-03-28 23:07:29,066 - config - INFO - Validation Loss: 0.5308
2024-03-28 23:07:29,066 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:29,117 - config - INFO - Epoch [45/260], Train Loss: 0.4164
2024-03-28 23:07:29,119 - config - INFO - Validation Loss: 0.5318
2024-03-28 23:07:29,119 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:29,170 - config - INFO - Epoch [46/260], Train Loss: 0.4156
2024-03-28 23:07:29,172 - config - INFO - Validation Loss: 0.5324
2024-03-28 23:07:29,172 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:29,223 - config - INFO - Epoch [47/260], Train Loss: 0.4150
2024-03-28 23:07:29,225 - config - INFO - Validation Loss: 0.5330
2024-03-28 23:07:29,225 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:29,276 - config - INFO - Epoch [48/260], Train Loss: 0.4144
2024-03-28 23:07:29,278 - config - INFO - Validation Loss: 0.5332
2024-03-28 23:07:29,278 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:29,329 - config - INFO - Epoch [49/260], Train Loss: 0.4138
2024-03-28 23:07:29,331 - config - INFO - Validation Loss: 0.5335
2024-03-28 23:07:29,331 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:29,382 - config - INFO - Epoch [50/260], Train Loss: 0.4134
2024-03-28 23:07:29,384 - config - INFO - Validation Loss: 0.5339
2024-03-28 23:07:29,384 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:29,435 - config - INFO - Epoch [51/260], Train Loss: 0.4127
2024-03-28 23:07:29,437 - config - INFO - Validation Loss: 0.5339
2024-03-28 23:07:29,437 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:29,508 - config - INFO - Epoch [52/260], Train Loss: 0.4122
2024-03-28 23:07:29,511 - config - INFO - Validation Loss: 0.5323
2024-03-28 23:07:29,511 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:29,568 - config - INFO - Epoch [53/260], Train Loss: 0.4118
2024-03-28 23:07:29,570 - config - INFO - Validation Loss: 0.5319
2024-03-28 23:07:29,570 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:29,627 - config - INFO - Epoch [54/260], Train Loss: 0.4112
2024-03-28 23:07:29,629 - config - INFO - Validation Loss: 0.5318
2024-03-28 23:07:29,629 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:29,686 - config - INFO - Epoch [55/260], Train Loss: 0.4108
2024-03-28 23:07:29,687 - config - INFO - Validation Loss: 0.5322
2024-03-28 23:07:29,687 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:29,737 - config - INFO - Epoch [56/260], Train Loss: 0.4103
2024-03-28 23:07:29,739 - config - INFO - Validation Loss: 0.5304
2024-03-28 23:07:29,739 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:29,789 - config - INFO - Epoch [57/260], Train Loss: 0.4099
2024-03-28 23:07:29,791 - config - INFO - Validation Loss: 0.5310
2024-03-28 23:07:29,791 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:29,840 - config - INFO - Epoch [58/260], Train Loss: 0.4093
2024-03-28 23:07:29,842 - config - INFO - Validation Loss: 0.5332
2024-03-28 23:07:29,842 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:29,892 - config - INFO - Epoch [59/260], Train Loss: 0.4092
2024-03-28 23:07:29,893 - config - INFO - Validation Loss: 0.5314
2024-03-28 23:07:29,894 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:29,943 - config - INFO - Epoch [60/260], Train Loss: 0.4086
2024-03-28 23:07:29,945 - config - INFO - Validation Loss: 0.5321
2024-03-28 23:07:29,945 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:29,995 - config - INFO - Epoch [61/260], Train Loss: 0.4081
2024-03-28 23:07:29,996 - config - INFO - Validation Loss: 0.5321
2024-03-28 23:07:29,997 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:30,046 - config - INFO - Epoch [62/260], Train Loss: 0.4076
2024-03-28 23:07:30,048 - config - INFO - Validation Loss: 0.5302
2024-03-28 23:07:30,048 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:30,098 - config - INFO - Epoch [63/260], Train Loss: 0.4073
2024-03-28 23:07:30,099 - config - INFO - Validation Loss: 0.5306
2024-03-28 23:07:30,100 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:30,149 - config - INFO - Epoch [64/260], Train Loss: 0.4068
2024-03-28 23:07:30,151 - config - INFO - Validation Loss: 0.5316
2024-03-28 23:07:30,151 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:30,201 - config - INFO - Epoch [65/260], Train Loss: 0.4067
2024-03-28 23:07:30,202 - config - INFO - Validation Loss: 0.5320
2024-03-28 23:07:30,202 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:30,252 - config - INFO - Epoch [66/260], Train Loss: 0.4061
2024-03-28 23:07:30,254 - config - INFO - Validation Loss: 0.5321
2024-03-28 23:07:30,254 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:30,303 - config - INFO - Epoch [67/260], Train Loss: 0.4057
2024-03-28 23:07:30,305 - config - INFO - Validation Loss: 0.5330
2024-03-28 23:07:30,305 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:30,355 - config - INFO - Epoch [68/260], Train Loss: 0.4057
2024-03-28 23:07:30,356 - config - INFO - Validation Loss: 0.5314
2024-03-28 23:07:30,357 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:30,406 - config - INFO - Epoch [69/260], Train Loss: 0.4052
2024-03-28 23:07:30,408 - config - INFO - Validation Loss: 0.5330
2024-03-28 23:07:30,408 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:30,460 - config - INFO - Epoch [70/260], Train Loss: 0.4047
2024-03-28 23:07:30,462 - config - INFO - Validation Loss: 0.5320
2024-03-28 23:07:30,462 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:30,512 - config - INFO - Epoch [71/260], Train Loss: 0.4045
2024-03-28 23:07:30,514 - config - INFO - Validation Loss: 0.5298
2024-03-28 23:07:30,514 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:30,564 - config - INFO - Epoch [72/260], Train Loss: 0.4041
2024-03-28 23:07:30,566 - config - INFO - Validation Loss: 0.5309
2024-03-28 23:07:30,566 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:30,615 - config - INFO - Epoch [73/260], Train Loss: 0.4040
2024-03-28 23:07:30,617 - config - INFO - Validation Loss: 0.5305
2024-03-28 23:07:30,617 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:30,667 - config - INFO - Epoch [74/260], Train Loss: 0.4036
2024-03-28 23:07:30,669 - config - INFO - Validation Loss: 0.5320
2024-03-28 23:07:30,669 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:30,719 - config - INFO - Epoch [75/260], Train Loss: 0.4031
2024-03-28 23:07:30,720 - config - INFO - Validation Loss: 0.5310
2024-03-28 23:07:30,720 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:30,770 - config - INFO - Epoch [76/260], Train Loss: 0.4029
2024-03-28 23:07:30,772 - config - INFO - Validation Loss: 0.5310
2024-03-28 23:07:30,772 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:30,821 - config - INFO - Epoch [77/260], Train Loss: 0.4026
2024-03-28 23:07:30,823 - config - INFO - Validation Loss: 0.5323
2024-03-28 23:07:30,823 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:30,873 - config - INFO - Epoch [78/260], Train Loss: 0.4020
2024-03-28 23:07:30,874 - config - INFO - Validation Loss: 0.5313
2024-03-28 23:07:30,874 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:30,924 - config - INFO - Epoch [79/260], Train Loss: 0.4020
2024-03-28 23:07:30,926 - config - INFO - Validation Loss: 0.5299
2024-03-28 23:07:30,926 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:30,975 - config - INFO - Epoch [80/260], Train Loss: 0.4016
2024-03-28 23:07:30,977 - config - INFO - Validation Loss: 0.5301
2024-03-28 23:07:30,977 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:31,027 - config - INFO - Epoch [81/260], Train Loss: 0.4013
2024-03-28 23:07:31,029 - config - INFO - Validation Loss: 0.5311
2024-03-28 23:07:31,029 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:31,078 - config - INFO - Epoch [82/260], Train Loss: 0.4010
2024-03-28 23:07:31,080 - config - INFO - Validation Loss: 0.5305
2024-03-28 23:07:31,080 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:31,130 - config - INFO - Epoch [83/260], Train Loss: 0.4008
2024-03-28 23:07:31,131 - config - INFO - Validation Loss: 0.5315
2024-03-28 23:07:31,131 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:31,181 - config - INFO - Epoch [84/260], Train Loss: 0.4005
2024-03-28 23:07:31,183 - config - INFO - Validation Loss: 0.5312
2024-03-28 23:07:31,183 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:31,232 - config - INFO - Epoch [85/260], Train Loss: 0.4004
2024-03-28 23:07:31,234 - config - INFO - Validation Loss: 0.5323
2024-03-28 23:07:31,234 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:31,285 - config - INFO - Epoch [86/260], Train Loss: 0.4000
2024-03-28 23:07:31,286 - config - INFO - Validation Loss: 0.5297
2024-03-28 23:07:31,287 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:31,336 - config - INFO - Epoch [87/260], Train Loss: 0.3997
2024-03-28 23:07:31,338 - config - INFO - Validation Loss: 0.5296
2024-03-28 23:07:31,338 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:31,388 - config - INFO - Epoch [88/260], Train Loss: 0.3995
2024-03-28 23:07:31,389 - config - INFO - Validation Loss: 0.5304
2024-03-28 23:07:31,389 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:31,439 - config - INFO - Epoch [89/260], Train Loss: 0.3992
2024-03-28 23:07:31,441 - config - INFO - Validation Loss: 0.5299
2024-03-28 23:07:31,441 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:31,494 - config - INFO - Epoch [90/260], Train Loss: 0.3991
2024-03-28 23:07:31,496 - config - INFO - Validation Loss: 0.5282
2024-03-28 23:07:31,496 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:31,545 - config - INFO - Epoch [91/260], Train Loss: 0.3989
2024-03-28 23:07:31,547 - config - INFO - Validation Loss: 0.5310
2024-03-28 23:07:31,547 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:31,597 - config - INFO - Epoch [92/260], Train Loss: 0.3984
2024-03-28 23:07:31,598 - config - INFO - Validation Loss: 0.5302
2024-03-28 23:07:31,598 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:31,648 - config - INFO - Epoch [93/260], Train Loss: 0.3981
2024-03-28 23:07:31,650 - config - INFO - Validation Loss: 0.5295
2024-03-28 23:07:31,650 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:31,699 - config - INFO - Epoch [94/260], Train Loss: 0.3980
2024-03-28 23:07:31,701 - config - INFO - Validation Loss: 0.5288
2024-03-28 23:07:31,701 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:31,751 - config - INFO - Epoch [95/260], Train Loss: 0.3978
2024-03-28 23:07:31,753 - config - INFO - Validation Loss: 0.5290
2024-03-28 23:07:31,753 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:31,802 - config - INFO - Epoch [96/260], Train Loss: 0.3975
2024-03-28 23:07:31,804 - config - INFO - Validation Loss: 0.5287
2024-03-28 23:07:31,804 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:31,854 - config - INFO - Epoch [97/260], Train Loss: 0.3973
2024-03-28 23:07:31,855 - config - INFO - Validation Loss: 0.5294
2024-03-28 23:07:31,855 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:31,905 - config - INFO - Epoch [98/260], Train Loss: 0.3972
2024-03-28 23:07:31,907 - config - INFO - Validation Loss: 0.5273
2024-03-28 23:07:31,907 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:31,956 - config - INFO - Epoch [99/260], Train Loss: 0.3968
2024-03-28 23:07:31,958 - config - INFO - Validation Loss: 0.5286
2024-03-28 23:07:31,958 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:32,007 - config - INFO - Epoch [100/260], Train Loss: 0.3966
2024-03-28 23:07:32,009 - config - INFO - Validation Loss: 0.5280
2024-03-28 23:07:32,009 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:32,059 - config - INFO - Epoch [101/260], Train Loss: 0.3963
2024-03-28 23:07:32,060 - config - INFO - Validation Loss: 0.5288
2024-03-28 23:07:32,061 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:32,110 - config - INFO - Epoch [102/260], Train Loss: 0.3961
2024-03-28 23:07:32,112 - config - INFO - Validation Loss: 0.5297
2024-03-28 23:07:32,112 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:32,161 - config - INFO - Epoch [103/260], Train Loss: 0.3959
2024-03-28 23:07:32,163 - config - INFO - Validation Loss: 0.5276
2024-03-28 23:07:32,163 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:32,213 - config - INFO - Epoch [104/260], Train Loss: 0.3957
2024-03-28 23:07:32,214 - config - INFO - Validation Loss: 0.5287
2024-03-28 23:07:32,214 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:32,264 - config - INFO - Epoch [105/260], Train Loss: 0.3955
2024-03-28 23:07:32,266 - config - INFO - Validation Loss: 0.5286
2024-03-28 23:07:32,266 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:32,315 - config - INFO - Epoch [106/260], Train Loss: 0.3952
2024-03-28 23:07:32,317 - config - INFO - Validation Loss: 0.5281
2024-03-28 23:07:32,317 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:32,366 - config - INFO - Epoch [107/260], Train Loss: 0.3951
2024-03-28 23:07:32,368 - config - INFO - Validation Loss: 0.5285
2024-03-28 23:07:32,368 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:32,418 - config - INFO - Epoch [108/260], Train Loss: 0.3948
2024-03-28 23:07:32,419 - config - INFO - Validation Loss: 0.5291
2024-03-28 23:07:32,420 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:32,476 - config - INFO - Epoch [109/260], Train Loss: 0.3946
2024-03-28 23:07:32,478 - config - INFO - Validation Loss: 0.5294
2024-03-28 23:07:32,478 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:32,528 - config - INFO - Epoch [110/260], Train Loss: 0.3946
2024-03-28 23:07:32,529 - config - INFO - Validation Loss: 0.5288
2024-03-28 23:07:32,530 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:32,579 - config - INFO - Epoch [111/260], Train Loss: 0.3943
2024-03-28 23:07:32,581 - config - INFO - Validation Loss: 0.5287
2024-03-28 23:07:32,581 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:32,630 - config - INFO - Epoch [112/260], Train Loss: 0.3943
2024-03-28 23:07:32,632 - config - INFO - Validation Loss: 0.5289
2024-03-28 23:07:32,632 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:32,684 - config - INFO - Epoch [113/260], Train Loss: 0.3939
2024-03-28 23:07:32,686 - config - INFO - Validation Loss: 0.5288
2024-03-28 23:07:32,686 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:32,736 - config - INFO - Epoch [114/260], Train Loss: 0.3936
2024-03-28 23:07:32,738 - config - INFO - Validation Loss: 0.5289
2024-03-28 23:07:32,738 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:32,788 - config - INFO - Epoch [115/260], Train Loss: 0.3934
2024-03-28 23:07:32,789 - config - INFO - Validation Loss: 0.5278
2024-03-28 23:07:32,789 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:32,839 - config - INFO - Epoch [116/260], Train Loss: 0.3934
2024-03-28 23:07:32,841 - config - INFO - Validation Loss: 0.5280
2024-03-28 23:07:32,841 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:32,893 - config - INFO - Epoch [117/260], Train Loss: 0.3930
2024-03-28 23:07:32,895 - config - INFO - Validation Loss: 0.5276
2024-03-28 23:07:32,895 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:32,944 - config - INFO - Epoch [118/260], Train Loss: 0.3929
2024-03-28 23:07:32,946 - config - INFO - Validation Loss: 0.5277
2024-03-28 23:07:32,946 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:32,995 - config - INFO - Epoch [119/260], Train Loss: 0.3927
2024-03-28 23:07:32,997 - config - INFO - Validation Loss: 0.5281
2024-03-28 23:07:32,997 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:33,047 - config - INFO - Epoch [120/260], Train Loss: 0.3926
2024-03-28 23:07:33,049 - config - INFO - Validation Loss: 0.5272
2024-03-28 23:07:33,049 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:33,099 - config - INFO - Epoch [121/260], Train Loss: 0.3923
2024-03-28 23:07:33,100 - config - INFO - Validation Loss: 0.5280
2024-03-28 23:07:33,101 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:33,150 - config - INFO - Epoch [122/260], Train Loss: 0.3921
2024-03-28 23:07:33,152 - config - INFO - Validation Loss: 0.5278
2024-03-28 23:07:33,152 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:33,201 - config - INFO - Epoch [123/260], Train Loss: 0.3920
2024-03-28 23:07:33,203 - config - INFO - Validation Loss: 0.5281
2024-03-28 23:07:33,203 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:33,253 - config - INFO - Epoch [124/260], Train Loss: 0.3918
2024-03-28 23:07:33,254 - config - INFO - Validation Loss: 0.5255
2024-03-28 23:07:33,254 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:33,304 - config - INFO - Epoch [125/260], Train Loss: 0.3917
2024-03-28 23:07:33,305 - config - INFO - Validation Loss: 0.5279
2024-03-28 23:07:33,306 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:33,355 - config - INFO - Epoch [126/260], Train Loss: 0.3915
2024-03-28 23:07:33,357 - config - INFO - Validation Loss: 0.5269
2024-03-28 23:07:33,357 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:33,407 - config - INFO - Epoch [127/260], Train Loss: 0.3912
2024-03-28 23:07:33,408 - config - INFO - Validation Loss: 0.5283
2024-03-28 23:07:33,408 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:33,458 - config - INFO - Epoch [128/260], Train Loss: 0.3912
2024-03-28 23:07:33,459 - config - INFO - Validation Loss: 0.5284
2024-03-28 23:07:33,460 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:33,509 - config - INFO - Epoch [129/260], Train Loss: 0.3910
2024-03-28 23:07:33,511 - config - INFO - Validation Loss: 0.5281
2024-03-28 23:07:33,511 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:33,560 - config - INFO - Epoch [130/260], Train Loss: 0.3909
2024-03-28 23:07:33,562 - config - INFO - Validation Loss: 0.5275
2024-03-28 23:07:33,562 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:33,612 - config - INFO - Epoch [131/260], Train Loss: 0.3906
2024-03-28 23:07:33,613 - config - INFO - Validation Loss: 0.5267
2024-03-28 23:07:33,613 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:33,663 - config - INFO - Epoch [132/260], Train Loss: 0.3907
2024-03-28 23:07:33,665 - config - INFO - Validation Loss: 0.5258
2024-03-28 23:07:33,665 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:33,715 - config - INFO - Epoch [133/260], Train Loss: 0.3906
2024-03-28 23:07:33,716 - config - INFO - Validation Loss: 0.5268
2024-03-28 23:07:33,717 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:33,766 - config - INFO - Epoch [134/260], Train Loss: 0.3901
2024-03-28 23:07:33,768 - config - INFO - Validation Loss: 0.5272
2024-03-28 23:07:33,768 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:33,817 - config - INFO - Epoch [135/260], Train Loss: 0.3899
2024-03-28 23:07:33,819 - config - INFO - Validation Loss: 0.5266
2024-03-28 23:07:33,819 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:33,868 - config - INFO - Epoch [136/260], Train Loss: 0.3900
2024-03-28 23:07:33,870 - config - INFO - Validation Loss: 0.5253
2024-03-28 23:07:33,870 - config - INFO - Validation Acc: 0.7500
2024-03-28 23:07:33,920 - config - INFO - Epoch [137/260], Train Loss: 0.3901
2024-03-28 23:07:33,921 - config - INFO - Validation Loss: 0.5284
2024-03-28 23:07:33,921 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:33,971 - config - INFO - Epoch [138/260], Train Loss: 0.3893
2024-03-28 23:07:33,972 - config - INFO - Validation Loss: 0.5259
2024-03-28 23:07:33,973 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:34,022 - config - INFO - Epoch [139/260], Train Loss: 0.3896
2024-03-28 23:07:34,024 - config - INFO - Validation Loss: 0.5269
2024-03-28 23:07:34,024 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:34,073 - config - INFO - Epoch [140/260], Train Loss: 0.3890
2024-03-28 23:07:34,075 - config - INFO - Validation Loss: 0.5255
2024-03-28 23:07:34,075 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:34,125 - config - INFO - Epoch [141/260], Train Loss: 0.3890
2024-03-28 23:07:34,126 - config - INFO - Validation Loss: 0.5263
2024-03-28 23:07:34,127 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:34,176 - config - INFO - Epoch [142/260], Train Loss: 0.3892
2024-03-28 23:07:34,178 - config - INFO - Validation Loss: 0.5248
2024-03-28 23:07:34,178 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:34,227 - config - INFO - Epoch [143/260], Train Loss: 0.3887
2024-03-28 23:07:34,229 - config - INFO - Validation Loss: 0.5260
2024-03-28 23:07:34,229 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:34,279 - config - INFO - Epoch [144/260], Train Loss: 0.3886
2024-03-28 23:07:34,280 - config - INFO - Validation Loss: 0.5271
2024-03-28 23:07:34,280 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:34,330 - config - INFO - Epoch [145/260], Train Loss: 0.3883
2024-03-28 23:07:34,332 - config - INFO - Validation Loss: 0.5254
2024-03-28 23:07:34,332 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:34,381 - config - INFO - Epoch [146/260], Train Loss: 0.3882
2024-03-28 23:07:34,383 - config - INFO - Validation Loss: 0.5258
2024-03-28 23:07:34,383 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:34,433 - config - INFO - Epoch [147/260], Train Loss: 0.3880
2024-03-28 23:07:34,434 - config - INFO - Validation Loss: 0.5262
2024-03-28 23:07:34,434 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:34,484 - config - INFO - Epoch [148/260], Train Loss: 0.3878
2024-03-28 23:07:34,486 - config - INFO - Validation Loss: 0.5260
2024-03-28 23:07:34,486 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:34,537 - config - INFO - Epoch [149/260], Train Loss: 0.3877
2024-03-28 23:07:34,539 - config - INFO - Validation Loss: 0.5264
2024-03-28 23:07:34,548 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:34,604 - config - INFO - Epoch [150/260], Train Loss: 0.3876
2024-03-28 23:07:34,605 - config - INFO - Validation Loss: 0.5259
2024-03-28 23:07:34,606 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:34,655 - config - INFO - Epoch [151/260], Train Loss: 0.3873
2024-03-28 23:07:34,657 - config - INFO - Validation Loss: 0.5259
2024-03-28 23:07:34,657 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:34,707 - config - INFO - Epoch [152/260], Train Loss: 0.3872
2024-03-28 23:07:34,708 - config - INFO - Validation Loss: 0.5246
2024-03-28 23:07:34,709 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:34,758 - config - INFO - Epoch [153/260], Train Loss: 0.3872
2024-03-28 23:07:34,760 - config - INFO - Validation Loss: 0.5259
2024-03-28 23:07:34,760 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:34,810 - config - INFO - Epoch [154/260], Train Loss: 0.3869
2024-03-28 23:07:34,811 - config - INFO - Validation Loss: 0.5253
2024-03-28 23:07:34,812 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:34,861 - config - INFO - Epoch [155/260], Train Loss: 0.3870
2024-03-28 23:07:34,863 - config - INFO - Validation Loss: 0.5240
2024-03-28 23:07:34,863 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:34,912 - config - INFO - Epoch [156/260], Train Loss: 0.3869
2024-03-28 23:07:34,914 - config - INFO - Validation Loss: 0.5263
2024-03-28 23:07:34,914 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:34,964 - config - INFO - Epoch [157/260], Train Loss: 0.3869
2024-03-28 23:07:34,965 - config - INFO - Validation Loss: 0.5235
2024-03-28 23:07:34,966 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:35,015 - config - INFO - Epoch [158/260], Train Loss: 0.3866
2024-03-28 23:07:35,017 - config - INFO - Validation Loss: 0.5266
2024-03-28 23:07:35,017 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:35,066 - config - INFO - Epoch [159/260], Train Loss: 0.3864
2024-03-28 23:07:35,068 - config - INFO - Validation Loss: 0.5244
2024-03-28 23:07:35,068 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:35,118 - config - INFO - Epoch [160/260], Train Loss: 0.3861
2024-03-28 23:07:35,119 - config - INFO - Validation Loss: 0.5253
2024-03-28 23:07:35,119 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:35,169 - config - INFO - Epoch [161/260], Train Loss: 0.3861
2024-03-28 23:07:35,171 - config - INFO - Validation Loss: 0.5239
2024-03-28 23:07:35,171 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:35,220 - config - INFO - Epoch [162/260], Train Loss: 0.3860
2024-03-28 23:07:35,222 - config - INFO - Validation Loss: 0.5245
2024-03-28 23:07:35,222 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:35,272 - config - INFO - Epoch [163/260], Train Loss: 0.3858
2024-03-28 23:07:35,273 - config - INFO - Validation Loss: 0.5247
2024-03-28 23:07:35,274 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:35,323 - config - INFO - Epoch [164/260], Train Loss: 0.3858
2024-03-28 23:07:35,325 - config - INFO - Validation Loss: 0.5256
2024-03-28 23:07:35,325 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:35,374 - config - INFO - Epoch [165/260], Train Loss: 0.3856
2024-03-28 23:07:35,376 - config - INFO - Validation Loss: 0.5253
2024-03-28 23:07:35,376 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:35,425 - config - INFO - Epoch [166/260], Train Loss: 0.3855
2024-03-28 23:07:35,427 - config - INFO - Validation Loss: 0.5246
2024-03-28 23:07:35,427 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:35,477 - config - INFO - Epoch [167/260], Train Loss: 0.3852
2024-03-28 23:07:35,478 - config - INFO - Validation Loss: 0.5247
2024-03-28 23:07:35,478 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:35,528 - config - INFO - Epoch [168/260], Train Loss: 0.3853
2024-03-28 23:07:35,530 - config - INFO - Validation Loss: 0.5241
2024-03-28 23:07:35,530 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:35,579 - config - INFO - Epoch [169/260], Train Loss: 0.3851
2024-03-28 23:07:35,581 - config - INFO - Validation Loss: 0.5231
2024-03-28 23:07:35,581 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:35,631 - config - INFO - Epoch [170/260], Train Loss: 0.3847
2024-03-28 23:07:35,632 - config - INFO - Validation Loss: 0.5233
2024-03-28 23:07:35,632 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:35,682 - config - INFO - Epoch [171/260], Train Loss: 0.3847
2024-03-28 23:07:35,684 - config - INFO - Validation Loss: 0.5241
2024-03-28 23:07:35,684 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:35,734 - config - INFO - Epoch [172/260], Train Loss: 0.3846
2024-03-28 23:07:35,735 - config - INFO - Validation Loss: 0.5243
2024-03-28 23:07:35,736 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:35,785 - config - INFO - Epoch [173/260], Train Loss: 0.3845
2024-03-28 23:07:35,787 - config - INFO - Validation Loss: 0.5231
2024-03-28 23:07:35,787 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:35,836 - config - INFO - Epoch [174/260], Train Loss: 0.3845
2024-03-28 23:07:35,838 - config - INFO - Validation Loss: 0.5245
2024-03-28 23:07:35,838 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:35,888 - config - INFO - Epoch [175/260], Train Loss: 0.3843
2024-03-28 23:07:35,890 - config - INFO - Validation Loss: 0.5216
2024-03-28 23:07:35,890 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:35,939 - config - INFO - Epoch [176/260], Train Loss: 0.3841
2024-03-28 23:07:35,941 - config - INFO - Validation Loss: 0.5227
2024-03-28 23:07:35,941 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:35,990 - config - INFO - Epoch [177/260], Train Loss: 0.3839
2024-03-28 23:07:35,992 - config - INFO - Validation Loss: 0.5238
2024-03-28 23:07:35,992 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:36,042 - config - INFO - Epoch [178/260], Train Loss: 0.3838
2024-03-28 23:07:36,043 - config - INFO - Validation Loss: 0.5229
2024-03-28 23:07:36,043 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:36,093 - config - INFO - Epoch [179/260], Train Loss: 0.3837
2024-03-28 23:07:36,095 - config - INFO - Validation Loss: 0.5220
2024-03-28 23:07:36,095 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:36,144 - config - INFO - Epoch [180/260], Train Loss: 0.3837
2024-03-28 23:07:36,146 - config - INFO - Validation Loss: 0.5226
2024-03-28 23:07:36,146 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:36,196 - config - INFO - Epoch [181/260], Train Loss: 0.3836
2024-03-28 23:07:36,197 - config - INFO - Validation Loss: 0.5218
2024-03-28 23:07:36,197 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:36,247 - config - INFO - Epoch [182/260], Train Loss: 0.3833
2024-03-28 23:07:36,248 - config - INFO - Validation Loss: 0.5236
2024-03-28 23:07:36,249 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:36,298 - config - INFO - Epoch [183/260], Train Loss: 0.3832
2024-03-28 23:07:36,300 - config - INFO - Validation Loss: 0.5224
2024-03-28 23:07:36,300 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:36,349 - config - INFO - Epoch [184/260], Train Loss: 0.3833
2024-03-28 23:07:36,351 - config - INFO - Validation Loss: 0.5237
2024-03-28 23:07:36,351 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:36,401 - config - INFO - Epoch [185/260], Train Loss: 0.3830
2024-03-28 23:07:36,402 - config - INFO - Validation Loss: 0.5223
2024-03-28 23:07:36,403 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:36,452 - config - INFO - Epoch [186/260], Train Loss: 0.3827
2024-03-28 23:07:36,454 - config - INFO - Validation Loss: 0.5231
2024-03-28 23:07:36,454 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:36,503 - config - INFO - Epoch [187/260], Train Loss: 0.3829
2024-03-28 23:07:36,505 - config - INFO - Validation Loss: 0.5214
2024-03-28 23:07:36,505 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:36,558 - config - INFO - Epoch [188/260], Train Loss: 0.3827
2024-03-28 23:07:36,560 - config - INFO - Validation Loss: 0.5233
2024-03-28 23:07:36,560 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:36,609 - config - INFO - Epoch [189/260], Train Loss: 0.3826
2024-03-28 23:07:36,611 - config - INFO - Validation Loss: 0.5237
2024-03-28 23:07:36,611 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:36,661 - config - INFO - Epoch [190/260], Train Loss: 0.3823
2024-03-28 23:07:36,662 - config - INFO - Validation Loss: 0.5239
2024-03-28 23:07:36,663 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:36,712 - config - INFO - Epoch [191/260], Train Loss: 0.3824
2024-03-28 23:07:36,714 - config - INFO - Validation Loss: 0.5231
2024-03-28 23:07:36,714 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:36,763 - config - INFO - Epoch [192/260], Train Loss: 0.3821
2024-03-28 23:07:36,765 - config - INFO - Validation Loss: 0.5229
2024-03-28 23:07:36,765 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:36,815 - config - INFO - Epoch [193/260], Train Loss: 0.3821
2024-03-28 23:07:36,816 - config - INFO - Validation Loss: 0.5235
2024-03-28 23:07:36,816 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:36,866 - config - INFO - Epoch [194/260], Train Loss: 0.3820
2024-03-28 23:07:36,867 - config - INFO - Validation Loss: 0.5222
2024-03-28 23:07:36,868 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:36,917 - config - INFO - Epoch [195/260], Train Loss: 0.3819
2024-03-28 23:07:36,919 - config - INFO - Validation Loss: 0.5226
2024-03-28 23:07:36,919 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:36,968 - config - INFO - Epoch [196/260], Train Loss: 0.3816
2024-03-28 23:07:36,970 - config - INFO - Validation Loss: 0.5228
2024-03-28 23:07:36,970 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:37,020 - config - INFO - Epoch [197/260], Train Loss: 0.3816
2024-03-28 23:07:37,021 - config - INFO - Validation Loss: 0.5229
2024-03-28 23:07:37,022 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:37,071 - config - INFO - Epoch [198/260], Train Loss: 0.3814
2024-03-28 23:07:37,073 - config - INFO - Validation Loss: 0.5224
2024-03-28 23:07:37,073 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:37,122 - config - INFO - Epoch [199/260], Train Loss: 0.3814
2024-03-28 23:07:37,124 - config - INFO - Validation Loss: 0.5223
2024-03-28 23:07:37,124 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:37,173 - config - INFO - Epoch [200/260], Train Loss: 0.3813
2024-03-28 23:07:37,175 - config - INFO - Validation Loss: 0.5238
2024-03-28 23:07:37,175 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:37,225 - config - INFO - Epoch [201/260], Train Loss: 0.3810
2024-03-28 23:07:37,226 - config - INFO - Validation Loss: 0.5231
2024-03-28 23:07:37,227 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:37,276 - config - INFO - Epoch [202/260], Train Loss: 0.3809
2024-03-28 23:07:37,278 - config - INFO - Validation Loss: 0.5217
2024-03-28 23:07:37,278 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:37,328 - config - INFO - Epoch [203/260], Train Loss: 0.3809
2024-03-28 23:07:37,329 - config - INFO - Validation Loss: 0.5216
2024-03-28 23:07:37,330 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:37,379 - config - INFO - Epoch [204/260], Train Loss: 0.3809
2024-03-28 23:07:37,381 - config - INFO - Validation Loss: 0.5206
2024-03-28 23:07:37,381 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:37,430 - config - INFO - Epoch [205/260], Train Loss: 0.3807
2024-03-28 23:07:37,432 - config - INFO - Validation Loss: 0.5216
2024-03-28 23:07:37,432 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:37,482 - config - INFO - Epoch [206/260], Train Loss: 0.3806
2024-03-28 23:07:37,483 - config - INFO - Validation Loss: 0.5202
2024-03-28 23:07:37,484 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:37,533 - config - INFO - Epoch [207/260], Train Loss: 0.3811
2024-03-28 23:07:37,535 - config - INFO - Validation Loss: 0.5228
2024-03-28 23:07:37,535 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:37,585 - config - INFO - Epoch [208/260], Train Loss: 0.3807
2024-03-28 23:07:37,586 - config - INFO - Validation Loss: 0.5194
2024-03-28 23:07:37,586 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:37,636 - config - INFO - Epoch [209/260], Train Loss: 0.3804
2024-03-28 23:07:37,637 - config - INFO - Validation Loss: 0.5199
2024-03-28 23:07:37,638 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:37,687 - config - INFO - Epoch [210/260], Train Loss: 0.3803
2024-03-28 23:07:37,689 - config - INFO - Validation Loss: 0.5213
2024-03-28 23:07:37,689 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:37,739 - config - INFO - Epoch [211/260], Train Loss: 0.3801
2024-03-28 23:07:37,741 - config - INFO - Validation Loss: 0.5187
2024-03-28 23:07:37,741 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:37,791 - config - INFO - Epoch [212/260], Train Loss: 0.3801
2024-03-28 23:07:37,792 - config - INFO - Validation Loss: 0.5191
2024-03-28 23:07:37,792 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:37,842 - config - INFO - Epoch [213/260], Train Loss: 0.3798
2024-03-28 23:07:37,844 - config - INFO - Validation Loss: 0.5197
2024-03-28 23:07:37,844 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:37,893 - config - INFO - Epoch [214/260], Train Loss: 0.3797
2024-03-28 23:07:37,895 - config - INFO - Validation Loss: 0.5185
2024-03-28 23:07:37,895 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:37,945 - config - INFO - Epoch [215/260], Train Loss: 0.3797
2024-03-28 23:07:37,946 - config - INFO - Validation Loss: 0.5199
2024-03-28 23:07:37,946 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:37,996 - config - INFO - Epoch [216/260], Train Loss: 0.3797
2024-03-28 23:07:37,998 - config - INFO - Validation Loss: 0.5194
2024-03-28 23:07:37,998 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:38,047 - config - INFO - Epoch [217/260], Train Loss: 0.3801
2024-03-28 23:07:38,049 - config - INFO - Validation Loss: 0.5234
2024-03-28 23:07:38,049 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:38,099 - config - INFO - Epoch [218/260], Train Loss: 0.3795
2024-03-28 23:07:38,100 - config - INFO - Validation Loss: 0.5202
2024-03-28 23:07:38,100 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:38,150 - config - INFO - Epoch [219/260], Train Loss: 0.3791
2024-03-28 23:07:38,152 - config - INFO - Validation Loss: 0.5209
2024-03-28 23:07:38,152 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:38,201 - config - INFO - Epoch [220/260], Train Loss: 0.3791
2024-03-28 23:07:38,203 - config - INFO - Validation Loss: 0.5209
2024-03-28 23:07:38,203 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:38,253 - config - INFO - Epoch [221/260], Train Loss: 0.3790
2024-03-28 23:07:38,254 - config - INFO - Validation Loss: 0.5203
2024-03-28 23:07:38,254 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:38,304 - config - INFO - Epoch [222/260], Train Loss: 0.3788
2024-03-28 23:07:38,305 - config - INFO - Validation Loss: 0.5213
2024-03-28 23:07:38,306 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:38,355 - config - INFO - Epoch [223/260], Train Loss: 0.3788
2024-03-28 23:07:38,357 - config - INFO - Validation Loss: 0.5200
2024-03-28 23:07:38,357 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:38,406 - config - INFO - Epoch [224/260], Train Loss: 0.3787
2024-03-28 23:07:38,408 - config - INFO - Validation Loss: 0.5203
2024-03-28 23:07:38,408 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:38,458 - config - INFO - Epoch [225/260], Train Loss: 0.3786
2024-03-28 23:07:38,459 - config - INFO - Validation Loss: 0.5210
2024-03-28 23:07:38,460 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:38,509 - config - INFO - Epoch [226/260], Train Loss: 0.3785
2024-03-28 23:07:38,511 - config - INFO - Validation Loss: 0.5186
2024-03-28 23:07:38,511 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:38,566 - config - INFO - Epoch [227/260], Train Loss: 0.3784
2024-03-28 23:07:38,568 - config - INFO - Validation Loss: 0.5204
2024-03-28 23:07:38,568 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:38,618 - config - INFO - Epoch [228/260], Train Loss: 0.3782
2024-03-28 23:07:38,619 - config - INFO - Validation Loss: 0.5205
2024-03-28 23:07:38,620 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:38,669 - config - INFO - Epoch [229/260], Train Loss: 0.3782
2024-03-28 23:07:38,671 - config - INFO - Validation Loss: 0.5199
2024-03-28 23:07:38,671 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:38,720 - config - INFO - Epoch [230/260], Train Loss: 0.3781
2024-03-28 23:07:38,722 - config - INFO - Validation Loss: 0.5214
2024-03-28 23:07:38,722 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:38,772 - config - INFO - Epoch [231/260], Train Loss: 0.3781
2024-03-28 23:07:38,773 - config - INFO - Validation Loss: 0.5224
2024-03-28 23:07:38,774 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:38,823 - config - INFO - Epoch [232/260], Train Loss: 0.3778
2024-03-28 23:07:38,825 - config - INFO - Validation Loss: 0.5209
2024-03-28 23:07:38,825 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:38,875 - config - INFO - Epoch [233/260], Train Loss: 0.3778
2024-03-28 23:07:38,876 - config - INFO - Validation Loss: 0.5205
2024-03-28 23:07:38,876 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:38,926 - config - INFO - Epoch [234/260], Train Loss: 0.3778
2024-03-28 23:07:38,927 - config - INFO - Validation Loss: 0.5218
2024-03-28 23:07:38,928 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:38,977 - config - INFO - Epoch [235/260], Train Loss: 0.3775
2024-03-28 23:07:38,979 - config - INFO - Validation Loss: 0.5200
2024-03-28 23:07:38,979 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:39,029 - config - INFO - Epoch [236/260], Train Loss: 0.3774
2024-03-28 23:07:39,030 - config - INFO - Validation Loss: 0.5198
2024-03-28 23:07:39,030 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:39,080 - config - INFO - Epoch [237/260], Train Loss: 0.3774
2024-03-28 23:07:39,082 - config - INFO - Validation Loss: 0.5180
2024-03-28 23:07:39,082 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:39,131 - config - INFO - Epoch [238/260], Train Loss: 0.3772
2024-03-28 23:07:39,133 - config - INFO - Validation Loss: 0.5178
2024-03-28 23:07:39,133 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:39,183 - config - INFO - Epoch [239/260], Train Loss: 0.3774
2024-03-28 23:07:39,184 - config - INFO - Validation Loss: 0.5200
2024-03-28 23:07:39,184 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:39,234 - config - INFO - Epoch [240/260], Train Loss: 0.3772
2024-03-28 23:07:39,236 - config - INFO - Validation Loss: 0.5200
2024-03-28 23:07:39,236 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:39,286 - config - INFO - Epoch [241/260], Train Loss: 0.3770
2024-03-28 23:07:39,287 - config - INFO - Validation Loss: 0.5204
2024-03-28 23:07:39,287 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:39,337 - config - INFO - Epoch [242/260], Train Loss: 0.3768
2024-03-28 23:07:39,338 - config - INFO - Validation Loss: 0.5199
2024-03-28 23:07:39,339 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:39,388 - config - INFO - Epoch [243/260], Train Loss: 0.3768
2024-03-28 23:07:39,390 - config - INFO - Validation Loss: 0.5193
2024-03-28 23:07:39,390 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:39,440 - config - INFO - Epoch [244/260], Train Loss: 0.3767
2024-03-28 23:07:39,441 - config - INFO - Validation Loss: 0.5191
2024-03-28 23:07:39,441 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:39,491 - config - INFO - Epoch [245/260], Train Loss: 0.3767
2024-03-28 23:07:39,492 - config - INFO - Validation Loss: 0.5192
2024-03-28 23:07:39,493 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:39,542 - config - INFO - Epoch [246/260], Train Loss: 0.3766
2024-03-28 23:07:39,544 - config - INFO - Validation Loss: 0.5195
2024-03-28 23:07:39,552 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:39,606 - config - INFO - Epoch [247/260], Train Loss: 0.3764
2024-03-28 23:07:39,608 - config - INFO - Validation Loss: 0.5196
2024-03-28 23:07:39,608 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:39,658 - config - INFO - Epoch [248/260], Train Loss: 0.3763
2024-03-28 23:07:39,659 - config - INFO - Validation Loss: 0.5197
2024-03-28 23:07:39,660 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:39,709 - config - INFO - Epoch [249/260], Train Loss: 0.3763
2024-03-28 23:07:39,711 - config - INFO - Validation Loss: 0.5202
2024-03-28 23:07:39,711 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:39,761 - config - INFO - Epoch [250/260], Train Loss: 0.3762
2024-03-28 23:07:39,763 - config - INFO - Validation Loss: 0.5212
2024-03-28 23:07:39,763 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:39,812 - config - INFO - Epoch [251/260], Train Loss: 0.3759
2024-03-28 23:07:39,814 - config - INFO - Validation Loss: 0.5198
2024-03-28 23:07:39,814 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:39,864 - config - INFO - Epoch [252/260], Train Loss: 0.3761
2024-03-28 23:07:39,865 - config - INFO - Validation Loss: 0.5196
2024-03-28 23:07:39,865 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:39,915 - config - INFO - Epoch [253/260], Train Loss: 0.3760
2024-03-28 23:07:39,917 - config - INFO - Validation Loss: 0.5200
2024-03-28 23:07:39,917 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:39,966 - config - INFO - Epoch [254/260], Train Loss: 0.3758
2024-03-28 23:07:39,968 - config - INFO - Validation Loss: 0.5190
2024-03-28 23:07:39,968 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:40,018 - config - INFO - Epoch [255/260], Train Loss: 0.3757
2024-03-28 23:07:40,019 - config - INFO - Validation Loss: 0.5205
2024-03-28 23:07:40,019 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:40,069 - config - INFO - Epoch [256/260], Train Loss: 0.3756
2024-03-28 23:07:40,071 - config - INFO - Validation Loss: 0.5197
2024-03-28 23:07:40,071 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:40,120 - config - INFO - Epoch [257/260], Train Loss: 0.3755
2024-03-28 23:07:40,122 - config - INFO - Validation Loss: 0.5193
2024-03-28 23:07:40,122 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:40,172 - config - INFO - Epoch [258/260], Train Loss: 0.3754
2024-03-28 23:07:40,173 - config - INFO - Validation Loss: 0.5183
2024-03-28 23:07:40,173 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:40,223 - config - INFO - Epoch [259/260], Train Loss: 0.3755
2024-03-28 23:07:40,225 - config - INFO - Validation Loss: 0.5197
2024-03-28 23:07:40,225 - config - INFO - Validation Acc: 0.8333
2024-03-28 23:07:40,274 - config - INFO - Epoch [260/260], Train Loss: 0.3753
2024-03-28 23:07:40,276 - config - INFO - Validation Loss: 0.5178
2024-03-28 23:07:40,276 - config - INFO - Validation Acc: 0.8333
